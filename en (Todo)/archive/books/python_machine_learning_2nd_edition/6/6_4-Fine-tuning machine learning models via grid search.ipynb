{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4. Fine-tuning machine learning models via grid search\n",
    "\n",
    "## Comment\n",
    "This section is about grid search. Grid search is a basic, but powerful hyperparameter tuning method which evalutes all the given hyperparameters. The drawback is it requires a lot of computational power because it performs an exaustive search.\n",
    "* from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "For details, refer to [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "An alternative method is Randomized Search which randomly selects a combination of the provided hyperparameters within the contrainst.\n",
    "* from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "For details, refer to [sklearn.model_selection.RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "\n",
    "## Sources:\n",
    "New part\n",
    "* [Fine-tuning machine learning models via grid search](https://render.githubusercontent.com/view/ipynb?commit=1b01e733d15a1808ebdb0e07e46dbb9cb1634323&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f72617362742f707974686f6e2d6d616368696e652d6c6561726e696e672d626f6f6b2d326e642d65646974696f6e2f316230316537333364313561313830386562646230653037653436646262396362313633343332332f636f64652f636830362f636830362e6970796e62&nwo=rasbt%2Fpython-machine-learning-book-2nd-edition&path=code%2Fch06%2Fch06.ipynb&repository_id=81413897&repository_type=Repository#Fine-tuning-machine-learning-models-via-grid-search)\n",
    "\n",
    "Related parts\n",
    "* [Debugging algorithms with learning and validation curves](https://render.githubusercontent.com/view/ipynb?commit=1b01e733d15a1808ebdb0e07e46dbb9cb1634323&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f72617362742f707974686f6e2d6d616368696e652d6c6561726e696e672d626f6f6b2d326e642d65646974696f6e2f316230316537333364313561313830386562646230653037653436646262396362313633343332332f636f64652f636830362f636830362e6970796e62&nwo=rasbt%2Fpython-machine-learning-book-2nd-edition&path=code%2Fch06%2Fch06.ipynb&repository_id=81413897&repository_type=Repository#Debugging-algorithms-with-learning-and-validation-curves)\n",
    "* [Streamlining workflows with pipelines](https://render.githubusercontent.com/view/ipynb?commit=1b01e733d15a1808ebdb0e07e46dbb9cb1634323&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f72617362742f707974686f6e2d6d616368696e652d6c6561726e696e672d626f6f6b2d326e642d65646974696f6e2f316230316537333364313561313830386562646230653037653436646262396362313633343332332f636f64652f636830362f636830362e6970796e62&nwo=rasbt%2Fpython-machine-learning-book-2nd-edition&path=code%2Fch06%2Fch06.ipynb&repository_id=81413897&repository_type=Repository#Streamlining-workflows-with-pipelines)\n",
    "* [Using k-fold cross-validation to assess model performance](https://render.githubusercontent.com/view/ipynb?commit=1b01e733d15a1808ebdb0e07e46dbb9cb1634323&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f72617362742f707974686f6e2d6d616368696e652d6c6561726e696e672d626f6f6b2d326e642d65646974696f6e2f316230316537333364313561313830386562646230653037653436646262396362313633343332332f636f64652f636830362f636830362e6970796e62&nwo=rasbt%2Fpython-machine-learning-book-2nd-edition&path=code%2Fch06%2Fch06.ipynb&repository_id=81413897&repository_type=Repository#Using-k-fold-cross-validation-to-assess-model-performance)\n",
    "\n",
    "## Summary\n",
    "### Part 1: Tuning hyperparameters via grid search\n",
    "There are two types of parameters related to a model:\n",
    "* model's weights\n",
    "* hyperparameters to control model, e.g. C of LogisticRegression, depth of Decision Tree\n",
    "\n",
    "Grid search is an exhaustive search method for the given hyperparameters\n",
    "\n",
    "## Part 2: Algorithm selection with nested cross-validation\n",
    "* Nested Cross-Validation Method\n",
    "* Example of 5-2 Cross validation: \n",
    "\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tuning hyperparameters via grid search\n",
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch the dataset\n",
    "url2breast_cancer_wisconsin_dataset='https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
    "url2dataset = url2breast_cancer_wisconsin_dataset\n",
    "df = pd.read_csv( url2dataset, header=None )\n",
    "\n",
    "# Get the actual data & label from the dataset\n",
    "X = df.loc[:, 2:].values  # actual data\n",
    "y = df.loc[:, 1].values   # label\n",
    "\n",
    "# Encode B to 0 and M to 1\n",
    "le = LabelEncoder()\n",
    "y  = le.fit_transform(y)\n",
    "\n",
    "# Split the dataset to train & test data\n",
    "test_over_train_ratio = 0.2\n",
    "random_seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=test_over_train_ratio, stratify=y, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC  # Support Vector Machine, Support Vector Classifier\n",
    "\n",
    "pipe_svc = make_pipeline( StandardScaler(), SVC(random_state=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]  # I added 10000.0\n",
    "param_grid = [{'svc__C': param_range, 'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, 'svc__kernel': ['rbf'], 'svc__gamma': param_range}\n",
    "             ]\n",
    "gs = GridSearchCV( estimator=pipe_svc,\n",
    "                   param_grid=param_grid,\n",
    "                   scoring='accuracy',\n",
    "                   cv=10,\n",
    "                   n_jobs=-1\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gs.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9846153846153847 {'svc__C': 100.0, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print( gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Best Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.974\n"
     ]
    }
   ],
   "source": [
    "# Fetch the hyperparameters for the best model\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "# Train the best model\n",
    "clf.fit( X_train, y_train )\n",
    "test_accuracy = clf.score( X_test, y_test )\n",
    "print( 'Test Accuracy %.3f' % test_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Algorithm selection with nested cross-validation\n",
    "Let's compare accuracy of two algorithms: SVM and Decision Tree.\n",
    "\n",
    "### SVC (Support Vector Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy 0.974 +/- 0.015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "gs = GridSearchCV( estimator=pipe_svc,\n",
    "                   param_grid=param_grid,\n",
    "                   scoring='accuracy',\n",
    "                   cv=2  # Cross-validation k-fold k=2\n",
    "                 )\n",
    "accuracy_scores = cross_val_score( gs,\n",
    "                                   X_train, y_train,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=5)\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print( 'Cross-Validation Accuracy %.3f +/- %.3f' % (mean_accuracy, std_accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy 0.934 +/- 0.016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = [ {'max_depth':[1,2,3,4,5,6,7,None]} ]\n",
    "gs = GridSearchCV( estimator=DecisionTreeClassifier(random_state=0),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring='accuracy',\n",
    "                 cv=2\n",
    "                 )\n",
    "accuracy_scores = cross_val_score( gs, X_train, y_train, scoring='accuracy', cv=5 )\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print( 'Cross-Validation Accuracy %.3f +/- %.3f' % (mean_accuracy, std_accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC > Decision Tree by 0.04\n",
    "The accuracies of SVM and Decision Tree are:\n",
    "* mean: 0.974 and 0.934\n",
    "* standard deviation: 0.015 and 0.016\n",
    "\n",
    "So SVM is a better choice than Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(EOF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
