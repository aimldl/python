,original,google_translate,,
0,"





Kubeflow for Machine Learning


Kubeflow for Machine Learning
by Trevor  Grant, Holden  Karau, Boris  Lublinsky, Richard  Liu, and Ilan  Filonenko
Copyright © 2021 Trevor Grant, Holden Karau, Boris Lublinsky, Richard Liu, and Ilan Filonenko.","기계 학습용 Kubeflow


기계 학습용 Kubeflow
작성자 : Trevor Grant, Holden Karau, Boris Lublinsky, Richard Liu, Ilan Filonenko
Copyright © 2021 Trevor Grant, Holden Karau, Boris Lublinsky, Richard Liu 및 Ilan Filonenko.",,
1,All rights reserved.,판권 소유.,,
2,Printed in the United States of America.,미국에서 인쇄 됨.,,
3,"Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.","O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472에서 발행했습니다.",,
4,"O’Reilly books may be purchased for educational, business, or sales promotional use.","O’Reilly 도서는 교육, 비즈니스 또는 판촉 용으로 구매할 수 있습니다.",,
5,Online editions are also available for most titles (http://oreilly.com).,대부분의 타이틀 (http://oreilly.com)에 대한 온라인 버전도 제공됩니다.,,
6,"For more information, contact our corporate/institutional sales department: 800-998-9938 or corporate@oreilly.com.",자세한 내용은 회사 / 기관 영업 부서 (800-998-9938 또는 corporate@oreilly.com)에 문의하십시오.,,
7,"Acquisitions Editor: Jonathan Hassell
Development Editor: Amelia Blevins
Production Editor: Deborah Baker
Copyeditor: JM Olejarz
Proofreader: Justin Billing
Indexer: Sue Klefstad
Interior Designer: David Futato
Cover Designer: Karen Montgomery
Illustrator: Kate Dullea


November 2020: First Edition



Revision History for the First Edition

2020-10-12: First Release


See http://oreilly.com/catalog/errata.csp?isbn=9781492050124 for release details.","인수 편집자 : Jonathan Hassell
개발 편집자 : Amelia Blevins
프로덕션 편집자 : Deborah Baker
카피 에디터 : JM Olejarz
교정자 : Justin Billing
인덱서 : Sue Klefstad
인테리어 디자이너 : David Futato
표지 디자이너 : Karen Montgomery
일러스트 레이터 : Kate Dullea


2020 년 11 월 : 초판



초판의 개정 내역

2020-10-12 : 첫 번째 릴리스


릴리스에 대한 자세한 내용은 http://oreilly.com/catalog/errata.csp?isbn=9781492050124를 참조하십시오.",,
8,"The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Kubeflow for Machine Learning, the cover image, and related trade dress are trademarks of O’Reilly Media, Inc.","O’Reilly 로고는 O’Reilly Media, Inc.의 등록 상표입니다. 기계 학습용 Kubeflow, 표지 이미지 및 관련 트레이드 드레스는 O’Reilly Media, Inc.의 상표입니다.",,
9,"The views expressed in this work are those of the authors, and do not represent the publisher’s views.",이 작품에 표현 된 견해는 저자의 견해이며 출판사의 견해를 나타내지 않습니다.,,
10,"While the publisher and the authors have used good faith efforts to ensure that the information and instructions contained in this work are accurate, the publisher and the authors disclaim all responsibility for errors or omissions, including without limitation responsibility for damages resulting from the use of or reliance on this work.","발행인과 저자는이 저작물에 포함 된 정보와 지침이 정확한지 확인하기 위해 성실하게 노력했지만, 발행인과 저자는 오류 또는 누락에 대한 모든 책임을지지 않습니다.이 작업에 대한 의존.",,
11,Use of the information and instructions contained in this work is at your own risk.,이 작업에 포함 된 정보 및 지침의 사용은 귀하의 책임입니다.,,
12,"If any code samples or other technology this work contains or describes is subject to open source licenses or the intellectual property rights of others, it is your responsibility to ensure that your use thereof complies with such licenses and/or rights.","이 저작물에 포함되거나 설명하는 코드 샘플 또는 기타 기술이 오픈 소스 라이선스 또는 타인의 지적 재산권의 적용을받는 경우, 해당 사용이 해당 라이선스 및 / 또는 권리를 준수하는지 확인하는 것은 귀하의 책임입니다.",,
13,"978-1-492-05012-4
[LSI]



Foreword
Occasionally over the years people will ask me what skills are most in demand in tech.","978-1-492-05012-4
[LSI]



머리말
때때로 사람들은 기술 분야에서 가장 필요한 기술이 무엇인지 물어볼 것입니다.",,
14,"Ten years ago I would tell them to study machine learning, which can scale automated decision making in ways previously impossible.",10 년 전에 저는 그들에게 이전에는 불가능했던 방식으로 자동화 된 의사 결정을 확장 할 수있는 머신 러닝을 연구하라고 말했었습니다.,,
15,"However, these days I have a different answer: machine learning engineering.",하지만 요즘에는 다른 답이 있습니다. 바로 기계 학습 공학입니다.,,
16,"Even just a few years ago if you knew machine learning and started at an organization, you would likely walk in the door as the only person with that skill set, allowing you to have an outsized impact.",불과 몇 년 전만해도 기계 학습을 알고 조직에서 시작했다면 해당 기술을 보유한 유일한 사람으로 문에 들어 서면 엄청난 영향을 미칠 수 있습니다.,,
17,"However, a side effect of the proliferation of books, tutorials, e-courses, and boot camps (some of which I have written myself) teaching an entire generation of technologists the skills required is that now machine learning is being used across tens of thousands of companies and organizations.","그러나 전 세대의 기술자에게 필요한 기술을 가르치는 책, 튜토리얼, e- 코스 및 부트 캠프 (일부는 직접 작성)의 확산으로 인한 부작용은 이제 기계 학습이 수만 명에 걸쳐 사용되고 있다는 것입니다.회사와 조직의.",,
18,"These days a more likely scenario is that, walking into your new job, you find an organization using machine learning locally but unable to deploy it to production or able to deploy models but unable to manage them effectively.",요즘 더 가능성이 높은 시나리오는 새로운 작업에 들어가서 기계 학습을 로컬에서 사용하지만 프로덕션에 배포 할 수 없거나 모델을 배포 할 수는 있지만 효과적으로 관리 할 수없는 조직을 발견하는 것입니다.,,
19,"In this setting, the most valuable skill is not being able to train a model, but rather to manage all those models and deploy them in ways that maximize their impact.",이 설정에서 가장 가치있는 기술은 모델을 교육 할 수있는 것이 아니라 모든 모델을 관리하고 그 영향력을 극대화하는 방식으로 배포하는 것입니다.,,
20,"In this volume, Trevor Grant, Holden Karau, Boris Lublinsky, Richard Liu, and Ilan Filonenko have put together what I believe is an important cornerstone in the education of data scientists and machine learning engineers.","이 책에서는 Trevor Grant, Holden Karau, Boris Lublinsky, Richard Liu 및 Ilan Filonenko가 데이터 과학자 및 기계 학습 엔지니어 교육의 중요한 초석이라고 생각하는 내용을 정리했습니다.",,
21,"For the foreseeable future the open source Kubeflow project will be a common tool in an organization’s toolkit for training, management, and deployment of machine learning models.","가까운 미래에 오픈 소스 Kubeflow 프로젝트는 머신 러닝 모델의 교육, 관리 및 배포를위한 조직의 도구 키트에서 공통 도구가 될 것입니다.",,
22,"This book represents the codification of a lot of knowledge that previously existed scattered around internal documentation, conference presentations, and blog posts.","이 책은 이전에 내부 문서, 컨퍼런스 프레젠테이션 및 블로그 게시물에 흩어져 있던 많은 지식의 코드화를 나타냅니다.",,
23,"If you believe, as I do, that machine learning is only as powerful as how we use it, then this book is for you.",저처럼 기계 학습이 우리가 사용하는 방식만큼 강력하다고 믿는다면이 책은 당신을위한 것입니다.,,
24,"Chris Albon
Director of Machine Learning,
The Wikimedia Foundation
https://chrisalbon.com


Preface
We wrote this book for data engineers and data scientists who are building machine learning systems/models they want to move to production.","크리스 알본
기계 학습 이사,
위키 미디어 재단
https://chrisalbon.com


머리말
이 책은 프로덕션으로 이동하려는 머신 러닝 시스템 / 모델을 구축하는 데이터 엔지니어와 데이터 과학자를 위해 작성되었습니다.",,
25,"If you’ve ever had the experience of training an excellent model only to ask yourself how to deploy it into production or keep it up to date once it gets there, this is the book for you.",프로덕션에 배포하는 방법을 스스로 물어 보거나 모델이 도착한 후 최신 상태로 유지하는 방법으로 만 우수한 모델을 교육 한 경험이 있다면이 책이 적합합니다.,,
26,We hope this gives you the tools to replace Untitled_5.ipynb with something that works relatively reliably in production.,이것이 Untitled_5.ipynb를 프로덕션에서 비교적 안정적으로 작동하는 것으로 대체 할 수있는 도구를 제공하기를 바랍니다.,,
27,This book is not intended to serve as your first introduction to machine learning.,이 책은 기계 학습에 대한 첫 번째 소개로 제공되지 않습니다.,,
28,The next section points to some resources that may be useful if you are just getting started on your machine learning journey.,다음 섹션에서는 기계 학습 여정을 막 시작하는 경우 유용 할 수있는 몇 가지 리소스에 대해 설명합니다.,,
29,"Our Assumption About You
This book assumes that you either understand how to train models locally, or are working with someone who does.","당신에 대한 우리의 가정
이 책은 로컬에서 모델을 훈련하는 방법을 이해하고 있거나이를 수행하는 사람과 함께 작업하고 있다고 가정합니다.",,
30,"If neither is true, there are many excellent introductory books on machine learning to get you started, including Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, by Aurélien Géron (O’Reilly).","둘 다 사실이 아니라면 Aurélien Géron (O'Reilly)의 Scikit-Learn, Keras 및 TensorFlow 2nd Edition을 사용한 Hands-On Machine Learning을 포함하여 시작하는 데 도움이되는 기계 학습에 대한 훌륭한 입문 책이 많이 있습니다.",,
31,"Our goal is to teach you how to do machine learning in a repeatable way, and how to automate the training and deployment of your models.",우리의 목표는 반복 가능한 방식으로 기계 학습을 수행하는 방법과 모델의 학습 및 배포를 자동화하는 방법을 가르치는 것입니다.,,
32,"A serious problem here is that this goal includes a wide range of topics, and it is more than reasonable that you may not be intimately familiar with all of them.",여기서 심각한 문제는이 목표가 광범위한 주제를 포함하고 있으며 모든 주제에 대해 잘 알지 못하는 것이 합리적이라는 것입니다.,,
33,"Since we can’t delve deeply into every topic, we would like to provide you a short list of our favorite primers on several of the topics you will see covered here:

Python for Data Analysis, 2nd Edition, by Wes McKinney (O’Reilly)
Data Science from Scratch, 2nd Edition, by Joel Grus (O’Reilly)
Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido (O’Reilly)
Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, by Aurélien Géron (O’Reilly)
Kubernetes: Up and Running by Brendan Burns et al.","모든 주제를 깊이 파고들 수는 없으므로 여기에서 다룰 몇 가지 주제에 대한 우리가 가장 좋아하는 입문서의 짧은 목록을 제공하고자합니다.

Python for Data Analysis, 2nd Edition, by Wes McKinney (O’Reilly)
Data Science from Scratch, 2nd Edition, by Joel Grus (O’Reilly)
Andreas C. Müller와 Sarah Guido (O’Reilly)의 Python을 사용한 머신 러닝 소개
Aurélien Géron (O’Reilly)의 Scikit-Learn, Keras 및 TensorFlow 2nd Edition을 사용한 실습 머신 러닝
Kubernetes : Brendan Burns et al.",,
34,"(O’Reilly)
Learning Spark by Holden Karau et al.","(오라일리)
Holden Karau 외 학습 Spark",,
35,"(O’Reilly)
Feature Engineering for Machine Learning by Alice Zheng and Amanda Casari (O’Reilly)
Building Machine Learning Pipelines by Hannes Hapke and Catherine Nelson (O’Reilly)
Apache Mahout: Beyond MapReduce by Dmitriy Lyubimov and Andrew Palumbo (CreateSpace)
R Cookbook, 2nd Edition, by J. D. Long and Paul Teetor (O’Reilly)
Serving Machine Learning Models by Boris Lublinsky (O’Reilly)
“Continuous Delivery for Machine Learning” by Danilo Sato et al.","(오라일리)
기계 학습을위한 기능 엔지니어링 (Alice Zheng 및 Amanda Casari (O’Reilly))
Hannes Hapke 및 Catherine Nelson (O’Reilly)의 기계 학습 파이프 라인 구축
Apache Mahout : Beyond MapReduce, Dmitriy Lyubimov 및 Andrew Palumbo (CreateSpace)
R Cookbook, 2nd Edition, J. D. Long 및 Paul Teetor (O’Reilly)
Boris Lublinsky (O’Reilly)의 머신 러닝 모델 제공
Danilo Sato et al.의“기계 학습을위한 지속적인 제공”",,
36,"Interpretable Machine Learning by Christoph Molnar (self-published)
“A Gentle Introduction to Concept Drift in Machine Learning” by Jason Brownlee
“Model Drift and Ensuring a Healthy Machine Learning Lifecycle” by A. Besir Kurtulmus
“The Rise of the Model Servers” by Alex Vikati
“An Overview of Model Explainability in Modern Machine Learning” by Rui Aguiar
Machine Learning with Python Cookbook by Chris Albon (O’Reilly)
Machine Learning Flashcards by Chris Albon

Of course, there are many others, but those should get you started.","Christoph Molnar의 해석 가능한 기계 학습 (자체 게시)
Jason Brownlee의 ""머신 러닝의 개념 드리프트에 대한 부드러운 소개""
A. Besir Kurtulmus의 ""모델 드리프트 및 건강한 기계 학습 수명주기 보장""
Alex Vikati의“The Rise of the Model Servers”
Rui Aguiar의 ""현대 기계 학습의 모델 설명 가능성 개요""
Chris Albon (O’Reilly)의 Python Cookbook을 사용한 머신 러닝
Chris Albon의 기계 학습 플래시 카드

물론 다른 많은 것들이 있지만 시작해야합니다.",,
37,Please don’t be overwhelmed by this list—you certainly don’t need to be an expert in each of these topics to effectively deploy and manage Kubeflow.,이 목록에 압도 당하지 마십시오. Kubeflow를 효과적으로 배포하고 관리하기 위해 이러한 각 주제에 대한 전문가 일 필요는 없습니다.,,
38,"In fact, Kubeflow exists to streamline many of these tasks.","사실, Kubeflow는 이러한 많은 작업을 간소화하기 위해 존재합니다.",,
39,"However, there may be some topic into which you wish to delve deeper—and so this should be thought of as a “getting started” list.","그러나 더 깊이 탐구하고 싶은 주제가있을 수 있으므로 ""시작하기""목록으로 생각해야합니다.",,
40,"Containers and Kubernetes are a wide, rapidly evolving area of practice.",컨테이너와 Kubernetes는 광범위하고 빠르게 진화하는 실행 영역입니다.,,
41,"If you want to deepen your knowledge of Kubernetes we recommend looking at the following:

Cloud Native Infrastructure by Justin Garrison and Kris Nova (O’Reilly)
Kubernetes: Up and Running by Brendan Burns et al.","Kubernetes에 대한 지식을 심화하려면 다음을 살펴 보는 것이 좋습니다.

Justin Garrison 및 Kris Nova (O’Reilly)의 클라우드 네이티브 인프라
Kubernetes : Brendan Burns et al.",,
42,"(O’Reilly)



Your Responsibility as a Practitioner
This book helps you put your machine learning models into production to solve real-world problems.","(오라일리)



실무자로서의 책임
이 책은 기계 학습 모델을 프로덕션에 적용하여 실제 문제를 해결하는 데 도움이됩니다.",,
43,"Solving real-world problems with machine learning is great, but as you go forth and apply your skills, remember to think about the impact.",기계 학습으로 실제 문제를 해결하는 것은 좋지만 계속해서 기술을 적용 할 때 영향에 대해 생각하는 것을 잊지 마십시오.,,
44,"First, it’s important to make sure your models are sufficiently accurate, and there are great tools for this in Kubeflow, covered in SECTION 2.2.","첫째, 모델이 충분히 정확한지 확인하는 것이 중요하며, 섹션 2.2에서 다루는 Kubeflow에는이를위한 훌륭한 도구가 있습니다.",,
45,"Even the best tools will not save you from all mistakes—for example, hyperparameter tuning on the same dataset to report final cross-validation results.",최고의 도구라고하더라도 모든 실수를 방지 할 수는 없습니다. 예를 들어 동일한 데이터 세트에서 하이퍼 파라미터를 조정하여 최종 교차 검증 결과를보고합니다.,,
46,Even models with significant predictive power can have unintended effects and biases that may not show up during the regular training-evaluation phase.,상당한 예측력을 가진 모델조차도 정규 학습 평가 단계에서 나타나지 않을 수있는 의도하지 않은 효과와 편향을 가질 수 있습니다.,,
47,"Unintended biases can be hard to discover, but there are many stories (e.g., the Amazon machine learning–based recruiting engine that turned out to have intense biases and decided to hire only men) that demonstrate the profound potential implications of our work.","의도하지 않은 편견은 발견하기 어려울 수 있지만, 우리 작업의 심오한 잠재적 영향을 보여주는 많은 이야기 (예 : 강렬한 편견이있는 것으로 밝혀지고 남성 만 고용하기로 결정한 Amazon 기계 학습 기반 채용 엔진)이 있습니다.",,
48,"Failing to address these issues early on can lead to having to abandon your entire work, as demonstrated by IBM’s decision to stop its facial recognition program and similar pauses across the industry after the implications of racial bias in facial recognition in the hands of law enforcement became clear.",이러한 문제를 조기에 해결하지 못하면 얼굴 인식 프로그램을 중단하기로 한 IBM의 결정과 법 집행 기관의 얼굴 인식에 대한 인종적 편견이 영향을받은 후 업계 전반에 걸쳐 유사한 일시 중지를 통해 알 수 있듯이 전체 작업을 포기해야 할 수 있습니다.맑은.,,
49,"Even seemingly unbiased data, like raw purchase records, can turn out to have intense biases resulting in incorrect recommendations or worse.",원시 구매 기록과 같이 편향되지 않은 것처럼 보이는 데이터조차도 강렬한 편향으로 인해 잘못된 권장 사항을 초래하거나 더 나빠질 수 있습니다.,,
50,Just because a dataset is public and widely available does not mean it is unbiased.,데이터 세트가 공개되고 널리 사용 가능하다고해서 편견이없는 것은 아닙니다.,,
51,"The well-known practice of word embeddings has been shown to have many types of bias, including sexism, anti-LGBTQ, and anti-immigrant.","잘 알려진 단어 삽입 관행은 성 차별, 반 LGBTQ 및 반 이민자를 포함하여 많은 유형의 편견을 가지고있는 것으로 나타났습니다.",,
52,When looking at a new dataset it is crucial to look for examples of bias in your data and attempt to mitigate it as much as possible.,새 데이터 세트를 볼 때 데이터에서 편향의 예를 찾아 가능한 한 많이 완화하는 것이 중요합니다.,,
53,"With the most popular public datasets, various techniques are often discussed in the research, and you can use these to guide your own work.",가장 인기있는 공개 데이터 세트를 사용하여 다양한 기술이 연구에서 자주 논의되며이를 사용하여 자신의 작업을 안내 할 수 있습니다.,,
54,"While this book does not have the tools to solve bias, we encourage you to think critically about potential biases in your system and explore solutions before going into production.",이 책에는 편견을 해결할 수있는 도구가 없지만 시스템의 잠재적 편향에 대해 비판적으로 생각하고 프로덕션에 들어가기 전에 솔루션을 탐색하는 것이 좋습니다.,,
55,"If you don’t know where to start, check out Katharine Jarmul’s excellent introductory talk.",어디서부터 시작해야할지 모르겠다면 Katharine Jarmul의 훌륭한 입문 강연을 확인하세요.,,
56,IBM has a collection of tools and examples in its AI Fairness 360 open source toolkit that can be a great place to start your exploration.,IBM은 탐색을 시작하기에 좋은 장소가 될 수있는 AI Fairness 360 오픈 소스 툴킷에 도구 및 예제 모음을 보유하고 있습니다.,,
57,A critical step to reducing bias in your models is to have a diverse team to notice potential issues early.,모델의 편향을 줄이는 중요한 단계는 잠재적 인 문제를 조기에 발견 할 수있는 다양한 팀을 구성하는 것입니다.,,
58,"As Jeff Dean said: “AI is full of promise, with the potential to revolutionize so many different areas of modern society.",Jeff Dean이 말했듯이 :“AI는 현대 사회의 다양한 영역을 혁신 할 잠재력이있는 가능성으로 가득 차 있습니다.,,
59,"In order to realize its true potential, our field needs to be welcoming to all people.",진정한 잠재력을 실현하기 위해 우리 분야는 모든 사람을 환영해야합니다.,,
60,"As it stands today, it is definitely not.",오늘날과 같이 확실히 그렇지 않습니다.,,
61,"Our field has a problem with inclusiveness.”
Tip
It’s important to note that removing biases or validating accuracy in your results is not a “one and done”; model performance can degrade and biases can be introduced over time—even if you don’t personally change anything.","우리 분야는 포용성에 문제가 있습니다.”
팁
결과에서 편견을 제거하거나 정확성을 검증하는 것은 ""한 번만 완료""하는 것이 아니라는 점에 유의해야합니다.개인적으로 아무것도 변경하지 않더라도 시간이 지남에 따라 모델 성능이 저하되고 편향이 발생할 수 있습니다.",,
62,"[1]



Conventions Used in This Book
The following typographical conventions are used in this book:

Italic

Indicates new terms, URLs, email addresses, filenames, and file extensions.","[1]



이 책에 사용 된 규칙
이 책에서는 다음과 같은 표기 규칙이 사용됩니다.

이탤릭체

새로운 용어, URL, 이메일 주소, 파일 이름 및 파일 확장자를 나타냅니다.",,
63,"Constant width

Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.","일정한 폭

변수 또는 함수 이름, 데이터베이스, 데이터 유형, 환경 변수, 명령문 및 키워드와 같은 프로그램 요소를 참조하기 위해 단락 내 에서뿐만 아니라 프로그램 목록에 사용됩니다.",,
64,"Constant width bold

Shows commands or other text that should be typed literally by the user.","고정 너비 굵게

사용자가 문자 그대로 입력해야하는 명령 또는 기타 텍스트를 표시합니다.",,
65,"Constant width italic

Shows text that should be replaced with user-supplied values or by values determined by context.","일정한 너비 기울임 꼴

사용자 제공 값 또는 컨텍스트에 의해 결정된 값으로 대체되어야하는 텍스트를 표시합니다.",,
66,"Tip
This element signifies a tip or suggestion.","팁
이 요소는 팁 또는 제안을 나타냅니다.",,
67,"Note
This element signifies a general note.","노트
이 요소는 일반적인 참고 사항을 나타냅니다.",,
68,"Warning
This element indicates a warning or caution.","경고
이 요소는 경고 또는주의를 나타냅니다.",,
69,We will use warnings to indicate any situations where the resulting pipeline is likely to be nonportable and call out portable alternatives that you can use.,경고를 사용하여 결과 파이프 라인이 이식 불가능할 가능성이있는 상황을 표시하고 사용할 수있는 이식 가능한 대안을 제시합니다.,,
70,"Code Examples
Supplemental material (code examples, etc.)","코드 예
보충 자료 (코드 예 등)",,
71,is available for download at https://oreil.ly/Kubeflow_for_ML.,https://oreil.ly/Kubeflow_for_ML에서 다운로드 할 수 있습니다.,,
72,"These code examples are available under an Apache 2 license, or as described in the next section.",이러한 코드 예제는 Apache 2 라이선스 또는 다음 섹션에 설명 된대로 사용할 수 있습니다.,,
73,There are additional examples under their own respective licenses that you may find useful.,유용 할 수있는 각 라이선스 아래에 추가 예제가 있습니다.,,
74,"The Kubeflow project has an example repo, which at the time of writing is available under an Apache 2 license.",Kubeflow 프로젝트에는 작성 시점에 Apache 2 라이선스로 사용할 수있는 예제 저장소가 있습니다.,,
75,Canonical also has  a set of resources that may be of special interest to MicroK8s users.,Canonical에는 MicroK8s 사용자에게 특별한 관심을 가질 수있는 리소스 세트도 있습니다.,,
76,"Using Code Examples
If you have a technical question or a problem using the code examples, please send email to bookquestions@oreilly.com.","코드 예제 사용
기술적 인 질문이나 코드 예제 사용에 문제가있는 경우 bookquestions@oreilly.com으로 이메일을 보내주십시오.",,
77,This book is here to help you get your job done.,이 책은 귀하의 업무 수행을 돕기 위해 여기에 있습니다.,,
78,"In general, if example code is offered with this book, you may use it in your programs and documentation.",일반적으로이 책에 예제 코드가 제공되는 경우 프로그램 및 문서에서 사용할 수 있습니다.,,
79,You do not need to contact us for permission unless you’re reproducing a significant portion of the code.,코드의 상당 부분을 복제하지 않는 한 Google에 연락하여 허가를받을 필요가 없습니다.,,
80,"For example, writing a program that uses several chunks of code from this book does not require permission.","예를 들어,이 책의 여러 코드를 사용하는 프로그램을 작성하는 데는 권한이 필요하지 않습니다.",,
81,Selling or distributing examples from O’Reilly books does require permission.,O’Reilly 책의 예를 판매하거나 배포하려면 허가가 필요합니다.,,
82,Answering a question by citing this book and quoting example code does not require permission.,이 책을 인용하고 예제 코드를 인용하여 질문에 답하는 것은 허가가 필요하지 않습니다.,,
83,"Incorporating a significant amount of example code from this book into your product’s documentation does require 
permission.","이 책의 상당량의 예제 코드를 제품 설명서에 통합하려면
허가.",,
84,Additional details on license can be found in the repos.,라이센스에 대한 추가 세부 사항은 저장소에서 찾을 수 있습니다.,,
85,"We appreciate, but generally do not require, attribution.",일반적으로 귀속을 요구하지는 않지만 감사합니다.,,
86,"An attribution usually includes the title, author, publisher, and ISBN.","일반적으로 저작자 표시에는 제목, 저자, 발행자 및 ISBN이 포함됩니다.",,
87,"For example: “Kubeflow for Machine Learning by Holden Karau, Trevor Grant, Boris Lublinsky, Richard Liu, and Ilan Filonenko (O’Reilly).","예 :“Holden Karau, Trevor Grant, Boris Lublinsky, Richard Liu, Ilan Filonenko (O’Reilly)의 기계 학습용 Kubeflow.",,
88,"Copyright 2021 Holden Karau, Trevor Grant, Boris Lublinsky, Richard Liu, and Ilan Filonenko, 978-1-492-05012-4.”
If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at permissions@oreilly.com.","Copyright 2021 Holden Karau, Trevor Grant, Boris Lublinsky, Richard Liu, Ilan Filonenko, 978-1-492-05012-4.”
코드 예제 사용이 공정 사용 또는 위에 제공된 권한을 벗어난다고 생각되면 permissions@oreilly.com으로 언제든지 문의하십시오.",,
89,"O’Reilly Online Learning
Note
For more than 40 years, O’Reilly Media has provided technology and business training, knowledge, and insight to help companies succeed.","O’Reilly 온라인 학습
노트
O’Reilly Media는 40 년 이상 기업의 성공에 도움이되는 기술 및 비즈니스 교육, 지식 및 통찰력을 제공해 왔습니다.",,
90,"Our unique network of experts and innovators share their knowledge and expertise through books, articles, and our online learning platform.","당사의 고유 한 전문가 및 혁신가 네트워크는 책, 기사 및 온라인 학습 플랫폼을 통해 지식과 전문성을 공유합니다.",,
91,"O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O’Reilly and 200+ other publishers.","O'Reilly의 온라인 학습 플랫폼은 실시간 교육 과정, 심층 학습 경로, 대화 형 코딩 환경, O'Reilly 및 200 개 이상의 다른 게시자가 제공하는 방대한 텍스트 및 비디오 컬렉션에 대한 주문형 액세스를 제공합니다.",,
92,"For more information, visit http://oreilly.com.",자세한 내용은 http://oreilly.com을 참조하십시오.,,
93,"How to Contact the Authors
For feedback, email us at intro-to-ml-kubeflow@googlegroups.com.","저자에게 연락하는 방법
의견이 필요하면 intro-to-ml-kubeflow@googlegroups.com으로 이메일을 보내주세요.",,
94,"For random ramblings, occasionally about Kubeflow, follow us online:

Trevor



Twitter


Blog


GitHub


Myspace



Holden



Twitter


YouTube


Twitch


LinkedIn


Blog


GitHub


Facebook



Boris



LinkedIn


GitHub



Richard



GitHub





Ilan



LinkedIn


GitHub






How to Contact Us
Please address comments and questions concerning this book to the publisher:

O’Reilly Media, Inc.
1005 Gravenstein Highway North
Sebastopol, CA 95472
800-998-9938 (in the United States or Canada)
707-829-0515 (international or local)
707-829-0104 (fax)

You can access the web page for this book, where we list errata, examples, and any additional information, at https://oreil.ly/Kubeflow_for_Machine_Learning.","가끔씩 Kubeflow에 대해 무작위로 떠돌이는 경우 온라인으로 팔로우하세요.

트레버



트위터


블로그


GitHub


내 공간



홀든



트위터


유튜브


경련


LinkedIn


블로그


GitHub


페이스 북



보리스



LinkedIn


GitHub



Richard



GitHub





일란



LinkedIn


GitHub






연락 방법
이 책에 대한 의견과 질문을 발행인에게 알려주십시오.

O’Reilly Media, Inc.
1005 Gravenstein 고속도로 북쪽
세 바스 토폴, CA 95472
800-998-9938 (미국 또는 캐나다)
707-829-0515 (국제 또는 지역)
707-829-0104 (팩스)

https://oreil.ly/Kubeflow_for_Machine_Learning에서 정오표, 예제 및 추가 정보를 나열하는이 책의 웹 페이지에 액세스 할 수 있습니다.",,
95,Email bookquestions@oreilly.com to comment or ask technical questions about this book.,이 책에 대한 의견을 말하거나 기술적 인 질문을하려면 bookquestions@oreilly.com으로 이메일을 보내십시오.,,
96,"For news and information about our books and courses, visit http://oreilly.com.",책과 과정에 대한 뉴스와 정보를 보려면 http://oreilly.com을 방문하십시오.,,
97,"Find us on Facebook: http://facebook.com/oreilly
Follow us on Twitter: http://twitter.com/oreillymedia
Watch us on YouTube: http://www.youtube.com/oreillymedia


Acknowledgments
The authors would like to thank everyone at O’Reilly Media, especially our editors Amelia Blevins and Deborah Baker, as well as the Kubeflow community for making this book possible.","Facebook에서 찾기 : http://facebook.com/oreilly
Twitter에서 팔로우하세요 : http://twitter.com/oreillymedia
YouTube에서보기 : http://www.youtube.com/oreillymedia


감사의 말
저자는 O’Reilly Media의 모든 사람, 특히 편집자 인 Amelia Blevins와 Deborah Baker, 그리고이 책을 가능하게 해준 Kubeflow 커뮤니티에 감사드립니다.",,
98,"Clive Cox and Alejandro Saucedo from Seldon made amazing contributions to CHAPTER 8, without which this book would be missing key parts.",Seldon의 Clive Cox와 Alejandro Saucedo는 CHAPTER 8에 놀라운 공헌을했습니다.,,
99,We’d like to thank Google Cloud Platform for resources that allowed us to ensure examples worked on GCP.,예제가 GCP에서 작동하는지 확인할 수있는 리소스에 대해 Google Cloud Platform에 감사드립니다.,,
100,"Perhaps most importantly, we’d like to thank our reviewers, without whom this book would not exist in its current form.",아마도 가장 중요한 것은이 책이 현재의 형태로 존재하지 않을 리뷰어들에게 감사를 표하는 것입니다.,,
101,"This includes Taka Shinagawa, Pete MacKinnon, Kevin Haas, Chris Albon, Hannes Hapke, and more.","여기에는 Taka Shinagawa, Pete MacKinnon, Kevin Haas, Chris Albon, Hannes Hapke 등이 포함됩니다.",,
102,"To all early readers and reviewers of books, thank you for your contributions.",책의 초기 독자와 평론가 모두에게 기여해 주셔서 감사합니다.,,
103,"Holden

Would like to thank her girlfriend Kris Nóva for her help debugging her first Kubeflow PR,
as well as the entire Kubeflow community for being so welcoming.","홀든

첫 Kubeflow PR을 디버깅하는 데 도움을 주신 여자 친구 Kris Nóva에게 감사드립니다.
뿐만 아니라 Kubeflow 커뮤니티 전체가 환영합니다.",,
104,"She would also like to thank her wife Carolyn DeSimone, her puppy Timbit DeSimone-Karau (pictured in FIGURE P-1), and her stuffed animals for the support needed to write.","그녀는 또한 그녀의 아내 Carolyn DeSimone, 그녀의 강아지 Timbit DeSimone-Karau (그림 P-1에서 사진), 그리고 글쓰기에 필요한 지원에 대해 그녀의 박제 동물들에게 감사하고 싶습니다.",,
105,She would like to thank the doctors at SF General and UCSF for fixing up her hands so she could finish writing this book (although she does wish the hands did not hurt anymore) and everyone who came to visit her in the hospital and nursing home.,그녀는이 책을 다 쓸 수 있도록 손을 고쳐 준 SF General과 UCSF의 의사들과 (더 이상 손이 아프지 않았 으면했지만) 병원과 요양원에서 그녀를 방문한 모든 사람에게 감사의 말씀을 전합니다.,,
106,"A special thank you to Ann Spencer, the first editor who showed her how to have fun writing.",재미있는 글쓰기 방법을 보여준 최초의 편집자 Ann Spencer에게 특별히 감사드립니다.,,
107,"Finally, she would like to thank her datefriend Els van Vessem for their support in recovering after her accident, especially reading stories and reminding her of her love of writing.","마지막으로, 그녀는 사고 후 회복, 특히 이야기를 읽고 글쓰기에 대한 그녀의 사랑을 상기시키는 데 도움을 준 데이트 친구 Els van Vessem에게 감사드립니다.",,
108,Figure P-1.,그림 P-1.,,
109,"Timbit the dog


Ilan

Would like to thank all his colleagues at Bloomberg who took the time to review, mentor, and encourage him to write and contribute to open source.","개 Timbit


일란

시간을내어 검토하고, 멘토링하고, 오픈 소스에 글을 쓰고 기여하도록 격려해 준 Bloomberg의 모든 동료에게 감사드립니다.",,
110,"The list includes but is not limited to: Kimberly Stoddard, Dan Sun, Keith Laban, Steven Bower, and Sudarshan Kadambi.","목록에는 Kimberly Stoddard, Dan Sun, Keith Laban, Steven Bower 및 Sudarshan Kadambi가 포함되지만 이에 국한되지는 않습니다.",,
111,"He would also like to thank his family—Galia, Yuriy, and Stan—for their unconditional love and support.","그는 또한 무조건적인 사랑과 지원에 대해 가족 (Galia, Yuriy, Stan)에게 감사를 표하고 싶습니다.",,
112,"Richard

Would like to thank the Google Kubeflow team, including but not limited to: Jeremy Lewi, Abhishek Gupta, Thea Lamkin, Zhenghui Wang, Kunming Qu, Gabriel Wen, Michelle Casbon, and Sarah Maddox—without whose support none of this would have been possible.","Richard

Jeremy Lewi, Abhishek Gupta, Thea Lamkin, Zhenghui Wang, Kunming Qu, Gabriel Wen, Michelle Casbon, Sarah Maddox를 포함하되 이에 국한되지 않는 Google Kubeflow 팀에 감사드립니다..",,
113,He would also like to thank his cat Tina (see FIGURE P-2) for her support and understanding during COVID-19.,그는 또한 COVID-19 동안 그녀의 지원과 이해에 대해 고양이 Tina (그림 P-2 참조)에게 감사를 표하고 싶습니다.,,
114,Figure P-2.,그림 P-2.,,
115,"Tina the cat


Boris

Would like to thank his colleagues at Lightbend, especially Karl Wehden, for their support in writing the book,
their suggestions and proofreads of the early versions of the text, and his wife Marina for putting up with his long hours and feeding him during these hours.","고양이 티나


보리스

Lightbend의 동료들, 특히 Karl Wehden이 책을 쓰는 데 도움을 주신 것에 감사드립니다.
텍스트의 초기 버전에 대한 그들의 제안과 교정, 그리고 그의 오랜 시간을 참아 내고이 시간 동안 그를 먹여 준 그의 아내 마리나.",,
116,"Trevor

Trevor would like to thank his office mates Apache and Meowska (see FIGURE P-3) for reminding him of the importance of naps, and everyone who listened to him give a talk on Kubeflow last year (especially the people who listened to the bad versions, and especially especially people who listened to the bad versions but still are reading this book now—you’re the best).","트레버

Trevor는 낮잠의 중요성을 상기시켜 준 그의 사무실 동료 인 Apache와 Meowska (그림 P-3 참조)에게 감사를 표하고 있으며, 그의 말을 들었던 모든 사람이 작년에 Kubeflow에 대해 이야기를 나눈다 (특히 나쁜 버전을 들었던 사람들), 특히 나쁜 버전을 들었지만 지금도이 책을 읽고있는 사람들은 당신이 최고입니다).",,
117,"He’d also like to thank his mom, sister, and brother for tolerating his various shenanigans over the years.","그는 또한 수년에 걸쳐 다양한 허풍을 참아 주신 엄마, 누이, 오빠에게 감사하고 싶습니다.",,
118,Figure P-3.,그림 P-3.,,
119,"Apache and Meowska



Grievances
The authors would also like to acknowledge the struggles of API changes, which made writing this book so frustrating.","Apache와 Meowska



불만
저자는 또한이 책을 작성하는 것이 매우 실망스러운 API 변경의 어려움을 인정하고 싶습니다.",,
120,"If you ever struggle with API changes, know that you are not alone; they are annoying to almost everyone.",API 변경으로 어려움을 겪는 경우 혼자가 아니라는 점을 알아 두십시오.거의 모든 사람에게 짜증이납니다.,,
121,Holden would also like to acknowledge the times Timbit DeSimone-Karau was a little sh*t and dug up the yard while she was working.,Holden은 또한 Timbit DeSimone-Karau가 일하는 동안 마당을 파고 들었던 시간을 인정하고 싶습니다.,,
122,"We have a special grievance to vent with the person who hit Holden with their car, slowing down the release of this book.",우리는 홀든을 차로 때린 사람에게 특별한 불만을 표출하여이 책의 출시를 늦추고 있습니다.,,
123,"Trevor has a grievance to air with his girlfriend, who has been badgering him (with increasing persistence) to propose to her throughout this entire project, and while he has been “working on it”—if he hasn’t asked her to marry him by the time this book comes out: Katie, will you marry me?","Trevor는 그의 여자 친구와 함께 불만을 품고 있습니다. 그녀는이 프로젝트 전체에서 그녀에게 청혼하기 위해 자신을 괴롭 히고 (지속력이 증가하면서) 그녀에게 ""일을하고있는 동안""그녀와 결혼 해달라고 요청하지 않았습니다.이 책이 나올 때 쯤이면 : Katie, 나와 결혼 해 줄래?",,
124,[1] Remember the Twitter bot that through reinforcement learning became a neo-Nazi in less than a weekend?,[1] 강화 학습을 통해 주말도 안되어 네오 나치가 된 트위터 봇을 기억하십니까?,,
125,Chapter 1.,1 장.,,
126,"Kubeflow: What It Is and Who It Is For
If you are a data scientist trying to get your models into production, or a data engineer trying to make your models scalable and reliable, Kubeflow provides tools to help.","Kubeflow : 정의 및 대상
모델을 프로덕션에 적용하려는 데이터 과학자이거나 모델을 확장 가능하고 안정적으로 만들려는 데이터 엔지니어 인 경우 Kubeflow는 도움이되는 도구를 제공합니다.",,
127,Kubeflow solves the problem of how to take machine learning from research to production.,Kubeflow는 기계 학습을 연구에서 생산으로 옮기는 방법에 대한 문제를 해결합니다.,,
128,"Despite common misconceptions, Kubeflow is more than just Kubernetes and TensorFlow—you can use it for all sorts of machine learning tasks.",일반적인 오해에도 불구하고 Kubeflow는 Kubernetes 및 TensorFlow 이상입니다. 모든 종류의 기계 학습 작업에 사용할 수 있습니다.,,
129,"We hope Kubeflow is the right tool for you, as long as your organization is using Kubernetes.",조직에서 Kubernetes를 사용하는 한 Kubeflow가 적합한 도구가되기를 바랍니다.,,
130,SECTION 1.6 introduces some options you may wish to explore.,섹션 1.6에서는 탐색 할 수있는 몇 가지 옵션을 소개합니다.,,
131,This chapter aims to help you decide if Kubeflow is the right tool for your use case.,이 장은 Kubeflow가 사용 사례에 적합한 도구인지 결정하는 데 도움이됩니다.,,
132,"We’ll cover the benefits you can expect from Kubeflow, some of the costs associated with it, and some of the alternatives.","Kubeflow에서 기대할 수있는 이점, 이와 관련된 일부 비용 및 일부 대안을 다룰 것입니다.",,
133,"After this chapter, we’ll dive into setting up Kubeflow and building an end-to-end solution to familiarize you with the basics.",이 장이 끝나면 Kubeflow를 설정하고 기본 사항을 익힐 수있는 종단 간 솔루션을 구축하는 방법에 대해 알아 봅니다.,,
134,1.1.,1.1.,,
135,"Model Development Life Cycle
Machine learning or model development essentially follows the path: data →  information →  knowledge →  insight.","모델 개발 수명주기
머신 러닝 또는 모델 개발은 기본적으로 데이터 → 정보 → 지식 → 통찰력의 경로를 따릅니다.",,
136,This path of generating insight from data can be graphically described with FIGURE 1-1.,데이터에서 통찰력을 생성하는이 경로는 그림 1-1에서 그래픽으로 설명 할 수 있습니다.,,
137,Model development life cycle (MDLC) is a term commonly used to describe the flow between training and inference.,MDLC (모델 개발 수명주기)는 훈련과 추론 간의 흐름을 설명하는 데 일반적으로 사용되는 용어입니다.,,
138,"FIGURE 1-1 is a visual representation of this continuous interaction, where upon triggering a model update the whole cycle kicks off yet again.","그림 1-1은 이러한 지속적인 상호 작용을 시각적으로 표현한 것으로, 모델 업데이트를 트리거하면 전체주기가 다시 시작됩니다.",,
139,Figure 1-1.,그림 1-1.,,
140,"Model development life cycle



1.2.","모델 개발 수명주기



1.2.",,
141,Where Does Kubeflow Fit In?,Kubeflow는 어디에 적합합니까?,,
142,"Kubeflow is a collection of cloud native tools for all of the stages of MDLC (data exploration, feature preparation, model training/tuning, model serving, model testing, and model versioning).","Kubeflow는 MDLC의 모든 단계 (데이터 탐색, 기능 준비, 모델 학습 / 조정, 모델 제공, 모델 테스트 및 모델 버전 관리)를위한 클라우드 네이티브 도구 모음입니다.",,
143,Kubeflow also has tooling that allows these traditionally separate tools to work seamlessly together.,또한 Kubeflow에는 이러한 전통적으로 분리 된 도구가 원활하게 함께 작동 할 수있는 도구가 있습니다.,,
144,"An important part of this tooling is the pipeline system, which allows users to build integrated end-to-end pipelines that connect all components of their MDLC.",이 도구의 중요한 부분은 사용자가 MDLC의 모든 구성 요소를 연결하는 통합 된 종단 간 파이프 라인을 구축 할 수있는 파이프 라인 시스템입니다.,,
145,Kubeflow is for both data scientists and data engineers looking to build production-grade machine learning implementations.,Kubeflow는 프로덕션 수준의 머신 러닝 구현을 구축하려는 데이터 과학자와 데이터 엔지니어 모두를위한 것입니다.,,
146,Kubeflow can be run either locally in your development environment or on a production cluster.,Kubeflow는 개발 환경 또는 프로덕션 클러스터에서 로컬로 실행할 수 있습니다.,,
147,Often pipelines will be developed locally and migrated once the pipelines are ready.,종종 파이프 라인은 로컬에서 개발되고 파이프 라인이 준비되면 마이그레이션됩니다.,,
148,"Kubeflow provides a unified system—leveraging Kubernetes for containerization and scalability, for the portability and repeatability of its pipelines.",Kubeflow는 파이프 라인의 이식성과 반복성을 위해 Kubernetes를 컨테이너화 및 확장성에 활용하는 통합 시스템을 제공합니다.,,
149,1.3.,1.3.,,
150,Why Containerize?,왜 컨테이너화할까요?,,
151,The isolation provided by containers allows machine learning stages to be portable and reproducible.,컨테이너가 제공하는 격리를 통해 기계 학습 단계를 이식 가능하고 재현 할 수 있습니다.,,
152,Containerized applications are isolated from the rest of your machine and have all their requirements included (from the operating system up).,컨테이너화 된 애플리케이션은 시스템의 나머지 부분과 격리되며 모든 요구 사항이 포함됩니다 (운영 체제부터).,,
153,"[1]
Containerization means no more conversations that include “It worked on my machine” or “Oh yeah, we forgot about just one, you need this extra package.”
Containers are built in composable layers, allowing you to use another container as a base.","[1]
컨테이너화는 ""내 컴퓨터에서 작동했습니다""또는 ""오 예, 하나만 잊어 버렸습니다.이 추가 패키지가 필요합니다.""라는 대화가 더 이상 필요하지 않음을 의미합니다.
컨테이너는 구성 가능한 레이어로 빌드되므로 다른 컨테이너를 기본으로 사용할 수 있습니다.",,
154,"For example, if you have a new natural language processing (NLP) library you want to use, you can add it on top of the existing container—you don’t have to start from scratch each time.",예를 들어 사용하려는 새로운 자연어 처리 (NLP) 라이브러리가있는 경우 기존 컨테이너 위에 추가 할 수 있습니다. 매번 처음부터 시작할 필요가 없습니다.,,
155,"The composability allows you to reuse a common base; for example, the R and Python containers we use both share a base Debian container.","구성 가능성을 통해 공통 기반을 재사용 할 수 있습니다.예를 들어, 우리가 사용하는 R 및 Python 컨테이너는 기본 Debian 컨테이너를 공유합니다.",,
156,A common worry about using containers is the overhead.,컨테이너 사용에 대한 일반적인 걱정은 오버 헤드입니다.,,
157,"The overhead of containers depends on your implementation, but a paper from IBM[2] found the overhead to be quite low, and generally faster than virtualization.",컨테이너의 오버 헤드는 구현에 따라 다르지만 IBM [2]의 논문에 따르면 오버 헤드가 상당히 낮고 일반적으로 가상화보다 빠릅니다.,,
158,"With Kubeflow, there is some additional overhead of having operators installed that you may not use.",Kubeflow를 사용하면 사용하지 않을 수있는 운영자 설치로 인한 추가 오버 헤드가 있습니다.,,
159,This overhead is negligible on a production cluster but may be noticeable on a laptop.,이 오버 헤드는 프로덕션 클러스터에서는 무시할 수 있지만 랩톱에서는 눈에 띌 수 있습니다.,,
160,"Tip
Data scientists with Python experience can think of containers as a heavy-duty virtual environment.","팁
Python 경험이있는 데이터 과학자는 컨테이너를 강력한 가상 환경으로 생각할 수 있습니다.",,
161,"In addition to what you’re used to in a virtual environment, containers also include the operating system, the packages, and everything in between.","가상 환경에서 익숙한 것 외에도 컨테이너에는 운영 체제, 패키지 및 그 사이의 모든 것이 포함됩니다.",,
162,1.4.,1.4.,,
163,Why Kubernetes?,왜 Kubernetes인가?,,
164,"Kubernetes is an open source system for automating the deployment, scaling, and management of containerized applications.","Kubernetes는 컨테이너화 된 애플리케이션의 배포, 확장 및 관리를 자동화하기위한 오픈 소스 시스템입니다.",,
165,"It allows our pipelines to be scalable without sacrificing portability, enabling us to avoid becoming locked into a specific cloud provider.",이를 통해 이식성을 희생하지 않고 파이프 라인을 확장 할 수 있으므로 특정 클라우드 제공 업체에 갇히는 것을 방지 할 수 있습니다.,,
166,"[3]
In addition to being able to switch from a single machine to a distributed cluster, different stages of your machine learning pipeline can request different amounts or types of resources.","[삼]
단일 머신에서 분산 클러스터로 전환 할 수있을뿐만 아니라 머신 러닝 파이프 라인의 여러 단계에서 다양한 양 또는 유형의 리소스를 요청할 수 있습니다.",,
167,"For example, your data preparation step may benefit more from running on multiple machines, while your model training may benefit more from computing on top of GPUs or tensor processing units (TPUs).",예를 들어 데이터 준비 단계는 여러 머신에서 실행하면 더 많은 이점을 얻을 수 있지만 모델 학습은 GPU 또는 텐서 처리 장치 (TPU)를 기반으로하는 컴퓨팅에서 더 많은 이점을 얻을 수 있습니다.,,
168,"This flexibility is especially useful in cloud environments, where you can reduce your costs by using expensive resources only when required.",이러한 유연성은 필요한 경우에만 값 비싼 리소스를 사용하여 비용을 절감 할 수있는 클라우드 환경에서 특히 유용합니다.,,
169,"You can, of course, build your own containerized machine learning pipelines on Kubernetes without using Kubeflow; however the goal of Kubeflow is to standardize this process and make it substantially easier and more efficient.",물론 Kubeflow를 사용하지 않고도 Kubernetes에서 자체 컨테이너화 된 머신 러닝 파이프 라인을 구축 할 수 있습니다.그러나 Kubeflow의 목표는이 프로세스를 표준화하고 훨씬 더 쉽고 효율적으로 만드는 것입니다.,,
170,"[4]
Kubeflow provides a common interface over the tools you would likely use for your machine learning implementations.","[4]
Kubeflow는 기계 학습 구현에 사용할 수있는 도구에 대한 공통 인터페이스를 제공합니다.",,
171,It also makes it easier to configure your implementations to use hardware accelerators like TPUs without changing your code.,또한 코드를 변경하지 않고도 TPU와 같은 하드웨어 가속기를 사용하도록 구현을 쉽게 구성 할 수 있습니다.,,
172,1.5.,1.5.,,
173,"Kubeflow’s Design and Core Components
In the machine learning landscape, there exists a diverse selection of libraries, tool sets, and frameworks.","Kubeflow의 디자인 및 핵심 구성 요소
기계 학습 환경에는 다양한 라이브러리, 도구 세트 및 프레임 워크가 있습니다.",,
174,"Kubeflow does not seek to reinvent the wheel or provide a “one size fits all” solution—instead, it allows machine learning practitioners to compose and customize their own stacks based on specific needs.","Kubeflow는 바퀴를 재발 명하거나 ""모든 것에 적합한""솔루션을 제공하지 않습니다. 대신 기계 학습 실무자가 특정 요구 사항에 따라 자신의 스택을 구성하고 사용자 지정할 수 있습니다.",,
175,It is designed to simplify the process of building and deploying machine learning systems at scale.,대규모 기계 학습 시스템 구축 및 배포 프로세스를 단순화하도록 설계되었습니다.,,
176,This allows data scientists to focus their energies on model development instead of infrastructure.,이를 통해 데이터 과학자는 인프라 대신 모델 개발에 에너지를 집중할 수 있습니다.,,
177,"Kubeflow seeks to tackle the problem of simplifying machine learning through three features: composability, portability, and scalability.","Kubeflow는 구성 성, 이식성 및 확장 성이라는 세 가지 기능을 통해 기계 학습을 단순화하는 문제를 해결하려고합니다.",,
178,"Composability

The core components of Kubeflow come from data science tools that are already familiar to machine learning practitioners.","구성 가능성

Kubeflow의 핵심 구성 요소는 이미 머신 러닝 실무자에게 익숙한 데이터 과학 도구에서 비롯됩니다.",,
179,"They can be used independently to facilitate specific stages of machine learning, or composed together to form end-to-end pipelines.",머신 러닝의 특정 단계를 용이하게하기 위해 독립적으로 사용하거나 함께 구성하여 엔드-투-엔드 파이프 라인을 형성 할 수 있습니다.,,
180,"Portability

By having a container-based design and taking advantage of Kubernetes and its cloud native architecture, Kubeflow does not require you to anchor to any particular developer environment.","휴대 성

컨테이너 기반 설계를 갖고 Kubernetes 및 클라우드 네이티브 아키텍처를 활용함으로써 Kubeflow는 특정 개발자 환경에 고정 할 필요가 없습니다.",,
181,"You can experiment and prototype on your laptop, and deploy to production effortlessly.",랩톱에서 실험하고 프로토 타입을 만들고 손쉽게 프로덕션에 배포 할 수 있습니다.,,
182,"Scalability 

By using Kubernetes, Kubeflow can dynamically scale according to the demand on your cluster, by changing the number and size of the underlying containers and machines.","확장 성

Kubernetes를 사용함으로써 Kubeflow는 기본 컨테이너 및 머신의 수와 크기를 변경하여 클러스터의 수요에 따라 동적으로 확장 할 수 있습니다.",,
183,"[5]


These features are critical for different parts of MDLC.","[5]


이러한 기능은 MDLC의 여러 부분에 중요합니다.",,
184,Scalability is important as your dataset grows.,데이터 세트가 증가함에 따라 확장 성이 중요합니다.,,
185,Portability is important to avoid vendor lock-in.,공급 업체 종속을 방지하려면 이식성이 중요합니다.,,
186,Composability gives you the freedom to mix and match the best tools for the job.,컴포저 빌리티는 작업에 가장 적합한 도구를 자유롭게 조합 할 수있는 기회를 제공합니다.,,
187,Let’s take a quick look at some of Kubeflow’s components and how they support these features.,Kubeflow의 일부 구성 요소와 이러한 기능을 지원하는 방법을 간략히 살펴 보겠습니다.,,
188,1.5.1.,1.5.1.,,
189,"Data Exploration with Notebooks
MDLC always begins with data exploration—plotting, segmenting, and manipulating your data to understand where possible insight might exist.","노트북을 사용한 데이터 탐색
MDLC는 항상 데이터 탐색 (데이터 플로팅, 세분화 및 조작)으로 시작하여 가능한 통찰력이 존재할 수있는 위치를 이해합니다.",,
190,One powerful tool that provides the tools and environment for such data exploration is Jupyter.,이러한 데이터 탐색을위한 도구와 환경을 제공하는 강력한 도구 중 하나는 Jupyter입니다.,,
191,"Jupyter is an open source web application that allows users to create and share data, code snippets, and experiments.","Jupyter는 사용자가 데이터, 코드 스 니펫 및 실험을 만들고 공유 할 수있는 오픈 소스 웹 애플리케이션입니다.",,
192,Jupyter is popular among machine learning practitioners due to its simplicity and portability.,Jupyter는 단순성과 이식성으로 인해 기계 학습 실무자에게 인기가 있습니다.,,
193,"In Kubeflow, you can spin up instances of Jupyter that directly interact with your cluster and its other components, as shown in FIGURE 1-2.",Kubeflow에서는 그림 1-2와 같이 클러스터 및 기타 구성 요소와 직접 상호 작용하는 Jupyter 인스턴스를 스핀 업할 수 있습니다.,,
194,"For example, you can write snippets of TensorFlow distributed training code on your laptop, and bring up a training cluster with just a few clicks.",예를 들어 노트북에 TensorFlow 분산 학습 코드의 스 니펫을 작성하고 몇 번의 클릭만으로 학습 클러스터를 불러올 수 있습니다.,,
195,Figure 1-2.,그림 1-2.,,
196,"Jupyter notebook running in Kubeflow



1.5.2.","Kubeflow에서 실행되는 Jupyter 노트북



1.5.2.",,
197,"Data/Feature Preparation
Machine learning algorithms require good data to be effective, and often special tools are needed to effectively extract, transform, and load data.","데이터 / 기능 준비
기계 학습 알고리즘은 효과적인 데이터를 필요로하며, 데이터를 효과적으로 추출, 변환 및로드하려면 종종 특수 도구가 필요합니다.",,
198,"One typically filters, normalizes, and prepares one’s input data in order to extract insightful features from otherwise unstructured, noisy data.","일반적으로 구조화되지 않은 잡음이 많은 데이터에서 통찰력있는 특징을 추출하기 위해 입력 데이터를 필터링, 정규화 및 준비합니다.",,
199,"Kubeflow supports a few different tools for this:


Apache Spark (one of the most popular big data tools)


TensorFlow Transform (integrated with TensorFlow Serving for easier inference)


These distinct data preparation components can handle a variety of formats and data sizes and are designed to play nicely with your data exploration environment.","Kubeflow는이를 위해 몇 가지 다른 도구를 지원합니다.


Apache Spark (가장 인기있는 빅 데이터 도구 중 하나)


TensorFlow Transform (더 쉬운 추론을 위해 TensorFlow Serving과 통합됨)


이러한 고유 한 데이터 준비 구성 요소는 다양한 형식과 데이터 크기를 처리 할 수 있으며 데이터 탐색 환경과 잘 어울리도록 설계되었습니다.",,
200,"[6]
Note
Support for Apache Beam with Apache Flink in Kubeflow Pipelines is an area of active development.","[6]
노트
Kubeflow Pipelines에서 Apache Flink를 사용한 Apache Beam 지원은 활발한 개발 영역입니다.",,
201,1.5.3.,1.5.3.,,
202,"Training
Once your features are prepped, you are ready to build and train your model.","훈련
기능이 준비되면 모델을 빌드하고 학습 할 준비가 된 것입니다.",,
203,Kubeflow supports a variety of distributed training frameworks.,Kubeflow는 다양한 분산 교육 프레임 워크를 지원합니다.,,
204,"As of the time of writing, Kubeflow has support for:


TensorFlow


PyTorch


Apache MXNet


XGBoost


Chainer


Caffe2


Message passing interface (MPI)


In CHAPTER 7 we will examine how Kubeflow trains a TensorFlow model in greater detail and CHAPTER 9 will explore other options.","작성 당시 Kubeflow는 다음을 지원합니다.


TensorFlow


파이 토치


Apache MXNet


XGBoost


Chainer


카페 2


메시지 전달 인터페이스 (MPI)


7 장에서는 Kubeflow가 TensorFlow 모델을 학습하는 방법을 자세히 살펴보고 9 장에서는 다른 옵션을 살펴 봅니다.",,
205,1.5.4.,1.5.4.,,
206,"Hyperparameter Tuning
How do you optimize your model architecture and training?","초 매개 변수 조정
모델 아키텍처와 훈련을 어떻게 최적화합니까?",,
207,"In machine learning, hyperparameters are variables that govern the training process.",기계 학습에서 하이퍼 파라미터는 훈련 프로세스를 제어하는 변수입니다.,,
208,"For example, what should the model’s learning rate be?",예를 들어 모델의 학습률은 얼마 여야합니까?,,
209,How many hidden layers and neurons should be in the neural network?,신경망에는 몇 개의 은닉층과 뉴런이 있어야합니까?,,
210,"These parameters are not part of the training data, but they can have a significant effect on the performance of the training models.",이러한 매개 변수는 학습 데이터의 일부가 아니지만 학습 모델의 성능에 상당한 영향을 미칠 수 있습니다.,,
211,"With Kubeflow, users can begin with a training model that they are unsure about, define the hyperparameter search space, and Kubeflow will take care of the rest—spin up training jobs using different hyperparameters, collect the metrics, and save the results to a model database so their performance can be compared.","Kubeflow를 사용하면 사용자가 확실하지 않은 학습 모델로 시작하여 초 매개 변수 검색 공간을 정의하면 Kubeflow가 나머지 작업을 처리합니다. 다른 초 매개 변수를 사용하여 학습 작업을 회전하고, 측정 항목을 수집하고, 결과를 모델에 저장합니다.성능을 비교할 수 있습니다.",,
212,1.5.5.,1.5.5.,,
213,"Model Validation
Before you put your model into production, it’s important to know how it’s likely to perform.","모델 검증
모델을 프로덕션에 적용하기 전에 성능이 어떻게 될지 아는 것이 중요합니다.",,
214,The same tool used for hyperparameter tuning can perform cross-validation for model validation.,하이퍼 파라미터 튜닝에 사용되는 동일한 도구는 모델 검증을위한 교차 검증을 수행 할 수 있습니다.,,
215,"When you’re updating existing models, techniques like A/B testing and multi-armed bandit can be used in model inference to validate your model online.",기존 모델을 업데이트 할 때 모델 추론에서 A / B 테스트 및 다중 슬롯 머신과 같은 기술을 사용하여 온라인으로 모델을 검증 할 수 있습니다.,,
216,1.5.6.,1.5.6.,,
217,"Inference/Prediction
After training your model, the next step is to serve the model in your cluster so it can handle prediction requests.","추론 / 예측
모델 학습 후 다음 단계는 예측 요청을 처리 할 수 있도록 클러스터에서 모델을 제공하는 것입니다.",,
218,Kubeflow makes it easy for data scientists to deploy machine learning models in production environments at scale.,Kubeflow를 사용하면 데이터 과학자가 대규모 프로덕션 환경에서 기계 학습 모델을 쉽게 배포 할 수 있습니다.,,
219,"Currently Kubeflow provides a multiframework component for model serving (KFServing), in addition to existing solutions like TensorFlow Serving and Seldon Core.",현재 Kubeflow는 TensorFlow Serving 및 Seldon Core와 같은 기존 솔루션 외에도 모델 제공 (KFServing)을위한 다중 프레임 워크 구성 요소를 제공합니다.,,
220,Serving many types of models on Kubeflow is fairly straightforward.,Kubeflow에서 다양한 유형의 모델을 제공하는 것은 매우 간단합니다.,,
221,"In most situations, there is no need to build or customize a container yourself—simply point Kubeflow to where your model is stored, and a server will be ready to service requests.",대부분의 상황에서 컨테이너를 직접 구축하거나 사용자 정의 할 필요가 없습니다. Kubeflow가 모델이 저장된 위치를 가리 키기 만하면 서버가 요청을 처리 할 준비가됩니다.,,
222,"Once the model is served, it needs to be monitored for performance and possibly updated.",모델이 제공되면 성능을 모니터링하고 업데이트해야합니다.,,
223,This monitoring and updating is possible via the cloud native design of Kubeflow and will be further expanded upon in CHAPTER 8.,이 모니터링 및 업데이트는 Kubeflow의 클라우드 네이티브 디자인을 통해 가능하며 8 장에서 더 확장 될 것입니다.,,
224,1.5.7.,1.5.7.,,
225,"Pipelines
Now that we have completed all aspects of MDLC, we wish to enable reusability and governance of these experiments.","파이프 라인
이제 MDLC의 모든 측면을 완료 했으므로 이러한 실험의 재사용 및 거버넌스를 활성화하고자합니다.",,
226,"To do this, Kubeflow treats MDLC as a machine learning pipeline and implements it as a graph, where each node is a stage in a workflow, as seen in FIGURE 1-3.",이를 위해 Kubeflow는 MDLC를 기계 학습 파이프 라인으로 취급하고 그래프로 구현합니다. 여기서 각 노드는 그림 1-3에 표시된대로 워크 플로의 한 단계입니다.,,
227,Kubeflow Pipelines is a component that allows users to compose reusable workflows at ease.,Kubeflow Pipelines는 사용자가 재사용 가능한 워크 플로를 쉽게 구성 할 수있는 구성 요소입니다.,,
228,"Its features include:


An orchestration engine for multistep workflows


An SDK to interact with pipeline components


A user interface that allows users to visualize and track experiments, and to share results with collaborators




Figure 1-3.","그 기능은 다음과 같습니다.


다단계 워크 플로를위한 오케스트레이션 엔진


파이프 라인 구성 요소와 상호 작용하는 SDK


사용자가 실험을 시각화 및 추적하고 결과를 공동 작업자와 공유 할 수있는 사용자 인터페이스




그림 1-3.",,
229,"A Kubeflow pipeline



1.5.8.","Kubeflow 파이프 라인



1.5.8.",,
230,"Component Overview
As you can see, Kubeflow has built-in components for all parts of MDLC: data preparation, feature preparation, model training, data exploration, hyperparameter tuning, and model inference, as well as pipelines to coordinate everything.","구성 요소 개요
보시다시피 Kubeflow에는 MDLC의 모든 부분 (데이터 준비, 기능 준비, 모델 학습, 데이터 탐색, 하이퍼 파라미터 튜닝, 모델 추론, 모든 것을 조정하는 파이프 라인)에 대한 기본 제공 구성 요소가 있습니다.",,
231,"However, you are not limited to just the components shipped as part of Kubeflow.",그러나 Kubeflow의 일부로 제공되는 구성 요소에만 국한되지 않습니다.,,
232,You can build on top of the components or even replace them.,구성 요소 위에 구축하거나 교체 할 수도 있습니다.,,
233,"This can be OK for occasional components, but if you find yourself wanting to replace many parts of Kubeflow, you may want to explore some of the alternatives available.",가끔 구성 요소에 대해서는 괜찮을 수 있지만 Kubeflow의 많은 부분을 교체하려는 경우 사용 가능한 몇 가지 대안을 탐색 할 수 있습니다.,,
234,1.6.,1.6.,,
235,"Alternatives to Kubeflow
Within the research community, various alternatives exist that provide uniquely different functionality to that of Kubeflow.","Kubeflow의 대안
연구 커뮤니티 내에는 Kubeflow와 고유하게 다른 기능을 제공하는 다양한 대안이 있습니다.",,
236,"Most recent research has focused around model development and training, with large improvements being made in infrastructure, theory, and systems.","가장 최근의 연구는 모델 개발 및 교육에 중점을 두 었으며 인프라, 이론 및 시스템이 크게 개선되었습니다.",,
237,"Prediction and model serving, on the other hand, have received relatively less attention.",반면에 예측 및 모델 제공은 상대적으로 덜 관심을 받았습니다.,,
238,"As such, data science practitioners often end up hacking together an amalgam of critical systems components that are integrated to support serving and inference across various workloads and continuously evolving frameworks.",따라서 데이터 과학 실무자들은 다양한 워크로드와 지속적으로 진화하는 프레임 워크에서 제공 및 추론을 지원하기 위해 통합 된 핵심 시스템 구성 요소의 조합을 해킹하는 경우가 많습니다.,,
239,"Given the demand for constant availability and horizontal scalability, solutions like Kubeflow and various others are gaining traction throughout the industry, as powerful architectural abstraction tools, and as convincing research scopes.",지속적인 가용성과 수평 적 확장성에 대한 요구를 감안할 때 Kubeflow 및 기타 다양한 솔루션은 강력한 아키텍처 추상화 도구 및 설득력있는 연구 범위로 업계 전반에 걸쳐 주목을 받고 있습니다.,,
240,1.6.1.,1.6.1.,,
241,"Clipper (RiseLabs)
One interesting alternative to Kubeflow is Clipper, a general-purpose low-latency prediction serving system developed by
RiseLabs.","Clipper (RiseLabs)
Kubeflow의 흥미로운 대안 중 하나는 다음에서 개발 한 범용 저 지연 예측 제공 시스템 인 Clipper입니다.
RiseLabs.",,
242,"In an attempt to simplify deployment, optimization, and inference, Clipper has a layered architecture system.","배포, 최적화 및 추론을 단순화하기 위해 Clipper는 계층화 된 아키텍처 시스템을 가지고 있습니다.",,
243,"Through various optimizations and its modular design, Clipper, achieves low latency and high-throughput predictions at levels comparable to TensorFlow Serving, on three TensorFlow models of varying inference costs.",다양한 최적화와 모듈 식 설계를 통해 Clipper는 다양한 추론 비용의 세 가지 TensorFlow 모델에서 TensorFlow Serving에 필적하는 수준에서 낮은 지연 시간과 높은 처리량 예측을 달성합니다.,,
244,"Clipper is divided across two abstractions, aptly named model selection and model abstraction layers.",Clipper는 적절하게 명명 된 모델 선택 레이어와 모델 추상화 레이어의 두 가지 추상화로 나뉩니다.,,
245,The model selection layer is quite sophisticated in that it uses an adaptive online model selection policy and various ensemble techniques.,모델 선택 계층은 적응 형 온라인 모델 선택 정책과 다양한 앙상블 기술을 사용한다는 점에서 매우 정교합니다.,,
246,"Since the model is continuously learning from feedback throughout the lifetime of the application, the model selection layer self-calibrates failed models without needing to interact directly with the policy layer.",모델은 애플리케이션의 수명 내내 피드백에서 지속적으로 학습하므로 모델 선택 계층은 정책 계층과 직접 상호 작용할 필요없이 실패한 모델을 자체 교정합니다.,,
247,"Clipper’s modular architecture and focus on containerization, similar to Kubeflow, enables caching and batching mechanisms to be shared across frameworks while also reaping the benefits of scalability, concurrency, and flexibility in adding new model frameworks.","Clipper의 모듈 식 아키텍처와 Kubeflow와 유사한 컨테이너화에 중점을 두어 캐싱 및 일괄 처리 메커니즘을 프레임 워크간에 공유 할 수 있으며 새로운 모델 프레임 워크를 추가 할 때 확장 성, 동시성 및 유연성의 이점을 얻을 수 있습니다.",,
248,"Graduating from theory into a functional end-to-end system, Clipper has gained traction within the scientific community and has had various parts of its architectural designs incorporated into recently introduced machine learning systems.",이론에서 기능적 엔드-투-엔드 시스템으로 졸업 한 Clipper는 과학계에서 주목을 받았으며 최근에 도입 된 기계 학습 시스템에 통합 된 아키텍처 설계의 다양한 부분을 보유하고 있습니다.,,
249,"Nonetheless, we have yet to see if it will be adopted in the industry at scale.",그럼에도 불구하고 우리는 그것이 업계에서 대규모로 채택 될 것인지 아직 확인하지 못했습니다.,,
250,1.6.2.,1.6.2.,,
251,"MLflow (Databricks)
MLflow was developed by Databricks as an open source machine learning development platform.","MLflow (Databricks)
MLflow는 Databricks에서 오픈 소스 기계 학습 개발 플랫폼으로 개발했습니다.",,
252,"The architecture of MLflow leverages a lot of the same architectural paradigms as Clipper, including its framework-agnostic nature, while focusing on three major components that it calls Tracking, Projects, and Models.","MLflow의 아키텍처는 프레임 워크에 구애받지 않는 특성을 포함하여 Clipper와 동일한 아키텍처 패러다임을 많이 활용하면서 추적, 프로젝트 및 모델이라고하는 세 가지 주요 구성 요소에 중점을 둡니다.",,
253,"MLflow Tracking functions as an API with a complementing UI for logging parameters, code versions, metrics, and output files.","MLflow 추적은 매개 변수, 코드 버전, 측정 항목 및 출력 파일 로깅을위한 보완 UI가있는 API로 작동합니다.",,
254,"This is quite powerful in machine learning as tracking parameters, metrics, and artifacts is of paramount importance.","매개 변수, 메트릭 및 아티팩트를 추적하는 것이 가장 중요하기 때문에 기계 학습에서 매우 강력합니다.",,
255,"MLflow Projects provides a standard format for packaging reusable data science code, defined by a YAML file that can leverage source-controlled code and dependency management via Anaconda.",MLflow Projects는 Anaconda를 통해 소스 제어 코드 및 종속성 관리를 활용할 수있는 YAML 파일로 정의 된 재사용 가능한 데이터 과학 코드 패키징을위한 표준 형식을 제공합니다.,,
256,"The project format makes it easy to share reproducible data science code, as reproducibility is critical for machine learning practitioners.",머신 러닝 실무자에게는 재현성이 중요하므로 프로젝트 형식을 사용하면 재현 가능한 데이터 과학 코드를 쉽게 공유 할 수 있습니다.,,
257,MLflow Models are a convention for packaging machine learning models in multiple formats.,MLflow 모델은 기계 학습 모델을 여러 형식으로 패키징하기위한 규칙입니다.,,
258,Each MLflow Model is saved as a directory containing arbitrary files and an MLmodel descriptor file.,각 MLflow 모델은 임의의 파일과 MLmodel 설명자 파일이 포함 된 디렉터리로 저장됩니다.,,
259,"MLflow also provides the model’s registry, showing lineage between deployed models and their creation metadata.",MLflow는 배포 된 모델과 생성 메타 데이터 간의 연계를 보여주는 모델의 레지스트리도 제공합니다.,,
260,"Like Kubeflow, MLflow is still in active development, and has an active community.",Kubeflow와 마찬가지로 MLflow는 아직 개발 중이며 활발한 커뮤니티가 있습니다.,,
261,1.6.3.,1.6.3.,,
262,"Others
Because of the challenges presented in machine learning development, many organizations have started to build internal platforms to manage their machine learning life cycle.","기타
기계 학습 개발에 제시된 과제로 인해 많은 조직이 기계 학습 수명주기를 관리하기위한 내부 플랫폼을 구축하기 시작했습니다.",,
263,"For example: Bloomberg, Facebook, Google, Uber, and IBM have built, respectively, the Data Science Platform, FBLearner Flow, TensorFlow Extended, Michelangelo, and Watson Studio to manage data preparation, model training, and deployment.","예 : Bloomberg, Facebook, Google, Uber 및 IBM은 각각 데이터 준비, 모델 교육 및 배포를 관리하기 위해 Data Science Platform, FBLearner Flow, TensorFlow Extended, Michelangelo 및 Watson Studio를 구축했습니다.",,
264,"[7]
With the machine learning infrastructure landscape always evolving and maturing, we are excited to see how open source projects, like Kubeflow, will bring much-needed simplicity and abstraction to machine learning development.","[7]
기계 학습 인프라 환경이 항상 진화하고 성숙 해짐에 따라 Kubeflow와 같은 오픈 소스 프로젝트가 기계 학습 개발에 절실히 필요한 단순성과 추상화를 어떻게 가져올 지 기대됩니다.",,
265,1.7.,1.7.,,
266,"Introducing Our Case Studies
Machine learning can use many different types of data, and the approaches and tools you use may vary.","사례 연구 소개
기계 학습은 다양한 유형의 데이터를 사용할 수 있으며 사용하는 접근 방식과 도구가 다를 수 있습니다.",,
267,"In order to showcase Kubeflow’s capabilities, we’ve chosen case studies with very different data and best practices.",Kubeflow의 기능을 보여주기 위해 매우 다른 데이터와 모범 사례를 사용하는 사례 연구를 선택했습니다.,,
268,"When possible, we will use data from these case studies to explore Kubeflow and some of its components.",가능한 경우 이러한 사례 연구의 데이터를 사용하여 Kubeflow 및 일부 구성 요소를 탐색합니다.,,
269,1.7.1.,1.7.1.,,
270,"Modified National Institute of Standards and Technology
In ML, Modified National Institute of Standards and Technology (MNIST) commonly refers to the dataset of handwritten digits for classification.","수정 된 국립 표준 및 기술 연구소
ML에서 MNIST (Modified National Institute of Standards and Technology)는 일반적으로 분류를 위해 손으로 쓴 숫자 데이터 세트를 참조합니다.",,
271,"The relatively small data size of digits, as well as its common use as an example, allows us to explore a variety of tools.",상대적으로 작은 데이터 크기의 숫자와 일반적인 사용 예를 통해 다양한 도구를 탐색 할 수 있습니다.,,
272,"In some ways, MNIST has become one of the standard “hello world” examples for machine learning.","어떤면에서 MNIST는 기계 학습을위한 표준 ""hello world""예제 중 하나가되었습니다.",,
273,We use MNIST as our first example in CHAPTER 2 to illustrate Kubeflow end-to-end.,MNIST를 2 장의 첫 번째 예제로 사용하여 Kubeflow 종단 간을 설명합니다.,,
274,1.7.2.,1.7.2.,,
275,"Mailing List Data
Knowing how to ask good questions is something of an art.","메일 링리스트 데이터
좋은 질문을하는 방법을 아는 것은 예술입니다.",,
276,"Have you ever posted a message to a mailing list, asking for help, only for no one to respond?",아무도 응답하지 않기 위해 도움을 요청하는 메시지를 메일 링리스트에 게시 한 적이 있습니까?,,
277,What are the different types of questions?,질문에는 어떤 유형이 있습니까?,,
278,We’ll look at some of the public Apache Software Foundation mailing list data and try to create a model that predicts if a message will be answered.,공개 된 Apache Software Foundation 메일 링리스트 데이터의 일부를 살펴보고 메시지에 대한 응답 여부를 예측하는 모델을 만들려고합니다.,,
279,"This example is scaled up and down by choosing which projects and what time period we want to look at, so we can use a variety of tools to solve it.",이 예제는 우리가보고자하는 프로젝트와 기간을 선택하여 확장 및 축소되므로 다양한 도구를 사용하여 해결할 수 있습니다.,,
280,1.7.3.,1.7.3.,,
281,"Product Recommender
Recommendation systems are one of the most common and easily understood applications of machine learning, with many examples from Amazon’s product recommender to Netflix’s movie suggestions.","제품 추천자
추천 시스템은 가장 일반적이고 이해하기 쉬운 머신 러닝 애플리케이션 중 하나이며 Amazon의 제품 추천에서 Netflix의 영화 추천에 이르기까지 많은 예가 있습니다.",,
282,"The majority of recommender implementations are based on collaborative filtering—an assumption that if person A has the same opinion as person B on a set of issues, A would be more likely to share B’s opinion on other issues than would a randomly chosen third person.","추천자 구현의 대부분은 공동 필터링을 기반으로합니다. 즉, 사용자 A가 일련의 문제에 대해 사용자 B와 동일한 의견을 가지고 있다면 A가 무작위로 선택한 제 3 자보다 다른 문제에 대해 B의 의견을 공유 할 가능성이 더 높다는 가정입니다.",,
283,"This approach is built on a well-developed algorithm with quite a few implementations, including TensorFlow/Keras implementation.",이 접근 방식은 TensorFlow / Keras 구현을 포함하여 상당히 많은 구현으로 잘 개발 된 알고리즘을 기반으로합니다.,,
284,"[8]
One of the problems with rating-based models is that they can’t be standardized easily for data with nonscaled target values, such as the purchase or frequency data.","[8]
등급 기반 모델의 문제점 중 하나는 구매 또는 빈도 데이터와 같이 확장되지 않은 대상 값이있는 데이터에 대해서는 쉽게 표준화 할 수 없다는 것입니다.",,
285,This excellent Medium post shows how to convert such data into a rating matrix that can be used for collaborative filtering.,이 훌륭한 Medium 게시물은 이러한 데이터를 협업 필터링에 사용할 수있는 등급 매트릭스로 변환하는 방법을 보여줍니다.,,
286,Our example leverages data and code from Data Driven Investor and code described on Piyushdharkar’s GitHub.,이 예에서는 Data Driven Investor의 데이터 및 코드와 Piyushdharkar의 GitHub에 설명 된 코드를 활용합니다.,,
287,"We’ll use this example to explore how to build an initial model in Jupyter and move on to building a production 
pipeline.","이 예제를 사용하여 Jupyter에서 초기 모델을 빌드하는 방법을 탐색하고 프로덕션 빌드로 이동합니다.
관로.",,
288,1.7.4.,1.7.4.,,
289,"CT Scans
As we were writing this book, the world was going through the COVID-19 pandemic.","CT 스캔
이 책을 쓰는 동안 전 세계가 COVID-19 대유행을 겪고있었습니다.",,
290,"AI researchers were being called on to
apply methods and techniques to assist medical providers with understanding the disease.","AI 연구자들은
의료 제공자가 질병을 이해하는 데 도움이되는 방법과 기술을 적용합니다.",,
291,"Some research
showed that CT scans were more effective at early detection than RT-PCR tests (the traditional COVID test).","일부 연구
CT 스캔이 RT-PCR 테스트 (기존의 COVID 테스트)보다 조기 발견에 더 효과적임을 보여주었습니다.",,
292,"However, diagnostic
CT scans use low dosages of radiation and are therefore “noisy”—that is to say, CT scans are more clear when more radiation
is used.","그러나 진단
CT 스캔은 낮은 선량의 방사선을 사용하므로 ""노이즈""합니다. 즉, CT 스캔은 더 많은 방사선이있을 때 더 선명합니다.
사용.",,
293,"A new paper proposes an open source solution for denoising CT scans with off-the-shelf methods available entirely from open
source projects (as opposed to proprietary FDA-approved solutions).","새로운 논문은 오픈 소스에서 완전히 사용할 수있는 기성 방법으로 CT 스캔 노이즈를 제거하기위한 오픈 소스 솔루션을 제안합니다.
소스 프로젝트 (독점적 인 FDA 승인 솔루션과 반대).",,
294,"We implement this approach to illustrate how one might
go from academic article to real-world solution, to show the value of Kubeflow for creating reproducible and sharable
research, and to provide a starting off point for any reader who might want to contribute to the fight against COVID-19.","이 접근 방식을 구현하여
학술 기사에서 실제 솔루션으로 이동하여 재현 가능하고 공유 가능한 제작을위한 Kubeflow의 가치를 보여줍니다.
COVID-19 퇴치에 기여하고자하는 독자에게 출발점을 제공합니다.",,
295,1.8.,1.8.,,
296,"Conclusion
We are so glad you’ve decided to use this book to start your adventures into Kubeflow.","결론
이 책을 사용하여 Kubeflow 로의 모험을 시작하게되어 매우 기쁩니다.",,
297,This introduction should have given you a feel for Kubeflow and its capabilities.,이 소개는 Kubeflow와 그 기능에 대한 느낌을 주었어야합니다.,,
298,"However, like all adventures, there may come a point when your guidebook isn’t enough to carry you through.",그러나 모든 모험과 마찬가지로 가이드 북이 충분하지 않은 시점이 올 수 있습니다.,,
299,"Thankfully, there is a collection of community resources where you can interact with others on similar paths.",고맙게도 비슷한 경로에서 다른 사람들과 상호 작용할 수있는 커뮤니티 리소스 모음이 있습니다.,,
300,"We encourage you to sign up for the Kubeflow Slack workspace, one
of the more active areas of discussion.","Kubeflow Slack 작업 영역에 등록하는 것이 좋습니다.
더 활발한 토론 영역에 대해",,
301,There is also a Kubeflow discussion mailing list.,Kubeflow 토론 메일 링리스트도 있습니다.,,
302,There is a Kubeflow project page as well.,Kubeflow 프로젝트 페이지도 있습니다.,,
303,"Tip
If you want to quickly explore Kubeflow end-to-end, there are some
Google codelabs that can help you.","팁
Kubeflow 엔드 투 엔드를 빠르게 탐색하고 싶다면
도움이 될 수있는 Google 코드 랩.",,
304,"In CHAPTER 2, we’ll install Kubeflow and use it to train and serve a relatively simple machine learning
model to give you an idea of the basics.","2 장에서는 Kubeflow를 설치하고이를 사용하여 비교적 간단한 기계 학습을 교육하고 제공합니다.
기본에 대한 아이디어를 제공하는 모델입니다.",,
305,"[1] For more on containers, see this Google cloud resource.",[1] 컨테이너에 대한 자세한 내용은이 Google 클라우드 리소스를 참조하세요.,,
306,"In situations with GPUs or TPUs, the details of isolation become more complicated.",GPU 또는 TPU가있는 상황에서는 격리 세부 정보가 더 복잡해집니다.,,
307,"[2] W. Felter et al., “An Updated Performance Comparison of Virtual Machines and Linux Containers,” 2015 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), March 29-31, 2015, doi: 10.1109/ISPASS.2015.7095802.","[2] W. Felter et al.,“An Updated Performance Comparison of Virtual Machines and Linux Containers,”2015 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), 2015 년 3 월 29-31 일, doi : 10.1109 / ISPASS.2015.7095802.",,
308,[3] Kubernetes does this by providing a container orchestration layer.,[3] Kubernetes는 컨테이너 오케스트레이션 계층을 제공하여이를 수행합니다.,,
309,"For more information about Kubernetes, check out its documentation.",Kubernetes에 대한 자세한 정보는 해당 문서를 확인하십시오.,,
310,[4] Spotify was able to increase the rate of experiments ~7x, see this  Spotify Engineering blog post.,[4] Spotify는 실험 속도를 7 배까지 높일 수있었습니다.이 Spotify Engineering 블로그 게시물을 참조하십시오.,
311,"[5] Local clusters like Minikube are limited to one machine, but most cloud clusters can dynamically change the kind and number of machines as needed.",[5] Minikube와 같은 로컬 클러스터는 하나의 머신으로 제한되지만 대부분의 클라우드 클러스터는 필요에 따라 머신의 종류와 수를 동적으로 변경할 수 있습니다.,,
312,"[6] There is still some setup work to make this function, which we cover in CHAPTER 5.",[6]이 기능을 만들기위한 설정 작업이 아직 남아 있습니다. 5 장에서 다룹니다.,,
313,"[7] If you want to explore more of these tools, two good overviews are  Ian Hellstrom’s 2020 blog post and this 2019 article by Austin Kodra.",[7] 이러한 도구를 더 많이 살펴보고 싶다면 Ian Hellstrom의 2020 블로그 게시물과 Austin Kodra의 2019 년 기사가 두 가지 좋은 개요입니다.,,
314,"[8] For example, see the Piyushdharkar’s GitHub.",[8] 예를 들어 Piyushdharkar의 GitHub를 참조하세요.,,
315,Chapter 2.,제 2 장.,,
316,"Hello Kubeflow
Welcome to your first steps into the exciting world of Kubeflow!","안녕하세요 Kubeflow
Kubeflow의 흥미 진진한 세계로의 첫 걸음을 환영합니다!",,
317,"First off, we’ll set up Kubeflow on your machine, or on a cloud provider.",먼저 컴퓨터 또는 클라우드 제공 업체에 Kubeflow를 설정합니다.,,
318,Then we’ll dive into a comprehensive example.,그런 다음 포괄적 인 예를 살펴 보겠습니다.,,
319,The goal of this example is to get a model trained and start serving as quickly as possible.,이 예의 목표는 모델을 학습시키고 최대한 빨리 서비스를 시작하는 것입니다.,,
320,"In some parts of the first section, it may seem like we are instructing you to mindlessly enter commands.",첫 번째 섹션의 일부에서는 명령을 무의식적으로 입력하도록 지시하는 것처럼 보일 수 있습니다.,,
321,"While we want
you to follow along, we strongly encourage you to revisit this chapter after you’ve finished the book to reflect on the
commands you entered, and consider how much your understanding has grown while reading.","우리가 원하는 동안
따라 가기 바랍니다. 책을 다 읽은 후이 장을 다시 방문하여
입력 한 명령을 읽고 읽는 동안 이해가 얼마나 커 졌는지 고려하십시오.",,
322,We’ll provide instructions for setting up and testing our example on a local machine and a link to instructions for performing the same on real clusters.,로컬 머신에서 예제를 설정하고 테스트하는 방법과 실제 클러스터에서 동일한 작업을 수행하는 방법에 대한 링크를 제공합니다.,,
323,"While we will point you to the config files and OCI containers that are driving all of this, they are not the focus of
this chapter; they will be covered in detail in subsequent chapters.","이 모든 것을 주도하는 구성 파일과 OCI 컨테이너를 알려 드리지만,
이 장;다음 장에서 자세히 다룰 것입니다.",,
324,The focus of this chapter is an end-to-end example that you can follow along with at home.,이 장의 초점은 집에서 따라 할 수있는 종단 간 예제입니다.,,
325,"In future chapters we will dig into the “why” of everything we’re doing, we promise.","향후 장에서는 우리가하는 모든 일의 ""이유""를 파헤칠 것입니다. 약속합니다.",,
326,"For now, just enjoy the ride.",지금은 그냥 즐기세요.,,
327,2.1.,2.1.,,
328,"Getting Set Up with Kubeflow
One of the great things about Kubeflow being built with Kubernetes is the ability to do our initial development and exploration locally, moving into more powerful and distributed tools later on.","Kubeflow로 설정하기
Kubernetes로 구축되는 Kubeflow의 가장 큰 장점 중 하나는 로컬에서 초기 개발 및 탐색을 수행하고 나중에 더 강력하고 분산 된 도구로 이동할 수 있다는 것입니다.",,
329,Your same pipeline can be developed locally and moved into a cluster.,동일한 파이프 라인을 로컬에서 개발하고 클러스터로 이동할 수 있습니다.,,
330,"Tip
Though you could get started with Kubeflow locally, you don’t have to.","팁
Kubeflow를 로컬에서 시작할 수 있지만 그럴 필요는 없습니다.",,
331,"You can just as easily do your initial work with
one of the cloud providers or on-premises Kubernetes clusters.","다음으로 초기 작업을 쉽게 수행 할 수 있습니다.
클라우드 제공 업체 또는 온 프레미스 Kubernetes 클러스터 중 하나입니다.",,
332,One of the faster ways to get started with Kubeflow is using the click-to-deploy app on Google Cloud Platform (GCP).,Kubeflow를 시작하는 더 빠른 방법 중 하나는 Google Cloud Platform (GCP)에서 클릭하여 배포하는 앱을 사용하는 것입니다.,,
333,"If you’re in a rush to get started, go ahead and check out this Kubeflow documentation page.",서두르고 싶다면이 Kubeflow 문서 페이지를 확인하세요.,,
334,2.1.1.,2.1.1.,,
335,"Installing Kubeflow and Its Dependencies
Before we approach the biggest requirement for Kubeflow, access to a Kubernetes cluster, let’s get the tools set up.","Kubeflow 및 해당 종속성 설치
Kubeflow의 가장 큰 요구 사항 인 Kubernetes 클러스터에 대한 액세스에 접근하기 전에 도구를 설정해 보겠습니다.",,
336,Kubeflow is fairly self-contained but does require kubectl.,Kubeflow는 상당히 독립적이지만 kubectl이 필요합니다.,,
337,"The rest of the dependencies are inside containers, so you don’t have to worry about installing them.",나머지 종속성은 컨테이너 내부에 있으므로 설치에 대해 걱정할 필요가 없습니다.,,
338,"Tip
Whether you use a local or a remote Kubernetes cluster, having the development tools installed locally will simplify your life.","팁
로컬 또는 원격 Kubernetes 클러스터 사용 여부에 관계없이 개발 도구를 로컬에 설치하면 생활이 단순화됩니다.",,
339,"Regardless of your cluster, you need to install Kubeflow’s core dependency kubectl, for communicating with Kubernetes.",클러스터에 관계없이 Kubernetes와 통신하려면 Kubeflow의 핵심 종속성 kubectl을 설치해야합니다.,,
340,"kubectl is widely packaged, with the different installation options covered in the Kubernetes documentation.",kubectl은 Kubernetes 문서에서 다루는 다양한 설치 옵션과 함께 광범위하게 패키징됩니다.,,
341,"If you want to use a package manager to install kubectl, Ubuntu users can use snap (see EXAMPLE 2-1) and Mac users can use Homebrew (see EXAMPLE 2-2); other installation options are covered in the Kubernetes documentation.",패키지 관리자를 사용하여 kubectl을 설치하려는 경우 Ubuntu 사용자는 snap (예 2-1 참조)을 사용할 수 있고 Mac 사용자는 Homebrew (예 2-2 참조)를 사용할 수 있습니다.다른 설치 옵션은 Kubernetes 문서에서 다룹니다.,,
342,kubectl can also be installed as a local binary from this Kubernetes documentation page.,kubectl은이 Kubernetes 문서 페이지에서 로컬 바이너리로 설치할 수도 있습니다.,,
343,Example 2-1.,예 2-1.,,
344,"Install kubectl with snap
sudo snap install kubectl --classic

Example 2-2.","스냅으로 kubectl 설치
sudo 스냅 설치 kubectl --classic

예 2-2.",,
345,"Install kubectl with Homebrew
brew install kubernetes-cli
Once you have the minimum dependencies installed, you can now install Kubeflow from this GitHub repo, as in EXAMPLE 2-3.","Homebrew로 kubectl 설치
kubernetes-cli 설치 양조
최소 종속성을 설치했으면 이제 예제 2-3에서와 같이이 GitHub 저장소에서 Kubeflow를 설치할 수 있습니다.",,
346,Example 2-3.,예 2-3.,,
347,"Install Kubeflow
PLATFORM=$(uname) # Either Linux or Darwin
export PLATFORM
mkdir -p ~/bin
#Configuration
export KUBEFLOW_TAG=1.0.1
# ^ You can also point this to a different version if you want to try
KUBEFLOW_BASE=""https://api.github.com/repos/kubeflow/kfctl/releases""
# Or just go to https://github.com/kubeflow/kfctl/releases
KFCTL_URL=$(curl -s ${KUBEFLOW_BASE} |\
	      grep http |\
	      grep ""${KUBEFLOW_TAG}"" |\
	      grep -i ""${PLATFORM}"" |\
	      cut -d : -f 2,3 |\
	      tr -d '\"" ' )
wget ""${KFCTL_URL}""
KFCTL_FILE=${KFCTL_URL##*/}
tar -xvf ""${KFCTL_FILE}""
mv ./kfctl ~/bin/
rm ""${KFCTL_FILE}""
# It's recommended that you add the scripts directory to your path
export PATH=$PATH:~/bin
You should now have Kubeflow installed on your machine.","Kubeflow 설치
PLATFORM = $ (uname) # Linux 또는 Darwin 중 하나
플랫폼 내보내기
mkdir -p ~ / bin
# 구성
내보내기 KUBEFLOW_TAG = 1.0.1
# ^ 시도하고 싶다면 이것을 다른 버전으로 가리킬 수도 있습니다.
KUBEFLOW_BASE = ""https://api.github.com/repos/kubeflow/kfctl/releases""
# 또는 https://github.com/kubeflow/kfctl/releases로 이동하십시오.
KFCTL_URL = $ (curl -s $ {KUBEFLOW_BASE} | \
grep http | \
grep ""$ {KUBEFLOW_TAG}""| \
grep -i ""$ {플랫폼}""| \
잘라 내기 -d : -f 2,3 | \
tr -d '\ ""')
wget ""$ {KFCTL_URL}""
KFCTL_FILE = $ {KFCTL_URL ## * /}
tar -xvf ""$ {KFCTL_FILE}""
mv ./kfctl ~ / bin /
rm ""$ {KFCTL_FILE}""
# 스크립트 디렉토리를 경로에 추가하는 것이 좋습니다.
내보내기 PATH = $ PATH : ~ / bin
이제 컴퓨터에 Kubeflow가 설치되어 있어야합니다.",,
348,"To make sure it’s installed, run kfctl version and check that it returns the expected version.",설치되었는지 확인하려면 kfctl 버전을 실행하고 예상 버전을 반환하는지 확인합니다.,,
349,Now let’s cover some optional tools that you can install to ease your future Kubeflowing.,이제 향후 Kubeflowing을 용이하게하기 위해 설치할 수있는 몇 가지 선택적 도구를 살펴 보겠습니다.,,
350,2.1.2.,2.1.2.,,
351,"Setting Up Local Kubernetes
Being able to have the same software running locally and in production is one of the great advantages of Kubeflow.","로컬 Kubernetes 설정
동일한 소프트웨어를 로컬 및 프로덕션에서 실행할 수 있다는 것은 Kubeflow의 큰 장점 중 하나입니다.",,
352,"To support this, you will need a local version of Kubernetes installed.",이를 지원하려면 로컬 버전의 Kubernetes가 설치되어 있어야합니다.,,
353,"While there are several options, we find Minikube the simplest.",몇 가지 옵션이 있지만 Minikube가 가장 간단합니다.,,
354,Minikube is a local version of Kubernetes that allows you to use your local computer to simulate a cluster.,Minikube는 로컬 컴퓨터를 사용하여 클러스터를 시뮬레이션 할 수있는 Kubernetes의 로컬 버전입니다.,,
355,"Two other common options for a local version of Kubeflow are microk8s, supported on many Linux platforms, and MiniKF, which uses Vagrant to launch a VM to run Kubernetes with Kubeflow.",Kubeflow의 로컬 버전에 대한 다른 두 가지 일반적인 옵션은 많은 Linux 플랫폼에서 지원되는 microk8s와 Kubeflow로 Kubernetes를 실행하기 위해 Vagrant를 사용하여 VM을 시작하는 MiniKF입니다.,,
356,"Tip
A local Kubernetes cluster is not strictly required, but many data scientists and developers find it helpful to have a local cluster to test with.","팁
로컬 Kubernetes 클러스터가 반드시 필요한 것은 아니지만 많은 데이터 과학자와 개발자는 테스트 할 로컬 클러스터가 있으면 도움이됩니다.",,
357,2.1.2.1.,2.1.2.1.,,
358,"Minikube
Minikube is a local version of Kubernetes that can run Kubeflow.","Minikube
Minikube는 Kubeflow를 실행할 수있는 Kubernetes의 로컬 버전입니다.",,
359,There are installation guides for Minikube on the main Kubernetes documentation page as well as the Kubeflow-specific page.,기본 Kubernetes 문서 페이지와 Kubeflow 관련 페이지에 Minikube에 대한 설치 가이드가 있습니다.,,
360,The most common failure in the automatic setup of Minikube is missing a hypervisor or Docker.,Minikube의 자동 설정에서 가장 일반적인 실패는 하이퍼 바이저 또는 Docker가 누락 된 것입니다.,,
361,"Regardless of your OS, you should be able to use VirtualBox; however, other options like KVM2 on Linux, Hyper-V on Windows, and HyperKit on macOS all work as well.","OS에 관계없이 VirtualBox를 사용할 수 있어야합니다.그러나 Linux의 KVM2, Windows의 Hyper-V 및 macOS의 HyperKit과 같은 다른 옵션도 모두 작동합니다.",,
362,"Tip
When starting Minikube make sure to give it plenty of memory and disk space, e.g., minikube start --cpus 16 --memory 12g --disk-size 15g.","팁
Minikube를 시작할 때 충분한 메모리와 디스크 공간을 제공해야합니다 (예 : minikube start --cpus 16 --memory 12g --disk-size 15g).",,
363,Note: you don’t need 16 CPU cores to run this, this is just the number of virtual CPUs Minikube will use.,참고 :이 작업을 실행하는 데 16 개의 CPU 코어가 필요하지 않습니다.이것은 Minikube가 사용할 가상 CPU의 수입니다.,
364,2.1.3.,2.1.3.,,
365,"Setting Up Your Kubeflow Development Environment
Kubeflow’s pipeline system is built in Python, and having the SDK installed locally will allow you to build pipelines faster.","Kubeflow 개발 환경 설정
Kubeflow의 파이프 라인 시스템은 Python으로 빌드되며 SDK를 로컬에 설치하면 파이프 라인을 더 빠르게 빌드 할 수 있습니다.",,
366,"However, if you can’t install software locally, you can still use Kubeflow’s Jupyter environment to build your pipelines.",그러나 소프트웨어를 로컬로 설치할 수없는 경우에도 Kubeflow의 Jupyter 환경을 사용하여 파이프 라인을 구축 할 수 있습니다.,,
367,2.1.3.1.,2.1.3.1.,,
368,"Setting up the Pipeline SDK
To begin setting up the Pipeline SDK you will need to have Python installed.","파이프 라인 SDK 설정
Pipeline SDK 설정을 시작하려면 Python이 설치되어 있어야합니다.",,
369,Many people find it useful to create isolated virtual environments for their different projects, see how in EXAMPLE 2-4.,많은 사람들이 서로 다른 프로젝트를 위해 격리 된 가상 환경을 만드는 것이 유용하다고 생각합니다.예 2-4에서 방법을 참조하십시오.,
370,Example 2-4.,예 2-4.,,
371,"Create a virtual environment
virtualenv kfvenv --python python3
source kfvenv/bin/activate
Now you can use the pip command to install the Kubeflow Pipelines package and its requirements, as in EXAMPLE 2-5.","가상 환경 만들기
virtualenv kfvenv --python python3
소스 kfvenv / bin / activate
이제 pip 명령을 사용하여 예제 2-5에서와 같이 Kubeflow Pipelines 패키지 및 해당 요구 사항을 설치할 수 있습니다.",,
372,Example 2-5.,예 2-5.,,
373,"Install Kubeflow Pipeline SDK
URL=https://storage.googleapis.com/ml-pipeline/release/latest/kfp.tar.gz
pip install ""${URL}"" --upgrade
If you use a virtual environment you will need to activate it whenever you want to use the Pipeline SDK.","Kubeflow Pipeline SDK 설치
URL = https : //storage.googleapis.com/ml-pipeline/release/latest/kfp.tar.gz
pip install ""$ {URL}""-업그레이드
가상 환경을 사용하는 경우 Pipeline SDK를 사용할 때마다 활성화해야합니다.",,
374,"In addition to the SDK, Kubeflow ships a number of components.",SDK 외에도 Kubeflow는 여러 구성 요소를 제공합니다.,,
375,"Checking out a fixed version of the standard components, as in EXAMPLE 2-6, allows us to create more reliable pipelines.",예 2-6에서와 같이 표준 구성 요소의 고정 버전을 확인하면보다 안정적인 파이프 라인을 만들 수 있습니다.,,
376,Example 2-6.,예 2-6.,,
377,"Clone the Kubeflow Pipelines repo
  git clone --single-branch --branch 0.3.0 https://github.com/kubeflow/pipelines.git


2.1.3.2.","Kubeflow Pipelines 저장소 복제
  git clone --single-branch --branch 0.3.0 https://github.com/kubeflow/pipelines.git


2.1.3.2.",,
378,"Setting up Docker
Docker is an important part of the minimum requirements, allowing you to customize
and add libraries and other functionality to your own custom containers.","Docker 설정
Docker는 최소 요구 사항의 중요한 부분이므로 사용자 지정할 수 있습니다.
사용자 지정 컨테이너에 라이브러리 및 기타 기능을 추가합니다.",,
379,We’ll cover more on Docker in CHAPTER 3.,Docker에 대한 자세한 내용은 3 장에서 다룰 것입니다.,,
380,Docker can be installed from the standard package managers in Linux or with Homebrew on macOS.,Docker는 Linux의 표준 패키지 관리자 또는 macOS의 Homebrew를 통해 설치할 수 있습니다.,,
381,"In addition to installing Docker, you will want a place to store the container images, called a container registry.",Docker를 설치하는 것 외에도 컨테이너 레지스트리라고하는 컨테이너 이미지를 저장할 위치가 필요합니다.,,
382,The container registry will be accessed by your Kubeflow cluster.,컨테이너 레지스트리는 Kubeflow 클러스터에서 액세스합니다.,,
383,"The company behind Docker offers
Docker Hub and RedHat offers Quay, a cloud neutral platform you can use.","Docker가 제공하는 회사
Docker Hub 및 RedHat는 사용할 수있는 클라우드 중립 플랫폼 인 Quay를 제공합니다.",,
384,"Alternatively, you can also use your cloud provider’s container registry.",또는 클라우드 제공 업체의 컨테이너 레지스트리를 사용할 수도 있습니다.,,
385,"[1]
A cloud vendor’s specific container registry often offers greater security on images stored there and can configure your Kubernetes cluster automatically with the permissions required to fetch those images.","[1]
클라우드 공급 업체의 특정 컨테이너 레지스트리는 종종 여기에 저장된 이미지에 대해 더 높은 보안을 제공하며 해당 이미지를 가져 오는 데 필요한 권한으로 Kubernetes 클러스터를 자동으로 구성 할 수 있습니다.",,
386,"In our examples, we’ll assume that you’ve set your container registry
via an environment variable 
$CONTAINER_REGISTRY, in your shell.","이 예에서는 컨테이너 레지스트리를 설정했다고 가정합니다.
환경 변수를 통해
$ CONTAINER_REGISTRY, 쉘에서.",,
387,"Tip
If you use a registry that isn’t on the Google Cloud Platform, you will need to configure Kubeflow Pipelines container builder to have access to your registry by following the Kaniko configuration guide.","팁
Google Cloud Platform에없는 레지스트리를 사용하는 경우 Kaniko 구성 가이드에 따라 레지스트리에 액세스 할 수 있도록 Kubeflow Pipelines 컨테이너 빌더를 구성해야합니다.",,
388,"To make sure your Docker installation is properly configured, you can write a one-line Dc and push it to your
registry.","Docker 설치가 올바르게 구성되었는지 확인하려면 한 줄 Dc를 작성하고
기재.",,
389,"For the Dockerfile we’ll use the FROM command to indicate we are based on top of Kubeflow’s TensorFlow
notebook container image, as in EXAMPLE 2-7 (we’ll talk more about this in CHAPTER 9).","Dockerfile의 경우 FROM 명령을 사용하여 Kubeflow의 TensorFlow를 기반으로 함을 나타냅니다.
예제 2-7에서와 같이 노트북 컨테이너 이미지 (9 장에서 더 자세히 설명하겠습니다).",,
390,"When you push a container, you need to specify the tag, which determines the image name, version, and where it is stored—as shown in EXAMPLE 2-8.","컨테이너를 푸시 할 때 이미지 이름, 버전 및 저장 위치를 결정하는 태그를 지정해야합니다 (예 2-8 참조).",,
391,Example 2-7.,예 2-7.,,
392,"Specify the new container is built on top of Kubeflow’s container
FROM gcr.io/kubeflow-images-public/tensorflow-2.1.0-notebook-cpu:1.0.0

Example 2-8.","새 컨테이너가 Kubeflow의 컨테이너 위에 빌드되도록 지정
gcr.io/kubeflow-images-public/tensorflow-2.1.0-notebook-cpu:1.0.0에서

예 2-8.",,
393,"Build the new container and push to a registry for use
IMAGE=""${CONTAINER_REGISTRY}/kubeflow/test:v1""
docker build  -t ""${IMAGE}"" -f Dockerfile .","새 컨테이너를 빌드하고 사용을 위해 레지스트리로 푸시
IMAGE = ""$ {CONTAINER_REGISTRY} / kubeflow / test : v1""
docker build -t ""$ {IMAGE}""-f Dockerfile.",,
394,"docker push ""${IMAGE}""
With this setup, you’re now ready to start customizing the containers and components in Kubeflow to meet your needs.","도커 푸시 ""$ {IMAGE}""
이 설정을 통해 이제 Kubeflow의 컨테이너 및 구성 요소를 사용자 정의하여 요구 사항을 충족 할 준비가되었습니다.",,
395,We’ll do a deeper dive into building containers from scratch in CHAPTER 9.,9 장에서 컨테이너를 처음부터 빌드하는 방법에 대해 자세히 살펴 보겠습니다.,,
396,As we move forward in future chapters we’ll use this pattern to add tools when needed.,향후 장에서 진행할 때이 패턴을 사용하여 필요할 때 도구를 추가 할 것입니다.,,
397,2.1.3.3.,2.1.3.3.,,
398,"Editing YAML
While Kubeflow abstracts the details of Kubernetes away from us to a large degree, there are still times when looking at
or modifying the configuration is useful.","YAML 편집
Kubeflow는 Kubernetes의 세부 사항을 우리에게서 크게 추상화하지만 아직 살펴볼 때가 있습니다.
또는 구성을 수정하는 것이 유용합니다.",,
399,"Most of Kubernetes configuration is represented in YAML, so having tools set up
to easily look at and edit YAMLs will be beneficial.","대부분의 Kubernetes 구성은 YAML로 표시되므로 도구 설정
YAML을 쉽게보고 편집하는 것이 좋습니다.",,
400,"Most integrated development environments (IDEs) offer some sort of tooling for editing YAML, but you may have to install these separately.",대부분의 IDE (통합 개발 환경)는 YAML 편집을위한 일종의 도구를 제공하지만 별도로 설치해야 할 수도 있습니다.,,
401,"Tip
For IntelliJ there is a YAML plugin.","팁
IntelliJ의 경우 YAML 플러그인이 있습니다.",,
402,"For emacs there are many modes available for YAML editing, including yaml-mode (which is installable from Milkypostman’s Emacs Lisp Package Archive (MELPA)).",emacs의 경우 yaml-mode (Milkypostman의 MELPA (Emacs Lisp Package Archive)에서 설치 가능)를 포함하여 YAML 편집에 사용할 수있는 많은 모드가 있습니다.,,
403,Atom has syntax highlighting available as a package YAML.,Atom에는 패키지 YAML로 사용할 수있는 구문 강조 표시가 있습니다.,,
404,"If you use a different IDE, don’t throw it away just for better YAML editing before you explore the plugin available.",다른 IDE를 사용하는 경우 사용 가능한 플러그인을 탐색하기 전에 더 나은 YAML 편집을 위해 버리지 마십시오.,,
405,Regardless of IDE you can also use the YAMLlint website to check your YAML.,IDE에 관계없이 YAMLlint 웹 사이트를 사용하여 YAML을 확인할 수도 있습니다.,,
406,2.1.4.,2.1.4.,,
407,"Creating Our First Kubeflow Project
First, we need to make a Kubeflow project to work in.","첫 번째 Kubeflow 프로젝트 만들기
먼저 작업 할 Kubeflow 프로젝트를 만들어야합니다.",,
408,To create a Kubeflow deployment we use the kfctl program.,Kubeflow 배포를 생성하기 위해 kfctl 프로그램을 사용합니다.,,
409,"[2]
When using Kubeflow you need to specify a manifest file that configures what is built and how there are various manifests for different cloud providers.","[2]
Kubeflow를 사용할 때 빌드 된 항목과 다양한 클라우드 공급자에 대한 다양한 매니페스트가있는 방법을 구성하는 매니페스트 파일을 지정해야합니다.",,
410,"We’ll start with an example project using a vanilla configuration, as seen in EXAMPLE 2-9.",예제 2-9에서 볼 수 있듯이 바닐라 구성을 사용하는 예제 프로젝트로 시작합니다.,,
411,In this project we’ll build a simple end-to-end pipeline for our MNIST example.,이 프로젝트에서는 MNIST 예제를위한 간단한 종단 간 파이프 라인을 구축합니다.,,
412,We chose this example because it’s the standard “hello world” of machine learning.,이 예는 머신 러닝의 표준 'hello world'이기 때문에 선택했습니다.,,
413,Example 2-9.,예 2-9.,,
414,"Create first example project
# Pick the correct config file for your platform from
# https://github.com/kubeflow/manifests/tree/[version]/kfdef
# You can download and edit the configuration at this point if you need to.","첫 번째 예제 프로젝트 만들기
# 플랫폼에 맞는 올바른 구성 파일을 선택하십시오.
# https://github.com/kubeflow/manifests/tree/ [버전] / kfdef
# 필요한 경우이 시점에서 구성을 다운로드하고 편집 할 수 있습니다.",,
415,"# For generic Kubernetes with Istio:
MANIFEST_BRANCH=${MANIFEST_BRANCH:-v1.0-branch}
export MANIFEST_BRANCH
MANIFEST_VERSION=${MANIFEST_VERSION:-v1.0.1}
export MANIFEST_VERSION

KF_PROJECT_NAME=${KF_PROJECT_NAME:-hello-kf-${PLATFORM}}
export KF_PROJECT_NAME
mkdir ""${KF_PROJECT_NAME}""
pushd ""${KF_PROJECT_NAME}""

manifest_root=https://raw.githubusercontent.com/kubeflow/manifests/
# On most environments this will create a ""vanilla"" Kubeflow install using Istio.","# Istio를 사용하는 일반 Kubernetes의 경우 :
MANIFEST_BRANCH = $ {MANIFEST_BRANCH : -v1.0-branch}
MANIFEST_BRANCH 내보내기
MANIFEST_VERSION = $ {MANIFEST_VERSION : -v1.0.1}
MANIFEST_VERSION 내보내기

KF_PROJECT_NAME = $ {KF_PROJECT_NAME : -hello-kf-$ {PLATFORM}}
KF_PROJECT_NAME 내보내기
mkdir ""$ {KF_PROJECT_NAME}""
""$ {KF_PROJECT_NAME}""을 푸시했습니다.

manifest_root = https : //raw.githubusercontent.com/kubeflow/manifests/
# 대부분의 환경에서 Istio를 사용하여 ""바닐라""Kubeflow 설치를 생성합니다.",,
416,"FILE_NAME=kfctl_k8s_istio.${MANIFEST_VERSION}.yaml
KFDEF=${manifest_root}${MANIFEST_BRANCH}/kfdef/${FILE_NAME}
kfctl apply -f $KFDEF -V
echo $?","FILE_NAME = kfctl_k8s_istio. $ {MANIFEST_VERSION} .yaml
KFDEF = $ {manifest_root} $ {MANIFEST_BRANCH} / kfdef / $ {FILE_NAME}
kfctl 적용 -f $ KFDEF -V
에코 $?",,
417,"popd
EXAMPLE 2-9 assumes you’re using an existing Kubernetes cluster (like local Minikube).","팝
예 2-9에서는 기존 Kubernetes 클러스터 (예 : 로컬 Minikube)를 사용하고 있다고 가정합니다.",,
418,While your running kfctl apply you will see lots of status messages and maybe even some error messages.,실행중인 kfctl이 적용되는 동안 많은 상태 메시지와 일부 오류 메시지가 표시 될 것입니다.,,
419,Provided it prints out a 0 at the end you can safely ignore most errors as they are automatically retried.,마지막에 0을 출력한다면 대부분의 오류는 자동으로 다시 시도되므로 무시해도됩니다.,,
420,"Warning
This deployment process can take up to 30 minutes.","경고
이 배포 프로세스는 최대 30 분이 소요될 수 있습니다.",,
421,"If you’ve decided to go straight ahead with a cloud provider, the Kubeflow installation guide has information on how to get started.",클라우드 제공 업체를 이용하기로 결정했다면 Kubeflow 설치 가이드에 시작 방법에 대한 정보가 있습니다.,,
422,"Warning
The Kubeflow user interface can come up before Kubeflow is fully deployed, and accessing it then can mean you won’t have a proper namespace.","경고
Kubeflow 사용자 인터페이스는 Kubeflow가 완전히 배포되기 전에 표시 될 수 있으며 액세스하면 적절한 네임 스페이스가 없을 수 있습니다.",,
423,"To make sure Kubeflow is ready, run kubectl get pods --all-namespaces -w and wait for all of the pods to become RUNNING or COMPLETED.",Kubeflow가 준비되었는지 확인하려면 kubectl get pods --all-namespaces -w를 실행하고 모든 포드가 RUNNING 또는 COMPLETED가 될 때까지 기다립니다.,,
424,"If you see pods being preempted, make sure you launched a cluster with enough RAM and disk space.",포드가 선점되는 경우 RAM과 디스크 공간이 충분한 클러스터를 시작했는지 확인하세요.,,
425,"If you can’t launch a large enough cluster locally, consider a cloud provider.",로컬에서 충분히 큰 클러스터를 시작할 수없는 경우 클라우드 제공 업체를 고려하십시오.,,
426,(Ilan and Holden are currently working on a blog post on this topic.),(Ilan과 Holden은 현재이 주제에 대한 블로그 게시물을 작성 중입니다.),,
427,2.2.,2.2.,,
428,"Training and Deploying a Model
In traditional machine learning texts, the training phase is the one that is given the most attention, with a few simple
examples on deployment, and very little treatment of model management.","모델 훈련 및 배포
전통적인 기계 학습 텍스트에서 훈련 단계는 몇 가지 간단한 방법으로 가장주의를 기울이는 단계입니다.
배포에 대한 예제, 모델 관리에 대한 처리가 거의 없습니다.",,
429,"Throughout this book, we assume that you are a data scientist who knows how to select the correct model/algorithm or work with someone who does.",이 책에서 우리는 당신이 올바른 모델 / 알고리즘을 선택하는 방법을 알고 있거나 그렇게하는 사람과 함께 작업하는 방법을 알고있는 데이터 과학자라고 가정합니다.,,
430,We focus on the deployment and model management more than traditional ML texts.,우리는 기존 ML 텍스트보다 배포 및 모델 관리에 더 중점을 둡니다.,,
431,2.2.1.,2.2.1.,,
432,"Training and Monitoring Progress
The next step is to train the model using a Kubeflow Pipeline.","교육 및 모니터링 진행
다음 단계는 Kubeflow 파이프 라인을 사용하여 모델을 학습시키는 것입니다.",,
433,We will use a precreated training container[3] that downloads the training data and trains the model.,훈련 데이터를 다운로드하고 모델을 훈련시키는 사전 생성 된 훈련 컨테이너 [3]를 사용합니다.,,
434,"For EXAMPLE 2-10, we have a prebuilt workflow in train_pipeline.py that trains a RandomForestClassifier in the ch2 folder on this book’s GitHub example repo.",예제 2-10의 경우이 책의 GitHub 예제 저장소에있는 ch2 폴더에서 RandomForestClassifier를 훈련시키는 train_pipeline.py에 미리 빌드 된 워크 플로가 있습니다.,,
435,Example 2-10.,예 2-10.,,
436,"Create training workflow example
dsl-compile --py train_pipeline.py --output job.yaml
If you run into problems here, you should check out the Kubeflow troubleshooting guide.","교육 워크 플로 예제 만들기
dsl-compile --py train_pipeline.py --output job.yaml
여기에서 문제가 발생하면 Kubeflow 문제 해결 가이드를 확인해야합니다.",,
437,"The Kubeflow UI, as seen in FIGURE 2-1, is accessed in a few different ways.",그림 2-1에 표시된 Kubeflow UI는 몇 가지 다른 방법으로 액세스됩니다.,,
438,For local deployments a quick port forward is the simplest way to get started: just run kubectl port-forward svc/istio-ingressgateway -n istio-system 7777:80 and then go to localhost:7777.,로컬 배포의 경우 빠른 포트 전달이 시작하는 가장 간단한 방법입니다. kubectl port-forward svc / istio-ingressgateway -n istio-system 7777 : 80을 실행 한 다음 localhost : 7777로 이동하면됩니다.,,
439,If you have deployed on GCP you should go to https://<deployment_name>.endpoints.<project_name>.cloud.goog.,GCP에 배포 한 경우 https : // <deployment_name> .endpoints. <project_name> .cloud.goog로 이동해야합니다.,,
440,"Otherwise, you can get the address of the gateway service by running kubectl get ingress -n istio-system.",그렇지 않으면 kubectl get ingress -n istio-system을 실행하여 게이트웨이 서비스의 주소를 가져올 수 있습니다.,,
441,Figure 2-1.,그림 2-1.,,
442,"Kubeflow web UI

Click pipelines, or add _/pipeline/ to the root URL and you should see the Pipelines web UI, as in FIGURE 2-2.","Kubeflow 웹 UI

파이프 라인을 클릭하거나 루트 URL에 _ / pipeline /을 추가하면 그림 2-2와 같이 Pipelines 웹 UI가 표시됩니다.",,
443,Figure 2-2.,그림 2-2.,,
444,"Pipelines web UI

From here we can upload our pipeline.","파이프 라인 웹 UI

여기에서 파이프 라인을 업로드 할 수 있습니다.",,
445,Once we’ve uploaded the pipeline we can use the same web UI to create a run of the pipeline.,파이프 라인을 업로드하면 동일한 웹 UI를 사용하여 파이프 라인 실행을 만들 수 있습니다.,,
446,"After you click the uploaded pipeline you’ll be able to create a run, as shown in FIGURE 2-3.",업로드 된 파이프 라인을 클릭하면 그림 2-3과 같이 실행을 생성 할 수 있습니다.,,
447,Figure 2-3.,그림 2-3.,,
448,"Pipeline detail page



2.2.2.","파이프 라인 세부 정보 페이지



2.2.2.",,
449,"Test Query
Finally, let’s query our model and monitor the results.","테스트 쿼리
마지막으로 모델을 쿼리하고 결과를 모니터링하겠습니다.",,
450,"A “sanity check” is a simple test to ensure our model is making
predictions that are theoretically reasonable.","""건전성 검사""는 모델이
이론적으로 합리적인 예측.",,
451,"For example—we’re attempting to guess what digit
was written.","예를 들어, 우리는 어떤 자릿수를 추측하려고합니다.
작성되었습니다.",,
452,"If our model comes back with answers like 77, orange Kool-Aid, or ERROR, those would all fail the sanity
check.","우리 모델이 77, 주황색 Kool-Aid 또는 ERROR와 같은 답변으로 돌아 오면 모두 정상에 실패 할 것입니다.
검사.",,
453,We expect to see digits between 0 and 9.,0에서 9 사이의 숫자가 표시 될 것으로 예상됩니다.,,
454,"Sanity checking models before putting them into production is always a
wise choice.","모델을 생산에 투입하기 전에 온 전성 검사 모델은 항상
현명한 선택.",,
455,The web UI and model serving are exposed through the same Istio gateway.,웹 UI 및 모델 제공은 동일한 Istio 게이트웨이를 통해 노출됩니다.,,
456,"So, the model will be available at http://<WEBUI_URL>/seldon<mnist-classifier/api<v0.1/predictions.",따라서 모델은 http : // <WEBUI_URL> / seldon <mnist-classifier / api <v0.1 / predictions에서 사용할 수 있습니다.,,
457,"If you’re using Google IAP, you may find the iap_curl project helpful for making requests.",Google IAP를 사용하는 경우 iap_curl 프로젝트가 요청에 도움이 될 수 있습니다.,,
458,"There is a Python script available for pulling an image from the MNIST dataset, turning it into a vector, displaying the image, and sending it to the model.",MNIST 데이터 세트에서 이미지를 가져 와서 벡터로 변환하고 이미지를 표시하고 모델로 보내는 데 사용할 수있는 Python 스크립트가 있습니다.,,
459,Turning the image into a vector is normally part of the preprediction transformation, we’ll cover more of this in CHAPTER 8.,이미지를 벡터로 바꾸는 것은 일반적으로 예측 변환의 일부입니다.이에 대해서는 8 장에서 더 다룰 것입니다.,
460,EXAMPLE 2-11 is a fairly clear Python example of how one can query the model.,예제 2-11은 모델을 쿼리하는 방법에 대한 상당히 명확한 Python 예제입니다.,,
461,The model returns a JSON of the 10 digits and the probability of whether the submitted vector represents a specific digit.,모델은 10 자리의 JSON과 제출 된 벡터가 특정 숫자를 나타내는 지 여부를 반환합니다.,,
462,"Specifically, we need an image of a handwritten digit that we can turn into an array of values.","특히, 값 배열로 바꿀 수있는 손으로 쓴 숫자의 이미지가 필요합니다.",,
463,Example 2-11.,예 2-11.,,
464,"Model query example
import requests
import numpy as np

from tensorflow.examples.tutorials.mnist import input_data
from matplotlib import pyplot as plt

def download_mnist():
    return input_data.read_data_sets(""MNIST_data/"", one_hot=True)


def gen_image(arr):
    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)
    plt.imshow(two_d, cmap=plt.cm.gray_r, interpolation='nearest')
    return plt
mnist = download_mnist()
batch_xs, batch_ys = mnist.train.next_batch(1)
chosen = 0
gen_image(batch_xs[chosen]).show()
data = batch_xs[chosen].reshape((1, 784))
features = [""X"" + str(i + 1) for i in range(0, 784)]
request = {""data"": {""names"": features, ""ndarray"": data.tolist()}}
deploymentName = ""mnist-classifier""
uri = ""http://"" + AMBASSADOR_API_IP + ""/seldon/"" + \
    deploymentName + ""/api/v0.1/predictions""

response = requests.post(uri, json=request)
For example, see the handwritten 3 in FIGURE 2-4.","모델 쿼리 예
수입 요청
numpy를 np로 가져 오기

tensorflow.examples.tutorials.mnist에서 import input_data
matplotlib에서 pyplot을 plt로 가져 오기

def download_mnist () :
    return input_data.read_data_sets ( ""MNIST_data /"", one_hot = True)


def gen_image (arr) :
    two_d = (np.reshape (arr, (28, 28)) * 255) .astype (np.uint8)
    plt.imshow (two_d, cmap = plt.cm.gray_r, 보간 = 'nearest')
    반환 plt
mnist = download_mnist ()
batch_xs, batch_ys = mnist.train.next_batch (1)
선택됨 = 0
gen_image (batch_xs [chosen]). show ()
데이터 = batch_xs [chosen] .reshape ((1, 784))
기능 = [ ""X""+ str (i + 1) for i in range (0, 784)]
요청 = { ""data"": { ""names"": 기능, ""ndarray"": data.tolist ()}}
deploymentName = ""mnist-classifier""
uri = ""http : //""+ AMBASSADOR_API_IP + ""/ seldon /""+ \
    deploymentName + ""/api/v0.1/predictions""

응답 = requests.post (uri, json = request)
예를 들어 그림 2-4의 손으로 쓴 3을 참조하십시오.",,
465,Figure 2-4.,그림 2-4.,,
466,"Handwritten 3

This returns the following:
{'data': {'names': ['class:0',
		    'class:1',
		    'class:2',
		    'class:3',
		    'class:4',
		    'class:5',
		    'class:6',
		    'class:7',
		    'class:8',
		    'class:9'],
	  'ndarray':[[0.03333333333333333,
		      0.26666666666666666,
		      0.03333333333333333,
		      0.13333333333333333, ## It was actually this
		      0.1,
		      0.06666666666666667,
		      0.1,
		      0.26666666666666666,
		      0.0,
		      0.0]]},
 'meta': {'puid': 'tb02ff58vcinl82jmkkoe80u4r', 'routing': {}, 'tags': {}}}
We can see that even though we wrote a pretty clear 3, the model’s best guess was a tie between 1 and 7.","필기 3

다음을 반환합니다.
{ '데이터': { '이름': [ '클래스 : 0',
'클래스 : 1',
'클래스 : 2',
'클래스 : 3',
'클래스 : 4',
'클래스 : 5',
'클래스 : 6',
'클래스 : 7',
'클래스 : 8',
'class : 9'],
'ndarray': [[0.03333333333333333,
0.26666666666666666,
0.03333333333333333,
0.13333333333333333, ## 사실 이건
0.1,
0.06666666666666667,
0.1,
0.26666666666666666,
0.0,
0.0]]},
 'meta': { 'puid': 'tb02ff58vcinl82jmkkoe80u4r', 'routing': {}, 'tags': {}}}
우리가 꽤 명확한 3을 썼지 만 모델의 최선의 추측은 1과 7 사이의 동점임을 알 수 있습니다.",,
467,"That
being said, RandomForestClassifier is a bad model for handwriting recognition—so this isn’t a surprising result.","그
RandomForestClassifier는 손글씨 인식에 좋지 않은 모델이므로 놀라운 결과가 아닙니다.",,
468,"We used RandomForestClassifier for two reasons: first, to illustrate model explainability in CHAPTER 8, and second, so you can experiment with a more reasonable model and compare performance.",두 가지 이유로 RandomForestClassifier를 사용했습니다. 첫 번째는 8 장의 모델 설명 가능성을 설명하기위한 것이고 두 번째는 더 합리적인 모델로 실험하고 성능을 비교할 수 있습니다.,,
469,"Note
While we’ve deployed our end-to-end example here without any real validation, you should always validate before real production.","노트
여기에서는 실제 검증없이 엔드 투 엔드 예제를 배포했지만 항상 실제 프로덕션 전에 검증해야합니다.",,
470,2.3.,2.3.,,
471,"Going Beyond a Local Deployment
Some of you have been trying this out on a local Kubernetes deployment.","로컬 배포를 넘어서
여러분 중 일부는 로컬 Kubernetes 배포에서 이것을 시도해 왔습니다.",,
472,One of the powers of Kubeflow is the ability to scale using Kubernetes.,Kubeflow의 강점 중 하나는 Kubernetes를 사용하여 확장 할 수있는 기능입니다.,,
473,"Kubernetes can run on a single machine or many computers, and some environments can dynamically add more resources as needed.",Kubernetes는 단일 머신 또는 여러 컴퓨터에서 실행될 수 있으며 일부 환경에서는 필요에 따라 더 많은 리소스를 동적으로 추가 할 수 있습니다.,,
474,"While Kubernetes is an industry standard, there are variations in Kubeflow’s setup steps required depending on your provider.",Kubernetes는 산업 표준이지만 제공 업체에 따라 필요한 Kubeflow의 설정 단계가 다양합니다.,,
475,"Kubeflow’s getting started guide has installation instructions for GCP, AWS, Azure, IBM Cloud, and OpenShift.","Kubeflow의 시작 가이드에는 GCP, AWS, Azure, IBM Cloud, OpenShift에 대한 설치 지침이 있습니다.",,
476,"Once Kubeflow is installed on your Kubernetes cluster, you can try this same example again and see how the same code can run, or take our word for it and move on to more interesting problems.",Kubeflow가 Kubernetes 클러스터에 설치되면 동일한 예제를 다시 시도하여 동일한 코드가 어떻게 실행되는지 확인하거나 우리의 말을 듣고 더 흥미로운 문제로 이동할 수 있습니다.,,
477,"Tip
When deploying on cloud providers, Kubeflow can create more than just Kubernetes resources that should be deleted too.","팁
클라우드 제공 업체에 배포 할 때 Kubeflow는 삭제해야하는 Kubernetes 리소스 이상을 생성 할 수 있습니다.",,
478,"For example, on Google you can delete the ancillary services by going to the deployment manager.",예를 들어 Google에서는 배치 관리자로 이동하여 보조 서비스를 삭제할 수 있습니다.,,
479,2.4.,2.4.,,
480,"Conclusion
In this chapter, you got your first real taste of Kubeflow.","결론
이 장에서는 Kubeflow를 처음으로 맛 보았습니다.",,
481,You now have your development environment properly configured and a Kubeflow deployment you can use throughout the rest of this book.,이제 개발 환경이 올바르게 구성되었으며이 책의 나머지 부분에서 사용할 수있는 Kubeflow 배포가 있습니다.,,
482,"We covered a simple end-to-end example with the standard MNIST, allowing you to see the different core components of Kubeflow in action.",표준 MNIST를 사용하여 간단한 엔드 투 엔드 예제를 다루었으므로 Kubeflow의 다양한 핵심 구성 요소가 작동하는 것을 볼 수 있습니다.,,
483,"We introduced the pipeline, which ties all of Kubeflow together, and you used it to train your model.",모든 Kubeflow를 하나로 묶는 파이프 라인을 도입했으며이를 사용하여 모델을 학습 시켰습니다.,,
484,In CHAPTER 3 we will explore Kubeflow’s design and set up some optional components.,3 장에서는 Kubeflow의 디자인을 살펴보고 몇 가지 선택적 구성 요소를 설정합니다.,,
485,Understanding the design will help you choose the right components.,디자인을 이해하면 올바른 구성 요소를 선택하는 데 도움이됩니다.,,
486,[1] Just search “cloudname” plus the container registry name for documentation.,"[1] 문서를 보려면 ""cloudname""과 컨테이너 레지스트리 이름을 검색하십시오.",,
487,[2] Not to be confused with the legacy kfctl.sh script.,[2] 레거시 kfctl.sh 스크립트와 혼동하지 마십시오.,,
488,[3] The container is from this GitHub repo.,[3] 컨테이너는이 GitHub 저장소에서 가져옵니다.,,
489,Chapter 3.,3 장.,,
490,"Kubeflow Design: Beyond the Basics
You made it through two chapters.","Kubeflow 디자인 : 기본을 넘어서
당신은 두 장을 통해 그것을 만들었습니다.",,
491,Well done.,잘 했어.,,
492,So far you have decided to learn Kubeflow and worked through a simple example.,지금까지 Kubeflow를 배우기로 결정하고 간단한 예제를 통해 작업했습니다.,,
493,Now we want to take a step back and look at each component in detail.,이제 한 걸음 물러나서 각 구성 요소를 자세히 살펴 보겠습니다.,,
494,FIGURE 3-1 shows the main Kubeflow components and the role they play in the overall architecture.,그림 3-1은 주요 Kubeflow 구성 요소와 전체 아키텍처에서 수행하는 역할을 보여줍니다.,,
495,Figure 3-1.,그림 3-1.,,
496,"Kubeflow architecture

Essentially, we’ll look at the core elements that make up our example deployment as well as the supporting pieces.","Kubeflow 아키텍처

기본적으로 예제 배포를 구성하는 핵심 요소와 지원 부분을 살펴 보겠습니다.",,
497,"In the chapters that follow, we will dig into each of these sections in greater depth.",이어지는 장에서는 이러한 각 섹션을 더 자세히 살펴볼 것입니다.,,
498,"That said, let’s get started.","즉, 시작하겠습니다.",,
499,3.1.,3.1.,,
500,"Getting Around the Central Dashboard
Your main interface to Kubeflow is the central dashboard (see FIGURE 3-2), which allows you to access the majority of Kubeflow components.","중앙 대시 보드 둘러보기
Kubeflow에 대한 기본 인터페이스는 대부분의 Kubeflow 구성 요소에 액세스 할 수있는 중앙 대시 보드 (그림 3-2 참조)입니다.",,
501,"Depending on your Kubernetes provider, it might take up to half an hour to have your ingress become available.",Kubernetes 공급자에 따라 수신을 사용할 수있게되는 데 최대 30 분 정도 걸릴 수 있습니다.,,
502,Figure 3-2.,그림 3-2.,,
503,"The central dashboard

Note
While it is meant to be automatic, if you don’t have a namespace created for your work, follow Kubeflow’s “Manual profile creation” instructions.","중앙 대시 보드

노트
자동으로 만들어졌지만 작업을 위해 생성 된 네임 스페이스가없는 경우 Kubeflow의 ""수동 프로필 생성""지침을 따르십시오.",,
504,"From the home page of the central dashboard you can access Kubeflow’s Pipelines, Notebooks, Katib (hyperparameter tuning), and the artifact store.","중앙 대시 보드의 홈 페이지에서 Kubeflow의 파이프 라인, 노트북, Katib (초 매개 변수 조정) 및 아티팩트 저장소에 액세스 할 수 있습니다.",,
505,We will cover the design of these components and how to use them next.,이러한 구성 요소의 디자인과 사용 방법을 다음에 다룹니다.,,
506,3.1.1.,3.1.1.,,
507,"Notebooks (JupyterHub)
The first step of most projects is some form of prototyping and experimentation.","노트북 (JupyterHub)
대부분의 프로젝트의 첫 번째 단계는 일종의 프로토 타이핑 및 실험입니다.",,
508,"Kubeflow’s tool for this purpose is JupyterHub—a multiuser hub that spawns, manages, and proxies multiple instances of a single-user Jupyter notebook.","이를위한 Kubeflow의 도구는 단일 사용자 Jupyter 노트북의 여러 인스턴스를 생성, 관리, 프록시하는 다중 사용자 허브 인 JupyterHub입니다.",,
509,"Jupyter notebooks support the whole computation process: developing, documenting, and executing code, as well as communicating the results.","Jupyter 노트북은 코드 개발, 문서화 및 실행과 결과 전달 등 전체 계산 프로세스를 지원합니다.",,
510,"To access JupyterHub, go to the main Kubeflow page and click the notebook button.",JupyterHub에 액세스하려면 기본 Kubeflow 페이지로 이동하여 노트북 버튼을 클릭합니다.,,
511,"On the notebook page, you can connect to existing servers or create a new one.",노트북 페이지에서 기존 서버에 연결하거나 새 서버를 만들 수 있습니다.,,
512,"To create a new server, you need to specify the server name and namespace, pick an image (from CPU optimized, GPU optimized, or a custom image that you can create), and specify resource requirements—CPU/memory, workspace, data volumes, custom configuration, and so on.","새 서버를 생성하려면 서버 이름과 네임 스페이스를 지정하고 이미지 (CPU 최적화, GPU 최적화 또는 생성 할 수있는 사용자 지정 이미지에서)를 선택하고 리소스 요구 사항 (CPU / 메모리, 작업 영역, 데이터 볼륨)을 지정해야합니다., 사용자 정의 구성 등.",,
513,"Once the server is created, you can connect to it and start creating and editing notebooks.",서버가 생성되면 여기에 연결하여 노트북 생성 및 편집을 시작할 수 있습니다.,,
514,"In order to allow data scientists to do cluster operations without leaving the notebook’s environment, Kubeflow adds
kubectl to the provided notebook images, which allows developers to use notebooks to create and manage Kubernetes resources.","데이터 과학자가 노트북 환경을 벗어나지 않고도 클러스터 작업을 수행 할 수 있도록 Kubeflow는
kubectl을 제공된 노트북 이미지에 추가하면 개발자가 노트북을 사용하여 Kubernetes 리소스를 만들고 관리 할 수 있습니다.",,
515,"The Jupyter notebook pods run under a special service account default-editor, which has namespace-scoped permissions to the following Kubernetes resources:


Pods


Deployments


Services


Jobs


TFJobs


PyTorchJobs


You can bind this account to a custom role, in order to limit/extend permissions of the notebook server.","Jupyter 노트북 포드는 다음 Kubernetes 리소스에 대한 네임 스페이스 범위 권한이있는 특수 서비스 계정 default-editor에서 실행됩니다.


포드


배포


서비스


직업


TFJobs


PyTorchJobs


노트북 서버의 권한을 제한 / 확장하기 위해이 계정을 사용자 지정 역할에 바인딩 할 수 있습니다.",,
516,This allows notebook developers to execute all of the (allowed by role) Kubernetes commands without leaving the notebook environment.,이를 통해 노트북 개발자는 노트북 환경을 벗어나지 않고도 모든 (역할에 의해 허용되는) Kubernetes 명령을 실행할 수 있습니다.,,
517,"For example, the creation of a new Kubernetes resource can be done by running the following command directly in a Jupyter notebook:
!kubectl create -f myspec.yaml
The contents of your yaml file will determine what resource is created.","예를 들어 Jupyter 노트북에서 직접 다음 명령어를 실행하여 새 Kubernetes 리소스를 생성 할 수 있습니다.
! kubectl create -f myspec.yaml
yaml 파일의 내용에 따라 생성되는 리소스가 결정됩니다.",,
518,"If you’re not used to making Kubernetes resources, don’t worry—Kubeflow’s pipelines include tools to make them for you.",Kubernetes 리소스를 만드는 데 익숙하지 않더라도 걱정하지 마십시오. Kubeflow의 파이프 라인에는이를위한 도구가 포함되어 있습니다.,,
519,"To further increase Jupyter capabilities, Kubeflow also provides support in the notebooks for such important Kubeflow components as Pipelines and metadata management (described later in SECTION 3.1.6).",Jupyter 기능을 더욱 향상시키기 위해 Kubeflow는 파이프 라인 및 메타 데이터 관리와 같은 중요한 Kubeflow 구성 요소에 대한 노트북 지원도 제공합니다 (섹션 3.1.6에서 설명).,,
520,Jupyter notebooks can also directly launch distributed training jobs.,Jupyter 노트북은 분산 된 학습 작업을 직접 시작할 수도 있습니다.,,
521,3.1.2.,3.1.2.,,
522,"Training Operators
JupyterHub is a great tool for initial experimentation with the data and prototyping ML jobs.","교육 운영자
JupyterHub는 데이터를 사용한 초기 실험 및 ML 작업 프로토 타이핑을위한 훌륭한 도구입니다.",,
523,"However, when moving to train in production, Kubeflow provides several training components to automate the execution of machine learning algorithms, including:


Chainer training


MPI training


Apache MXNet training


PyTorch training


TensorFlow training


In Kubeflow, distributed training jobs are managed by application-specific controllers, known as operators.","그러나 프로덕션 교육으로 이동할 때 Kubeflow는 다음을 포함하여 기계 학습 알고리즘의 실행을 자동화하는 여러 교육 구성 요소를 제공합니다.


Chainer 교육


MPI 교육


Apache MXNet 교육


PyTorch 교육


TensorFlow 교육


Kubeflow에서 분산 훈련 작업은 운영자라고하는 애플리케이션 별 컨트롤러에 의해 관리됩니다.",,
524,"These operators extend the Kubernetes APIs to create, manage, and manipulate the state of resources.","이러한 연산자는 Kubernetes API를 확장하여 리소스 상태를 생성, 관리 및 조작합니다.",,
525,"For example, to run a distributed TensorFlow training job, the user just needs to provide a specification that describes the desired state (number of workers and parameter servers, etc.",예를 들어 분산 형 TensorFlow 학습 작업을 실행하려면 사용자가 원하는 상태 (작업자 및 매개 변수 서버 수 등)를 설명하는 사양 만 제공하면됩니다.,,
526,"), and the TensorFlow operator component will take care of the rest and manage the life cycle of the training job.","), TensorFlow 연산자 구성 요소가 나머지를 처리하고 학습 작업의 수명주기를 관리합니다.",,
527,"These operators allow the automation of important deployment concepts such as scalability, observability, and failover.","이러한 운영자를 통해 확장 성, 관찰 가능성 및 장애 조치와 같은 중요한 배포 개념을 자동화 할 수 있습니다.",,
528,They can also be used by pipelines to chain their execution with the execution of other components of the system.,또한 파이프 라인에서 실행을 시스템의 다른 구성 요소 실행과 연결하는 데 사용할 수도 있습니다.,,
529,3.1.3.,3.1.3.,,
530,"Kubeflow Pipelines
In addition to providing specialized parameters implementing specific functionality, Kubeflow has Pipelines, which allows you to orchestrate the execution of machine learning applications.","Kubeflow 파이프 라인
특정 기능을 구현하는 특수 매개 변수를 제공하는 것 외에도 Kubeflow에는 파이프 라인이있어 기계 학습 애플리케이션의 실행을 조율 할 수 있습니다.",,
531,"This implementation is based on
Argo Workflows, an open source, container-native workflow engine for Kubernetes.","이 구현은
Argo Workflows는 Kubernetes 용 오픈 소스 컨테이너 네이티브 워크 플로 엔진입니다.",,
532,Kubeflow installs all of the Argo components.,Kubeflow는 모든 Argo 구성 요소를 설치합니다.,,
533,"At a high level, the execution of a pipeline contains the following
components:

Python SDK

You create components or specify a pipeline using the Kubeflow Pipelines  domain-specific language (DSL).","높은 수준에서 파이프 라인 실행에는 다음이 포함됩니다.
구성 요소 :

Python SDK

Kubeflow Pipelines 도메인 별 언어 (DSL)를 사용하여 구성 요소를 생성하거나 파이프 라인을 지정합니다.",,
534,"DSL compiler

The DSL compiler transforms your pipeline’s Python code into a static configuration (YAML).","DSL 컴파일러

DSL 컴파일러는 파이프 라인의 Python 코드를 정적 구성 (YAML)으로 변환합니다.",,
535,"Pipeline Service

The Pipeline Service creates a pipeline run from the static configuration.","파이프 라인 서비스

파이프 라인 서비스는 정적 구성에서 실행되는 파이프 라인을 생성합니다.",,
536,"Kubernetes resources

The Pipeline Service calls the Kubernetes API server to create the necessary Kubernetes custom resource definitions (CRDs) to run the pipeline.","Kubernetes 리소스

파이프 라인 서비스는 Kubernetes API 서버를 호출하여 파이프 라인을 실행하는 데 필요한 Kubernetes 사용자 지정 리소스 정의 (CRD)를 만듭니다.",,
537,"Orchestration controllers

A set of orchestration controllers execute the containers needed to complete the pipeline execution specified by the Kubernetes resources (CRDs).","오케스트레이션 컨트롤러

오케스트레이션 컨트롤러 세트는 Kubernetes 리소스 (CRD)에서 지정한 파이프 라인 실행을 완료하는 데 필요한 컨테이너를 실행합니다.",,
538,The containers execute within Kubernetes Pods on virtual machines.,컨테이너는 가상 머신의 Kubernetes 포드 내에서 실행됩니다.,,
539,"An example controller is the Argo Workflow controller, which orchestrates task-driven workflows.",예제 컨트롤러는 작업 중심 워크 플로를 조정하는 Argo Workflow 컨트롤러입니다.,,
540,"Artifact storage

The Kubernetes Pods store two kinds of data:

Metadata

Experiments, jobs, runs, single scalar metrics (generally aggregated for the purposes of sorting and filtering), etc.","아티팩트 저장소

Kubernetes Pod는 두 가지 종류의 데이터를 저장합니다.

메타 데이터

실험, 작업, 실행, 단일 스칼라 메트릭 (일반적으로 정렬 및 필터링을 위해 집계 됨) 등",,
541,Kubeflow Pipelines stores the metadata in a MySQL database.,Kubeflow Pipelines는 메타 데이터를 MySQL 데이터베이스에 저장합니다.,,
542,"Artifacts

Pipeline packages, views, large-scale metrics like time series (usually used for investigating an individual run’s performance and for debugging), etc.","아티팩트

파이프 라인 패키지,보기, 시계열과 같은 대규모 측정 항목 (일반적으로 개별 실행의 성능 조사 및 디버깅에 사용됨) 등",,
543,"Kubeflow Pipelines stores the artifacts in an artifact store like
MinIO server,
Google Cloud Storage (GCS),
or Amazon S3.","Kubeflow Pipelines는 다음과 같은 아티팩트 저장소에 아티팩트를 저장합니다.
MinIO 서버,
Google Cloud Storage (GCS),
또는 Amazon S3.",,
544,Kubeflow Pipelines gives you the ability to make your machine learning jobs repeatable and handle new data.,Kubeflow Pipelines는 기계 학습 작업을 반복 가능하게 만들고 새로운 데이터를 처리 할 수있는 기능을 제공합니다.,,
545,It provides an intuitive DSL in Python to write your pipelines with.,파이프 라인을 작성하기 위해 Python에서 직관적 인 DSL을 제공합니다.,,
546,Your pipelines are then compiled down to an existing Kubernetes workflow engine (currently Argo Workflows).,그런 다음 파이프 라인은 기존 Kubernetes 워크 플로 엔진 (현재 Argo Workflows)으로 컴파일됩니다.,,
547,Kubeflow’s pipeline components make it easy to use and coordinate the different tools required to build an end-to-end machine learning project.,Kubeflow의 파이프 라인 구성 요소를 사용하면 엔드 투 엔드 머신 러닝 프로젝트를 빌드하는 데 필요한 다양한 도구를 쉽게 사용하고 조정할 수 있습니다.,,
548,"On top of that, Kubeflow can track both data and metadata, improving how we can understand our jobs.",또한 Kubeflow는 데이터와 메타 데이터를 모두 추적하여 작업을 이해하는 방법을 개선 할 수 있습니다.,,
549,"For example, in CHAPTER 5 we use these artifacts to understand the schema.","예를 들어, 5 장에서는 이러한 아티팩트를 사용하여 스키마를 이해합니다.",,
550,"Pipelines can expose the parameters of the underlying machine learning algorithms, allowing Kubeflow to perform tuning.",파이프 라인은 기본 기계 학습 알고리즘의 매개 변수를 노출하여 Kubeflow가 튜닝을 수행 할 수 있도록합니다.,,
551,3.1.4.,3.1.4.,,
552,"Hyperparameter Tuning
Finding the right set of hyperparameters for your training model can be a challenging task.","초 매개 변수 조정
학습 모델에 적합한 하이퍼 파라미터 세트를 찾는 것은 어려운 작업 일 수 있습니다.",,
553,Traditional methodologies such as grid search can be time-consuming and quite tedious.,그리드 검색과 같은 전통적인 방법론은 시간이 많이 걸리고 매우 지루할 수 있습니다.,,
554,Most existing hyperparameter systems are tied to one machine learning framework and have only a few options for searching the parameter space.,대부분의 기존 초 매개 변수 시스템은 하나의 기계 학습 프레임 워크에 연결되어 있으며 매개 변수 공간을 검색하기위한 몇 가지 옵션 만 있습니다.,,
555,Kubeflow provides a component (called Katib) that allows users to perform hyperparameter optimizations easily on Kubernetes clusters.,Kubeflow는 사용자가 Kubernetes 클러스터에서 하이퍼 파라미터 최적화를 쉽게 수행 할 수있는 구성 요소 (Katib이라고 함)를 제공합니다.,,
556,"Katib is inspired by Google Vizier, a black-box optimization framework.",Katib은 블랙 박스 최적화 프레임 워크 인 Google Vizier에서 영감을 받았습니다.,,
557,It leverages advanced searching algorithms such as Bayesian optimization to find optimal hyperparameter configurations.,Bayesian 최적화와 같은 고급 검색 알고리즘을 활용하여 최적의 하이퍼 파라미터 구성을 찾습니다.,,
558,"Katib supports
hyperparameter tuning and can run with any deep learning framework, including TensorFlow, MXNet, and PyTorch.","Katib 지원
하이퍼 파라미터 튜닝은 TensorFlow, MXNet 및 PyTorch를 포함한 모든 딥 러닝 프레임 워크와 함께 실행할 수 있습니다.",,
559,"As in Google Vizier, Katib is based on four main concepts:

Experiment

A single optimization run over a feasible space.","Google Vizier에서와 마찬가지로 Katib은 다음 네 가지 주요 개념을 기반으로합니다.

실험

실행 가능한 공간에서 단일 최적화가 실행됩니다.",,
560,"Each experiment contains a configuration describing the feasible space, as well as a set of trials.",각 실험에는 실행 가능한 공간과 일련의 시도를 설명하는 구성이 포함되어 있습니다.,,
561,It is assumed that objective function f(x) does not change in the course of the experiment.,목적 함수 f (x)는 실험 과정에서 변하지 않는다고 가정합니다.,,
562,"Trial

A list of parameter values, x, that will lead to a single evaluation of f(x).","시도

f (x)의 단일 평가로 이어지는 매개 변수 값 x의 목록입니다.",,
563,"A trial can be “completed,” which means that it has been evaluated and the objective value f(x) has been assigned to it, otherwise it is “pending.” One trial corresponds to one job.","시험은 ""완료""될 수 있습니다. 이는 평가가 완료되고 목표 값 f (x)가 할당되었음을 의미합니다. 그렇지 않으면 ""보류 중""입니다.하나의 시험은 하나의 직업에 해당합니다.",,
564,"Job

A process responsible for evaluating a pending trial and calculating its objective value.","일

보류중인 시도를 평가하고 목표 값을 계산하는 프로세스입니다.",,
565,"Suggestion

An algorithm to construct a parameter set.","암시

매개 변수 세트를 구성하는 알고리즘입니다.",,
566,"Currently, Katib supports the following exploration algorithms:


Random


Grid


Hyperband


Bayesian optimization




Using these core concepts, you can increase your model’s performance.","현재 Katib은 다음 탐색 알고리즘을 지원합니다.


랜덤


그리드


하이퍼 밴드


베이지안 최적화




이러한 핵심 개념을 사용하여 모델의 성능을 높일 수 있습니다.",,
567,"Since Katib is not tied to one machine learning library, you can explore new algorithms and tools with minimal modifications.",Katib은 하나의 기계 학습 라이브러리에 연결되어 있지 않기 때문에 최소한의 수정으로 새로운 알고리즘과 도구를 탐색 할 수 있습니다.,,
568,3.1.5.,3.1.5.,,
569,"Model Inference
Kubeflow makes it easy to deploy machine learning models in production environments at scale.","모델 추론
Kubeflow를 사용하면 대규모 프로덕션 환경에서 기계 학습 모델을 쉽게 배포 할 수 있습니다.",,
570,"It provides several model serving options, including TFServing, Seldon serving, PyTorch serving, and TensorRT.","TFServing, Seldon 서비스, PyTorch 서비스 및 TensorRT를 포함한 여러 모델 서비스 옵션을 제공합니다.",,
571,"It also provides an umbrella implementation, KFServing, which generalizes the model inference concerns of autoscaling, networking, health checking, and server 
configuration.","또한 자동 확장, 네트워킹, 상태 확인 및 서버의 모델 추론 문제를 일반화하는 우산 구현 인 KFServing을 제공합니다.
구성.",,
572,The overall implementation is based on leveraging Istio (covered later) and Knative serving—serverless containers on Kubernetes.,전반적인 구현은 Istio (나중에 설명) 및 Kubernetes의 서버리스 컨테이너 인 Knative 서비스를 활용하는 것을 기반으로합니다.,,
573,"As defined in the Knative documentation, the Knative serving project provides middleware primitives that enable:


Rapid deployment of serverless containers


Automatic scaling up and down to zero


Routing and network programming for Istio components


Since model serving is inherently spiky, rapid scaling up and down is important.","Knative 문서에 정의 된대로 Knative 제공 프로젝트는 다음을 가능하게하는 미들웨어 기본 요소를 제공합니다.


서버리스 컨테이너의 신속한 배포


0까지 자동 확장 및 축소


Istio 구성 요소를위한 라우팅 및 네트워크 프로그래밍


모델 제공은 본질적으로 급증하므로 빠른 확장 및 축소가 중요합니다.",,
574,"Knative serving simplifies the support for continuous model updates, by automatically routing requests to newer model deployments.",Knative 제공은 요청을 최신 모델 배포로 자동 라우팅하여 지속적인 모델 업데이트 지원을 단순화합니다.,,
575,This requires scaling down to zero (minimizing resource utilization) for unused models while keeping them available for rollbacks.,이를 위해서는 사용하지 않는 모델에 대해 0으로 축소 (자원 활용도 최소화)하면서 롤백에 사용할 수 있도록 유지해야합니다.,,
576,"Since Knative is cloud native it benefits from its underlying infrastructure stack and therefore provides all the monitoring capabilities that exist within Kubernetes, such as logging, tracing, and monitoring.","Knative는 클라우드 네이티브이기 때문에 기본 인프라 스택의 이점을 누리고 있으므로 로깅, 추적 및 모니터링과 같이 Kubernetes 내에 존재하는 모든 모니터링 기능을 제공합니다.",,
577,KFServing also makes use of Knative eventing to give optional support for pluggable event sources.,KFServing은 또한 Knative 이벤트를 사용하여 플러그 가능한 이벤트 소스에 대한 선택적 지원을 제공합니다.,,
578,"Similar to Seldon, every KFServing deployment is an orchestrator, wiring together the following components:

Preprocessor

An optional component responsible for the transformation of the input data into content/format required for model serving

Predictor

A mandatory component responsible for an actual model serving

Postprocessor

An optional component responsible for the transformation/enriching of the model serving result into content/format required for output


Additional components can enhance one’s overall model serving implementation, but are outside of the main execution pipeline.","Seldon과 마찬가지로 모든 KFServing 배포는 오케 스트레이터이며 다음 구성 요소를 함께 연결합니다.

전 처리기

입력 데이터를 모델 제공에 필요한 콘텐츠 / 형식으로 변환하는 선택적 구성 요소

예언자

실제 모델 제공을 담당하는 필수 구성 요소

포스트 프로세서

모델 제공 결과를 출력에 필요한 콘텐츠 / 형식으로 변환 / 강화하는 선택적 구성 요소


추가 구성 요소는 전체 모델 제공 구현을 향상시킬 수 있지만 기본 실행 파이프 라인 외부에 있습니다.",,
579,Tools like outlier detection and model explainability can run in this environment without slowing down the overall system.,이상치 감지 및 모델 설명 가능성과 같은 도구는 전체 시스템 속도를 저하시키지 않고이 환경에서 실행할 수 있습니다.,,
580,"While all of these individual components and techniques have existed for a long time, having them integrated into the serving system of Kubeflow reduces the complexity involved in bringing new models into production.",이러한 모든 개별 구성 요소와 기술은 오랫동안 존재 해 왔지만이를 Kubeflow의 서빙 시스템에 통합하면 새로운 모델을 생산에 도입하는 데 따르는 복잡성이 줄어 듭니다.,,
581,"In addition to the components directly supporting ML operations, Kubeflow also provides several supporting components.",ML 작업을 직접 지원하는 구성 요소 외에도 Kubeflow는 여러 지원 구성 요소를 제공합니다.,,
582,3.1.6.,3.1.6.,,
583,"Metadata
An important component of Kubeflow is metadata management, providing capabilities to capture and track information about a model’s creation.","메타 데이터
Kubeflow의 중요한 구성 요소는 모델 생성에 대한 정보를 캡처하고 추적하는 기능을 제공하는 메타 데이터 관리입니다.",,
584,"Many organizations build hundreds of models a day, but it’s very hard to manage all of a model’s related information.",많은 조직이 하루에 수백 개의 모델을 구축하지만 모델의 모든 관련 정보를 관리하는 것은 매우 어렵습니다.,,
585,ML Metadata is both the infrastructure and a library for recording and retrieving metadata associated with an ML developer’s and data scientist’s workflow.,ML 메타 데이터는 ML 개발자 및 데이터 과학자의 워크 플로와 관련된 메타 데이터를 기록하고 검색하기위한 인프라이자 라이브러리입니다.,,
586,"The information, which can be registered in the metadata component includes:


Data sources used for the model’s creation


The artifacts generated through the components/steps of the pipeline


The executions of these components/steps


The pipeline and associated lineage information


ML Metadata tracks the inputs and outputs of all components and steps in an ML workflow and their lineage.","메타 데이터 구성 요소에 등록 할 수있는 정보는 다음과 같습니다.


모델 생성에 사용되는 데이터 소스


파이프 라인의 구성 요소 / 단계를 통해 생성 된 아티팩트


이러한 구성 요소 / 단계의 실행


파이프 라인 및 관련 계보 정보


ML 메타 데이터는 ML 워크 플로 및 해당 계보에있는 모든 구성 요소 및 단계의 입력 및 출력을 추적합니다.",,
587,This data powers several important features listed in TABLE 3-1 and shown in FIGURE 3-3.,이 데이터는 표 3-1에 나열되고 그림 3-3에 표시된 몇 가지 중요한 기능을 제공합니다.,,
588,Table 3-1.,표 3-1.,,
589,"Examples of ML Metadata operations


Operation
Example




List all artifacts of a specific type.","ML 메타 데이터 작업의 예


조작
예




특정 유형의 모든 이슈를 나열합니다.",,
590,All models that have been trained.,훈련 된 모든 모델.,,
591,Compare two artifacts of the same type.,동일한 유형의 두 아티팩트를 비교하십시오.,,
592,Compare results from two experiments.,두 실험의 결과를 비교합니다.,,
593,Show a DAG of all related executions and their input and output artifacts.,모든 관련 실행 및 해당 입력 및 출력 아티팩트의 DAG를 표시합니다.,,
594,Visualize the workflow of an experiment for debugging and discovery.,디버깅 및 발견을위한 실험의 워크 플로를 시각화합니다.,,
595,Display how an artifact was created.,이슈가 어떻게 생성되었는지 표시합니다.,,
596,See what data went into a model, enforce data retention plans.,어떤 데이터가 모델로 들어 갔는지 확인하십시오.데이터 보존 계획을 시행합니다.,
597,Identify all artifacts that were created using a given artifact.,주어진 이슈를 사용하여 생성 된 모든 이슈를 식별합니다.,,
598,Mark all models trained from a specific dataset with bad data.,특정 데이터 세트에서 학습 된 모든 모델을 잘못된 데이터로 표시합니다.,,
599,Determine if an execution has been run on the same inputs before.,이전에 동일한 입력에서 실행이 실행되었는지 확인합니다.,,
600,Determine whether a component/step has already completed the same work and the previous output can just be reused.,구성 요소 / 단계가 이미 동일한 작업을 완료했고 이전 출력을 다시 사용할 수 있는지 확인합니다.,,
601,Record and query context of workflow runs.,워크 플로 실행의 컨텍스트를 기록하고 쿼리합니다.,,
602,Track the owner and changes used for a workflow run, group the lineage by experiments, manage artifacts by projects.,워크 플로 실행에 사용되는 소유자 및 변경 사항을 추적합니다.실험별로 혈통을 그룹화하십시오.프로젝트별로 아티팩트를 관리합니다.
603,Figure 3-3.,그림 3-3.,,
604,"Metadata diagram



3.1.7.","메타 데이터 다이어그램



3.1.7.",,
605,"Component Summary
The magic of Kubeflow is making all of these traditionally distinct components work together.","구성 요소 요약
Kubeflow의 마법은 이러한 전통적으로 구별되는 모든 구성 요소가 함께 작동하도록하는 것입니다.",,
606,"While Kubeflow is certainly not the only system to bring together different parts of the machine learning landscape, it is unique in its flexibility in supporting a wide range of components.",Kubeflow가 머신 러닝 환경의 여러 부분을 통합하는 유일한 시스템은 아니지만 다양한 구성 요소를 지원하는 유연성이 독특합니다.,,
607,"In addition to that, since it runs on standard Kubernetes, you can add your own components as desired.",또한 표준 Kubernetes에서 실행되므로 원하는대로 고유 한 구성 요소를 추가 할 수 있습니다.,,
608,"Much of this magic of tool integration happens inside of Kubeflow’s pipelines, but some of the support components are essential to allowing these tools to interact.",이러한 도구 통합 마법의 대부분은 Kubeflow의 파이프 라인 내부에서 발생하지만 일부 지원 구성 요소는 이러한 도구가 상호 작용할 수 있도록하는 데 필수적입니다.,,
609,3.2.,3.2.,,
610,"Support Components
While these components aren’t explicitly exposed by Kubeflow, they play an important role in the overall Kubeflow ecosystem.","지원 구성 요소
이러한 구성 요소는 Kubeflow에서 명시 적으로 노출되지는 않지만 전체 Kubeflow 생태계에서 중요한 역할을합니다.",,
611,Let’s briefly discuss each of them.,각각에 대해 간단히 설명하겠습니다.,,
612,We also encourage you to research them more on your own.,또한 직접 조사해 보는 것도 좋습니다.,,
613,3.2.1.,3.2.1.,,
614,"MinIO
The foundation of the pipeline architecture is shared storage.","MinIO
파이프 라인 아키텍처의 기반은 공유 스토리지입니다.",,
615,A common practice today is to keep data in external storage.,오늘날 일반적인 관행은 데이터를 외부 저장소에 보관하는 것입니다.,,
616,"Different cloud providers have different solutions, like Amazon S3, Azure Data Storage, Google Cloud Storage, etc.","클라우드 제공 업체마다 Amazon S3, Azure Data Storage, Google Cloud Storage 등과 같은 솔루션이 다릅니다.",,
617,The variety of solutions makes it complex to port solutions from one cloud provider to another.,다양한 솔루션으로 인해 한 클라우드 공급자에서 다른 클라우드 공급자로 솔루션을 이식하는 것이 복잡해집니다.,,
618,"To minimize this dependency, Kubeflow ships with MinIO, a high-performance distributed object storage server, designed for large-scale private cloud infrastructure.",이러한 종속성을 최소화하기 위해 Kubeflow는 대규모 사설 클라우드 인프라를 위해 설계된 고성능 분산 개체 스토리지 서버 인 MinIO와 함께 제공됩니다.,,
619,"Not just for private clouds, MinIO can also act as a consistent gateway to public APIs.",프라이빗 클라우드뿐만 아니라 MinIO는 퍼블릭 API에 대한 일관된 게이트웨이 역할도 할 수 있습니다.,,
620,MinIO can be deployed in several different configurations.,MinIO는 여러 가지 구성으로 배포 할 수 있습니다.,,
621,The default with Kubeflow is as a single container mode when MinIO runs using the Kubernetes built-in persistent storage on one container.,Kubeflow의 기본값은 MinIO가 하나의 컨테이너에서 Kubernetes 내장 영구 스토리지를 사용하여 실행될 때 단일 컨테이너 모드입니다.,,
622,Distributed MinIO lets you pool multiple volumes into a single object storage service.,분산 형 MinIO를 사용하면 여러 볼륨을 단일 개체 스토리지 서비스로 풀링 할 수 있습니다.,,
623,[1] It can also withstand multiple node failures and yet ensure full data protection (the number of failures depends on your replication configuration).,[1] 또한 여러 노드 장애를 견딜 수 있지만 완전한 데이터 보호를 보장합니다 (장애 수는 복제 구성에 따라 다름).,,
624,"MinIO Gateway provides S3 APIs on top of Azure Blob storage, Google Cloud storage, Gluster, or NAS storage.","MinIO Gateway는 Azure Blob Storage, Google Cloud Storage, Gluster 또는 NAS 스토리지 위에 S3 API를 제공합니다.",,
625,"The gateway option is the most flexible, and allows you to create cloud independent implementation without scale limits.",게이트웨이 옵션은 가장 유연하며 확장 제한없이 클라우드 독립적 구현을 생성 할 수 있습니다.,,
626,"While Kubeflow’s default MinIO setup works, you will likely want to configure it further.",Kubeflow의 기본 MinIO 설정이 작동하는 동안 추가로 구성하는 것이 좋습니다.,,
627,Kubeflow installs both the MinIO server and UI.,Kubeflow는 MinIO 서버와 UI를 모두 설치합니다.,,
628,"You can get access to the MinIO UI and explore what is stored, as seen in FIGURE 3-4, by using port-forwarding, as in EXAMPLE 3-1, or exposing an ingress.",예 3-1에서와 같이 포트 전달을 사용하거나 수신을 노출하여 그림 3-4에 표시된 것처럼 MinIO UI에 액세스하고 저장된 항목을 탐색 할 수 있습니다.,,
629,You can log in using Kubeflow’s default minio/minio123 user.,Kubeflow의 기본 minio / minio123 사용자를 사용하여 로그인 할 수 있습니다.,,
630,Example 3-1.,예 3-1.,,
631,"Setting up port-forwarding
kubectl port-forward -n kubeflow svc/minio-service 9000:9000 &


Figure 3-4.","포트 포워딩 설정
kubectl port-forward -n kubeflow svc / minio-service 9000 : 9000 &


그림 3-4.",,
632,"MinIO dashboard

In addition, you can also install the MinIO CLI (mc) to access your MinIO installation using commands from your workstation.","MinIO 대시 보드

또한 MinIO CLI (mc)를 설치하여 워크 스테이션의 명령을 사용하여 MinIO 설치에 액세스 할 수도 있습니다.",,
633,"For macOS, use Homebrew, as in EXAMPLE 3-2.",macOS의 경우 예 3-2와 같이 Homebrew를 사용합니다.,,
634,"For Linux Ubuntu, use snap, as in EXAMPLE 3-3.",Linux Ubuntu의 경우 예 3-3과 같이 snap을 사용합니다.,,
635,Example 3-2.,예 3-2.,,
636,"Install MinIO on Mac
brew install minio/stable/minio

Example 3-3.","Mac에 MinIO 설치
brew install minio / stable / minio

예 3-3.",,
637,"Install MinIO on Linux
pushd ~/bin
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod a+x mc
You need to configure MinIO to talk to the correct endpoint, as in EXAMPLE 3-4.","Linux에 MinIO 설치
푸시 ~ / 빈
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod a + x mc
예 3-4에서와 같이 올바른 엔드 포인트와 통신하도록 MinIO를 구성해야합니다.",,
638,Example 3-4.,예 3-4.,,
639,"Configure MinIO client to talk to Kubeflow’s MinIO
mc config host add minio http://localhost:9000 minio minio123
Once you’ve configured the command line you can make new buckets, as in EXAMPLE 3-5, or change your setup.","Kubeflow의 MinIO와 통신하도록 MinIO 클라이언트 구성
mc 구성 호스트 minio 추가 http : // localhost : 9000 minio minio123
명령 줄을 구성한 후에는 예 3-5에서와 같이 새 버킷을 만들거나 설정을 변경할 수 있습니다.",,
640,Example 3-5.,예 3-5.,,
641,"Create a bucket with MinIO
mc mb minio/kf-book-examples
MinIO exposes both native and S3-compatible APIs.","MinIO를 사용하여 버킷 생성
mc mb minio / kf-book-examples
MinIO는 네이티브 및 S3 호환 API를 모두 노출합니다.",,
642,"The S3-compatible APIs are most important since most of our software can talk to S3, like TensorFlow and Spark.",대부분의 소프트웨어가 TensorFlow 및 Spark와 같은 S3와 통신 할 수 있기 때문에 S3 호환 API가 가장 중요합니다.,,
643,"Warning
Using MinIO with systems built on top of Hadoop (mostly Java-based) requires Hadoop 2.8 or higher.","경고
Hadoop (대부분 Java 기반) 위에 구축 된 시스템에서 MinIO를 사용하려면 Hadoop 2.8 이상이 필요합니다.",,
644,"Kubeflow installation hardcodes MinIO credentials—minio/minio123, which you can use directly in your applications—but it’s generally a better practice to use a secret, especially if you might switch to regular S3.",Kubeflow 설치는 MinIO 자격 증명 (애플리케이션에서 직접 사용할 수있는 minio / minio123)을 하드 코딩하지만 일반적으로 보안 비밀을 사용하는 것이 더 좋습니다.,,
645,Kubernetes secrets provide you with a way to store credentials on the cluster separate from your application.,Kubernetes 시크릿은 애플리케이션과 별도로 클러스터에 자격 증명을 저장하는 방법을 제공합니다.,,
646,"[2] To set one up for MinIO or S3, create a secret file like in EXAMPLE 3-6.",[2] MinIO 또는 S3 용으로 설정하려면 예제 3-6과 같이 비밀 파일을 생성합니다.,,
647,In Kubernetes secret values for the ID and key have to be base64 encoded.,Kubernetes에서 ID 및 키의 비밀 값은 base64로 인코딩되어야합니다.,,
648,"To encode a value, run the command echo -n xxx | base64.",값을 인코딩하려면 echo -n xxx |base64.,,
649,Example 3-6.,예 3-6.,,
650,"Sample MinIO secret
apiVersion: v1
kind: Secret
metadata:
  name: minioaccess
  namespace: mynamespace
data:
  AWS_ACCESS_KEY_ID: xxxxxxxxxx
  AWS_SECRET_ACCESS_KEY: xxxxxxxxxxxxxxxxxxxxx
Save this YAML to the file minioaccess.yaml, and deploy the secret using the command kubectl apply -f minioaccess.yaml.","샘플 MinIO 비밀
apiVersion : v1
종류 : 비밀
메타 데이터 :
  이름 : minioaccess
  네임 스페이스 : mynamespace
데이터:
  AWS_ACCESS_KEY_ID : xxxxxxxxxx
  AWS_SECRET_ACCESS_KEY : xxxxxxxxxxxxxxxxxxxxx
이 YAML을 minioaccess.yaml 파일에 저장하고 kubectl apply -f minioaccess.yaml 명령을 사용하여 보안 비밀을 배포합니다.",,
651,"Now that we understand data communication between pipeline stages, let’s work to understand network communication between components.",이제 파이프 라인 단계 간의 데이터 통신을 이해 했으므로 구성 요소 간의 네트워크 통신을 이해해 보겠습니다.,,
652,3.2.2.,3.2.2.,,
653,"Istio
Another supporting component of Kubeflow is Istio—a service mesh providing such vital features as service discovery, load balancing, failure recovery, metrics, monitoring, rate limiting, access control, and end-to-end authentication.","Istio
Kubeflow의 또 다른 지원 구성 요소는 서비스 검색,로드 밸런싱, 장애 복구, 메트릭, 모니터링, 속도 제한, 액세스 제어 및 종단 간 인증과 같은 중요한 기능을 제공하는 서비스 메시 인 Istio입니다.",,
654,"Istio, as a service mesh, layers transparently onto a Kubernetes cluster.",Istio는 서비스 메시로서 Kubernetes 클러스터에 투명하게 계층화됩니다.,,
655,"It integrates into any logging platform, or telemetry or policy system and promotes a uniform way to secure, connect, and monitor microservices.","모든 로깅 플랫폼, 원격 측정 또는 정책 시스템에 통합되며 마이크로 서비스를 보호, 연결 및 모니터링하는 일관된 방법을 촉진합니다.",,
656,Istio implementation co-locates each service instance with a sidecar network proxy.,Istio 구현은 각 서비스 인스턴스를 사이드카 네트워크 프록시와 함께 배치합니다.,,
657,"All network traffic (HTTP, REST, gRPC, etc.)","모든 네트워크 트래픽 (HTTP, REST, gRPC 등)",,
658,from an individual service instance flows via its local sidecar proxy to the appropriate destination.,개별 서비스 인스턴스에서 로컬 사이드카 프록시를 통해 적절한 대상으로 흐릅니다.,,
659,"Thus, the service instance is not aware of the network at large and only knows about its local proxy.",따라서 서비스 인스턴스는 네트워크 전체를 인식하지 못하고 로컬 프록시 만 알고 있습니다.,,
660,"In effect, the distributed system network has been abstracted away from the service programmer.",실제로 분산 시스템 네트워크는 서비스 프로그래머로부터 추상화되었습니다.,,
661,Istio implementation is logically split into a data plane and control plane.,Istio 구현은 논리적으로 데이터 플레인과 컨트롤 플레인으로 분할됩니다.,,
662,The data plane is composed of a set of intelligent proxies.,데이터 플레인은 일련의 지능형 프록시로 구성됩니다.,,
663,These proxies mediate and control all network communication between pods.,이러한 프록시는 포드 간의 모든 네트워크 통신을 중재하고 제어합니다.,,
664,The control plane manages and configures the proxies to route traffic.,제어 플레인은 트래픽을 라우팅 할 프록시를 관리하고 구성합니다.,,
665,"The main components of Istio are:

Envoy

Istio data plane is based on Envoy proxy, which provides features like failure handling (for example, health checks and bounded retries), dynamic service discovery, and load balancing.","Istio의 주요 구성 요소는 다음과 같습니다.

사절

Istio 데이터 플레인은 장애 처리 (예 : 상태 확인 및 제한된 재시도), 동적 서비스 검색 및로드 밸런싱과 같은 기능을 제공하는 Envoy 프록시를 기반으로합니다.",,
666,"Envoy has many built-in features, including:


Dynamic service discovery


Load balancing


TLS termination


HTTP/2 and gRPC proxies


Circuit breakers


Health checks


Staged rollouts with percent-based traffic splitting


Fault injection


Rich metrics



Mixer

Mixer enforces access control and usage policies across the service mesh, and collects telemetry data from the Envoy proxy and other services.","Envoy에는 다음과 같은 다양한 기본 제공 기능이 있습니다.


동적 서비스 검색


부하 분산


TLS 종료


HTTP / 2 및 gRPC 프록시


회로 차단기


건강 검진


백분율 기반 트래픽 분할을 통한 단계적 출시


결함 주입


풍부한 지표



믹서

Mixer는 서비스 메시 전반에 걸쳐 액세스 제어 및 사용 정책을 시행하고 Envoy 프록시 및 기타 서비스에서 원격 측정 데이터를 수집합니다.",,
667,"The proxy extracts request-level attributes, and sends them to Mixer for evaluation.",프록시는 요청 수준 속성을 추출하여 평가를 위해 Mixer로 보냅니다.,,
668,"Pilot

Pilot provides service discovery for the Envoy sidecars and traffic management capabilities for intelligent routing (e.g., A/B tests, canary rollouts) and resiliency (timeouts, retries, circuit breakers, etc.).","조종사

Pilot은 지능형 라우팅 (예 : A / B 테스트, 카나리아 롤아웃) 및 탄력성 (시간 초과, 재시도, 회로 차단기 등)을위한 Envoy 사이드카 및 트래픽 관리 기능에 대한 서비스 검색을 제공합니다.",,
669,"This is done by converting high-level routing rules that control traffic behavior into Envoy-specific configurations, and propagating them to the sidecars at runtime.",이는 트래픽 동작을 제어하는 높은 수준의 라우팅 규칙을 Envoy 전용 구성으로 변환하고이를 런타임에 사이드카로 전파하여 수행됩니다.,,
670,Pilot abstracts platform-specific service discovery mechanisms and synthesizes them into a standard format that any sidecar conforming with the Envoy data plane APIs can consume.,Pilot은 플랫폼 별 서비스 검색 메커니즘을 추상화하고 Envoy 데이터 플레인 API를 준수하는 모든 사이드카가 사용할 수있는 표준 형식으로 합성합니다.,,
671,"Galley

Galley is Istio’s configuration validation, ingestion, processing, and distribution component.","갤리

Galley는 Istio의 구성 유효성 검사, 수집, 처리 및 배포 구성 요소입니다.",,
672,It is responsible for insulating the rest of the Istio components from the details of obtaining user configuration from the underlying platform.,기본 플랫폼에서 사용자 구성을 가져 오는 세부 정보로부터 나머지 Istio 구성 요소를 격리하는 역할을합니다.,,
673,"Citadel

Citadel enables strong service-to-service and end-user authentication by providing identity and credential management.","성

Citadel은 ID 및 자격 증명 관리를 제공하여 강력한 서비스 대 서비스 및 최종 사용자 인증을 지원합니다.",,
674,It allows for upgrading unencrypted traffic in the service mesh.,서비스 메시에서 암호화되지 않은 트래픽을 업그레이드 할 수 있습니다.,,
675,"Using Citadel, operators can enforce policies based on service identity rather than on relatively unstable layer 3 or layer 4 network 
identifiers.","운영자는 Citadel을 사용하여 상대적으로 불안정한 계층 3 또는 계층 4 네트워크가 아닌 서비스 ID를 기반으로 정책을 시행 할 수 있습니다.
식별자.",,
676,Istio’s overall architecture is illustrated in FIGURE 3-5.,Istio의 전체 아키텍처는 그림 3-5에 나와 있습니다.,,
677,Figure 3-5.,그림 3-5.,,
678,"Istio architecture

Kubeflow uses Istio to provide a proxy to the Kubeflow UI and to route requests appropriately and securely.","Istio 아키텍처

Kubeflow는 Istio를 사용하여 Kubeflow UI에 프록시를 제공하고 요청을 적절하고 안전하게 라우팅합니다.",,
679,"Kubeflow’s KFServing leverages Knative, which requires a service mesh, like Istio.",Kubeflow의 KFServing은 Istio와 같은 서비스 메시가 필요한 Knative를 활용합니다.,,
680,3.2.3.,3.2.3.,,
681,"Knative
Another unseen support component used by Kubeflow is Knative.","Knative
Kubeflow에서 사용하는 또 다른 보이지 않는 지원 구성 요소는 Knative입니다.",,
682,We will begin by describing the most important part: Knative Serving.,가장 중요한 부분 인 Knative Serving을 설명하는 것으로 시작합니다.,,
683,"Built on Kubernetes and Istio, Knative Serving supports the deploying and serving of serverless applications.",Kubernetes 및 Istio를 기반으로 구축 된 Knative Serving은 서버리스 애플리케이션의 배포 및 제공을 지원합니다.,,
684,"The Knative Serving project provides middleware primitives that enable:


Rapid deployment of serverless containers


Automatic scaling up and down to zero


Routing and network programming for Istio components


Point-in-time snapshots of deployed code and configurations


Knative Serving is implemented as a set of Kubernetes CRDs.","Knative Serving 프로젝트는 다음을 가능하게하는 미들웨어 기본 요소를 제공합니다.


서버리스 컨테이너의 신속한 배포


0까지 자동 확장 및 축소


Istio 구성 요소를위한 라우팅 및 네트워크 프로그래밍


배포 된 코드 및 구성의 시점 스냅 샷


Knative Serving은 Kubernetes CRD 세트로 구현됩니다.",,
685,"These objects are used to define and control behavior of a serverless workload:

Service

The service.serving.knative.dev resource manages the workload as a whole.","이러한 개체는 서버리스 워크로드의 동작을 정의하고 제어하는 데 사용됩니다.

서비스

service.serving.knative.dev 리소스는 전체 워크로드를 관리합니다.",,
686,"It orchestrates the creation and execution of other objects to ensure that an app has a configuration, a route, and a new revision for each update of the service.","앱에 서비스의 각 업데이트에 대한 구성, 경로 및 새 개정이 있는지 확인하기 위해 다른 개체의 생성 및 실행을 조정합니다.",,
687,Service can be defined to always route traffic to the latest revision or to a specified revision.,항상 최신 개정 또는 지정된 개정으로 트래픽을 라우팅하도록 서비스를 정의 할 수 있습니다.,,
688,"Route

The route.serving.knative.dev resource maps a network endpoint to one or more revisions.","노선

route.serving.knative.dev 리소스는 네트워크 엔드 포인트를 하나 이상의 수정 버전에 매핑합니다.",,
689,"This allows for multiple traffic management approaches, including fractional traffic and named routes.",이를 통해 부분 트래픽 및 명명 된 경로를 포함한 여러 트래픽 관리 접근 방식을 사용할 수 있습니다.,,
690,"Configuration

The configuration.serving.knative.dev resource maintains the desired state for deployment.","구성

configuration.serving.knative.dev 리소스는 원하는 배포 상태를 유지합니다.",,
691,It provides a clean separation between code and configuration and follows the Twelve-Factor App methodology.,코드와 구성을 명확하게 구분하고 Twelve-Factor App 방법론을 따릅니다.,,
692,Modifying a configuration creates a new revision.,구성을 수정하면 새 개정이 생성됩니다.,,
693,"Revision

The revision.serving.knative.dev resource is a point-in-time snapshot of the code and configuration for each modification made to the workload.","개정

Rev.serving.knative.dev 리소스는 워크로드에 대한 각 수정 사항에 대한 코드 및 구성의 특정 시점 스냅 샷입니다.",,
694,Revisions are immutable objects and can be retained for as long as is useful.,개정판은 변경 불가능한 객체이며 유용한 한 오랫동안 유지할 수 있습니다.,,
695,Knative Serving Revisions can be automatically scaled up and down according to incoming traffic.,Knative Serving 개정은 수신 트래픽에 따라 자동으로 확장 및 축소 될 수 있습니다.,,
696,Knative’s overall architecture is illustrated in FIGURE 3-6.,Knative의 전체 아키텍처는 그림 3-6에 나와 있습니다.,,
697,Figure 3-6.,그림 3-6.,,
698,"Knative architecture



3.2.4.","Knative 아키텍처



3.2.4.",,
699,"Apache Spark
A more visible supporting component in Kubeflow is Apache Spark.","Apache Spark
Kubeflow에서 더 눈에 띄는 지원 구성 요소는 Apache Spark입니다.",,
700,"Starting in Kubeflow 1.0, Kubeflow has a built-in Spark operator for running Spark jobs.",Kubeflow 1.0부터 Kubeflow에는 Spark 작업을 실행하기위한 기본 제공 Spark 연산자가 있습니다.,,
701,"In addition to the Spark operator, Kubeflow provides integration for using Google’s Dataproc and Amazon’s Elastic Map Reduce (EMR), two managed cloud services for running Spark.",Spark 운영자 외에도 Kubeflow는 Spark를 실행하기위한 두 가지 관리 형 클라우드 서비스 인 Google의 Dataproc 및 Amazon의 Elastic Map Reduce (EMR)를 사용하기위한 통합을 제공합니다.,,
702,The components and the operator are focused on production use and are not well suited to exploration.,구성 요소와 운영자는 생산 사용에 초점을 맞추고 있으며 탐사에 적합하지 않습니다.,,
703,"For exploration, you can use Spark inside of your Jupyter notebook.",탐색을 위해 Jupyter 노트북 내부에서 Spark를 사용할 수 있습니다.,,
704,Apache Spark allows you to handle larger datasets and scale problems that cannot fit on a single machine.,Apache Spark를 사용하면 더 큰 데이터 세트를 처리하고 단일 머신에 맞지 않는 문제를 확장 할 수 있습니다.,,
705,"While Spark does have its own machine learning libraries, it is more commonly used as part of a machine learning pipeline for data or feature preparation.",Spark에는 자체 기계 학습 라이브러리가 있지만 데이터 또는 기능 준비를위한 기계 학습 파이프 라인의 일부로 더 일반적으로 사용됩니다.,,
706,We cover Spark in more detail in CHAPTER 5.,Spark는 5 장에서 자세히 다룹니다.,,
707,3.2.5.,3.2.5.,,
708,"Kubeflow Multiuser Isolation
The latest version of Kubeflow introduced multiuser isolation, which allows sharing the same pool of resources across different teams and users.","Kubeflow 다중 사용자 격리
최신 버전의 Kubeflow는 여러 팀과 사용자간에 동일한 리소스 풀을 공유 할 수있는 다중 사용자 격리를 도입했습니다.",,
709,"Multiuser isolation provides users with a reliable way to isolate and protect their own resources, without accidentally viewing or changing each other’s resources.",다중 사용자 격리는 사용자가 실수로 서로의 리소스를 보거나 변경하지 않고도 자신의 리소스를 격리하고 보호 할 수있는 안정적인 방법을 제공합니다.,,
710,"The key concepts of such isolation are:

Administrator

An administrator is someone who creates and maintains the Kubeflow cluster.","이러한 격리의 주요 개념은 다음과 같습니다.

관리자

관리자는 Kubeflow 클러스터를 생성하고 유지하는 사람입니다.",,
711,This person has permission to grant access permissions to others.,이 사람은 다른 사람에게 액세스 권한을 부여 할 권한이 있습니다.,,
712,"User

A user is someone who has access to some set of resources in the cluster.","사용자

사용자는 클러스터의 일부 리소스 집합에 액세스 할 수있는 사람입니다.",,
713,A user needs to be granted access permissions by the administrator.,사용자는 관리자로부터 액세스 권한을 부여 받아야합니다.,,
714,"Profile

A profile is a grouping of all Kubernetes namespaces and resources owned by a user.","프로필

프로필은 사용자가 소유 한 모든 Kubernetes 네임 스페이스 및 리소스의 그룹입니다.",,
715,"As of version 1.0, Kubeflow’s Jupyter notebook service is the first application to be fully integrated with multiuser isolation.",버전 1.0부터 Kubeflow의 Jupyter 노트북 서비스는 다중 사용자 격리와 완전히 통합 된 최초의 애플리케이션입니다.,,
716,Notebooks and their creation are controlled by the profile access policies set by the administrator or the owners of the profiles.,노트북 및 노트북 생성은 관리자 또는 프로필 소유자가 설정 한 프로필 액세스 정책에 의해 제어됩니다.,,
717,"Resources created by the notebooks (e.g., training jobs and deployments) will also inherit the same access.",노트북에서 생성 된 리소스 (예 : 교육 작업 및 배포)도 동일한 액세스 권한을 상속합니다.,,
718,"By default, Kubeflow provides automatic profile creation for authenticated users on first login,[3] which creates a new namespace.",기본적으로 Kubeflow는 최초 로그인시 인증 된 사용자를위한 자동 프로필 생성을 제공합니다. [3] 새로운 네임 스페이스를 생성합니다.,,
719,"Alternatively, profiles for users can be created manually.",또는 사용자 프로필을 수동으로 만들 수 있습니다.,,
720,This means that every user can work independently in their own namespace and use their own Jupyter server and notebooks.,이는 모든 사용자가 자신의 네임 스페이스에서 독립적으로 작업하고 자신의 Jupyter 서버 및 노트북을 사용할 수 있음을 의미합니다.,,
721,"To share access to your server/notebooks with others, go to the manage contributors page and add your collaborators’ emails.",다른 사람과 서버 / 노트북에 대한 액세스 권한을 공유하려면 참여자 관리 페이지로 이동하여 공동 작업자의 이메일을 추가하세요.,,
722,"Kubeflow’s Repositories
As you’ve seen, Kubeflow is comprised of a number of different components.","Kubeflow의 저장소
보시다시피 Kubeflow는 다양한 구성 요소로 구성됩니다.",,
723,These components are hosted under the Kubeflow GitHub organization.,이러한 구성 요소는 Kubeflow GitHub 조직에서 호스팅됩니다.,,
724,"The most important repositories to be familiar with are kfctl, which is hosted in the kfctl repo, and Kubeflow Pipelines, in the pipelines repo.",익숙해 져야 할 가장 중요한 리포지토리는 kfctl 리포지토리에서 호스팅되는 kfctl과 파이프 라인 리포지토리에서 Kubeflow Pipelines입니다.,,
725,The pipelines repo is especially important as its prebuilt components can save you time.,파이프 라인 저장소는 미리 빌드 된 구성 요소가 시간을 절약 할 수 있으므로 특히 중요합니다.,,
726,"Using the other components does not require explicit installation, but looking at the components issues, like in Katib, can be useful to check for known workarounds for any problems you encounter.",다른 구성 요소를 사용하는 데 명시적인 설치가 필요하지는 않지만 Katib에서와 같은 구성 요소 문제를 살펴보면 발생하는 문제에 대해 알려진 해결 방법을 확인하는 데 유용 할 수 있습니다.,,
727,3.3.,3.3.,,
728,"Conclusion
You now know the different components of Kubeflow and how they fit together.","결론
이제 Kubeflow의 다양한 구성 요소와 이들이 어떻게 결합되는지 알게되었습니다.",,
729,Kubeflow’s central dashboard gives you access to its web components.,Kubeflow의 중앙 대시 보드를 통해 웹 구성 요소에 액세스 할 수 있습니다.,,
730,You’ve seen that JupyterHub facilitates the explorative phase of model development.,JupyterHub가 모델 개발의 탐색 단계를 용이하게한다는 것을 확인했습니다.,,
731,We’ve covered the different built-in training operators for Kubeflow.,Kubeflow에 대한 다양한 기본 제공 교육 연산자를 다루었습니다.,,
732,We revisited Kubeflow pipelines to discuss how they tie together all of Kubeflow’s other components.,Kubeflow 파이프 라인을 다시 방문하여 Kubeflow의 다른 모든 구성 요소를 연결하는 방법을 논의했습니다.,,
733,"We introduced Katib, Kubeflow’s tool for hyperparameter tuning that works on pipelines.",파이프 라인에서 작동하는 초 매개 변수 조정을위한 Kubeflow 도구 인 Katib를 도입했습니다.,,
734,We talked about the different options for serving your models with Kubeflow (including KF Serving and Seldon).,Kubeflow (KF Serving 및 Seldon 포함)로 모델을 제공하기위한 다양한 옵션에 대해 이야기했습니다.,,
735,We discussed Kubeflow’s system for tracking your machine learning metadata and artifacts.,기계 학습 메타 데이터 및 아티팩트를 추적하기위한 Kubeflow의 시스템에 대해 논의했습니다.,,
736,"Then we wrapped it up with some of Kubeflow’s supporting components that enable the rest, Knative and Istio.",그런 다음 나머지 Knative 및 Istio를 활성화하는 Kubeflow의 지원 구성 요소 중 일부로 마무리했습니다.,,
737,"By understanding the different parts of Kubeflow, as well as the overall design, you should now be able to start seeing how your machine learning tasks and workflow translate to 
Kubeflow.","Kubeflow의 다양한 부분과 전체 디자인을 이해하면 이제 기계 학습 작업 및 워크 플로가 어떻게 변환되는지 확인할 수 있습니다.
Kubeflow.",,
738,The next few chapters will help you gain insights into these components and how to apply them to your use cases.,다음 몇 장에서는 이러한 구성 요소에 대한 통찰력을 얻고이를 사용 사례에 적용하는 방법을 설명합니다.,,
739,[1] This can run on multiple servers while exposing a consistent endpoint.,[1] 일관된 엔드 포인트를 노출시키면서 여러 서버에서 실행할 수 있습니다.,,
740,[2] Storing credentials inside your application can lead to security breaches.,[2] 애플리케이션 내부에 자격 증명을 저장하면 보안 침해가 발생할 수 있습니다.,,
741,"[3] To enable users to log in, they should be given minimal permission scope that allows them to connect to the Kubernetes cluster.",[3] 사용자가 로그인 할 수 있도록하려면 Kubernetes 클러스터에 연결할 수있는 최소 권한 범위를 제공해야합니다.,,
742,"For example, for GCP users, they can be granted IAM roles: Kubernetes Engine Cluster Viewer and IAP-secured Web App User.",예를 들어 GCP 사용자의 경우 Kubernetes Engine 클러스터 뷰어 및 IAP 보안 웹 앱 사용자와 같은 IAM 역할을 부여받을 수 있습니다.,,
743,Chapter 4.,4 장.,,
744,"Kubeflow Pipelines
In the previous chapter we described Kubeflow Pipelines,
 the component of Kubeflow that orchestrates machine learning applications.","Kubeflow 파이프 라인
이전 장에서 Kubeflow 파이프 라인에 대해 설명했습니다.
 기계 학습 애플리케이션을 조율하는 Kubeflow의 구성 요소입니다.",,
745,"Orchestration is necessary
because a typical machine learning implementation uses a combination of tools to prepare data, train the
model, evaluate performance, and deploy.","오케스트레이션이 필요합니다.
일반적인 기계 학습 구현에서는 도구 조합을 사용하여 데이터를 준비하기 때문에
모델, 성능 평가 및 배포.",,
746,"By formalizing the steps and their sequencing in code, pipelines allow users
to formally capture all of the data processing steps, ensuring their reproducibility and auditability, and training and
deployment steps.","코드에서 단계와 순서를 공식화함으로써 파이프 라인은 사용자가
모든 데이터 처리 단계를 공식적으로 캡처하여 재현성 및 감사 가능성을 보장하고 교육 및
배포 단계.",,
747,"We will start this chapter by taking a look at the Pipelines UI and showing how to start writing simple pipelines in
Python.","파이프 라인 UI를 살펴보고 간단한 파이프 라인 작성을 시작하는 방법을 보여 주면서이 장을 시작하겠습니다.
파이썬.",,
748,"We’ll explore how to transfer data between stages, then continue
by getting into ways of leveraging existing applications as part of a pipeline.","단계간에 데이터를 전송하는 방법을 살펴본 다음 계속합니다.
파이프 라인의 일부로 기존 애플리케이션을 활용하는 방법을 알아 봅니다.",,
749,"We will also look at the underlying workflow
engine—Argo Workflows, a standard Kubernetes pipeline tool—that Kubeflow uses to run pipelines.","기본 워크 플로도 살펴 보겠습니다.
엔진 — Kubeflow가 파이프 라인을 실행하는 데 사용하는 표준 Kubernetes 파이프 라인 도구 인 Argo Workflows입니다.",,
750,"Understanding the basics of
Argo Workflows allows you to gain a deeper understanding of Kubeflow Pipelines and will aid in debugging.","의 기본 이해
Argo Workflows를 사용하면 Kubeflow 파이프 라인을 더 깊이 이해할 수 있으며 디버깅에 도움이됩니다.",,
751,"We will then show what
Kubeflow Pipelines adds to Argo.","그런 다음
Kubeflow Pipelines가 Argo에 추가되었습니다.",,
752,"We’ll wrap up Kubeflow Pipelines by showing how to implement conditional execution in pipelines and how to run
pipelines execution on schedule.","파이프 라인에서 조건부 실행을 구현하는 방법과 실행 방법을 보여줌으로써 Kubeflow 파이프 라인을 마무리하겠습니다.
일정대로 파이프 라인 실행.",,
753,Task-specific components of pipelines will be covered in their respective chapters.,파이프 라인의 작업 별 구성 요소는 해당 장에서 다룹니다.,,
754,4.1.,4.1.,,
755,"Getting Started with Pipelines
The Kubeflow Pipelines platform consists of:


A UI for managing and tracking pipelines and their execution


An engine for scheduling a pipeline’s execution


An SDK for defining, building, and deploying pipelines in Python


Notebook support for using the SDK and pipeline execution


The easiest way to familiarize yourself with pipelines is to take a look at prepackaged examples.","파이프 라인 시작하기
Kubeflow Pipelines 플랫폼은 다음으로 구성됩니다.


파이프 라인과 실행을 관리하고 추적하기위한 UI


파이프 라인의 실행을 예약하기위한 엔진


Python에서 파이프 라인을 정의, 빌드 및 배포하기위한 SDK


SDK 및 파이프 라인 실행 사용을위한 노트북 지원


파이프 라인에 익숙해지는 가장 쉬운 방법은 사전 패키징 된 예제를 살펴 보는 것입니다.",,
756,4.1.1.,4.1.1.,,
757,"Exploring the Prepackaged Sample Pipelines
To help users understand pipelines, Kubeflow installs with a few sample pipelines.","사전 패키징 된 샘플 파이프 라인 탐색
사용자가 파이프 라인을 이해할 수 있도록 Kubeflow는 몇 개의 샘플 파이프 라인을 설치합니다.",,
758,"You can find these prepackaged
in the Pipeline web UI, as seen in FIGURE 4-1.","이러한 사전 패키지를 찾을 수 있습니다.
파이프 라인 웹 UI에서 (그림 4-1 참조).",,
759,"Note that at the time of writing, only the Basic to Conditional execution
pipelines are generic, while the rest of them will run only on Google Kubernetes Engine (GKE).","작성 당시에는 Basic to Conditional 실행 만
파이프 라인은 일반적이지만 나머지는 Google Kubernetes Engine (GKE)에서만 실행됩니다.",,
760,"If you try to run them on non-GKE environments, they will fail.",GKE가 아닌 환경에서 실행하려고하면 실패합니다.,,
761,Figure 4-1.,그림 4-1.,,
762,"Kubeflow pipelines UI: prepackaged pipelines

Clicking a specific pipeline will show its execution graph or source, as seen in FIGURE 4-2.","Kubeflow 파이프 라인 UI : 사전 패키징 된 파이프 라인

특정 파이프 라인을 클릭하면 그림 4-2와 같이 실행 그래프 또는 소스가 표시됩니다.",,
763,Figure 4-2.,그림 4-2.,,
764,"Kubeflow pipelines UI: pipeline graph view

Clicking the source tab will show the pipeline’s compiled code, which is an Argo YAML file (this is covered in more detail in SECTION 4.2.1).","Kubeflow 파이프 라인 UI : 파이프 라인 그래프보기

소스 탭을 클릭하면 Argo YAML 파일 인 파이프 라인의 컴파일 된 코드가 표시됩니다 (이는 섹션 4.2.1에서 자세히 다룹니다).",,
765,In this area you are welcome to experiment with running pipelines to get a better feel for their execution and the capabilities of the Pipelines UI.,이 영역에서는 실행중인 파이프 라인을 실험하여 파이프 라인 UI의 실행 및 기능에 대해 더 나은 느낌을 얻을 수 있습니다.,,
766,"To invoke a specific pipeline, simply click it; this will bring up Pipeline’s view as presented in FIGURE 4-3.",특정 파이프 라인을 호출하려면 클릭하기 만하면됩니다.그러면 그림 4-3과 같이 Pipeline의보기가 나타납니다.,,
767,Figure 4-3.,그림 4-3.,,
768,"Kubeflow pipelines UI: pipeline view

To run the pipeline, click the “Create Run” button and follow the instructions on the screen.","Kubeflow 파이프 라인 UI : 파이프 라인보기

파이프 라인을 실행하려면 ""Create Run""버튼을 클릭하고 화면의 지침을 따릅니다.",,
769,"Tip
When running a pipeline you must choose an experiment.","팁
파이프 라인을 실행할 때 실험을 선택해야합니다.",,
770,"Experiment here is just a convenience grouping for pipeline
executions (runs).","여기서 실험은 파이프 라인에 대한 편리한 그룹 화일뿐입니다.
실행 (실행).",,
771,You can always use the “Default” experiment created by Kubeflow’s installation.,Kubeflow의 설치로 생성 된 '기본'실험을 항상 사용할 수 있습니다.,,
772,"Also, pick “One-off”
for the Run type to execute the pipeline once.","또한 ""일회성""을 선택하십시오
실행 유형에 대해 파이프 라인을 한 번 실행합니다.",,
773,We will talk about recurring execution in SECTION 4.3.2.,4.3.2 절에서 반복 실행에 대해 설명합니다.,,
774,4.1.2.,4.1.2.,,
775,"Building a Simple Pipeline in Python
We have seen how to execute precompiled Kubeflow Pipelines, now let’s investigate how to author our own new pipelines.","Python으로 간단한 파이프 라인 구축
미리 컴파일 된 Kubeflow 파이프 라인을 실행하는 방법을 살펴 보았습니다. 이제 새로운 파이프 라인을 작성하는 방법을 조사해 보겠습니다.",,
776,Kubeflow Pipelines are stored as YAML files executed by a program called Argo (see SECTION 4.2.1).,Kubeflow 파이프 라인은 Argo라는 프로그램이 실행하는 YAML 파일로 저장됩니다 (섹션 4.2.1 참조).,,
777,"Thankfully, Kubeflow exposes a Python domain-specific language (DSL) for authoring pipelines.",고맙게도 Kubeflow는 파이프 라인 작성을 위해 Python 도메인 별 언어 (DSL)를 제공합니다.,,
778,The DSL is a Pythonic representation of the operations performed in the ML workflow and built with ML workloads specifically in mind.,DSL은 ML 워크 플로에서 수행되는 작업을 Python으로 표현한 것으로 특히 ML 워크로드를 염두에두고 구축되었습니다.,,
779,The DSL also allows for some simple Python functions to be used as pipeline stages without you having to explicitly build a container.,또한 DSL을 사용하면 컨테이너를 명시 적으로 빌드 할 필요없이 몇 가지 간단한 Python 함수를 파이프 라인 단계로 사용할 수 있습니다.,,
780,"Tip
The Chapter 4 examples can be found in the notebooks in this book’s GitHub repository.","팁
4 장 예제는이 책의 GitHub 저장소에있는 노트북에서 찾을 수 있습니다.",,
781,"A pipeline is, in its essence, a graph of container execution.",파이프 라인은 본질적으로 컨테이너 실행 그래프입니다.,,
782,"In addition to specifying which containers should run
in which order, it also allows the user to pass arguments to the entire pipeline and between participating containers.","실행할 컨테이너를 지정하는 것 외에도
또한 사용자는 전체 파이프 라인과 참여 컨테이너간에 인수를 전달할 수 있습니다.",,
783,"For each container (when using the Python SDK), we must:


Create the container—either as a simple Python function, or with any Docker container (read more in CHAPTER 9).","각 컨테이너 (Python SDK를 사용하는 경우)에 대해 다음을 수행해야합니다.


간단한 Python 함수로 또는 Docker 컨테이너를 사용하여 컨테이너를 만듭니다 (자세한 내용은 9 장 참조).",,
784,"Create an operation that references that container as well as the command line arguments, data mounts, and variable to pass the container.","컨테이너를 전달하기 위해 명령 줄 인수, 데이터 마운트 및 변수뿐만 아니라 해당 컨테이너를 참조하는 작업을 만듭니다.",,
785,"Sequence the operations, defining which may happen in parallel and which must complete before moving on to a further step.",작업 순서를 지정하여 병렬로 발생할 수있는 작업과 추가 단계로 이동하기 전에 완료해야하는 작업을 정의합니다.,,
786,"[1]


Compile this pipeline, defined in Python, into a YAML file that Kubeflow Pipelines can consume.","[1]


Python에 정의 된이 파이프 라인을 Kubeflow Pipelines에서 사용할 수있는 YAML 파일로 컴파일합니다.",,
787,Pipelines are a key feature of Kubeflow and you will see them again throughout the book.,파이프 라인은 Kubeflow의 핵심 기능이며 책 전체에서 다시 볼 수 있습니다.,,
788,"In this chapter we are going to
show the simplest examples possible to illustrate the basic principles of Pipelines.","이 장에서 우리는
파이프 라인의 기본 원칙을 설명 할 수있는 가장 간단한 예를 보여줍니다.",,
789,"This won’t feel like “machine
learning” and that is by design.","이것은 ""기계
학습”은 의도적으로 설계된 것입니다.",,
790,"For our first Kubeflow operation, we are going to use a technique known as lightweight Python functions.",첫 번째 Kubeflow 작업에서는 경량 Python 함수로 알려진 기술을 사용할 것입니다.,,
791,"We should not,
however, let the word lightweight deceive us.","우린 그러지 말았어야 했어,
그러나 경량이라는 단어가 우리를 속이게하십시오.",,
792,"In a lightweight Python function, we define a Python function and
then let Kubeflow take care of packaging that function into a container and creating an operation.","경량 Python 함수에서 Python 함수를 정의하고
그런 다음 Kubeflow가 해당 함수를 컨테이너에 패키징하고 작업을 생성하도록합니다.",,
793,"For the sake of simplicity, let’s declare the simplest of functions an echo.",단순함을 위해 가장 단순한 함수를 에코로 선언하겠습니다.,,
794,"That is a function that takes a single
input, an integer, and returns that input.","그것은 하나를 취하는 함수입니다.
입력, 정수 및 해당 입력을 반환합니다.",,
795,"Let’s start by importing kfp and defining our function:
import kfp
def simple_echo(i: int) -> int:
    return i
Warning
Note that we use snake_case, not camelCase, for our function names.","kfp를 가져 와서 함수를 정의하는 것으로 시작하겠습니다.
kfp 가져 오기
def simple_echo (i : int)-> int :
    돌려줘
경고
함수 이름으로 camelCase가 아닌 snake_case를 사용합니다.",,
796,"At the time of writing there exists a bug
(feature?)","글을 쓰는 시점에 버그가 있습니다.
(특색?)",,
797,such that camel case names (for example: naming our function simpleEcho) will produce errors.,낙타 케이스 이름 (예 : 함수 simpleEcho 이름 지정)은 오류를 생성합니다.,,
798,"Next, we want to wrap our function simple_echo into a Kubeflow Pipeline operation.",다음으로 simple_echo 함수를 Kubeflow 파이프 라인 작업으로 래핑하려고합니다.,,
799,"There’s a nice little
method to do this: kfp.components.func_to_container_op.","좋은 작은
이를 수행하는 방법 : kfp.components.func_to_container_op.",,
800,"This method returns a factory function with a strongly typed signature:
simpleStronglyTypedFunction =
  kfp.components.func_to_container_op(deadSimpleIntEchoFn)
When we create a pipeline in the next step, the factory function will construct a ContainerOp, which will run the original function (echo_fn) in a container:
foo = simpleStronglyTypedFunction(1)
type(foo)
Out[5]: kfp.dsl._container_op.ContainerOp
Tip
If your code can be accelerated by a GPU it is easy to mark a stage as using GPU resources; simply add .set_gpu_limit(NUM_GPUS) to your ContainerOp.","이 메서드는 강력한 형식의 서명이있는 팩토리 함수를 반환합니다.
simpleStronglyTypedFunction =
  kfp.components.func_to_container_op (deadSimpleIntEchoFn)
다음 단계에서 파이프 라인을 생성하면 팩토리 함수가 ContainerOp를 생성하여 컨테이너에서 원래 함수 (echo_fn)를 실행합니다.
foo = simpleStronglyTypedFunction (1)
유형 (foo)
출력 [5] : kfp.dsl._container_op.ContainerOp
팁
코드가 GPU로 가속화 될 수 있다면 GPU 리소스를 사용하는 것으로 스테이지를 쉽게 표시 할 수 있습니다.ContainerOp에 .set_gpu_limit (NUM_GPUS)를 추가하기 만하면됩니다.",,
801,Now let’s sequence the ContainerOp(s) (there is only one) into a pipeline.,이제 ContainerOp (하나만 있음)를 파이프 라인으로 시퀀싱 해 보겠습니다.,,
802,"This pipeline will take one parameter (the
number we will echo).","이 파이프 라인은 하나의 매개 변수 (
우리가 에코 할 수).",,
803,The pipeline also has a bit of metadata associated with it.,파이프 라인에는 이와 관련된 약간의 메타 데이터도 있습니다.,,
804,"While echoing numbers may be a
trivial use of parameters, in real-world use cases you would include variables you might want to tune later such as
hyperparameters for machine learning algorithms.","반향 숫자는
매개 변수의 사소한 사용, 실제 사용 사례에서는 다음과 같이 나중에 조정할 수있는 변수를 포함합니다.
기계 학습 알고리즘을위한 하이퍼 파라미터.",,
805,"Finally, we compile our pipeline into a zipped YAML file, which we can then upload to the Pipelines UI.",마지막으로 파이프 라인을 압축 된 YAML 파일로 컴파일 한 다음 파이프 라인 UI에 업로드 할 수 있습니다.,,
806,"@kfp.dsl.pipeline(
  name='Simple Echo',
  description='This is an echo pipeline.","@ kfp.dsl.pipeline (
  name = '단순 에코',
  description = '이것은 에코 파이프 라인입니다.",,
807,It echoes numbers.',그것은 숫자를 반영합니다. ',,
808,")
def echo_pipeline(param_1: kfp.dsl.PipelineParam):
  my_step = simpleStronglyTypedFunction(i= param_1)

kfp.compiler.Compiler().compile(echo_pipeline,
  'echo-pipeline.zip')
Tip
It is also possible to run the pipeline directly from the notebook, which we’ll do in the next example.",")
def echo_pipeline (param_1 : kfp.dsl.PipelineParam) :
  my_step = simpleStronglyTypedFunction (i = param_1)

kfp.compiler.Compiler (). compile (echo_pipeline,
  'echo-pipeline.zip')
팁
다음 예제에서 수행 할 노트북에서 직접 파이프 라인을 실행할 수도 있습니다.",,
809,A pipeline with only one component is not very interesting.,구성 요소가 하나 뿐인 파이프 라인은 그다지 흥미롭지 않습니다.,,
810,"For our next example, we will customize the containers of our lightweight Python functions.",다음 예제에서는 경량 Python 함수의 컨테이너를 사용자 지정합니다.,,
811,"We’ll create a new pipeline that installs and imports additional Python libraries, builds from a specified base image, and passes output between 
containers.","추가 Python 라이브러리를 설치 및 가져오고 지정된 기본 이미지에서 빌드하고 다음 사이에 출력을 전달하는 새로운 파이프 라인을 생성합니다.
용기.",,
812,"We are going to create a pipeline that divides a number by another number, and then adds a third number.",숫자를 다른 숫자로 나누고 세 번째 숫자를 더하는 파이프 라인을 만들 것입니다.,,
813,"First let’s create our simple add function, as shown in EXAMPLE 4-1.",먼저 예제 4-1과 같이 간단한 추가 함수를 만들어 보겠습니다.,,
814,Example 4-1.,예 4-1.,,
815,"A simple Python function
def add(a: float, b: float) -> float:
   '''Calculates sum of two arguments'''
   return a + b

add_op = comp.func_to_container_op(add)
Next, let’s create a slightly more complex function.","간단한 Python 함수
def add (a : float, b : float)-> float :
   '' '두 인수의 합을 계산합니다.' ''
   반환 a + b

add_op = comp.func_to_container_op (추가)
다음으로 조금 더 복잡한 함수를 만들어 보겠습니다.",,
816,"Additionally, let’s have this function require and import from a nonstandard Python library, numpy.",또한이 함수를 비표준 Python 라이브러리 인 numpy에서 가져와야합니다.,,
817,This must be done within the function.,이는 함수 내에서 수행되어야합니다.,,
818,That is because global imports from the notebook will not be packaged into the containers we create.,노트북의 글로벌 가져 오기는 우리가 만든 컨테이너에 패키징되지 않기 때문입니다.,,
819,"Of course, it is also important to make sure that our container has the libraries we are importing installed.",물론 컨테이너에 우리가 가져 오는 라이브러리가 설치되어 있는지 확인하는 것도 중요합니다.,,
820,"To do that we’ll pass the specific container we want to use as our base image to .func_to_container(, as in EXAMPLE 4-2.",이를 위해 기본 이미지로 사용하려는 특정 컨테이너를 .func_to_container ((예제 4-2)에 전달합니다.,,
821,Example 4-2.,예 4-2.,,
822,"A less-simple Python function
from typing import NamedTuple
def my_divmod(dividend: float, divisor:float) -> \
       NamedTuple('MyDivmodOutput', [('quotient', float), ('remainder', float)]):
    '''Divides two numbers and calculate  the quotient and remainder'''
    #Imports inside a component function:
    import numpy as np 

    #This function demonstrates how to use nested functions inside a
    # component function:
    def divmod_helper(dividend, divisor): 
	return np.divmod(dividend, divisor)

    (quotient, remainder) = divmod_helper(dividend, divisor)

    from collections import namedtuple
    divmod_output = namedtuple('MyDivmodOutput', ['quotient', 'remainder'])
    return divmod_output(quotient, remainder)

divmod_op = comp.func_to_container_op(
                my_divmod, base_image='tensorflow/tensorflow:1.14.0-py3') 


Importing libraries inside the function.","덜 간단한 Python 함수
Import NamedTuple 입력에서
def my_divmod (dividend : float, divisor : float)-> \
       NamedTuple ( 'MyDivmodOutput', [( 'quotient', float), ( 'remainder', float)]) :
    '' '두 숫자를 나누고 몫과 나머지를 계산합니다.' ''
    # 컴포넌트 함수 내에서 가져 오기 :
    numpy를 np로 가져 오기

    #이 함수는 내부에 중첩 된 함수를 사용하는 방법을 보여줍니다.
    # 구성 요소 기능 :
    def divmod_helper (dividend, divisor) :
return np.divmod (dividend, divisor)

    (몫, 나머지) = divmod_helper (dividend, divisor)

    컬렉션에서 namedtuple 가져 오기
    divmod_output = namedtuple ( 'MyDivmodOutput', [ 'quotient', 'remainder'])
    return divmod_output (몫, 나머지)

divmod_op = comp.func_to_container_op (
                my_divmod, base_image = 'tensorflow / tensorflow : 1.14.0-py3')


함수 내에서 라이브러리 가져 오기.",,
823,Nested functions inside lightweight Python functions are also OK.,경량 Python 함수 내의 중첩 함수도 괜찮습니다.,,
824,Calling for a specific base container.,특정 기본 컨테이너를 호출합니다.,,
825,Now we will build a pipeline.,이제 우리는 파이프 라인을 구축 할 것입니다.,,
826,"The pipeline in EXAMPLE 4-3 uses the functions defined previously, my_divmod and add, as stages.",예제 4-3의 파이프 라인은 이전에 정의 된 my_divmod 및 add 함수를 단계로 사용합니다.,,
827,Example 4-3.,예 4-3.,,
828,"A simple pipeline
@dsl.pipeline(
   name='Calculation pipeline',
   description='A toy pipeline that performs arithmetic calculations.'","간단한 파이프 라인
@ dsl.pipeline (
   name = '계산 파이프 라인',
   description = '산술 계산을 수행하는 장난감 파이프 라인.'",,
829,")
def calc_pipeline(
   a='a',
   b='7',
   c='17',
):
    #Passing pipeline parameter and a constant value as operation arguments
    add_task = add_op(a, 4) #Returns a dsl.ContainerOp class instance.",")
def calc_pipeline (
   a = 'a',
   b = '7',
   c = '17 ',
) :
    # 작업 인수로 파이프 라인 매개 변수 및 상수 값 전달
    add_task = add_op (a, 4) # dsl.ContainerOp 클래스 인스턴스를 반환합니다.",,
830,"#Passing a task output reference as operation arguments
    #For an operation with a single return value, the output
    # reference can be accessed using `task.output`
    # or `task.outputs['output_name']` syntax
    divmod_task = divmod_op(add_task.output, b) 

    #For an operation with multiple return values, the output references
    # can be accessed using `task.outputs['output_name']` syntax
    result_task = add_op(divmod_task.outputs['quotient'], c) 


Values being passed between containers.","# 작업 출력 참조를 작업 인수로 전달
    # 단일 반환 값이있는 작업의 경우 출력
    #`task.output`을 사용하여 참조에 액세스 할 수 있습니다.
    # 또는`task.outputs [ 'output_name']`구문
    divmod_task = divmod_op (add_task.output, b)

    # 여러 반환 값이있는 작업의 경우 출력은
    #`task.outputs [ 'output_name']`구문을 사용하여 액세스 할 수 있습니다.
    result_task = add_op (divmod_task.outputs [ 'quotient'], c)


컨테이너간에 전달되는 값입니다.",,
831,Order of operations is inferred from this.,이로부터 작업 순서가 유추됩니다.,,
832,"Finally, we use the client to submit the pipeline for execution, which returns the links to execution and experiment.",마지막으로 클라이언트를 사용하여 실행을위한 파이프 라인을 제출하면 실행 및 실험에 대한 링크가 반환됩니다.,,
833,Experiments group the executions together.,실험은 실행을 함께 그룹화합니다.,,
834,"You can also use kfp.compiler.Compiler().compile and upload the zip file as
in the first example if you prefer:
client = kfp.Client()
#Specify pipeline argument values
# arguments = {'a': '7', 'b': '8'} #whatever makes sense for new version
#Submit a pipeline run
client.create_run_from_pipeline_func(calc_pipeline, arguments=arguments)
Following the link returned by create_run_from_pipeline_func, we can get to the execution web UI, which shows the
pipeline itself and intermediate results, as seen in FIGURE 4-4.","kfp.compiler.Compiler (). compile을 사용하고 zip 파일을 다음과 같이 업로드 할 수도 있습니다.
원하는 경우 첫 번째 예에서 :
클라이언트 = kfp.Client ()
# 파이프 라인 인수 값 지정
# arguments = { 'a': '7', 'b': '8'} # 새 버전에 적합한 것은 무엇이든
# 파이프 라인 실행 제출
client.create_run_from_pipeline_func (calc_pipeline, arguments = arguments)
create_run_from_pipeline_func에서 반환 한 링크를 따라 실행 웹 UI로 이동할 수 있습니다.
파이프 라인 자체 및 중간 결과 (그림 4-4 참조).",,
835,Figure 4-4.,그림 4-4.,,
836,"Pipeline execution

As we’ve seen, the lightweight in lightweight Python functions refers to the ease of making these steps in our process and not the power of the functions themselves.","파이프 라인 실행

지금까지 살펴본 것처럼 경량 Python 함수의 경량은 함수 자체의 힘이 아니라 프로세스에서 이러한 단계를 쉽게 수행 할 수 있음을 의미합니다.",,
837,"We can use custom imports, base images, and how to hand off small results between containers.","사용자 지정 가져 오기, 기본 이미지 및 컨테이너간에 작은 결과를 전달하는 방법을 사용할 수 있습니다.",,
838,"In the next section, we’ll show how to hand larger data files between containers by mounting volumes to the containers.",다음 섹션에서는 컨테이너에 볼륨을 마운트하여 컨테이너간에 더 큰 데이터 파일을 전달하는 방법을 보여줍니다.,,
839,"Using Annotations to Simplify Our Pipeline
As you may have noticed, directly calling comp.func_to_container_op all the time can get kind of repetitive.","주석을 사용하여 파이프 라인 단순화
아시다시피, 항상 comp.func_to_container_op을 직접 호출하면 일종의 반복적 일 수 있습니다.",,
840,"To avoid this, you can create a function that returns a kfp.dsl.ContainerOp.",이를 방지하기 위해 kfp.dsl.ContainerOp를 반환하는 함수를 만들 수 있습니다.,,
841,"Since people don’t always like creating absurdly large and
fat functions to do everything in real life, we’ll leave this here as an aside in case the reader is interested in it.","사람들은 항상 터무니없이 크고
실제 생활에서 모든 것을 수행하는 뚱뚱한 기능이 있습니다. 독자가 관심을 가질 경우를 대비하여 여기에 남겨 두겠습니다.",,
842,"It’s also worth noting that adding the @kfp.dsl.component annotation instructs the Kubeflow compiler to turn on static type checking:
@kfp.dsl.component
def my_component(my_param):
  ...
  return kfp.dsl.ContainerOp(
    name='My component name',
    image='gcr.io/path/to/container/image'
  )
Finally, when it comes to incorporating these components into pipelines, you would do something like this:
@kfp.dsl.pipeline(
  name='My pipeline',
  description='My machine learning pipeline'
)
def my_pipeline(param_1: PipelineParam, param_2: PipelineParam):
  my_step = my_component(my_param='a')



4.1.3.","@ kfp.dsl.component 주석을 추가하면 Kubeflow 컴파일러가 정적 유형 검사를 켜도록 지시한다는 점도 주목할 가치가 있습니다.
@ kfp.dsl.component
def my_component (my_param) :
  ...
  return kfp.dsl.ContainerOp (
    name = '내 구성 요소 이름',
    image = 'gcr.io / path / to / container / image'
  )
마지막으로, 이러한 구성 요소를 파이프 라인에 통합 할 때 다음과 같이 할 수 있습니다.
@ kfp.dsl.pipeline (
  name = '내 파이프 라인',
  description = '내 머신 러닝 파이프 라인'
)
def my_pipeline (param_1 : PipelineParam, param_2 : PipelineParam) :
  my_step = my_component (my_param = 'a')



4.1.3.",,
843,"Storing Data Between Steps
In the previous example, the data passed between containers was small and of primitive types (such as numeric, string, list, and arrays).","단계 사이에 데이터 저장
이전 예에서 컨테이너간에 전달 된 데이터는 작고 기본 유형 (예 : 숫자, 문자열, 목록 및 배열)이었습니다.",,
844,"In practice however, we will likely be passing much larger data (for instance, entire datasets).",그러나 실제로는 훨씬 더 큰 데이터 (예 : 전체 데이터 세트)를 전달할 수 있습니다.,,
845,"In Kubeflow, there are two primary methods for doing this—persistent volumes inside the Kubernetes cluster, and cloud
storage options (such as S3), though each method has inherent problems.","Kubeflow에는이를 수행하는 두 가지 기본 방법이 있습니다. Kubernetes 클러스터 내부의 영구 볼륨과 클라우드
스토리지 옵션 (예 : S3), 각 방법에는 고유 한 문제가 있습니다.",,
846,Persistent volumes abstract the storage layer.,영구 볼륨은 스토리지 계층을 추상화합니다.,,
847,"Depending on the vendor, persistent volumes can be slow with provisioning
and have IO limits.","공급 업체에 따라 프로비저닝시 영구 볼륨이 느려질 수 있습니다.
IO 제한이 있습니다.",,
848,"Check to see if your vendor supports read-write-many storage classes, allowing for storage access by multiple pods, which is required for some types of parallelism.",공급 업체가 읽기-쓰기가 많은 스토리지 클래스를 지원하는지 확인하여 일부 유형의 병렬 처리에 필요한 여러 포드의 스토리지 액세스를 허용합니다.,,
849,Storage classes can be one of the following.,스토리지 클래스는 다음 중 하나 일 수 있습니다.,,
850,"[2]

ReadWriteOnce

The volume can be mounted as read-write by a single node.","[2]

ReadWriteOnce

볼륨은 단일 노드에 의해 읽기-쓰기로 마운트 될 수 있습니다.",,
851,"ReadOnlyMany

The volume can be mounted read-only by many nodes.","ReadOnlyMany

볼륨은 많은 노드에서 읽기 전용으로 마운트 될 수 있습니다.",,
852,"ReadWriteMany

The volume can be mounted as read-write by many nodes.","ReadWriteMany

볼륨은 많은 노드에서 읽기-쓰기로 마운트 될 수 있습니다.",,
853,"Your system/cluster administrator may be able to add
read-write-many support.","시스템 / 클러스터 관리자가 추가 할 수 있습니다.
읽기-쓰기-다수 지원.",,
854,"[3] Additionally, many cloud providers include their proprietary read-write-many implementations, see for example dynamic provisioning on GKE.",[3] 또한 많은 클라우드 제공 업체가 독점적 인 읽기-쓰기-다수 구현을 포함합니다. 예를 들어 GKE의 동적 프로비저닝을 참조하세요.,,
855,but make sure to ask if there is a single node bottleneck.,그러나 단일 노드 병목 현상이 있는지 확인하십시오.,,
856,"Kubeflow Pipelines’ VolumeOp allows you to create an automatically managed persistent volume, as shown in EXAMPLE 4-4.",Kubeflow Pipelines의 VolumeOp를 사용하면 예 4-4에 표시된대로 자동으로 관리되는 영구 볼륨을 만들 수 있습니다.,,
857,"To add the volume to your operation you can just call add_pvolumes with a dictionary of mount points to volumes, e.g., download_data_op(year).add_pvolumes({""/data_processing"": dvop.volume}).","작업에 볼륨을 추가하려면 볼륨에 대한 마운트 지점 사전을 사용하여 add_pvolumes를 호출하면됩니다 (예 : download_data_op (year) .add_pvolumes ({ ""/ data_processing"": dvop.volume})).",,
858,Example 4-4.,예 4-4.,,
859,"Mailing list data prep
dvop = dsl.VolumeOp(name=""create_pvc"",
                    resource_name=""my-pvc-2"",
                    size=""5Gi"",
                    modes=dsl.VOLUME_MODE_RWO)
While less common in the Kubeflow examples, using an object storage solution, in some cases, may be more suitable.","메일 링리스트 데이터 준비
dvop = dsl.VolumeOp (name = ""create_pvc"",
                    resource_name = ""my-pvc-2"",
                    size = ""5Gi"",
                    모드 = dsl.VOLUME_MODE_RWO)
Kubeflow 예제에서는 덜 일반적이지만, 경우에 따라 오브젝트 스토리지 솔루션을 사용하는 것이 더 적합 할 수 있습니다.",,
860,"MinIO provides cloud native object storage by working either as a gateway to an existing object storage engine or on its
own.","MinIO는 기존 개체 스토리지 엔진에 대한 게이트웨이 역할을하거나 해당 엔진에서 클라우드 네이티브 개체 스토리지를 제공합니다.
개인적인.",,
861,[4] We covered how to configure MinIO back in CHAPTER 3.,[4] MinIO를 구성하는 방법은 3 장에서 다뤘습니다.,,
862,Kubeflow’s built-in file_output mechanism automatically transfers the specified local file into MinIO between pipeline steps for you.,Kubeflow의 기본 제공 file_output 메커니즘은 파이프 라인 단계간에 지정된 로컬 파일을 MinIO로 자동 전송합니다.,,
863,"To use file_output, write your files locally in your container and specify the parameter in your ContainerOp, as shown in EXAMPLE 4-5.",file_output을 사용하려면 예 4-5와 같이 컨테이너에 로컬로 파일을 작성하고 ContainerOp에 매개 변수를 지정합니다.,,
864,Example 4-5.,예 4-5.,,
865,"File output example
    fetch = kfp.dsl.ContainerOp(name='download',
                                image='busybox',
                                command=['sh', '-c'],
                                arguments=[
                                    'sleep 1;'
                                    'mkdir -p /tmp/data;'
                                    'wget ' + data_url +
                                    ' -O /tmp/data/results.csv'
                                ],
                                file_outputs={'downloaded': '/tmp/data'})
    # This expects a directory of inputs not just a single file
If you don’t want to use MinIO, you can also directly use your provider’s object storage, but this may compromise some portability.","파일 출력 예
    fetch = kfp.dsl.ContainerOp (name = 'download',
                                image = 'busybox',
                                명령 = [ 'sh', '-c'],
                                인수 = [
                                    '수면 1;'
                                    'mkdir -p / tmp / data;'
                                    'wget'+ data_url +
                                    '-O /tmp/data/results.csv'
                                ],
                                file_outputs = { '다운로드 됨': '/ tmp / data'})
    # 이것은 단일 파일이 아닌 입력 디렉토리를 기대합니다
MinIO를 사용하지 않으려면 공급자의 개체 스토리지를 직접 사용할 수도 있지만 이로 인해 일부 이식성이 손상 될 수 있습니다.",,
866,The ability to mount data locally is an essential task in any machine learning pipeline.,데이터를 로컬로 마운트하는 기능은 모든 기계 학습 파이프 라인에서 필수적인 작업입니다.,,
867,"Here we have briefly outlined multiple
 methods and provided examples for each.","여기서 우리는 여러
 각각에 대한 방법 및 제공된 예제.",,
868,4.2.,4.2.,,
869,"Introduction to Kubeflow Pipelines Components
Kubeflow Pipelines builds on Argo Workflows, an open source, container-native workflow engine for
Kubernetes.","Kubeflow 파이프 라인 구성 요소 소개
Kubeflow Pipelines는 다음을위한 오픈 소스 컨테이너 네이티브 워크 플로 엔진 인 Argo Workflows를 기반으로합니다.
Kubernetes.",,
870,"In this section we will describe how Argo works, what it does, and how Kubeflow Pipeline supplements Argo to make it easier to use by data scientists.","이 섹션에서는 Argo의 작동 방식, 기능 및 데이터 과학자가 쉽게 사용할 수 있도록 Kubeflow Pipeline이 Argo를 보완하는 방법에 대해 설명합니다.",,
871,4.2.1.,4.2.1.,,
872,"Argo: the Foundation of Pipelines
Kubeflow installs all of the Argo components.","Argo : 파이프 라인의 기초
Kubeflow는 모든 Argo 구성 요소를 설치합니다.",,
873,"Though having Argo installed on your computer is not necessary to use Kubeflow Pipelines, having the Argo command-line tool makes it easier to understand and debug your pipelines.",Kubeflow Pipelines를 사용하기 위해 컴퓨터에 Argo를 설치할 필요는 없지만 Argo 명령 줄 도구를 사용하면 파이프 라인을 더 쉽게 이해하고 디버깅 할 수 있습니다.,,
874,"Tip
By default, Kubeflow configures Argo to use the Docker executor.","팁
기본적으로 Kubeflow는 Docker 실행기를 사용하도록 Argo를 구성합니다.",,
875,"If your platform does not support the Docker APIs, you need to switch your executor to a compatible one.",플랫폼이 Docker API를 지원하지 않는 경우 실행기를 호환 가능한 것으로 전환해야합니다.,,
876,This is done by changing the containerRuntimeExecutor value in the Argo params file.,이는 Argo params 파일에서 containerRuntimeExecutor 값을 변경하여 수행됩니다.,,
877,See APPENDIX A for details on the trade-offs.,장단점에 대한 자세한 내용은 부록 A를 참조하십시오.,,
878,The majority of the examples in this book use the Docker executor but can be adapted to other executors.,이 책에있는 대부분의 예제는 Docker 실행기를 사용하지만 다른 실행기에 적용 할 수 있습니다.,,
879,"On macOS, you can install Argo with Homebrew, as shown in EXAMPLE 4-6.",macOS에서는 예제 4-6과 같이 Homebrew와 함께 Argo를 설치할 수 있습니다.,,
880,"[5]

Example 4-6.","[5]

예 4-6.",,
881,"Argo installation
#!/bin/bash
# Download the binary
curl -sLO https://github.com/argoproj/argo/releases/download/v2.8.1/argo-linux-amd64

# Make binary executable
chmod +x argo-linux-amd64

# Move binary to path
mv ./argo-linux-amd64 ~/bin/argo
You can verify your Argo installation by running the Argo examples with the command-line tool in the Kubeflow namespace: follow these Argo instructions.","아르고 설치
#! / bin / bash
# 바이너리 다운로드
curl -sLO https://github.com/argoproj/argo/releases/download/v2.8.1/argo-linux-amd64

# 바이너리를 실행 가능하게 만들기
chmod + x argo-linux-amd64

# 바이너리를 경로로 이동
mv ./argo-linux-amd64 ~ / bin / argo
Kubeflow 네임 스페이스에서 명령 줄 도구로 Argo 예제를 실행하여 Argo 설치를 확인할 수 있습니다. 다음 Argo 지침을 따르십시오.",,
882,"When you run the Argo examples the pipelines are visible with the argo command, as in EXAMPLE 4-7.",Argo 예제를 실행하면 예제 4-7에서와 같이 argo 명령을 사용하여 파이프 라인을 볼 수 있습니다.,,
883,Example 4-7.,예 4-7.,,
884,"Listing Argo executions
$ argo list -n kubeflow
NAME                STATUS      AGE   DURATION
loops-maps-4mxp5    Succeeded   30m   12s
hello-world-wsxbr   Succeeded   39m   15s
Since pipelines are implemented with Argo, you can use the same technique to check on them as well.","Argo 실행 나열
$ argo 목록 -n kubeflow
이름 상태 연령 기간
loops-maps-4mxp5 30m 12 초 성공
hello-world-wsxbr 39 분 15 초 성공
파이프 라인은 Argo로 구현되므로 동일한 기술을 사용하여 파이프 라인을 확인할 수도 있습니다.",,
885,"You can
also get information about specific workflow execution, as shown in EXAMPLE 4-8.","당신은 할 수 있습니다
또한 예 4-8에 표시된대로 특정 워크 플로 실행에 대한 정보를 가져옵니다.",,
886,Example 4-8.,예 4-8.,,
887,"Getting Argo execution details
$ argo get hello-world-wsxbr -n kubeflow  
Name:                hello-world-wsxbr
Namespace:           kubeflow
ServiceAccount:      default
Status:              Succeeded
Created:             Tue Feb 12 10:05:04 -0600 (2 minutes ago)
Started:             Tue Feb 12 10:05:04 -0600 (2 minutes ago)
Finished:            Tue Feb 12 10:05:23 -0600 (1 minute ago)
Duration:            19 seconds

STEP                  PODNAME            DURATION  MESSAGE
 ✔ hello-world-wsxbr  hello-world-wsxbr  18s


hello-world-wsxbr is the name that we got using argo list -n kubeflow above.","Argo 실행 세부 정보 얻기
$ argo get hello-world-wsxbr -n kubeflow
이름 : hello-world-wsxbr
네임 스페이스 : kubeflow
ServiceAccount : 기본값
상태 : 성공
생성됨 : Tue Feb 12 10:05:04 -0600 (2 분 전)
시작 : 2 월 12 일 화요일 10:05:04 -0600 (2 분 전)
종료 : 2 월 12 일 화요일 10:05:23 -0600 (1 분 전)
지속 시간 : 19 초

단계 PODNAME 기간 메시지
 ✔ hello-world-wsxbr hello-world-wsxbr 18 초


hello-world-wsxbr은 위의 argo list -n kubeflow를 사용하여 얻은 이름입니다.",,
888,In your case the name will be different.,귀하의 경우 이름이 다를 것입니다.,,
889,We can also view the execution logs by using the command in EXAMPLE 4-9.,예 4-9의 명령을 사용하여 실행 로그를 볼 수도 있습니다.,,
890,Example 4-9.,예 4-9.,,
891,"Getting the log of Argo execution
$ argo logs hello-world-wsxbr -n kubeflow
This produces the result shown in EXAMPLE 4-10.","Argo 실행 로그 얻기
$ argo 로그 hello-world-wsxbr -n kubeflow
이것은 예 4-10에 표시된 결과를 생성합니다.",,
892,Example 4-10.,예 4-10.,,
893,"Argo execution log
< hello world >
 -------------
    \
     \
      \
		    ##        .","Argo 실행 로그
<헬로 월드>
 -------------
    \
     \
      \
##.",,
894,"## ## ##       ==
	   ## ## ## ##      ===
       /""""""""""""""""""""""""""""""""___/ ===
  ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ /  ===- ~~~
       \______ o          __/
	\    \        __/
	  \____\______/
You can also delete a specific workflow; see EXAMPLE 4-11.","## ## ## ==
## ## ## ## ===
       / """" """" """" """" """" """" """" """"___ / ===
  ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===-~~~
       \ ______ o __ /
\ \ __ /
\ ____ \ ______ /
특정 워크 플로를 삭제할 수도 있습니다.예 4-11 참조.",,
895,Example 4-11.,예 4-11.,,
896,"Deleting Argo execution
$ argo delete hello-world-wsxbr -n kubeflow
Alternatively, you can get pipeline execution information using the Argo UI, as seen in FIGURE 4-5.","Argo 실행 삭제
$ argo delete hello-world-wsxbr -n kubeflow
또는 그림 4-5와 같이 Argo UI를 사용하여 파이프 라인 실행 정보를 얻을 수 있습니다.",,
897,Figure 4-5.,그림 4-5.,,
898,"Argo UI for pipeline execution


Installing Argo UI
By default, Kubeflow does not provide access to the Argo UI.","파이프 라인 실행을위한 Argo UI


Argo UI 설치
기본적으로 Kubeflow는 Argo UI에 대한 액세스를 제공하지 않습니다.",,
899,"To enable access, you have to do the following:


Make sure that your Argo UI deployment corresponds to the UI provided in code in this book’s GitHub repo.","액세스를 활성화하려면 다음을 수행해야합니다.


Argo UI 배포가이 책의 GitHub 저장소에있는 코드에 제공된 UI와 일치하는지 확인하세요.",,
900,Create a virtual service by applying the YAML provided in code in this book’s GitHub repo.,이 책의 GitHub 저장소에있는 코드로 제공된 YAML을 적용하여 가상 서비스를 만듭니다.,,
901,Point your browser to <cluster main url>/argo.,브라우저에서 <cluster main url> / argo를 가리 킵니다.,,
902,"You can also look at the details of the flow execution graph by clicking a specific workflow, as seen in FIGURE 4-6.",그림 4-6과 같이 특정 워크 플로를 클릭하여 흐름 실행 그래프의 세부 정보를 볼 수도 있습니다.,,
903,Figure 4-6.,그림 4-6.,,
904,"Argo UI execution graph

For any Kubeflow pipeline you run, you can also view that pipeline in the Argo CLI/UI.","Argo UI 실행 그래프

실행하는 모든 Kubeflow 파이프 라인의 경우 Argo CLI / UI에서 해당 파이프 라인을 볼 수도 있습니다.",,
905,"Note that because ML pipelines
are using the Argo CRD, you can also see the result of the pipeline execution in the Argo UI (as in FIGURE 4-7).","ML 파이프 라인은
Argo CRD를 사용하는 경우 Argo UI에서 파이프 라인 실행 결과를 볼 수도 있습니다 (그림 4-7 참조).",,
906,Figure 4-7.,그림 4-7.,,
907,"Viewing Kubeflow pipelines in Argo UI

Tip
Currently, the Kubeflow community is actively looking at alternative foundational technologies for running Kubeflow pipelines, one of which is Tekton.","Argo UI에서 Kubeflow 파이프 라인보기

팁
현재 Kubeflow 커뮤니티는 Kubeflow 파이프 라인을 실행하기위한 대체 기반 기술을 적극적으로 모색하고 있으며, 그중 하나는 Tekton입니다.",,
908,"The paper by A. Singh et al.,  “Kubeflow Pipelines with Tekton”, gives “initial design, specifications, and code for enabling Kubeflow Pipelines to run on top of Tekton.” The basic idea here is to create an intermediate format that can be produced by pipelines and then executed using Argo, Tekton, or other runtimes.","A. Singh 등의 논문,“Tekton을 사용한 Kubeflow 파이프 라인”은“Kubeflow 파이프 라인이 Tekton 위에서 실행될 수 있도록하기위한 초기 설계, 사양 및 코드”를 제공합니다.여기서 기본 아이디어는 파이프 라인에서 생성 한 다음 Argo, Tekton 또는 기타 런타임을 사용하여 실행할 수있는 중간 형식을 만드는 것입니다.",,
909,The initial code for this implementation is found in this Kubeflow GitHub repo.,이 구현의 초기 코드는이 Kubeflow GitHub 저장소에서 찾을 수 있습니다.,,
910,4.2.2.,4.2.2.,,
911,"What Kubeflow Pipelines Adds to Argo Workflow
Argo underlies the workflow execution; however, using it directly requires you to do awkward things.","Kubeflow Pipelines가 Argo 워크 플로에 추가하는 사항
Argo는 워크 플로우 실행의 기초가됩니다.그러나 직접 사용하려면 어색한 작업을 수행해야합니다.",,
912,"First, you must define your workflow in YAML, which can be difficult.",먼저 YAML로 워크 플로를 정의해야하는데 이는 어려울 수 있습니다.,,
913,"Second, you must containerize your code, which can be tedious.","둘째, 코드를 컨테이너화해야하므로 지루할 수 있습니다.",,
914,"The main advantage of KF Pipelines is that you can use Python APIs for defining/creating pipelines, which automates the generation of much of the YAML boilerplate for workflow definitions and is extremely friendly for data scientists/Python developers.",KF Pipelines의 주요 장점은 파이프 라인을 정의 / 생성하는 데 Python API를 사용할 수 있다는 것입니다.이 API는 워크 플로 정의를위한 YAML 상용구의 대부분을 자동화하고 데이터 과학자 / Python 개발자에게 매우 친숙합니다.,,
915,"Kubeflow Pipelines also has hooks that add building blocks for machine learning-specific 
components.","또한 Kubeflow Pipelines에는 머신 러닝 관련 빌딩 블록을 추가하는 후크가 있습니다.
구성 요소.",,
916,These APIs not only generate the YAML but can also simplify container creation and resource usage.,이러한 API는 YAML을 생성 할뿐만 아니라 컨테이너 생성 및 리소스 사용을 단순화 할 수도 있습니다.,,
917,"In addition to the APIs, Kubeflow adds a recurring scheduler and UI for configuration and execution.",API 외에도 Kubeflow는 구성 및 실행을위한 반복 스케줄러 및 UI를 추가합니다.,,
918,4.2.3.,4.2.3.,,
919,"Building a Pipeline Using Existing Images
Building pipeline stages directly from Python provides a straightforward entry point.","기존 이미지를 사용하여 파이프 라인 구축
Python에서 직접 파이프 라인 단계를 빌드하면 간단한 진입 점이 제공됩니다.",,
920,"It does limit our implementation
to Python, though.","그것은 우리의 구현을 제한합니다
하지만 파이썬에.",,
921,"Another feature of Kubeflow Pipelines is the ability to orchestrate the execution of a multilanguage
implementation leveraging prebuilt Docker images (see CHAPTER 9).","Kubeflow Pipelines의 또 다른 기능은 다국어 실행을 조율하는 기능입니다.
사전 빌드 된 Docker 이미지를 활용하는 구현 (9 장 참조).",,
922,"Using Custom Code Inside Pipelines
In order to use custom code and tools inside Kubeflow Pipelines, it needs to be packaged into a container: see  this Kubeflow documentation page.","파이프 라인 내에서 사용자 지정 코드 사용
Kubeflow Pipelines 내에서 사용자 지정 코드와 도구를 사용하려면 컨테이너로 패키징해야합니다.이 Kubeflow 문서 페이지를 참조하세요.",,
923,"Once the container is uploaded to an accessible repository, it can be included in the pipeline.",컨테이너가 액세스 가능한 저장소에 업로드되면 파이프 라인에 포함될 수 있습니다.,,
924,"Pipelines allow the user to configure
some of the container execution through environment variables and pass data between pipeline components.","파이프 라인을 통해 사용자는
일부 컨테이너 실행은 환경 변수를 통해 파이프 라인 구성 요소간에 데이터를 전달합니다.",,
925,Environment variables can be set using Kubernetes Python library.,환경 변수는 Kubernetes Python 라이브러리를 사용하여 설정할 수 있습니다.,,
926,"Include the Kubernetes library and then implement the code:
from kubernetes import client as k8s_client

data = dsl.ContainerOp(
      name='updatedata',
      image='lightbend/recommender-data-update-publisher:0.2') \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_KEY', value='minio')) 


Here we set the environment variable MINIO_KEY to the value of minio.","Kubernetes 라이브러리를 포함하고 코드를 구현합니다.
kubernetes에서 클라이언트를 k8s_client로 가져 오기

데이터 = dsl.ContainerOp (
      name = 'updatedata',
      image = 'lightbend / recommender-data-update-publisher : 0.2') \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_KEY', value = 'minio'))


여기서 환경 변수 MINIO_KEY를 minio 값으로 설정합니다.",,
927,"The way you can pass parameters between steps (containers), depends on the Argo runtime that you are using.",단계 (컨테이너)간에 매개 변수를 전달할 수있는 방법은 사용중인 Argo 런타임에 따라 다릅니다.,,
928,"For example, in the case of the docker runtime, you can pass parameters by value.",예를 들어 Docker 런타임의 경우 매개 변수를 값으로 전달할 수 있습니다.,,
929,Those parameters are exposed by the image.,이러한 매개 변수는 이미지에 의해 노출됩니다.,,
930,"If you are using the k8api runtime, then the only way to pass parameters is through the file.",k8api 런타임을 사용하는 경우 매개 변수를 전달하는 유일한 방법은 파일을 사용하는 것입니다.,,
931,"In addition to our previous imports, we also want to import the Kubernetes client, which allows us to use Kubernetes functions directly from Python code (see EXAMPLE 4-12).",이전 가져 오기 외에도 Python 코드에서 직접 Kubernetes 함수를 사용할 수있는 Kubernetes 클라이언트도 가져 오려고합니다 (예 4-12 참조).,,
932,Example 4-12.,예 4-12.,,
933,"Exporting Kubernetes client
from kubernetes import client as k8s_client
Again, we create a client and experiment to run our pipeline.","Kubernetes 클라이언트 내보내기
kubernetes에서 클라이언트를 k8s_client로 가져 오기
다시 클라이언트를 만들고 파이프 라인을 실행하기위한 실험을합니다.",,
934,"As mentioned earlier, experiments group the runs of
pipelines.","앞서 언급했듯이 실험은
파이프 라인.",,
935,"You can only create a given experiment once, so EXAMPLE 4-13 shows how to either create a new experiment or
use an existing one.","주어진 실험은 한 번만 만들 수 있으므로 예 4-13에서는 새 실험을 만들거나
기존 것을 사용하십시오.",,
936,Example 4-13.,예 4-13.,,
937,"Obtaining pipeline experiment
client = kfp.Client()
exp = client.get_experiment(experiment_name ='mdupdate')
Now we create our pipeline (EXAMPLE 4-14).","파이프 라인 실험 구하기
클라이언트 = kfp.Client ()
exp = client.get_experiment (experiment_name = 'mdupdate')
이제 파이프 라인을 생성합니다 (예 4-14).",,
938,"The images used need to be accessible, and we’re specifying the full names, so they resolve.",사용 된 이미지는 액세스 할 수 있어야하며 전체 이름을 지정하므로 해결됩니다.,,
939,"Since these containers are prebuilt, we need to configure them for our pipeline.",이러한 컨테이너는 미리 빌드되었으므로 파이프 라인에 맞게 구성해야합니다.,,
940,The pre-built containers we are using have their storage configured by the MINIO_* environment variables.,우리가 사용하는 미리 빌드 된 컨테이너에는 MINIO_ * 환경 변수로 구성된 스토리지가 있습니다.,,
941,So we configure them to use our local MinIO install by calling  add_env_variable.,따라서 add_env_variable을 호출하여 로컬 MinIO 설치를 사용하도록 구성합니다.,,
942,"In addition to the automatic dependencies created when passing parameters between stages, you can also specify that a
stage requires a previous stage with after.","단계간에 매개 변수를 전달할 때 생성되는 자동 종속성 외에도
stage는 after와 함께 이전 단계가 필요합니다.",,
943,"This is most useful when there is an external side effect, like updating a database.",이는 데이터베이스 업데이트와 같은 외부 부작용이있을 때 가장 유용합니다.,,
944,Example 4-14.,예 4-14.,,
945,"Example recommender pipeline
@dsl.pipeline(
  name='Recommender model update',
  description='Demonstrate usage of pipelines for multi-step model update'
)
def recommender_pipeline():
    # Load new data
  data = dsl.ContainerOp(
      name='updatedata',
      image='lightbend/recommender-data-update-publisher:0.2') \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_URL',
        value='http://minio-service.kubeflow.svc.cluster.local:9000')) \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_KEY', value='minio')) \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_SECRET', value='minio123'))
    # Train the model
  train = dsl.ContainerOp(
      name='trainmodel',
      image='lightbend/ml-tf-recommender:0.2') \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_URL',
            value='minio-service.kubeflow.svc.cluster.local:9000')) \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_KEY', value='minio')) \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_SECRET', value='minio123'))
  train.after(data)
    # Publish new model
  publish = dsl.ContainerOp(
      name='publishmodel',
      image='lightbend/recommender-model-publisher:0.2') \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_URL',
            value='http://minio-service.kubeflow.svc.cluster.local:9000')) \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_KEY', value='minio')) \
    .add_env_variable(k8s_client.V1EnvVar(name='MINIO_SECRET', value='minio123')) \
    .add_env_variable(k8s_client.V1EnvVar(name='KAFKA_BROKERS',
            value='cloudflow-kafka-brokers.cloudflow.svc.cluster.local:9092')) \
    .add_env_variable(k8s_client.V1EnvVar(name='DEFAULT_RECOMMENDER_URL',
            value='http://recommendermodelserver.kubeflow.svc.cluster.local:8501')) \
    .add_env_variable(k8s_client.V1EnvVar(name='ALTERNATIVE_RECOMMENDER_URL',
            value='http://recommendermodelserver1.kubeflow.svc.cluster.local:8501'))
  publish.after(train)
Since the pipeline definition is just code, you can make it more compact by using a loop to set the MinIO parameters instead of doing it on each stage.","추천자 파이프 라인 예시
@ dsl.pipeline (
  name = '추천 모델 업데이트',
  description = '다단계 모델 업데이트를위한 파이프 라인 사용 시연'
)
def 추천자 _ 파이프 라인 () :
    # 새 데이터로드
  데이터 = dsl.ContainerOp (
      name = 'updatedata',
      image = 'lightbend / recommender-data-update-publisher : 0.2') \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_URL',
        value = 'http : //minio-service.kubeflow.svc.cluster.local : 9000')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_KEY', value = 'minio')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_SECRET', value = 'minio123'))
    # 모델 훈련
  기차 = dsl.ContainerOp (
      name = 'trainmodel',
      image = 'lightbend / ml-tf-recommender : 0.2') \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_URL',
            value = 'minio-service.kubeflow.svc.cluster.local : 9000')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_KEY', value = 'minio')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_SECRET', value = 'minio123'))
  train.after (데이터)
    # 새 모델 게시
  게시 = dsl.ContainerOp (
      name = 'publishmodel',
      image = 'lightbend / recommender-model-publisher : 0.2') \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_URL',
            value = 'http : //minio-service.kubeflow.svc.cluster.local : 9000')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_KEY', value = 'minio')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'MINIO_SECRET', value = 'minio123')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'KAFKA_BROKERS',
            value = 'cloudflow-kafka-brokers.cloudflow.svc.cluster.local : 9092')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'DEFAULT_RECOMMENDER_URL',
            value = 'http : //recommendermodelserver.kubeflow.svc.cluster.local : 8501')) \
    .add_env_variable (k8s_client.V1EnvVar (name = 'ALTERNATIVE_RECOMMENDER_URL',
            value = 'http : //recommendermodelserver1.kubeflow.svc.cluster.local : 8501'))
  publish.after (기차)
파이프 라인 정의는 코드 일 뿐이므로 각 단계에서 수행하는 대신 루프를 사용하여 MinIO 매개 변수를 설정하여 더 간결하게 만들 수 있습니다.",,
946,"As before, we need to compile the pipeline, either explicitly with compiler.Compiler().compile or implicitly with
create_run_from_pipeline_func.","이전과 마찬가지로, 우리는 명시 적으로 compiler.Compiler (). compile을 사용하거나 암시 적으로 다음을 사용하여 파이프 라인을 컴파일해야합니다.
create_run_from_pipeline_func.",,
947,Now go ahead and run the pipeline (as in FIGURE 4-8).,이제 파이프 라인을 실행합니다 (그림 4-8 참조).,,
948,Figure 4-8.,그림 4-8.,,
949,"Execution of recommender pipelines example



4.2.4.","추천 파이프 라인 실행 예시



4.2.4.",,
950,"Kubeflow Pipeline Components
In addition to container operations which we’ve just discussed, Kubeflow Pipelines also exposes additional operations
with components.","Kubeflow 파이프 라인 구성 요소
방금 논의한 컨테이너 작업 외에도 Kubeflow Pipelines는 추가 작업도 제공합니다.
구성 요소.",,
951,Components expose different Kubernetes resources or external operations (like dataproc).,구성 요소는 다른 Kubernetes 리소스 또는 외부 작업 (예 : dataproc)을 노출합니다.,,
952,Kubeflow components allow developers to package machine learning tools while abstracting away the specifics on the containers or CRDs used.,Kubeflow 구성 요소를 통해 개발자는 사용 된 컨테이너 또는 CRD에 대한 세부 사항을 추상화하면서 기계 학습 도구를 패키징 할 수 있습니다.,,
953,"We have used Kubeflow’s building blocks fairly directly, and we have used the func_to_container component.",우리는 Kubeflow의 빌딩 블록을 공정하게 직접 사용했으며 func_to_container 구성 요소를 사용했습니다.,,
954,"[6]
Some components, like func_to_container, are available as Python code and can be imported like normal.","[6]
func_to_container와 같은 일부 구성 요소는 Python 코드로 사용할 수 있으며 정상적으로 가져올 수 있습니다.",,
955,Other components are specified using Kubeflow’s component.yaml system and need to be loaded.,다른 구성 요소는 Kubeflow의 component.yaml 시스템을 사용하여 지정되며로드해야합니다.,,
956,"In our opinion, the best way to work with Kubeflow components is to download a specific tag of the repo, allowing us to use load_component_from_file, as shown in EXAMPLE 4-15.",우리의 의견으로는 Kubeflow 구성 요소를 사용하는 가장 좋은 방법은 저장소의 특정 태그를 다운로드하여 예제 4-15에 표시된 것처럼 load_component_from_file을 사용할 수 있도록하는 것입니다.,,
957,Example 4-15.,예 4-15.,,
958,"Pipeline release
wget https://github.com/kubeflow/pipelines/archive/0.2.5.tar.gz
tar -xvf 0.2.5.tar.gz
Warning
There is a load_component function that takes a component’s name and attempts to resolve it.","파이프 라인 출시
wget https://github.com/kubeflow/pipelines/archive/0.2.5.tar.gz
tar -xvf 0.2.5.tar.gz
경고
구성 요소의 이름을 가져와 해결을 시도하는 load_component 함수가 있습니다.",,
959,"We don’t recommend
using this function since it defaults to a search path that includes fetching, from Github, the master branch of the pipelines library, which is unstable.","권장하지 않습니다.
이 함수는 불안정한 파이프 라인 라이브러리의 마스터 브랜치 인 Github에서 가져 오기를 포함하는 검색 경로로 기본 설정되기 때문에이 함수를 사용합니다.",,
960,"We explore data preparation components in depth in the next chapter; however, let’s quickly look at a file-fetching component as an example.",다음 장에서 데이터 준비 구성 요소를 자세히 살펴 봅니다.그러나 파일 가져 오기 구성 요소를 예로 빠르게 살펴 보겠습니다.,,
961,"In our recommender example earlier in the chapter, we used a special prebuilt container to fetch our data since it was not already in a persistent volume.",이 장의 앞부분에있는 추천 예제에서는 데이터가 아직 영구 볼륨에 있지 않았기 때문에 미리 빌드 된 특수 컨테이너를 사용하여 데이터를 가져 왔습니다.,,
962,"Instead, we can use the Kubeflow GCS component google-cloud/storage/download/ to download our data.",대신 Kubeflow GCS 구성 요소 google-cloud / storage / download /를 사용하여 데이터를 다운로드 할 수 있습니다.,,
963,"Assuming you’ve downloaded the pipeline release as in EXAMPLE 4-15, you can load the component with load_component_from_file as in EXAMPLE 4-16.",예 4-15 에서처럼 파이프 라인 릴리스를 다운로드했다고 가정하면 예 4-16 에서처럼 load_component_from_file을 사용하여 구성 요소를로드 할 수 있습니다.,,
964,Example 4-16.,예 4-16.,,
965,"Load GCS download component
gcs_download_component = kfp.components.load_component_from_file(
    ""pipelines-0.2.5/components/google-cloud/storage/download/component.yaml"")
When a component is loaded, it returns a function that produces a pipeline stage when called.","GCS 다운로드 구성 요소로드
gcs_download_component = kfp.components.load_component_from_file (
    ""pipelines-0.2.5 / components / google-cloud / storage / download / component.yaml"")
구성 요소가로드되면 호출 될 때 파이프 라인 단계를 생성하는 함수를 반환합니다.",,
966,Most components take parameters to configure their behavior.,대부분의 구성 요소는 매개 변수를 사용하여 동작을 구성합니다.,,
967,"You can get a list of the components’ options by calling help on the loaded component, or looking at the component.yaml.",로드 된 구성 요소에 대한 도움말을 호출하거나 component.yaml을 확인하여 구성 요소의 옵션 목록을 가져올 수 있습니다.,,
968,"The GCS download component requires us to configure what we are downloading
with gcs_path, shown in EXAMPLE 4-17.","GCS 다운로드 구성 요소를 사용하려면 다운로드중인 항목을 구성해야합니다.
gcs_path 사용 (예 4-17 참조).",,
969,Example 4-17.,예 4-17.,,
970,"Loading pipeline storage component from relative path and web link
    dl_op = gcs_download_component(
        gcs_path=
        ""gs://ml-pipeline-playground/tensorflow-tfx-repo/tfx/components/testdata/external/csv""
    )  # Your path goes here
In CHAPTER 5, we explore more common Kubeflow pipeline components for data and feature preparation.","상대 경로 및 웹 링크에서 파이프 라인 스토리지 구성 요소로드
    dl_op = gcs_download_component (
        gcs_path =
        ""gs : // ml-pipeline-playground / tensorflow-tfx-repo / tfx / components / testdata / external / csv""
    ) # 경로는 여기에 있습니다.
5 장에서는 데이터 및 기능 준비를위한보다 일반적인 Kubeflow 파이프 라인 구성 요소를 살펴 봅니다.",,
971,4.3.,4.3.,,
972,"Advanced Topics in Pipelines
All of the examples that we have shown so far are purely sequential.","파이프 라인의 고급 주제
지금까지 보여 드린 모든 예제는 순전히 순차적입니다.",,
973,There are also cases in which we need the ability to check conditions and change the behavior of the pipeline accordingly.,조건을 확인하고 그에 따라 파이프 라인의 동작을 변경하는 기능이 필요한 경우도 있습니다.,,
974,4.3.1.,4.3.1.,,
975,"Conditional Execution of Pipeline Stages
Kubeflow Pipelines allows conditional executions via dsl.Condition.","파이프 라인 단계의 조건부 실행
Kubeflow Pipelines는 dsl.Condition을 통해 조건부 실행을 허용합니다.",,
976,"Let’s look at a very simple example, where, depending on the value of a variable, different calculations are executed.",변수 값에 따라 다른 계산이 실행되는 매우 간단한 예를 살펴 보겠습니다.,,
977,A simple notebook implementing this example follows.,이 예제를 구현하는 간단한 노트북은 다음과 같습니다.,,
978,"It starts with the imports necessary for this, in EXAMPLE 4-18.",이를 위해 필요한 가져 오기로 시작합니다 (예 4-18).,,
979,Example 4-18.,예 4-18.,,
980,"Importing required components
import kfp
from kfp import dsl
from kfp.components import func_to_container_op, InputPath, OutputPath
Once the imports are in place, we can implement several simple functions, as shown in EXAMPLE 4-19.","필수 구성 요소 가져 오기
kfp 가져 오기
kfp import dsl에서
kfp.components에서 import func_to_container_op, InputPath, OutputPath
가져 오기가 완료되면 예제 4-19에 표시된대로 몇 가지 간단한 기능을 구현할 수 있습니다.",,
981,Example 4-19.,예 4-19.,,
982,"Functions implementation
@func_to_container_op
def get_random_int_op(minimum: int, maximum: int) -> int:
    """"""Generate a random number between minimum and maximum (inclusive).""""""","기능 구현
안녕하세요.
def get_random_int_op (최소 : int, 최대 : int)-> int :
    """" ""최소값과 최대 값 (포함) 사이의 임의의 숫자를 생성합니다."" """"",,
983,"import random
    result = random.randint(minimum, maximum)
    print(result)
    return result

@func_to_container_op
def process_small_op(data: int):
    """"""Process small numbers.""""""","무작위로 가져 오기
    결과 = random.randint (최소, 최대)
    인쇄 (결과)
    반환 결과

안녕하세요.
def process_small_op (데이터 : int) :
    """" ""작은 숫자 처리."" """"",,
984,"print(""Processing small result"", data)
    return

@func_to_container_op
def process_medium_op(data: int):
    """"""Process medium numbers.""""""","print ( ""작은 결과 처리"", 데이터)
    반환

안녕하세요.
def process_medium_op (데이터 : 정수) :
    """" ""매체 번호 처리"" """"",,
985,"print(""Processing medium result"", data)
    return

@func_to_container_op
def process_large_op(data: int):
    """"""Process large numbers.""""""","print ( ""처리 매체 결과"", 데이터)
    반환

안녕하세요.
def process_large_op (데이터 : 정수) :
    """" ""많은 수를 처리합니다."" """"",,
986,"print(""Processing large result"", data)
    return
We implement all of the functions directly using Python (as in the previous example).","print ( ""큰 결과 처리 중"", 데이터)
    반환
모든 함수를 Python을 사용하여 직접 구현합니다 (이전 예제에서와 같이).",,
987,"The first function generates an integer between 0 and 100, and the next three constitute a simple skeleton for the actual processing.",첫 번째 함수는 0에서 100 사이의 정수를 생성하고 다음 세 함수는 실제 처리를위한 간단한 골격을 구성합니다.,,
988,The pipeline is implemented as in EXAMPLE 4-20.,파이프 라인은 예 4-20에서와 같이 구현됩니다.,,
989,Example 4-20.,예 4-20.,,
990,"Pipeline implementation
@dsl.pipeline(
    name='Conditional execution pipeline',
    description='Shows how to use dsl.Condition().'","파이프 라인 구현
@ dsl.pipeline (
    name = '조건부 실행 파이프 라인',
    description = 'dsl.Condition () 사용법을 보여줍니다.'",,
991,")
def conditional_pipeline():
    number = get_random_int_op(0, 100).output 
    with dsl.Condition(number < 10): 
	process_small_op(number)
    with dsl.Condition(number > 10 and number < 50): 
	process_medium_op(number)
    with dsl.Condition(number > 50): 
	process_large_op(number)

kfp.Client().create_run_from_pipeline_func(conditional_pipeline, arguments={}) 


Depending on the number we get here…

We will continue on to one of these operations.",")
def conditional_pipeline () :
    숫자 = get_random_int_op (0, 100) .output
    dsl.Condition (숫자 <10) :
process_small_op (숫자)
    dsl.Condition (숫자> 10 및 숫자 <50) 사용 :
process_medium_op (숫자)
    dsl.Condition (숫자> 50) :
process_large_op (숫자)

kfp.Client (). create_run_from_pipeline_func (조건부 _ 파이프 라인, 인수 = {})


여기에 오는 숫자에 따라 ...

우리는 이러한 작업 중 하나를 계속할 것입니다.",,
992,Note here that we are specifying empty arguments—required parameter.,여기서는 필수 매개 변수 인 빈 인수를 지정하고 있습니다.,,
993,"Finally, the execution graph, as shown in FIGURE 4-9.",마지막으로 그림 4-9에 표시된 실행 그래프입니다.,,
994,Figure 4-9.,그림 4-9.,,
995,"Execution of conditional pipelines example

From this graph, we can see that the pipeline really splits into three branches and process-large-op execution is selected in this run.","조건부 파이프 라인 실행 예제

이 그래프에서 파이프 라인이 실제로 세 개의 분기로 분할되고이 실행에서 프로세스 대규모 작업 실행이 선택되었음을 알 수 있습니다.",,
996,"To validate that this is correct, we look at the execution log, shown in FIGURE 4-10.",이것이 올바른지 확인하기 위해 그림 4-10에 표시된 실행 로그를 살펴 봅니다.,,
997,Figure 4-10.,그림 4-10.,,
998,"Viewing conditional pipeline log

Here we can see that the generated number is 67.","조건부 파이프 라인 로그보기

여기에서 생성 된 숫자가 67임을 알 수 있습니다.",,
999,"This number is larger than 50, which means that the process_large_op branch should be executed.",이 숫자는 50보다 크므로 process_large_op 분기를 실행해야합니다.,,
1000,"[7]


4.3.2.","[7]


4.3.2.",,
1001,"Running Pipelines on Schedule
We have run our pipeline manually.","일정에 따라 파이프 라인 실행
파이프 라인을 수동으로 실행했습니다.",,
1002,"This is good for testing, but is often insufficient for production environments.",이것은 테스트에는 좋지만 프로덕션 환경에는 종종 충분하지 않습니다.,,
1003,"Fortunately, you can run pipelines on a schedule, as described on  thisKubeflow documentation page.",다행히이 Kubeflow 문서 페이지에 설명 된대로 일정에 따라 파이프 라인을 실행할 수 있습니다.,,
1004,"First, you need to upload a pipeline definition and specify a description.",먼저 파이프 라인 정의를 업로드하고 설명을 지정해야합니다.,,
1005,"When this is done, you can create a periodic run by
creating a run and selecting a run type of “Recurring,” then following the instructions on the screen, as seen in FIGURE 4-11.","이 작업이 완료되면 다음을 통해 정기적 인 실행을 만들 수 있습니다.
실행을 만들고 ""반복""실행 유형을 선택한 다음 그림 4-11에 표시된대로 화면의 지침을 따릅니다.",,
1006,In this figure we are setting a pipeline to run every day.,이 그림에서는 매일 실행되도록 파이프 라인을 설정하고 있습니다.,,
1007,"Warning
When creating a periodic run we are specifying how often to run a pipeline, not when to run it.","경고
주기적 실행을 생성 할 때 파이프 라인 실행시기가 아니라 실행 빈도를 지정합니다.",,
1008,"In the
current implementation, the time of execution is defined by when the run is created.","에서
현재 구현에서 실행 시간은 실행이 생성 될 때 정의됩니다.",,
1009,"Once it is created, it is executed
immediately and then executed with the defined frequency.","생성되면 실행됩니다.
즉시 정의 된 빈도로 실행됩니다.",,
1010,"If, for example, a daily run is created at 10 am, it will be executed at 10 am daily.",예를 들어 일일 실행이 오전 10시에 생성되면 매일 오전 10시에 실행됩니다.,,
1011,"Setting periodic execution of pipelines is an important functionality, allowing you to completely automate pipeline execution.",파이프 라인의주기적인 실행을 설정하는 것은 파이프 라인 실행을 완전히 자동화 할 수있는 중요한 기능입니다.,,
1012,Figure 4-11.,그림 4-11.,,
1013,"Setting up periodic execution of a pipeline




4.4.","파이프 라인의 주기적 실행 설정




4.4.",,
1014,"Conclusion
You should now have the basics of how to build, schedule, and run some simple pipelines.","결론
이제 몇 가지 간단한 파이프 라인을 빌드, 예약 및 실행하는 방법에 대한 기본 사항이 있습니다.",,
1015,"You also learned about the
tools that pipelines use for when you need to debug.","당신은 또한에 대해 배웠습니다
디버그해야 할 때 파이프 라인에서 사용하는 도구입니다.",,
1016,"We showed how to integrate existing software into pipelines, how to implement conditional execution inside a pipeline, and how to run pipelines on a schedule.","기존 소프트웨어를 파이프 라인에 통합하는 방법, 파이프 라인 내에서 조건부 실행을 구현하는 방법, 일정에 따라 파이프 라인을 실행하는 방법을 보여주었습니다.",,
1017,"In our next chapter, we look at how to use pipelines for data preparation with some examples.",다음 장에서는 몇 가지 예를 통해 데이터 준비를 위해 파이프 라인을 사용하는 방법을 살펴 봅니다.,,
1018,[1] This can often be automatically inferred when passing the result of one pipeline stage as the input to others.,[1] 이것은 종종 한 파이프 라인 단계의 결과를 다른 단계의 입력으로 전달할 때 자동으로 추론 될 수 있습니다.,,
1019,You can also specify additional dependencies manually.,추가 종속성을 수동으로 지정할 수도 있습니다.,,
1020,[2] Kubernetes persistent volumes can provide different access modes.,[2] Kubernetes 영구 볼륨은 다양한 액세스 모드를 제공 할 수 있습니다.,,
1021,[3] Generic read-write-many implementation is NFS server.,[3] 일반적인 읽기-쓰기-다수 구현은 NFS 서버입니다.,,
1022,[4] Usage of the cloud native access storage can be handy if you need to ensure portability of your solution across multiple cloud providers.,[4] 여러 클라우드 공급자간에 솔루션의 이식성을 보장해야하는 경우 클라우드 네이티브 액세스 스토리지를 사용하면 편리 할 수 있습니다.,,
1023,"[5] For installation of Argo Workflow on another OS, refer to these Argo instructions.",[5] 다른 OS에 Argo Workflow를 설치하려면이 Argo 지침을 참조하십시오.,,
1024,[6] Many of the standard components are in this Kubeflow GitHub repo.,[6] 많은 표준 구성 요소가이 Kubeflow GitHub 저장소에 있습니다.,,
1025,[7] A slightly more complex example of conditional processing (with nested conditions) can be found in this GitHub site.,[7]이 GitHub 사이트에서 조건부 처리의 약간 더 복잡한 예 (중첩 된 조건 포함)를 찾을 수 있습니다.,,
1026,Chapter 5.,5 장.,,
1027,"Data and Feature Preparation
Machine learning algorithms are only as good as their training data.","데이터 및 기능 준비
기계 학습 알고리즘은 훈련 데이터만큼 우수합니다.",,
1028,Getting good data for training involves data and feature preparation.,훈련을위한 좋은 데이터를 얻으려면 데이터와 기능 준비가 필요합니다.,,
1029,Data preparation is the process of sourcing the data and making sure it’s valid.,데이터 준비는 데이터를 소싱하고 유효한지 확인하는 프로세스입니다.,,
1030,"This is a multistep process[1] that can include data collection, augmentation, statistics calculation, schema validation, outlier pruning, and various validation techniques.","이것은 데이터 수집, 증강, 통계 계산, 스키마 유효성 검사, 이상치 정리 및 다양한 유효성 검사 기술을 포함 할 수있는 다단계 프로세스 [1]입니다.",,
1031,"Not having enough data can lead to overfitting, missing significant correlations, and more.","데이터가 충분하지 않으면 과적 합, 중요한 상관 관계 누락 등이 발생할 수 있습니다.",,
1032,Putting in the effort to collect more records and information about each sample during data preparation can considerably improve the model.,데이터 준비 중에 각 샘플에 대한 더 많은 기록과 정보를 수집하려는 노력을 기울이면 모델을 상당히 개선 할 수 있습니다.,,
1033,"[2]
Feature preparation (sometimes called feature engineering) refers to transforming the raw input data into features that the machine learning model can use.","[2]
특성 준비 (특성 엔지니어링이라고도 함)는 원시 입력 데이터를 기계 학습 모델이 사용할 수있는 특성으로 변환하는 것을 의미합니다.",,
1034,"[3] Poor feature preparation can lead to losing out on important relations, such as a linear model with nonlinear terms not expanded, or a deep learning model with inconsistent image 
orientation.","[3] 잘못된 특성 준비는 비선형 용어가 확장되지 않은 선형 모델 또는 일관되지 않은 이미지가있는 딥 러닝 모델과 같은 중요한 관계를 놓칠 수 있습니다.
정위.",,
1035,Small changes in data and feature preparation can lead to significantly different model outputs.,데이터 및 기능 준비의 작은 변경으로 인해 모델 출력이 크게 달라질 수 있습니다.,,
1036,"The iterative approach is the best for both feature and data preparation, revisiting them as your understanding of the problem and model changes.",반복적 접근 방식은 기능 및 데이터 준비 모두에 가장 적합하며 문제에 대한 이해와 모델 변경에 따라 다시 검토합니다.,,
1037,Kubeflow Pipelines makes it easier for us to iterate our data and feature preparation.,Kubeflow Pipelines를 사용하면 데이터 및 기능 준비를 더 쉽게 반복 할 수 있습니다.,,
1038,We will explore how to use hyperparameter tuning to iterate in CHAPTER 10.,10 장에서 반복하기 위해 하이퍼 파라미터 튜닝을 사용하는 방법을 살펴 보겠습니다.,,
1039,"In this chapter, we will cover different approaches to data and feature preparation and demonstrate how to make them repeatable by using pipelines.",이 장에서는 데이터 및 기능 준비에 대한 다양한 접근 방식을 다루고 파이프 라인을 사용하여 반복 가능하게 만드는 방법을 보여줍니다.,,
1040,We assume you are already familiar with local tools.,이미 로컬 도구에 익숙하다고 가정합니다.,,
1041,"As such, we’ll start by covering how to structure our local code for pipelines, and then move on to more scalable distributed tools.",따라서 파이프 라인에 대한 로컬 코드를 구성하는 방법부터 시작하여 확장 가능한 분산 도구로 이동합니다.,,
1042,"Once we’ve explored the tools, we’ll put them together in a pipeline, using the examples from SECTION 1.7.",도구를 살펴본 후에는 섹션 1.7의 예를 사용하여 도구를 파이프 라인에 통합 할 것입니다.,,
1043,5.1.,5.1.,,
1044,"Deciding on the Correct Tooling
There are a wide variety of data and feature preparation tools.","올바른 툴링 결정
다양한 데이터 및 기능 준비 도구가 있습니다.",,
1045,[4] We can categorize them into distributed and local.,[4] 분산 형과 로컬 형으로 분류 할 수 있습니다.,,
1046,Local tools run on a single machine and offer a great amount of flexibility.,로컬 도구는 단일 시스템에서 실행되며 상당한 유연성을 제공합니다.,,
1047,Distributed tools run on many machines so they can handle larger and more complex tasks.,분산 도구는 많은 컴퓨터에서 실행되므로 더 크고 복잡한 작업을 처리 할 수 있습니다.,,
1048,"With two very distinct paths of tooling, making the wrong decision here can require substantial changes in code later.",두 가지 매우 다른 도구 경로를 사용하여 여기서 잘못된 결정을 내리려면 나중에 코드를 크게 변경해야 할 수 있습니다.,,
1049,"If the input data size is relatively small, a single machine offers you all of the tools you are used to.",입력 데이터 크기가 상대적으로 작은 경우 단일 머신이 익숙한 모든 도구를 제공합니다.,,
1050,Larger data sizes tend to require distributed tools for the entire pipeline or just as a sampling stage.,데이터 크기가 클수록 전체 파이프 라인 또는 샘플링 단계에 분산 된 도구가 필요한 경향이 있습니다.,,
1051,"Even with smaller datasets, distributed systems, like Apache Spark, Dask, or TFX with Beam, can be faster but may require learning new tools.","더 작은 데이터 세트로도 Apache Spark, Dask 또는 TFX with Beam과 같은 분산 시스템은 더 빠를 수 있지만 새로운 도구를 학습해야 할 수 있습니다.",,
1052,"[5]
Using the same tool for all of the data and feature preparation activities is not necessary.","[5]
모든 데이터 및 기능 준비 활동에 동일한 도구를 사용할 필요는 없습니다.",,
1053,Using multiple tools is especially common when working with different datasets where using the same tools would be inconvenient.,여러 도구를 사용하는 것은 동일한 도구를 사용하는 것이 불편할 수있는 다른 데이터 세트로 작업 할 때 특히 일반적입니다.,,
1054,Kubeflow Pipelines allows you to split the implementation into multiple steps and connect them (even if they use different languages) into a cohesive system.,Kubeflow Pipelines를 사용하면 구현을 여러 단계로 분할하고 서로 다른 언어를 사용하더라도 하나의 응집 된 시스템으로 연결할 수 있습니다.,,
1055,5.2.,5.2.,,
1056,"Local Data and Feature Preparation
Working locally limits the scale of data but offers the most comprehensive range of tools.","로컬 데이터 및 기능 준비
로컬 작업은 데이터의 규모를 제한하지만 가장 포괄적 인 도구 범위를 제공합니다.",,
1057,A common way to implement data and feature preparation is with Jupyter notebooks.,데이터 및 기능 준비를 구현하는 일반적인 방법은 Jupyter 노트북을 사용하는 것입니다.,,
1058,"In CHAPTER 4, we covered how to turn parts of the notebook into a pipeline, and here we’ll look at how to structure our data and feature prep code to make this easy.",4 장에서는 노트북의 일부를 파이프 라인으로 전환하는 방법을 다루었으며 여기에서는이를 쉽게 수행 할 수 있도록 데이터 및 기능 준비 코드를 구성하는 방법을 살펴 보겠습니다.,,
1059,Using notebooks for data preparation can be a great way to start exploring the data.,데이터 준비를 위해 노트북을 사용하는 것은 데이터 탐색을 시작하는 좋은 방법이 될 수 있습니다.,,
1060,"Notebooks can be especially useful at this stage since we often have the least amount of understanding, and because using visualizations to understand our data can be quite beneficial.",우리는 종종 최소한의 이해도를 가지고 있고 시각화를 사용하여 데이터를 이해하는 것이 매우 유익 할 수 있기 때문에 노트북은이 단계에서 특히 유용 할 수 있습니다.,,
1061,5.2.1.,5.2.1.,,
1062,"Fetching the Data
For our mailing list example, we use data from public archives on the internet.","데이터 가져 오기
메일 링리스트의 예에서는 인터넷에있는 공개 아카이브의 데이터를 사용합니다.",,
1063,"Ideally, you want to connect to a database, stream, or other data repository.","이상적으로는 데이터베이스, 스트림 또는 기타 데이터 저장소에 연결하려고합니다.",,
1064,"However, even in production, fetching web data can be necessary.",그러나 프로덕션 환경에서도 웹 데이터를 가져와야 할 수 있습니다.,,
1065,"First, we’ll implement our data-fetching algorithm, which takes an Apache Software Foundation (ASF) project’s email list location along with the year from which to fetch messages.",먼저 ASF (Apache Software Foundation) 프로젝트의 이메일 목록 위치와 메시지를 가져올 연도를 가져 오는 데이터 가져 오기 알고리즘을 구현합니다.,,
1066,EXAMPLE 5-1 returns the path to the records it fetches so we can use that as the input to the next pipeline stage.,예 5-1은 가져 오는 레코드의 경로를 반환하므로이를 다음 파이프 라인 단계의 입력으로 사용할 수 있습니다.,,
1067,"Note
The function downloads at most one year of data, and it sleeps between calls.","노트
이 함수는 최대 1 년 분량의 데이터를 다운로드하며 호출 사이에 휴면합니다.",,
1068,This is to prevent overwhelming the ASF mail archive servers.,이는 ASF 메일 보관 서버의 과부하를 방지하기위한 것입니다.,,
1069,The ASF is a charity, please be mindful of that when downloading data and do not abuse this service.,ASF는 자선 단체입니다.데이터를 다운로드 할 때이를 염두에두고이 서비스를 남용하지 마십시오.,
1070,Example 5-1.,예 5-1.,,
1071,"Downloading the mailing list data
def download_data(year: int) -> str:

  # The imports are inline here so Kubeflow can serialize the function correctly.","메일 링리스트 데이터 다운로드
def download_data (year : int)-> str :

  # 가져 오기는 여기에서 인라인되므로 Kubeflow가 함수를 올바르게 직렬화 할 수 있습니다.",,
1072,"from datetime import datetime
  from lxml import etree
  from requests import get
  from time import sleep

 import json

  def scrapeMailArchives(mailingList: str, year: int, month: int):
      #Ugly xpath code goes here.","datetime 가져 오기 datetime에서
  lxml에서 etree 가져 오기
  요청에서 가져 오기 가져 오기
  시간 수입 수면에서

 json 가져 오기

  def scrapeMailArchives (mailingList : str, year : int, month : int) :
      #Ugly xpath 코드는 여기에 있습니다.",,
1073,See the example repo if you're curious.,궁금하다면 예제 저장소를 참조하세요.,,
1074,"datesToScrape =  [(year, i) for i in range(1,2)]

   records = []
   for y,m in datesToScrape:
     print(m,""-"",y)
     records += scrapeMailArchives(""spark-dev"", y, m)
   output_path = '/data_processing/data.json'
   with open(output_path, 'w') as f:
     json.dump(records, f)

   return output_path
This code downloads all of the mailing list data for a given year and saves it to a known path.","dateToScrape = [(year, i) for i in range (1,2)]]

   레코드 = []
   dateToScrape의 y, m :
     print (m, ""-"", y)
     레코드 + = scrapeMailArchives ( ""spark-dev"", y, m)
   output_path = '/data_processing/data.json'
   open (output_path, 'w')를 f로 사용 :
     json.dump (레코드, f)

   output_path 반환
이 코드는 특정 연도의 모든 메일 링리스트 데이터를 다운로드하여 알려진 경로에 저장합니다.",,
1075,"In this example, a persistent volume needs to be mounted there to allow this data to move between stages, when we make our pipeline.",이 예에서는 파이프 라인을 만들 때이 데이터가 단계간에 이동할 수 있도록 영구 볼륨을 마운트해야합니다.,,
1076,"You may have a data dump as part of the machine learning pipeline, or a different system or team may provide one.",머신 러닝 파이프 라인의 일부로 데이터 덤프가 있거나 다른 시스템 또는 팀에서 제공 할 수 있습니다.,,
1077,"For data on GCS or a PV, you can use the built-in components google-cloud/storage/download or filesystem/get_subdirectory to load the data instead of writing a custom function.",GCS 또는 PV의 데이터의 경우 맞춤 함수를 작성하는 대신 기본 제공 구성 요소 google-cloud / storage / download 또는 filesystem / get_subdirectory를 사용하여 데이터를로드 할 수 있습니다.,,
1078,5.2.2.,5.2.2.,,
1079,"Data Cleaning: Filtering Out the Junk
Now that we’ve loaded our data, it’s time to do some simple data cleaning.","데이터 정리 : 정크 필터링
이제 데이터를로드 했으므로 간단한 데이터 정리를 수행 할 차례입니다.",,
1080,"Local tools are more common, so we’ll focus on them first.",로컬 도구가 더 일반적이므로 먼저 해당 도구에 초점을 맞출 것입니다.,,
1081,"While data cleaning often depends on domain expertise, there are standard tools to assist with common tasks.",데이터 정리는 종종 도메인 전문 지식에 의존하지만 일반적인 작업을 지원하는 표준 도구가 있습니다.,,
1082,A first step can be validating input records by checking the schema.,첫 번째 단계는 스키마를 확인하여 입력 레코드의 유효성을 검사하는 것입니다.,,
1083,"That is to say, we check to see if the fields are present and are the right type.","즉, 필드가 있고 올바른 유형인지 확인합니다.",,
1084,"To check the schema in the mailing list example, we ensure a sender,  subject, and body all exist.","메일 링리스트 예제에서 스키마를 확인하기 위해 보낸 사람, 제목 및 본문이 모두 존재하는지 확인합니다.",,
1085,"To convert this into an independent component, we’ll make our function take a parameter for the input path and return the file path to the cleaned records.",이를 독립적 인 구성 요소로 변환하기 위해 함수가 입력 경로에 대한 매개 변수를 취하고 파일 경로를 정리 된 레코드로 반환하도록 할 것입니다.,,
1086,"The amount of code it takes to do this is relatively small, shown in EXAMPLE 5-2.",이를 수행하는 데 필요한 코드의 양은 비교적 적습니다 (예제 5-2 참조).,,
1087,Example 5-2.,예 5-2.,,
1088,"Data cleaning
def clean_data(input_path: str) -> str:
    import json
    import pandas as pd

    print(""loading records..."")
    with open(input_path, 'r') as f:
        records = json.load(f)
    print(""records loaded"")

    df = pd.DataFrame(records)
    # Drop records without a subject, body, or sender
    cleaned = df.dropna(subset=[""subject"", ""body"", ""from""])

    output_path_hdf = '/data_processing/clean_data.hdf'
    cleaned.to_hdf(output_path_hdf, key=""clean"")

    return output_path_hdf
There are many other standard data quality techniques besides dropping missing fields.","데이터 정리
def clean_data (input_path : str)-> str :
    json 가져 오기
    팬더를 pd로 가져 오기

    print ( ""레코드로드 중 ..."")
    open (input_path, 'r')을 f로 사용 :
        레코드 = json.load (f)
    print ( ""로드 된 레코드"")

    df = pd.DataFrame (레코드)
    # 제목, 본문 또는 보낸 사람없이 레코드 삭제
    clean = df.dropna (subset = [ ""subject"", ""body"", ""from""])

    output_path_hdf = '/data_processing/clean_data.hdf'
    clean.to_hdf (output_path_hdf, key = ""clean"")

    output_path_hdf 반환
누락 된 필드를 삭제하는 것 외에 다른 많은 표준 데이터 품질 기술이 있습니다.",,
1089,Two of the more popular ones are imputing missing data[6] and analyzing and removing outliers that may be the result of incorrect measurements.,더 많이 사용되는 두 가지 방법은 누락 된 데이터를 대치하고 [6] 잘못된 측정의 결과 일 수있는 이상 값을 분석 및 제거하는 것입니다.,,
1090,"Regardless of which additional general techniques you decide to perform, you can simply add them to your data-cleaning function.",수행하기로 결정한 추가 일반 기술에 관계없이 단순히 데이터 정리 기능에 추가 할 수 있습니다.,,
1091,Domain specific data cleaning tools can also be beneficial.,도메인 별 데이터 정리 도구도 유용 할 수 있습니다.,,
1092,"In the mailing list example, one potential source of noise in our data could be spam messages.",메일 링리스트 예에서 데이터의 잠재적 잡음 원인 중 하나는 스팸 메시지 일 수 있습니다.,,
1093,One way to solve this would be by using SpamAssassin.,이를 해결하는 한 가지 방법은 SpamAssassin을 사용하는 것입니다.,,
1094,We can add this package to our container as shown in EXAMPLE 5-3.,예제 5-3에 표시된대로 컨테이너에이 패키지를 추가 할 수 있습니다.,,
1095,"Adding system software, not managed by pip, on top of the notebook images is a bit more complicated because of permissions.",노트북 이미지 위에 pip로 관리되지 않는 시스템 소프트웨어를 추가하는 것은 권한 때문에 조금 더 복잡합니다.,,
1096,"Most containers run as root, making it simple to install new system packages.",대부분의 컨테이너는 루트로 실행되므로 새 시스템 패키지를 간단하게 설치할 수 있습니다.,,
1097,"However, because of Jupyter, the notebook containers run as a less privileged user.",그러나 Jupyter로 인해 노트북 컨테이너는 권한이 낮은 사용자로 실행됩니다.,,
1098,"Installing new packages like this requires switching to the root user and back, which is not common in other Dockerfiles.",이와 같은 새 패키지를 설치하려면 루트 사용자로 전환했다가 다시 돌아 가야합니다. 이는 다른 Dockerfile에서는 일반적이지 않습니다.,,
1099,Example 5-3.,예 5-3.,,
1100,"Installing SpamAssassin
ARG base
FROM $base
# Run as root for updates
USER root
# Install SpamAssassin
RUN apt-get update && \
    apt-get install -yq spamassassin spamc && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    rm -rf /var/cache/apt
# Switch back to the expected user
USER jovyan
After you created this Dockerfile, you’ll want to build it and push the resulting image somewhere that the Kubeflow cluster can access, as in EXAMPLE 2-8.","SpamAssassin 설치
ARG베이스
$ base에서
# 업데이트를 위해 루트로 실행
USER 루트
# SpamAssassin 설치
apt-get 업데이트 실행 && \
    apt-get install -yq spamassassin spamc && \
    apt-get clean && \
    rm -rf / var / lib / apt / lists / * && \
    rm -rf / var / cache / apt
# 예상 사용자로 다시 전환
사용자 jovyan
이 Dockerfile을 만든 후에는이를 빌드하고 결과 이미지를 Kubeflow 클러스터가 액세스 할 수있는 위치에 푸시하려고합니다 (예제 2-8 참조).",,
1101,Pushing a new container is not enough to let Kubeflow know that we want to use it.,새 컨테이너를 푸시하는 것만으로는 Kubeflow에 우리가 사용하고 싶다는 것을 알 수 없습니다.,,
1102,"When constructing a pipeline stage with func_to_container_op, you then need to specify the base_image parameter to the func_to_container_op function call.",func_to_container_op을 사용하여 파이프 라인 단계를 생성 할 때 func_to_container_op 함수 호출에 base_image 매개 변수를 지정해야합니다.,,
1103,We’ll show this when we bring the example together as a pipeline in EXAMPLE 5-35.,예제 5-35에서 예제를 파이프 라인으로 함께 가져올 때이를 보여줍니다.,,
1104,Here we see the power of containers again.,여기서 우리는 컨테이너의 힘을 다시 봅니다.,,
1105,You can add the tools we need on top of the building blocks provided by Kubeflow rather than making everything from scratch.,모든 것을 처음부터 만드는 대신 Kubeflow에서 제공하는 빌딩 블록 위에 필요한 도구를 추가 할 수 있습니다.,,
1106,"Once the data is cleaned, it’s time to make sure you have enough of it, or if not, explore augmenting your data.",데이터가 정리되면 데이터가 충분한 지 확인하거나 그렇지 않은 경우 데이터 보강을 탐색해야합니다.,,
1107,5.2.3.,5.2.3.,,
1108,"Formatting the Data
The correct format depends on which tool you’re using to do the feature preparation.","데이터 포맷
올바른 형식은 기능 준비를 위해 사용하는 도구에 따라 다릅니다.",,
1109,"If you’re sticking with the same tool you used for data preparation, an output can be the same as input.",데이터 준비에 사용한 것과 동일한 도구를 고수하는 경우 출력은 입력과 동일 할 수 있습니다.,,
1110,"Otherwise, you might find this a good place to change formats.",그렇지 않으면 여기가 형식을 변경하기에 좋은 곳임을 알 수 있습니다.,,
1111,"For example, when using Spark for data prep and TensorFlow for training, we often implement conversion to  TFRecords here.",예를 들어 Spark를 데이터 준비에 사용하고 TensorFlow를 학습에 사용할 때 여기에서 TFRecord로 변환을 구현하는 경우가 많습니다.,,
1112,5.2.4.,5.2.4.,,
1113,"Feature Preparation
How to do feature preparation depends on the problem.","기능 준비
기능 준비 방법은 문제에 따라 다릅니다.",,
1114,"With the mailing list example, we can write all kinds of text-processing functions and combine them into features, as shown in EXAMPLE 5-4.",메일 링리스트 예제를 사용하면 예제 5-4에서와 같이 모든 종류의 텍스트 처리 기능을 작성하고 기능으로 결합 할 수 있습니다.,,
1115,Example 5-4.,예 5-4.,,
1116,"Writing and combining text-processing functions into features
    df['domains'] = df['links'].apply(extract_domains)
    df['isThreadStart'] = df['depth'] == '0'

    # Arguably, you could split building the dataset away from the actual witchcraft.","텍스트 처리 기능을 기능에 작성 및 결합
    df [ '도메인'] = df [ '링크'] .apply (extract_domains)
    df [ 'isThreadStart'] = df [ 'depth'] == '0'

    # 논란의 여지가 있지만, 실제 요술과는 별도로 데이터 세트를 구축 할 수 있습니다.",,
1117,"from sklearn.feature_extraction.text import TfidfVectorizer

    bodyV = TfidfVectorizer()
    bodyFeatures = bodyV.fit_transform(df['body'])

    domainV = TfidfVectorizer()

    def makeDomainsAList(d):
        return ' '.join([a for a in d if not a is None])

    domainFeatures = domainV.fit_transform(
        df['domains'].apply(makeDomainsAList))

    from scipy.sparse import csr_matrix, hstack

    data = hstack([
        csr_matrix(df[[
            'containsPythonStackTrace', 'containsJavaStackTrace',
            'containsExceptionInTaskBody', 'isThreadStart'
        ]].to_numpy()), bodyFeatures, domainFeatures
    ])
So far, the example code is structured to allow you to turn each function into a separate pipeline stage; however, other options exist.","sklearn.feature_extraction.text에서 가져 오기 TfidfVectorizer

    bodyV = TfidfVectorizer ()
    bodyFeatures = bodyV.fit_transform (df [ 'body'])

    domainV = TfidfVectorizer ()

    def makeDomainsAList (d) :
        return ''.join ([a가 아닌 경우 d에 대한 a가 없음])

    domainFeatures = domainV.fit_transform (
        df [ 'domains']. apply (makeDomainsAList))

    scipy.sparse에서 가져 오기 csr_matrix, hstack

    데이터 = hstack ([
        csr_matrix (df [[
            'containsPythonStackTrace', 'containsJavaStackTrace',
            'containsExceptionInTaskBody', 'isThreadStart'
        ]]. to_numpy ()), bodyFeatures, domainFeatures
    ])
지금까지 예제 코드는 각 함수를 별도의 파이프 라인 단계로 전환 할 수 있도록 구성되었습니다.그러나 다른 옵션이 있습니다.",,
1118,We’ll examine how to use the entire notebook as a pipeline stage in SECTION 5.4.,섹션 5.4에서 전체 노트북을 파이프 라인 단계로 사용하는 방법을 살펴 보겠습니다.,,
1119,"There are data preparation tools beyond notebooks and Python, of course.",물론 노트북과 Python 외에도 데이터 준비 도구가 있습니다.,,
1120,Notebooks are not always the best tool as they can have difficulty with version control.,노트북은 버전 관리에 어려움을 겪을 수 있으므로 항상 최고의 도구는 아닙니다.,,
1121,Python doesn’t always have the libraries (or performance) you need.,Python에 필요한 라이브러리 (또는 성능)가 항상있는 것은 아닙니다.,,
1122,So we’ll now look at how to use other available tools.,이제 사용 가능한 다른 도구를 사용하는 방법을 살펴 보겠습니다.,,
1123,5.2.5.,5.2.5.,,
1124,"Custom Containers
Pipelines are not just limited to notebooks or even to specific languages.","커스텀 컨테이너
파이프 라인은 노트북이나 특정 언어에만 국한되지 않습니다.",,
1125,"[7] Depending on the project, you may have a regular Python project, custom tooling, Python 2, or even FORTRAN code as an essential component.","[7] 프로젝트에 따라 일반 Python 프로젝트, 사용자 지정 도구, Python 2 또는 FORTRAN 코드를 필수 구성 요소로 사용할 수 있습니다.",,
1126,"For instance, in CHAPTER 9 we will use Scala to perform one step in our pipeline.",예를 들어 9 장에서는 Scala를 사용하여 파이프 라인의 한 단계를 수행합니다.,,
1127,"Also, in ‘Using RStats’, we discuss how to get started with an RStats container.",또한 'RStat 사용'에서는 RStats 컨테이너를 시작하는 방법에 대해 설명합니다.,,
1128,Sometimes you won’t be able to find a container that so closely matches your needs as we did here.,때때로 우리가 여기에서했던 것처럼 귀하의 필요에 매우 근접한 용기를 찾을 수 없을 것입니다.,,
1129,"In these cases, you can take a generic base image and build on top of it, which we look at more in CHAPTER 9.",이 경우 일반적인 기본 이미지를 가져와 그 위에 빌드 할 수 있습니다. 자세한 내용은 9 장에서 살펴 보겠습니다.,,
1130,"Beyond the need for custom containers, another reason you might choose to move beyond notebooks is to explore distributed tools.",사용자 지정 컨테이너의 필요성 외에도 노트북을 넘어서는 또 다른 이유는 분산 된 도구를 탐색하는 것입니다.,,
1131,5.3.,5.3.,,
1132,"Distributed Tooling
Using a distributed platform makes it possible to work with large datasets (beyond a single machine memory) and can provide significantly better performance.","분산 툴링
분산 플랫폼을 사용하면 단일 머신 메모리를 넘어서 대규모 데이터 세트로 작업 할 수 있으며 훨씬 더 나은 성능을 제공 할 수 있습니다.",,
1133,Often the time when we need to start using distributed tooling is when our problem has out-grown our initial notebook solution.,분산 도구 사용을 시작해야하는 경우는 종종 문제가 초기 노트북 솔루션보다 커질 때입니다.,,
1134,The two main data-parallel distributed systems in Kubeflow are Apache Spark and Google’s Dataflow (via Apache Beam).,Kubeflow의 두 가지 주요 데이터 병렬 분산 시스템은 Apache Spark와 Google의 Dataflow (Apache Beam을 통한)입니다.,,
1135,Apache Spark has a larger install base and variety of formats and libraries supported.,Apache Spark에는 더 큰 설치 기반과 다양한 형식 및 라이브러리가 지원됩니다.,,
1136,"Apache Beam supports TensorFlow Extended (TFX), an end-to-end ML tool, which integrates smoothly into TFServing for model inference.",Apache Beam은 모델 추론을 위해 TFServing에 원활하게 통합되는 엔드 투 엔드 ML 도구 인 TensorFlow Extended (TFX)를 지원합니다.,,
1137,"As it’s the most tightly integrated, we’ll start with exploring TFX on Apache Beam and then continue to the more standard Apache Spark.",가장 긴밀하게 통합되어 있으므로 Apache Beam에서 TFX를 탐색 한 다음 더 표준적인 Apache Spark로 계속 진행할 것입니다.,,
1138,5.3.1.,5.3.1.,,
1139,"TensorFlow Extended
The TensorFlow community has created an excellent set of integrated tools for everything from data validation to model serving.","TensorFlow Extended
TensorFlow 커뮤니티는 데이터 유효성 검사에서 모델 제공에 이르기까지 모든 것을위한 훌륭한 통합 도구 세트를 만들었습니다.",,
1140,"At present, TFX’s data tools are all built on top of Apache Beam, which has the most support for distributed processing on Google Cloud.",현재 TFX의 데이터 도구는 모두 Google Cloud에서 분산 처리를 가장 많이 지원하는 Apache Beam을 기반으로 구축되었습니다.,,
1141,"If you want to use Kubeflow’s TFX components, you are limited to a single node; this may change in future versions.",Kubeflow의 TFX 구성 요소를 사용하려는 경우 단일 노드로 제한됩니다.이는 향후 버전에서 변경 될 수 있습니다.,,
1142,"Note
Apache Beam’s Python support outside of Google Cloud’s Dataflow is not as mature.","노트
Google Cloud의 Dataflow 외부에서 Apache Beam의 Python 지원은 그다지 성숙하지 않습니다.",,
1143,"TFX is a Python tool, so scaling it depends on Apache Beam’s Python support.",TFX는 Python 도구이므로 Apache Beam의 Python 지원에 따라 확장됩니다.,,
1144,You can scale the job by using the GCP only Dataflow component.,GCP 전용 Dataflow 구성 요소를 사용하여 작업을 확장 할 수 있습니다.,,
1145,"As Apache Beam’s support for Apache Flink and Spark improves, support may be added for scaling the TFX components in a portable manner.",Apache Beam의 Apache Flink 및 Spark 지원이 향상됨에 따라 TFX 구성 요소를 이식 가능한 방식으로 확장하기위한 지원이 추가 될 수 있습니다.,,
1146,"[8]

Kubeflow includes many of the TFX components in its pipeline system.","[8]

Kubeflow는 파이프 라인 시스템에 많은 TFX 구성 요소를 포함합니다.",,
1147,TFX also has its own concept of pipelines.,TFX에는 자체 파이프 라인 개념도 있습니다.,,
1148,"These are separate from Kubeflow pipelines, and in some cases TFX can be an alternative to Kubeflow.",이는 Kubeflow 파이프 라인과 별개이며 경우에 따라 TFX가 Kubeflow의 대안이 될 수 있습니다.,,
1149,"Here we will focus on the data and feature preparation components, since those are the simplest to be used with the rest of the Kubeflow ecosystem.",나머지 Kubeflow 생태계에서 가장 간단하게 사용할 수있는 데이터 및 기능 준비 구성 요소에 초점을 맞출 것입니다.,,
1150,5.3.1.1.,5.3.1.1.,,
1151,"Keeping your data quality: TensorFlow data validation
It’s crucial to make sure data quality doesn’t decline over time.","데이터 품질 유지 : TensorFlow 데이터 유효성 검사
시간이 지나도 데이터 품질이 저하되지 않도록하는 것이 중요합니다.",,
1152,Data validation allows us to ensure that the schema and distribution of our data are only evolving in expected ways and catch data quality issues before they become production issues.,데이터 유효성 검사를 통해 데이터의 스키마와 배포가 예상되는 방식으로 만 진화하고 있는지 확인하고 데이터 품질 문제가 생산 문제가되기 전에 포착 할 수 있습니다.,,
1153,TensorFlow Data Validation (TFDV) gives us the ability to validate our data.,TensorFlow 데이터 유효성 검사 (TFDV)는 데이터 유효성 검사 기능을 제공합니다.,,
1154,"To make the development process more straightforward, you should install TFX and TFDV locally.",개발 프로세스를보다 간단하게 만들려면 TFX 및 TFDV를 로컬에 설치해야합니다.,,
1155,"While the code can be evaluated inside of Kubeflow only, having the library locally will speed up your development work.",코드는 Kubeflow 내에서만 평가할 수 있지만 라이브러리를 로컬에두면 개발 작업 속도가 빨라집니다.,,
1156,"Installing TFX and TFDV is a simple pip install, shown in EXAMPLE 5-5.",TFX 및 TFDV 설치는 예제 5-5에 표시된 간단한 pip 설치입니다.,,
1157,"[9]

Example 5-5.","[9]

예 5-5.",,
1158,"Installing TFX and TFDV
pip3 install tfx tensorflow-data-validation
Now let’s look at how to use TFX and TFDV in Kubeflow’s pipelines.","TFX 및 TFDV 설치
pip3 tfx tensorflow-data-validation 설치
이제 Kubeflow의 파이프 라인에서 TFX 및 TFDV를 사용하는 방법을 살펴 보겠습니다.",,
1159,The first step is loading the relevant components that we want to use.,첫 번째 단계는 사용하려는 관련 구성 요소를로드하는 것입니다.,,
1160,"As we discussed in the previous chapter, while Kubeflow does have a load_component function, it automatically resolves on master making it unsuitable for production use cases.",이전 장에서 논의했듯이 Kubeflow에는 load_component 함수가 있지만 마스터에서 자동으로 해결되어 프로덕션 사용 사례에 적합하지 않습니다.,,
1161,So we’ll use load_component_from_file along with a local copy of Kubeflow components from EXAMPLE 4-15 to load our TFDV components.,따라서 TFDV 구성 요소를로드하기 위해 예제 4-15의 Kubeflow 구성 요소의 로컬 복사본과 함께 load_component_from_file을 사용합니다.,,
1162,"The basic components we need to load are: an example generator (think data loader), schema, statistics generators, and the validator itself.","로드해야하는 기본 구성 요소는 예제 생성기 (데이터 로더를 생각해보십시오), 스키마, 통계 생성기 및 유효성 검사기 자체입니다.",,
1163,Loading the components is illustrated in EXAMPLE 5-6.,구성 요소로드는 예 5-6에 설명되어 있습니다.,,
1164,Example 5-6.,예 5-6.,,
1165,"Loading the components
tfx_csv_gen = kfp.components.load_component_from_file(
    ""pipelines-0.2.5/components/tfx/ExampleGen/CsvExampleGen/component.yaml"")
tfx_statistic_gen = kfp.components.load_component_from_file(
    ""pipelines-0.2.5/components/tfx/StatisticsGen/component.yaml"")
tfx_schema_gen = kfp.components.load_component_from_file(
    ""pipelines-0.2.5/components/tfx/SchemaGen/component.yaml"")
tfx_example_validator = kfp.components.load_component_from_file(
    ""pipelines-0.2.5/components/tfx/ExampleValidator/component.yaml"")
In addition to the components, we also need our data.","구성 요소로드
tfx_csv_gen = kfp.components.load_component_from_file (
    ""pipelines-0.2.5 / components / tfx / ExampleGen / CsvExampleGen / component.yaml"")
tfx_statistic_gen = kfp.components.load_component_from_file (
    ""pipelines-0.2.5 / components / tfx / StatisticsGen / component.yaml"")
tfx_schema_gen = kfp.components.load_component_from_file (
    ""pipelines-0.2.5 / components / tfx / SchemaGen / component.yaml"")
tfx_example_validator = kfp.components.load_component_from_file (
    ""pipelines-0.2.5 / components / tfx / ExampleValidator / component.yaml"")
구성 요소 외에도 데이터도 필요합니다.",,
1166,The current TFX components pass data between pipeline stages using Kubeflow’s file_output mechanism.,현재 TFX 구성 요소는 Kubeflow의 file_output 메커니즘을 사용하여 파이프 라인 단계간에 데이터를 전달합니다.,,
1167,"This places the output into MinIO, automatically tracking the artifacts related to the pipeline.",그러면 출력이 MinIO에 배치되고 파이프 라인과 관련된 아티팩트가 자동으로 추적됩니다.,,
1168,"To use TFDV on the recommender example’s input, we first download it using a standard container operation, as in EXAMPLE 5-7.",추천 예제의 입력에 TFDV를 사용하려면 먼저 예제 5-7과 같이 표준 컨테이너 작업을 사용하여 다운로드합니다.,,
1169,Example 5-7.,예 5-7.,,
1170,"Download recommender data
    fetch = kfp.dsl.ContainerOp(name='download',
                                image='busybox',
                                command=['sh', '-c'],
                                arguments=[
                                    'sleep 1;'
                                    'mkdir -p /tmp/data;'
                                    'wget ' + data_url +
                                    ' -O /tmp/data/results.csv'
                                ],
                                file_outputs={'downloaded': '/tmp/data'})
    # This expects a directory of inputs not just a single file
Tip
If we had the data on a persistent volume (say, data fetched in a previous stage), we could then use the filesystem/get_file 
component.","추천자 데이터 다운로드
    fetch = kfp.dsl.ContainerOp (name = 'download',
                                image = 'busybox',
                                명령 = [ 'sh', '-c'],
                                인수 = [
                                    '수면 1;'
                                    'mkdir -p / tmp / data;'
                                    'wget'+ data_url +
                                    '-O /tmp/data/results.csv'
                                ],
                                file_outputs = { '다운로드 됨': '/ tmp / data'})
    # 이것은 단일 파일이 아닌 입력 디렉토리를 기대합니다
팁
영구 볼륨에 데이터가있는 경우 (예 : 이전 단계에서 가져온 데이터) filesystem / get_file을 사용할 수 있습니다.
구성 요소.",,
1171,"Once you have the data loaded, TFX has a set of tools called example generators that ingest data.",데이터가로드되면 TFX에는 데이터를 수집하는 예제 생성기라는 도구 세트가 있습니다.,,
1172,"These support a few different formats, including CSV and TFRecord.",이들은 CSV 및 TFRecord를 포함한 몇 가지 다른 형식을 지원합니다.,,
1173,"There are also example generators for other systems, including Google’s BigQuery.",Google의 BigQuery를 비롯한 다른 시스템 용 예제 생성기도 있습니다.,,
1174,"There is not the same wide variety of formats supported by Spark or Pandas, so you may find a need to preprocess the records with another tool.",Spark 또는 Pandas에서 지원하는 다양한 형식이 동일하지 않으므로 다른 도구를 사용하여 레코드를 사전 처리해야 할 수도 있습니다.,,
1175,"[10] In our recommender example, we use the CSV component, as shown in EXAMPLE 5-8.",추천자 예에서는 예 5-8과 같이 CSV 구성 요소를 사용합니다.,,
1176,Example 5-8.,예 5-8.,,
1177,"Using CSV component
    records_example = tfx_csv_gen(input_base=fetch.output)
Now that we have a channel of examples, we can use this as one of the inputs for TFDV.","CSV 구성 요소 사용
    records_example = tfx_csv_gen (input_base = fetch.output)
이제 예제 채널이 있으므로이를 TFDV의 입력 중 하나로 사용할 수 있습니다.",,
1178,The recommended approach for creating a schema is to use TFDV to infer the schema.,스키마 생성에 권장되는 접근 방식은 TFDV를 사용하여 스키마를 추론하는 것입니다.,,
1179,"To be able to infer the schema, TFDV first needs to compute some summary statistics of our data.",스키마를 추론 할 수 있으려면 먼저 TFDV가 데이터의 요약 통계를 계산해야합니다.,,
1180,EXAMPLE 5-9 illustrates the pipeline stages for both of these steps.,예제 5-9는이 두 단계에 대한 파이프 라인 단계를 보여줍니다.,,
1181,Example 5-9.,예 5-9.,,
1182,"Creating the schema
    stats = tfx_statistic_gen(input_data=records_example.output)
    schema_op = tfx_schema_gen(stats.output)
If we infer the schema each time, we are unlikely to catch schema changes.","스키마 생성
    통계 = tfx_statistic_gen (input_data = records_example.output)
    schema_op = tfx_schema_gen (stats.output)
매번 스키마를 추론하면 스키마 변경 사항을 포착 할 가능성이 거의 없습니다.",,
1183,"Instead, you should save the schema and reuse it in future runs for validation.",대신 스키마를 저장하고 유효성 검사를 위해 향후 실행에서 재사용해야합니다.,,
1184,"The pipeline’s run web page has a link to the schema in MinIO, and you can either fetch it or copy it somewhere using another component or container operation.",파이프 라인의 실행 웹 페이지에는 MinIO의 스키마에 대한 링크가 있으며이를 가져 오거나 다른 구성 요소 또는 컨테이너 작업을 사용하여 어딘가에 복사 할 수 있습니다.,,
1185,"Regardless of where you persist the schema, you should inspect it.",스키마를 유지하는 위치에 관계없이 스키마를 검사해야합니다.,,
1186,"To inspect the schema, you need to import the TFDV library, as shown in EXAMPLE 5-10.",스키마를 검사하려면 예 5-10에 표시된대로 TFDV 라이브러리를 가져와야합니다.,,
1187,"Before you start using a schema to validate data, you should inspect the schema.",스키마를 사용하여 데이터의 유효성을 검사하기 전에 스키마를 검사해야합니다.,,
1188,"To inspect the schema, download the schema locally (or onto your notebook) and use the display_schema function from TFDV, as shown in EXAMPLE 5-11.",스키마를 검사하려면 스키마를 로컬로 (또는 노트북에) 다운로드하고 예 5-11에 표시된대로 TFDV에서 display_schema 함수를 사용합니다.,,
1189,Example 5-10.,예 5-10.,,
1190,"Download the schema locally
import tensorflow_data_validation as tfdv

Example 5-11.","로컬로 스키마 다운로드
tensorflow_data_validation을 tfdv로 가져 오기

예 5-11.",,
1191,"Display the schema
schema = tfdv.load_schema_text(""schema_info_2"")
tfdv.display_schema(schema)
If needed, the schema_util.py script (downloadble from the TensorFlow GitHub repo) provides the tools to modify your schema (be it for evolution or incorrect inference).","스키마 표시
스키마 = tfdv.load_schema_text ( ""schema_info_2"")
tfdv.display_schema (스키마)
필요한 경우 schema_util.py 스크립트 (TensorFlow GitHub 저장소에서 다운로드 가능)는 스키마를 수정하는 도구를 제공합니다 (진화 또는 잘못된 추론 용).",,
1192,"Now that we know we’re using the right schema, let’s validate our data.",올바른 스키마를 사용하고 있다는 것을 알았으므로 이제 데이터를 검증 해 보겠습니다.,,
1193,"The validate component takes in both the schema and the statistics we’ve generated, as shown in EXAMPLE 5-12.",유효성 검사 구성 요소는 예제 5-12에 표시된 것처럼 우리가 생성 한 스키마와 통계를 모두받습니다.,,
1194,You should replace the schema and statistics generation components with downloads of their outputs at production time.,스키마 및 통계 생성 구성 요소를 프로덕션 시간에 다운로드 한 출력으로 바꿔야합니다.,,
1195,Example 5-12.,예 5-12.,,
1196,"Validating the data
    tfx_example_validator(stats=stats.outputs['output'],
                          schema=schema_op.outputs['output'])
Tip
Check the size of the rejected records before pushing to production.","데이터 검증
    tfx_example_validator (stats = stats.outputs [ 'output'],
                          schema = schema_op.outputs [ 'output'])
팁
프로덕션으로 푸시하기 전에 거부 된 레코드의 크기를 확인하십시오.",,
1197,"You may find that the data format has changed, and you need to use the schema evolution guide and possibly update the rest of the pipeline.",데이터 형식이 변경된 것을 알 수 있으며 스키마 진화 가이드를 사용하고 나머지 파이프 라인을 업데이트해야합니다.,,
1198,5.3.1.2.,5.3.1.2.,,
1199,"TensorFlow Transform, with TensorFlow Extended on Beam
The TFX program for doing feature preparation is called TensorFlow Transform (TFT) and integrates into the TensorFlow and Kubeflow ecosystems.","TensorFlow 변환, 빔에서 TensorFlow 확장
기능 준비를위한 TFX 프로그램은 TensorFlow Transform (TFT)이라고하며 TensorFlow 및 Kubeflow 생태계에 통합됩니다.",,
1200,"As with TFDV, Kubeflow’s TensorFlow Transform component currently does not scale beyond single node processing.",TFDV와 마찬가지로 Kubeflow의 TensorFlow Transform 구성 요소는 현재 단일 노드 처리 이상으로 확장되지 않습니다.,,
1201,"The best benefit of TFT is its integration into the TensorFlow Model Analysis tool, simplifying feature preparation during inference.",TFT의 가장 큰 이점은 TensorFlow 모델 분석 도구에 통합되어 추론하는 동안 기능 준비를 단순화한다는 것입니다.,,
1202,We need to specify what transformations we want TFT to apply.,TFT에서 적용 할 변환을 지정해야합니다.,,
1203,"Our TFT program should be in a file separate from the pipeline definition, although it is possible to inline it as a string.",TFT 프로그램은 파이프 라인 정의와는 별개의 파일에 있어야하지만 문자열로 인라인 할 수도 있습니다.,,
1204,"To start with, we need some standard TFT imports, as shown in EXAMPLE 5-13.",시작하려면 예제 5-13에 표시된대로 표준 TFT 가져 오기가 필요합니다.,,
1205,Example 5-13.,예 5-13.,,
1206,"TFT imports
import tensorflow as tf
import tensorflow_transform as tft
from tensorflow_transform.tf_metadata import schema_utils
Now that we’ve got the imports, it’s time to create the entry point into our code for the component, shown in EXAMPLE 5-14.","TFT 수입
tensorflow를 tf로 가져 오기
tensorflow_transform을 tft로 가져 오기
tensorflow_transform.tf_metadata import schema_utils에서
이제 가져 오기가 완료되었으므로 예제 5-14에 표시된 구성 요소의 코드에 진입 점을 만들 차례입니다.",,
1207,Example 5-14.,예 5-14.,,
1208,"Creating the entry point
def preprocessing_fn(inputs):
Inside this function is where we do our data transformations to produce our features.","진입 점 만들기
def preprocessing_fn (입력) :
이 함수 내에서 데이터 변환을 수행하여 기능을 생성합니다.",,
1209,"Not all features need to be transformed, which is why there is also a copy method to mirror the input to the output if you’re only adding features.",모든 기능을 변환 할 필요는 없습니다. 따라서 기능 만 추가하는 경우 입력을 출력에 미러링하는 복사 방법도 있습니다.,,
1210,"With our mailing list example, we can compute the vocabulary, as shown in EXAMPLE 5-15.",메일 링리스트 예제를 사용하면 예제 5-15에 표시된대로 어휘를 계산할 수 있습니다.,,
1211,Example 5-15.,예 5-15.,,
1212,"Compute the vocabulary
    outputs = {}
    # TFT business logic goes here
    outputs[""body_stuff""] = tft.compute_and_apply_vocabulary(inputs[""body""],
                                                             top_k=1000)
    return outputs
This function does not support arbitrary python code.","어휘 계산
    출력 = {}
    # TFT 비즈니스 로직은 여기에 있습니다.
    출력 [ ""body_stuff""] = tft.compute_and_apply_vocabulary (inputs [ ""body""],
                                                             top_k = 1000)
    반환 출력
이 함수는 임의의 파이썬 코드를 지원하지 않습니다.",,
1213,All transformations must be expressed as TensorFlow or TensorFlow Transform operations.,모든 변환은 TensorFlow 또는 TensorFlow Transform 작업으로 표현되어야합니다.,,
1214,"TensorFlow operations operate on one tensor at a time, but in data preparation we often want to compute something over all of our input data, and TensorFlow Transform’s operations give us this ability.",TensorFlow 작업은 한 번에 하나의 텐서에서 작동하지만 데이터 준비 과정에서 종종 모든 입력 데이터에 대해 무언가를 계산하고 싶어하며 TensorFlow Transform의 작업은이 기능을 제공합니다.,,
1215,See the TFT Python docs or call help(tft) to see some starting operations.,TFT Python 문서를 참조하거나 몇 가지 시작 작업을 보려면 help (tft)를 호출하십시오.,,
1216,"Once you’ve written the desired transformations, it is time to add them to the pipeline.",원하는 변환을 작성했으면 이제 파이프 라인에 추가 할 차례입니다.,,
1217,The simplest way to do this is with Kubeflow’s tfx/Transform component.,이를 수행하는 가장 간단한 방법은 Kubeflow의 tfx / Transform 구성 요소를 사용하는 것입니다.,,
1218,"Loading the component is the same as the other TFX components, illustrated in EXAMPLE 5-6.",구성 요소로드는 예 5-6에 설명 된 다른 TFX 구성 요소와 동일합니다.,,
1219,Using this component is unique in requiring the transformation code to be passed in as a file uploaded to either S3 or GCS.,이 구성 요소를 사용하는 것은 S3 또는 GCS에 업로드 된 파일로 변환 코드를 전달해야한다는 점에서 고유합니다.,,
1220,"It also needs the data, and you can use the output from TFDV (if you used it) or load the examples as we did for TFDV.",또한 데이터가 필요하며 TFDV의 출력 (사용한 경우)을 사용하거나 TFDV에서했던 것처럼 예제를로드 할 수 있습니다.,,
1221,Using the TFT component is illustrated in EXAMPLE 5-16.,TFT 구성 요소를 사용하는 방법은 예제 5-16에 설명되어 있습니다.,,
1222,Example 5-16.,예 5-16.,,
1223,"Using the TFT component
    transformed_output = tfx_transform(
        input_data=records_example.output,
        schema=schema_op.outputs['output'],
        module_file=module_file)  # Path to your TFT code on GCS/S3
Now you have a machine learning pipeline that has feature preparation along with a critical artifact to transform requests at serving time.","TFT 구성 요소 사용
    transformed_output = tfx_transform (
        input_data = records_example.output,
        schema = schema_op.outputs [ 'output'],
        module_file = module_file) # GCS / S3의 TFT 코드 경로
이제 제공 시간에 요청을 변환하기위한 중요한 아티팩트와 함께 기능 준비가 포함 된 기계 학습 파이프 라인이 있습니다.",,
1224,The close integration of TensorFlow Transform can make model serving much less complicated.,TensorFlow Transform의 긴밀한 통합은 모델 제공을 훨씬 덜 복잡하게 만들 수 있습니다.,,
1225,"TensorFlow Transform with Kubeflow components doesn’t have the power for all projects, so we’ll look at distributed feature preparation next.",Kubeflow 구성 요소를 사용하는 TensorFlow Transform은 모든 프로젝트에 적용 할 수있는 기능이 없으므로 다음에 분산 기능 준비를 살펴 보겠습니다.,,
1226,5.3.2.,5.3.2.,,
1227,"Distributed Data Using Apache Spark
Apache Spark is an open source distributed data processing tool that can run on a variety of clusters.","Apache Spark를 사용한 분산 데이터
Apache Spark는 다양한 클러스터에서 실행할 수있는 오픈 소스 분산 데이터 처리 도구입니다.",,
1228,Kubeflow supports Apache Spark through a few different components so you can access cloud-specific features.,Kubeflow는 몇 가지 다른 구성 요소를 통해 Apache Spark를 지원하므로 클라우드 관련 기능에 액세스 할 수 있습니다.,,
1229,Since you may not be familiar with Spark we’ll briefly introduce Spark’s Dataset/Dataframe APIs in the context of data and feature preparation.,Spark에 익숙하지 않을 수 있으므로 데이터 및 기능 준비의 맥락에서 Spark의 Dataset / Dataframe API를 간략하게 소개합니다.,,
1230,"If you want to go beyond the basics, we recommend Learning Spark, Spark: The Definitive Guide, or High Performance Spark as resources to improve your Spark skills.","기본 사항을 넘어서고 싶다면 Spark 기술 향상을위한 리소스로 Learning Spark, Spark : The Definitive Guide 또는 High Performance Spark를 권장합니다.",,
1231,"Note
Here our code is structured to go in as a single stage for all of the feature and data preparation, since once you’re at scale, writing and loading the data between steps is costly.","노트
여기에서 우리의 코드는 모든 기능과 데이터 준비를위한 단일 단계로 들어가도록 구성되어 있습니다. 일단 규모에 도달하면 단계 사이에 데이터를 쓰고로드하는 데 많은 비용이 들기 때문입니다.",,
1232,"Spark in Jupyter
Spark is not preinstalled in the notebook images.","Jupyter의 Spark
Spark는 노트북 이미지에 사전 설치되어 있지 않습니다.",,
1233,"You can use pip inside your notebook to install Spark, but this does not support complex environments.",노트북 내부에서 pip를 사용하여 Spark를 설치할 수 있지만 복잡한 환경은 지원하지 않습니다.,,
1234,"Instead, take the notebook container you’re working with and add Spark with a new Dockerfile, as shown in EXAMPLE 5-17.",대신 작업중인 노트북 컨테이너를 가져 와서 예제 5-17에 표시된 것처럼 새 Dockerfile로 Spark를 추가합니다.,,
1235,Example 5-17.,예 5-17.,,
1236,"Adding Spark
# See https://www.kubeflow.org/docs/notebooks/custom-notebook/
ARG base
FROM $base
ARG sparkversion
ARG sparkrelease
ARG sparkserver https://www-us.apache.org/dist/spark
# We need to run as root for updates
USER root

# Set an environment variable for where we are going to put Spark
ENV SPARK_HOME /opt/spark

# Install Java because Spark needs it
RUN apt-get update && \
    apt-get install -yq openjdk-8-jre openjdk-8-jre-headless && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install Spark
RUN set -ex && \
    rm /bin/sh && \
    ln -sv /bin/bash /bin/sh

RUN  echo ""Setting up $sparkversion""
RUN  cd /tmp && \
     (wget ${sparkserver}/spark-${sparkversion}/${sparkrelease}.tgz) && \
     cd /opt && tar -xvf /tmp/${sparkrelease}.tgz && \
     rm /tmp/${sparkrelease}.tgz && mv ${sparkrelease} spark && \
     cd spark/python && pip install -e .","Spark 추가
# https://www.kubeflow.org/docs/notebooks/custom-notebook/ 참조
ARG베이스
$ base에서
ARG 스파크 버전
ARG 스파크 릴리즈
ARG 스파크 서버 https://www-us.apache.org/dist/spark
# 업데이트를 위해 루트로 실행해야합니다
USER 루트

# Spark를 둘 위치에 대한 환경 변수를 설정합니다.
ENV SPARK_HOME / opt / spark

# Spark에 필요한 Java 설치
apt-get 업데이트 실행 && \
    apt-get install -yq openjdk-8-jre openjdk-8-jre-headless && \
    apt-get clean && \
    rm -rf / var / lib / apt / lists / *

# Spark 설치
실행 세트 -ex && \
    rm / bin / sh && \
    ln -sv / bin / bash / bin / sh

RUN echo ""$ sparkversion 설정""
실행 cd / tmp && \
     (wget $ {sparkserver} / spark-$ {sparkversion} / $ {sparkrelease} .tgz) && \
     cd / opt && tar -xvf /tmp/${sparkrelease}.tgz && \
     rm /tmp/${sparkrelease}.tgz && mv $ {sparkrelease} 스파크 && \
     cd spark / python && pip install -e.",,
1237,"# Fix permissions
WORKDIR /opt/spark/work-dir
RUN chmod -R 777 /opt/spark/

# Switch the user back; using jovyan as a user is bad but the base image
# depends on it.","# 권한 수정
WORKDIR / opt / spark / work-dir
chmod -R 777 / opt / spark / 실행

# 사용자를 다시 전환합니다.jovyan을 사용자로 사용하는 것은 나쁘지만 기본 이미지
# 그것에 따라 다릅니다.",,
1238,"USER jovyan
# Install some common tools
pip install pandas numpy scipy pyarrow
The Spark workers don’t have a way to connect to our notebook server so we can’t send data and requests back and forth.","사용자 jovyan
# 몇 가지 일반적인 도구 설치
pip install pandas numpy scipy pyarrow
Spark 작업자는 노트북 서버에 연결할 방법이 없으므로 데이터와 요청을주고받을 수 없습니다.",,
1239,"To enable this, you can create a service using the name of the notebook to make it discoverable.",이를 활성화하려면 노트북 이름을 사용하여 검색 가능하도록 서비스를 생성 할 수 있습니다.,,
1240,"The service definition exposes two ports, as shown in EXAMPLE 5-18, for a user in the “programmerboo” namespace with a notebook named “spark-test-2.” Once you’ve written the service definition, all that is needed is to run kubectl apply -f my_spark_service.yaml.","서비스 정의는 ""spark-test-2""라는 노트북이있는 ""programmerboo""네임 스페이스의 사용자에 대해 예 5-18에 표시된대로 두 개의 포트를 노출합니다.서비스 정의를 작성했으면 kubectl apply -f my_spark_service.yaml을 실행하기 만하면됩니다.",,
1241,Example 5-18.,예 5-18.,,
1242,"Sample service definition
apiVersion: v1
kind: Service
metadata:
  name: spark-driver
  namespace: kubeflow-programmerboo
spec:
  selector:
    notebook-name: spark-test-2
  ports:
    - port: 39235
      targetPort: 39235
      name: spark-driver-port
    - port: 39236
      targetPort: 39236
      name: spark-block-port
When we make the SparkContext, we’ll configure it to use this service as the hostname.","샘플 서비스 정의
apiVersion : v1
종류 : 서비스
메타 데이터 :
  이름 : 스파크 드라이버
  네임 스페이스 : kubeflow-programmerboo
투기:
  선택자:
    노트북 이름 : spark-test-2
  포트 :
    -포트 : 39235
      targetPort : 39235
      이름 : spark-driver-port
    -포트 : 39236
      targetPort : 39236
      이름 : spark-block-port
SparkContext를 만들 때이 서비스를 호스트 이름으로 사용하도록 구성합니다.",,
1243,Jupyter notebooks make important activities like testing and version management challenging.,Jupyter 노트북은 테스트 및 버전 관리와 같은 중요한 활동을 어렵게 만듭니다.,,
1244,"Notebooks are great for the exploration phase, but as you move on, you should consider using a Spark operator.",노트북은 탐색 단계에 적합하지만 계속 진행하면서 Spark 연산자 사용을 고려해야합니다.,,
1245,5.3.2.1.,5.3.2.1.,,
1246,"Spark operators in Kubeflow
Using Kubeflow’s native Spark operator EMR, or Dataproc is best once you’ve moved beyond the experimental phase.","Kubeflow의 Spark 연산자
Kubeflow의 기본 Spark 연산자 EMR 또는 Dataproc을 사용하는 것이 실험 단계를 넘어선 경우 가장 좋습니다.",,
1247,"The most portable operator is the native Spark operator, which does not depend on any specific cloud.",가장 이식 가능한 연산자는 특정 클라우드에 의존하지 않는 기본 Spark 연산자입니다.,,
1248,"To use any of the operators, you need to package the Spark program and store it on either a distributed filesystem (such as GCS, S3, and so on) or put it inside a container.","연산자를 사용하려면 Spark 프로그램을 패키징하여 분산 파일 시스템 (예 : GCS, S3 등)에 저장하거나 컨테이너 안에 넣어야합니다.",,
1249,"If you’re working in Python or R, we recommend building a Spark container so you can install your dependencies.",Python 또는 R로 작업하는 경우 종속성을 설치할 수 있도록 Spark 컨테이너를 빌드하는 것이 좋습니다.,,
1250,"With Scala or Java code, this is less critical.",Scala 또는 Java 코드를 사용하면 덜 중요합니다.,,
1251,"If you put the application inside of a container, you can reference it with local:///.",컨테이너 내부에 애플리케이션을 넣으면 local : ///으로 참조 할 수 있습니다.,,
1252,"You can use the gcr.io/spark-operator/spark-py:v2.4.5 container as the base or build your own container—follow Spark on Kubernetes instructions, or see CHAPTER 9.",gcr.io/spark-operator/spark-py:v2.4.5 컨테이너를 기반으로 사용하거나 자체 컨테이너를 빌드 할 수 있습니다. Kubernetes의 Spark 지침을 따르거나 9 장을 참조하십시오.,,
1253,EXAMPLE 5-19 shows how to install any requirements and copy the application.,예 5-19는 요구 사항을 설치하고 응용 프로그램을 복사하는 방법을 보여줍니다.,,
1254,"If you decide to update the application, you can still use the container, just configure the main resource with a distributed filesystem.",응용 프로그램을 업데이트하기로 결정한 경우에도 컨테이너를 계속 사용할 수 있으며 분산 파일 시스템으로 기본 리소스를 구성하기 만하면됩니다.,,
1255,We cover building custom containers additionally in CHAPTER 9.,우리는 9 장에서 맞춤형 컨테이너 구축을 추가로 다룹니다.,,
1256,Example 5-19.,예 5-19.,,
1257,"Installing requirements and copying the application
# Use the Spark operator image as base
FROM gcr.io/spark-operator/spark-py:v2.4.5
# Install Python requirements
COPY requirements.txt /
RUN pip3 install -r /requirements.txt
# Now you can reference local:///job/my_file.py
RUN mkdir -p /job
COPY *.py /job

ENTRYPOINT [""/opt/entrypoint.sh""]
Two cloud-specific options for running Spark are the Amazon EMR and Google Dataproc components in Kubeflow.","요구 사항 설치 및 애플리케이션 복사
# Spark 연산자 이미지를 기본으로 사용
gcr.io/spark-operator/spark-py:v2.4.5에서
# Python 요구 사항 설치
requirements.txt 복사 /
pip3 install -r /requirements.txt 실행
# 이제 local : ///job/my_file.py를 참조 할 수 있습니다.
mkdir -p / job 실행
복사 * .py / job

ENTRYPOINT [ ""/opt/entrypoint.sh""]
Spark 실행을위한 두 가지 클라우드 관련 옵션은 Kubeflow의 Amazon EMR 및 Google Dataproc 구성 요소입니다.",,
1258,"However, they each take different parameters, meaning that you will need to translate your pipeline.",그러나 각각 다른 매개 변수를 사용하므로 파이프 라인을 번역해야합니다.,,
1259,"The EMR components allow you to set up clusters, submit jobs, and clean up the clusters.","EMR 구성 요소를 사용하여 클러스터를 설정하고, 작업을 제출하고, 클러스터를 정리할 수 있습니다.",,
1260,The two cluster task components are aws/emr/create_cluster for the start and aws/emr/delete_cluster.,두 개의 클러스터 작업 구성 요소는 시작을위한 aws / emr / create_cluster와 aws / emr / delete_cluster입니다.,,
1261,The component for running a PySpark job is aws/emr/submit_pyspark_job.,PySpark 작업을 실행하기위한 구성 요소는 aws / emr / submit_pyspark_job입니다.,,
1262,"If you are not reusing an external cluster, it’s important to trigger the delete component regardless whether the submit_pyspark_job component succeeds.",외부 클러스터를 재사용하지 않는 경우 submit_pyspark_job 구성 요소의 성공 여부에 관계없이 구성 요소 삭제를 트리거하는 것이 중요합니다.,,
1263,"While they have different parameters, the workflow for Dataproc clusters mirrors that of EMR.",매개 변수가 다르지만 Dataproc 클러스터의 워크 플로는 EMR의 워크 플로를 반영합니다.,,
1264,"The components are similarly named, with gcp/dataproc/create_cluster/ and gcp/dataproc/delete_cluster/ for the life cycle and gcp/dataproc/submit_pyspark_job/ for running our job.",구성 요소의 이름은 비슷하며 수명주기는 gcp / dataproc / create_cluster / 및 gcp / dataproc / delete_cluster /이고 작업 실행에는 gcp / dataproc / submit_pyspark_job /입니다.,,
1265,"Unlike the EMR and Dataproc components, the Spark operator does not have a component.",EMR 및 Dataproc 구성 요소와 달리 Spark 연산자에는 구성 요소가 없습니다.,,
1266,"For Kubernetes operators without components, you can use the dsl.ResourceOp to call them.",구성 요소가없는 Kubernetes 연산자의 경우 dsl.ResourceOp를 사용하여 호출 할 수 있습니다.,,
1267,EXAMPLE 5-20 illustrates using the ResourceOp to launch a Spark job.,예제 5-20은 ResourceOp를 사용하여 Spark 작업을 시작하는 방법을 보여줍니다.,,
1268,Example 5-20.,예 5-20.,,
1269,"Using the ResourceOp to launch a Spark job
resource = {
    ""apiVersion"": ""sparkoperator.k8s.io/v1beta2"",
    ""kind"": ""SparkApplication"",
    ""metadata"": {
        ""name"": ""boop"",
        ""namespace"": ""kubeflow""
    },
    ""spec"": {
        ""type"": ""Python"",
        ""mode"": ""cluster"",
        ""image"": ""gcr.io/boos-demo-projects-are-rad/kf-steps/kubeflow/myspark"",
        ""imagePullPolicy"": ""Always"",
        # See the Dockerfile OR use GCS/S3/...
        ""mainApplicationFile"": ""local:///job/job.py"",
        ""sparkVersion"": ""2.4.5"",
        ""restartPolicy"": {
            ""type"": ""Never""
        },
        ""driver"": {
            ""cores"": 1,
            ""coreLimit"": ""1200m"",
            ""memory"": ""512m"",
            ""labels"": {
                ""version"": ""2.4.5"",
            },
            # also try spark-operatoroperator-sa
            ""serviceAccount"": ""spark-operatoroperator-sa"",
        },
        ""executor"": {
            ""cores"": 1,
            ""instances"": 2,
            ""memory"": ""512m""
        },
        ""labels"": {
            ""version"": ""2.4.5""
        },
    }
}


@dsl.pipeline(name=""local Pipeline"", description=""No need to ask why."")","ResourceOp를 사용하여 Spark 작업 시작
자원 = {
    ""apiVersion"": ""sparkoperator.k8s.io/v1beta2"",
    ""kind"": ""SparkApplication"",
    ""metadata"": {
        ""name"": ""boop"",
        ""네임 스페이스"": ""kubeflow""
    },
    ""spec"": {
        ""type"": ""Python"",
        ""모드"": ""클러스터"",
        ""image"": ""gcr.io/boos-demo-projects-are-rad/kf-steps/kubeflow/myspark"",
        ""imagePullPolicy"": ""항상"",
        # Dockerfile을 보거나 GCS / S3 / ...
        ""mainApplicationFile"": ""local : ///job/job.py"",
        ""sparkVersion"": ""2.4.5"",
        ""restartPolicy"": {
            ""type"": ""안함""
        },
        ""드라이버"": {
            ""코어"": 1,
            ""coreLimit"": ""1200m"",
            ""메모리"": ""512m"",
            ""labels"": {
                ""버전"": ""2.4.5"",
            },
            # 또한 spark-operatoroperator-sa 시도
            ""serviceAccount"": ""spark-operatoroperator-sa"",
        },
        ""실행자"": {
            ""코어"": 1,
            ""인스턴스"": 2,
            ""메모리"": ""512m""
        },
        ""labels"": {
            ""버전"": ""2.4.5""
        },
    }
}


@ dsl.pipeline (name = ""local Pipeline"", description = ""이유를 물어볼 필요가 없습니다."")",,
1270,"def local_pipeline():

    rop = dsl.ResourceOp(
        name=""boop"",
        k8s_resource=resource,
        action=""create"",
        success_condition=""status.applicationState.state == COMPLETED"")
Warning
Kubeflow doesn’t apply any validation to ResourceOp requests.","def local_pipeline () :

    rop = dsl.ResourceOp (
        name = ""boop"",
        k8s_resource = 자원,
        action = ""create"",
        success_condition = ""status.applicationState.state == COMPLETED"")
경고
Kubeflow는 ResourceOp 요청에 유효성 검사를 적용하지 않습니다.",,
1271,"For example, in Spark, the job name must be able to be used as the start of a valid DNS name, and while in container ops container names are rewritten, ResourceOps just directly passes through requests.",예를 들어 Spark에서는 작업 이름을 유효한 DNS 이름의 시작으로 사용할 수 있어야하며 컨테이너 작업에서는 컨테이너 이름이 다시 작성되지만 ResourceOps는 요청을 직접 전달합니다.,,
1272,"Spark Basics
Apache Spark has APIs available in Python, R, Scala, and Java, with some third-party support for other languages.","Spark 기본 사항
Apache Spark에는 Python, R, Scala 및 Java에서 사용할 수있는 API가 있으며 다른 언어에 대한 일부 타사 지원이 있습니다.",,
1273,"We’ll use the Python interface, as it is popular in the machine learning community.",머신 러닝 커뮤니티에서 널리 사용되는 Python 인터페이스를 사용합니다.,,
1274,The first thing needed in any Spark program is a Spark session or context (as in EXAMPLE 5-21).,Spark 프로그램에서 가장 먼저 필요한 것은 Spark 세션 또는 컨텍스트입니다 (예 5-21 참조).,,
1275,Example 5-21.,예 5-21.,,
1276,"Launching your Spark session
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date
from pyspark.sql.types import *
session = SparkSession.builder.getOrCreate()
This example was so simple because it reads its configuration from the environment it is called in.","Spark 세션 시작
pyspark.sql에서 SparkSession 가져 오기
pyspark.sql.functions import col, to_date에서
pyspark.sql.types에서 가져 오기 *
세션 = SparkSession.builder.getOrCreate ()
이 예제는 호출 된 환경에서 구성을 읽어 오기 때문에 매우 간단했습니다.",,
1277,"This works with the Spark operator, which does much of the setup for us.",이는 대부분의 설정을 수행하는 Spark 연산자와 함께 작동합니다.,,
1278,"When working in a notebook, though, we need to provide some extra information so the executors can connect back to the notebook.",하지만 노트북에서 작업 할 때는 실행자가 노트북에 다시 연결할 수 있도록 몇 가지 추가 정보를 제공해야합니다.,,
1279,"Once you’ve set up the service so the notebook and the driver can communicate, as described in EXAMPLE 5-18, you would then configure your Spark session to tell the executors to use this service, as shown in EXAMPLE 5-22.",예 5-18에 설명 된대로 노트북과 드라이버가 통신 할 수 있도록 서비스를 설정했으면 예 5-22에 표시된대로 실행자에게이 서비스를 사용하도록 지시하도록 Spark 세션을 구성합니다.,,
1280,Example 5-22.,예 5-22.,,
1281,"Configuring your Spark session
    .config(""spark.driver.bindAddress"",
            ""0.0.0.0"").config(""spark.kubernetes.namespace"",
                              ""kubeflow-programmerboo"").","Spark 세션 구성
    .config ( ""spark.driver.bindAddress"",
            ""0.0.0.0""). config ( ""spark.kubernetes.namespace"",
                              ""kubeflow-programmerboo"").",,
1282,"config(""spark.master"", ""k8s://https://kubernetes.default"").config(
        ""spark.driver.host"",
        ""spark-driver.kubeflow-programmerboo.svc.cluster.local"").config(
            ""spark.kubernetes.executor.annotation.sidecar.istio.io/inject"",
            ""false"").config(""spark.driver.port"",
                            ""39235"").config(""spark.blockManager.port"", ""39236"")
Also, we need the versions of Python to match, since a version mismatch may cause serialization and function errors.","config ( ""spark.master"", ""k8s : // https : //kubernetes.default"") .config (
        ""spark.driver.host"",
        ""spark-driver.kubeflow-programmerboo.svc.cluster.local""). config (
            ""spark.kubernetes.executor.annotation.sidecar.istio.io/inject"",
            ""false""). config ( ""spark.driver.port"",
                            ""39235""). config ( ""spark.blockManager.port"", ""39236"")
또한 버전 불일치로 인해 직렬화 및 함수 오류가 발생할 수 있으므로 일치시킬 Python 버전이 필요합니다.",,
1283,"To do this we add os.environ[""PYSPARK_PYTHON""] = ""python3.6"" to our notebook and install Python 3.6 in Spark’s worker container, as in EXAMPLE 5-23.","이를 위해 os.environ [ ""PYSPARK_PYTHON""] = ""python3.6""을 노트북에 추가하고 예제 5-23에서와 같이 Spark의 작업자 컨테이너에 Python 3.6을 설치합니다.",,
1284,Example 5-23.,예 5-23.,,
1285,"Installing Python 3.6 in Spark’s worker container
ARG base
FROM $base

USER root

# Install libraries we need to build Python 3.6
RUN apt-get update && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y -q \
    make build-essential libssl-dev zlib1g-dev libbz2-dev \
    libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev \
    libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev && \
    rm -rf /var/cache/apt

# Install Python 3.6 to match the notebook
RUN cd /tmp && \
    wget https://www.python.org/ftp/python/3.6.10/Python-3.6.10.tgz && \
    tar -xvf Python-3.6.10.tgz && \
    cd Python-3.6.10 && \
    ./configure && \
    make -j 8 && \
    make altinstall

RUN python3.6 -m pip install pandas pyarrow==0.11.0 spacy
# We depend on Spark being on the PYTHONPATH so no pip install
USER 185
Using MinIO, Kubeflow’s built-in S3-like service, requires some additional configuration.","Spark의 작업자 컨테이너에 Python 3.6 설치
ARG베이스
$ base에서

USER 루트

# Python 3.6을 빌드하는 데 필요한 라이브러리 설치
apt-get 업데이트 실행 && \
    DEBIAN_FRONTEND = 비대화 형 apt-get install -y -q \
    빌드 필수 libssl-dev zlib1g-dev libbz2-dev \
    libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev \
    libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev && \
    rm -rf / var / cache / apt

# 노트북과 일치하도록 Python 3.6 설치
실행 cd / tmp && \
    wget https://www.python.org/ftp/python/3.6.10/Python-3.6.10.tgz && \
    tar -xvf Python-3.6.10.tgz && \
    cd Python-3.6.10 && \
    ./ 구성 && \
    make -j 8 && \
    altinstall 만들기

실행 python3.6 -m pip install pandas pyarrow == 0.11.0 spacy
# 스파크가 PYTHONPATH에 있으므로 pip 설치가 필요하지 않습니다.
사용자 185
Kubeflow의 기본 제공 S3 유사 서비스 인 MinIO를 사용하려면 몇 가지 추가 구성이 필요합니다.",,
1286,EXAMPLE 5-24 illustrates how to configure Spark to use MinIO in Kubeflow.,예 5-24는 Kubeflow에서 MinIO를 사용하도록 Spark를 구성하는 방법을 보여줍니다.,,
1287,Example 5-24.,예 5-24.,,
1288,"Configuring Spark to use MinIO
    .config(""spark.hadoop.fs.s3a.endpoint"",
            ""minio-service.kubeflow.svc.cluster.local:9000"").config(
                ""fs.s3a.connection.ssl.enabled"",
                ""false"").config(""fs.s3a.path.style.access"", ""true"")
    # You can also add an account using the minio command as described in
    # Chapter 1.","MinIO를 사용하도록 Spark 구성
    .config ( ""spark.hadoop.fs.s3a.endpoint"",
            ""minio-service.kubeflow.svc.cluster.local : 9000""). config (
                ""fs.s3a.connection.ssl.enabled"",
                ""false""). config ( ""fs.s3a.path.style.access"", ""true"")
    # 다음에 설명 된대로 minio 명령을 사용하여 계정을 추가 할 수도 있습니다.
    # 1 장.",,
1289,".config(""spark.hadoop.fs.s3a.access.key"",
            ""minio"").config(""spark.hadoop.fs.s3a.secret.key"", ""minio123"")
Note
MinIO only works out of the box with Spark 3 or higher.",".config ( ""spark.hadoop.fs.s3a.access.key"",
            ""minio""). config ( ""spark.hadoop.fs.s3a.secret.key"", ""minio123"")
노트
MinIO는 Spark 3 이상에서만 즉시 작동합니다.",,
1290,"Now that we’ve got Spark up and running, it’s time to look at the basic tasks you will want to do for data preparation and cleaning in Spark.",이제 Spark를 시작하고 실행 했으므로 Spark에서 데이터 준비 및 정리를 위해 수행 할 기본 작업을 살펴볼 차례입니다.,,
1291,5.3.2.2.,5.3.2.2.,,
1292,"Reading the input data
Spark supports a wide variety of data sources, including (but not limited to): Parquet, JSON, JDBC, ORC, JSON, Hive, CSV, ElasticSearch, MongoDB, Neo4j, Cassandra, Snowflake, Redis, Riak Time Series, etc.","입력 데이터 읽기
Spark는 Parquet, JSON, JDBC, ORC, JSON, Hive, CSV, ElasticSearch, MongoDB, Neo4j, Cassandra, Snowflake, Redis, Riak Time Series 등을 포함하지만 이에 국한되지 않는 다양한 데이터 소스를 지원합니다.",,
1293,"[11]
Loading data is very straightforward, and often all that is needed is specifying the format.","[11]
데이터로드는 매우 간단하며 종종 필요한 것은 형식을 지정하는 것뿐입니다.",,
1294,"For instance, in our mailing list example, reading the Parquet-formatted output of our data preparation stage is done as in EXAMPLE 5-25.","예를 들어, 메일 링리스트 예제에서 데이터 준비 단계의 Parquet 형식 출력 읽기는 예제 5-25에서와 같이 수행됩니다.",,
1295,Example 5-25.,예 5-25.,,
1296,"Reading our data’s Parquet-formatted output
initial_posts = session.read.format(""parquet"").load(fs_prefix +
                                                    ""/initial_posts"")
ids_in_reply = session.read.format(""parquet"").load(fs_prefix + ""/ids_in_reply"")
If this had instead been formatted as JSON, we would only have to change “parquet” to “JSON.”[12]

Fetching Input Data
We can also speed up our data fetching by using a block of our Python code to fetch our data in parallel.","데이터의 Parquet 형식 출력 읽기
initial_posts = session.read.format ( ""parquet""). load (fs_prefix +
                                                    ""/ initial_posts"")
ids_in_reply = session.read.format ( ""parquet""). load (fs_prefix + ""/ ids_in_reply"")
대신 JSON으로 형식이 지정 되었다면 ""parquet""를 ""JSON""으로 변경하기 만하면됩니다. [12]

입력 데이터 가져 오기
또한 Python 코드 블록을 사용하여 데이터를 병렬로 가져옴으로써 데이터 가져 오기 속도를 높일 수 있습니다.",,
1297,"If we look back at the mailing list example, we could download each year on a different computer.",메일 링리스트 예제를 되돌아 보면 매년 다른 컴퓨터에 다운로드 할 수 있습니다.,,
1298,"Or if we wanted to look at multiple projects, we could also fetch by project.",또는 여러 프로젝트를보고 싶다면 프로젝트별로 가져올 수도 있습니다.,,
1299,"We can do this by using parallelize, which gives us a distributed list, and flatMap, which runs a Python function on the different executors.",우리는 분산 목록을 제공하는 parallelize와 다른 실행기에서 Python 함수를 실행하는 flatMap을 사용하여이를 수행 할 수 있습니다.,,
1300,"For example, sc.parallelize([1, 2, 3]).map(fetchRecord) effectively runs the fetchRecords function in parallel 3 times with the inputs 1, 2, and 3, respectively, and concatenates the results.","예를 들어, sc.parallelize ([1, 2, 3]). map (fetchRecord)는 fetchRecords 함수를 각각 입력 1, 2 및 3과 함께 3 번 병렬로 효과적으로 실행하고 결과를 연결합니다.",,
1301,5.3.2.3.,5.3.2.3.,,
1302,"Validating the schema
We often believe we know the fields and types of our data.","스키마 유효성 검사
우리는 종종 데이터의 필드와 유형을 알고 있다고 믿습니다.",,
1303,Spark can quickly discover the schema when our data is in a self-describing format like Parquet.,Spark는 데이터가 Parquet과 같은 자체 설명 형식 일 때 스키마를 빠르게 검색 할 수 있습니다.,,
1304,"In other formats, like JSON, the schema isn’t known until Spark reads the records.",JSON과 같은 다른 형식에서는 Spark가 레코드를 읽을 때까지 스키마를 알 수 없습니다.,,
1305,"Regardless of the data format, it is good practice to specify the schema and ensure the data matches it, as shown in EXAMPLE 5-26.",데이터 형식에 관계없이 예 5-26에 표시된 것처럼 스키마를 지정하고 데이터가 스키마와 일치하는지 확인하는 것이 좋습니다.,,
1306,Errors during data load are easier to debug than errors during model deployment.,데이터로드 중 오류는 모델 배포 중 오류보다 디버그하기 쉽습니다.,,
1307,Example 5-26.,예 5-26.,,
1308,"Specifying the schema
ids_schema = StructType([
    StructField(""In-Reply-To"", StringType(), nullable=True),
    StructField(""message-id"", StringType(), nullable=True)
])
ids_in_reply = session.read.format(""parquet"").schema(ids_schema).load(
    fs_prefix + ""/ids_in_reply"")
You can configure Spark to handle corrupted and nonconforming records by dropping them, keeping them, or stopping the process (i.e., failing the job).","스키마 지정
ids_schema = StructType ([
    StructField ( ""응답 대상"", StringType (), nullable = True),
    StructField ( ""message-id"", StringType (), nullable = True)
])
ids_in_reply = session.read.format ( ""parquet""). schema (ids_schema) .load (
    fs_prefix + ""/ ids_in_reply"")
Spark를 구성하여 손상되거나 부적합한 레코드를 삭제하거나 보관하거나 프로세스를 중지 (즉, 작업 실패)하여 처리 할 수 있습니다.",,
1309,"The default is permissive, which keeps the invalid records while setting the fields to null, allowing us to handle schema mismatch with the same techniques for missing fields.",기본값은 허용이며 필드를 null로 설정하는 동안 잘못된 레코드를 유지하므로 누락 된 필드에 대해 동일한 기술로 스키마 불일치를 처리 할 수 있습니다.,,
1310,5.3.2.4.,5.3.2.4.,,
1311,"Handling missing fields
In many situations, some of our data is missing.","누락 된 필드 처리
많은 상황에서 일부 데이터가 누락되었습니다.",,
1312,"You can choose to drop records with missing fields, fall back to secondary fields, impute averages, or leave as is.","누락 된 필드가있는 레코드를 삭제하거나, 보조 필드로 대체하거나, 평균을 대치하거나, 그대로 두도록 선택할 수 있습니다.",,
1313,Spark’s built-in tools for these tasks are inside DataFrameNaFunctions.,이러한 작업을위한 Spark의 기본 제공 도구는 DataFrameNaFunctions 내에 있습니다.,,
1314,The correct solution depends on both your data and the algorithm you end up using.,올바른 솔루션은 데이터와 사용하게되는 알고리즘에 따라 다릅니다.,,
1315,"The most common is to drop records and make sure that we have not filtered out too many records, illustrated using the mailing list data in EXAMPLE 5-27.",가장 일반적인 방법은 레코드를 삭제하고 너무 많은 레코드를 필터링하지 않았는지 확인하는 것입니다 (예 5-27의 메일 링리스트 데이터를 사용하여 설명 됨).,,
1316,Example 5-27.,예 5-27.,,
1317,"Dropping records
initial_posts_count = initial_posts.count()
initial_posts_cleaned = initial_posts.na.drop(how='any',
                                              subset=['body', 'from'])
initial_posts_cleaned_count = initial_posts_cleaned.count()


5.3.2.5.","기록 삭제
initial_posts_count = initial_posts.count ()
initial_posts_cleaned = initial_posts.na.drop (how = 'any',
                                              하위 집합 = [ '본문', '보낸 사람'])
initial_posts_cleaned_count = initial_posts_cleaned.count ()


5.3.2.5.",,
1318,"Filtering out bad data
Detecting incorrect data can be challenging.","잘못된 데이터 필터링
잘못된 데이터를 감지하는 것은 어려울 수 있습니다.",,
1319,"However, without performing at least some data cleaning, the model may train on noise.",그러나 최소한 일부 데이터 정리를 수행하지 않으면 모델이 노이즈에 대해 학습 할 수 있습니다.,,
1320,"Often, determining bad data depends on the practitioner’s domain knowledge of the problem.",종종 잘못된 데이터를 결정하는 것은 문제에 대한 실무자의 도메인 지식에 따라 달라집니다.,,
1321,A common technique supported in Spark is outlier removal.,Spark에서 지원되는 일반적인 기술은 이상 값 제거입니다.,,
1322,"However, naively applying this can remove valid records.",그러나 순진하게 적용하면 유효한 레코드를 제거 할 수 있습니다.,,
1323,"Using your domain experience, you can write a custom validation function and remove any records that do not match it using Spark’s filter function, as illustrated with our mailing list example in EXAMPLE 5-28.",도메인 경험을 사용하여 사용자 지정 유효성 검사 함수를 작성하고 예 5-28의 메일 링 목록 예제에 설명 된대로 Spark의 필터 기능을 사용하여 일치하지 않는 레코드를 제거 할 수 있습니다.,,
1324,Example 5-28.,예 5-28.,,
1325,"Filtering out bad data
def is_ok(post):
    # Your special business logic goes here
    return True


spark_mailing_list_data_cleaned = spark_mailing_list_data_with_date.filter(
    is_ok)

Using Spark SQL
If you’re a pro at SQL and less so with Scala or Python, you can also directly write SQL queries.","잘못된 데이터 필터링
def is_ok (post) :
    # 당신의 특별한 비즈니스 로직은 여기에 있습니다
    True 반환


spark_mailing_list_data_cleaned = spark_mailing_list_data_with_date.filter (
    is_ok)

Spark SQL 사용
SQL 전문가이고 Scala 또는 Python을 사용하는 전문가라면 SQL 쿼리를 직접 작성할 수도 있습니다.",,
1326,"After you’ve loaded data, you can give the data names with registerTempTable and then use the SQL function on the Spark session (see EXAMPLE 5-29).",데이터를로드 한 후 registerTempTable로 데이터 이름을 지정한 다음 Spark 세션에서 SQL 함수를 사용할 수 있습니다 (예제 5-29 참조).,,
1327,Example 5-29.,예 5-29.,,
1328,"Using Spark SQL
ids_in_reply.registerTempTable(""cheese"")
no_text = session.sql(""select * from cheese where body = '' AND subject = ''"")



5.3.2.6.","Spark SQL 사용
ids_in_reply.registerTempTable ( ""치즈"")
no_text = session.sql ( ""select * from cheese where body = ''AND subject = ''"")



5.3.2.6.",,
1329,"Saving the output
Once you have the data ready, it’s time to save the output.","출력 저장
데이터가 준비되면 출력을 저장할 차례입니다.",,
1330,"If you’re going to use Apache Spark to do feature preparation, you can skip this step for now.",Apache Spark를 사용하여 기능을 준비하려는 경우 지금은이 단계를 건너 뛸 수 있습니다.,,
1331,"If you want to go back to single-machine tools, it’s often simplest to save to a persistent volume.",단일 공작 기계로 돌아 가려는 경우 영구 볼륨에 저장하는 것이 가장 간단한 경우가 많습니다.,,
1332,"To do this, bring the data back to the main program by calling toPandas(), as shown in EXAMPLE 5-30.",이렇게하려면 예제 5-30에 표시된대로 toPandas ()를 호출하여 데이터를 기본 프로그램으로 다시 가져옵니다.,,
1333,Now you can save the data in whatever format the next tool expects.,이제 다음 도구에서 예상하는 형식으로 데이터를 저장할 수 있습니다.,,
1334,Example 5-30.,예 5-30.,,
1335,"Saving to a persistent volume
initial_posts.toPandas()
If the data is large, or you otherwise want to use an object store, Spark can write to many different formats (just as it can load from many different formats).","영구 볼륨에 저장
initial_posts.toPandas ()
데이터가 크거나 객체 저장소를 사용하려는 경우 Spark는 여러 다른 형식에서로드 할 수있는 것처럼 다양한 형식으로 쓸 수 있습니다.",,
1336,The correct format depends on the tool you intend to use for feature preparation.,올바른 형식은 기능 준비에 사용하려는 도구에 따라 다릅니다.,,
1337,Writing to Parquet is shown in EXAMPLE 5-31.,Parquet에 쓰기는 예제 5-31에 나와 있습니다.,,
1338,Example 5-31.,예 5-31.,,
1339,"Writing to Parquet
initial_posts.write.format(""parquet"").mode('overwrite').save(fs_prefix +
                                                             ""/initial_posts"")
ids_in_reply.write.format(""parquet"").mode('overwrite').save(fs_prefix +
                                                            ""/ids_in_reply"")
Now you’ve seen a variety of different tools you can use to source and clean the data.","마루에 쓰기
initial_posts.write.format ( ""parquet""). mode ( 'overwrite'). save (fs_prefix +
                                                             ""/ initial_posts"")
ids_in_reply.write.format ( ""parquet""). mode ( 'overwrite'). save (fs_prefix +
                                                            ""/ ids_in_reply"")
이제 데이터를 소싱하고 정리하는 데 사용할 수있는 다양한 도구를 살펴 보았습니다.",,
1340,"We’ve looked at the flexibility of local tools, the scalability of distributed tools, and the integration from TensorFlow Extended.","로컬 도구의 유연성, 분산 도구의 확장 성, TensorFlow Extended의 통합을 살펴 보았습니다.",,
1341,"With the data in shape, let’s now make sure the right features are available and get them in a usable format for the machine learning model.",데이터가 정리되었으므로 이제 올바른 기능을 사용할 수 있는지 확인하고 기계 학습 모델에 사용할 수있는 형식으로 가져 오겠습니다.,,
1342,5.3.3.,5.3.3.,,
1343,"Distributed Feature Preparation Using Apache Spark
Apache Spark has a large number of built-in feature preparation tools, in pyspark.ml.feature, that you can use to generate features.","Apache Spark를 사용한 분산 기능 준비
Apache Spark에는 기능을 생성하는 데 사용할 수있는 pyspark.ml.feature에 기본 제공 기능 준비 도구가 많이 있습니다.",,
1344,You can use Spark in the same way as you did during data preparation.,데이터 준비 중에했던 것과 동일한 방식으로 Spark를 사용할 수 있습니다.,,
1345,You may find using Spark’s own ML pipeline an easy way to put together multiple feature preparation stages.,Spark의 자체 ML 파이프 라인을 사용하면 여러 기능 준비 단계를 쉽게 구성 할 수 있습니다.,,
1346,"For the Spark mailing list example, we have textual input data.",Spark 메일 링리스트 예의 경우 텍스트 입력 데이터가 있습니다.,,
1347,"To allow us to train a variety of models, converting this into word vectors is our preferred form of feature prep.",다양한 모델을 학습 할 수 있도록이를 단어 벡터로 변환하는 것이 우리가 선호하는 기능 준비 형식입니다.,,
1348,Doing so involves first tokenizing the data with Spark’s Tokenizer.,이를 위해서는 먼저 Spark의 Tokenizer로 데이터를 토큰 화해야합니다.,,
1349,"Once we have the tokens, we can train a Word2Vec model and produce our word vectors.",토큰이 있으면 Word2Vec 모델을 훈련시키고 단어 벡터를 생성 할 수 있습니다.,,
1350,EXAMPLE 5-32 illustrates how to prepare features for the mailing list example using Spark.,예 5-32는 Spark를 사용하여 메일 링리스트 예를위한 기능을 준비하는 방법을 보여줍니다.,,
1351,Example 5-32.,예 5-32.,,
1352,"Preparing features for the mailing list
tokenizer = Tokenizer(inputCol=""body"", outputCol=""body_tokens"")
body_hashing = HashingTF(inputCol=""body_tokens"",
                         outputCol=""raw_body_features"",
                         numFeatures=10000)
body_idf = IDF(inputCol=""raw_body_features"", outputCol=""body_features"")
body_word2Vec = Word2Vec(vectorSize=5,
                         minCount=0,
                         numPartitions=10,
                         inputCol=""body_tokens"",
                         outputCol=""body_vecs"")
assembler = VectorAssembler(inputCols=[
    ""body_features"", ""body_vecs"", ""contains_python_stack_trace"",
    ""contains_java_stack_trace"", ""contains_exception_in_task""
],
                            outputCol=""features"")
With this final distributed feature preparation example, you’re ready to scale up to handle larger data sizes if they ever come your way.","메일 링리스트를위한 기능 준비
tokenizer = Tokenizer (inputCol = ""body"", outputCol = ""body_tokens"")
body_hashing = HashingTF (inputCol = ""body_tokens"",
                         outputCol = ""raw_body_features"",
                         numFeatures = 10000)
body_idf = IDF (inputCol = ""raw_body_features"", outputCol = ""body_features"")
body_word2Vec = Word2Vec (vectorSize = 5,
                         minCount = 0,
                         numPartitions = 10,
                         inputCol = ""body_tokens"",
                         outputCol = ""body_vecs"")
어셈블러 = VectorAssembler (inputCols = [
    ""body_features"", ""body_vecs"", ""contains_python_stack_trace"",
    ""contains_java_stack_trace"", ""contains_exception_in_task""
],
                            outputCol = ""기능"")
이 최종 분산 기능 준비 예제를 사용하면 더 큰 데이터 크기를 처리 할 수 있도록 확장 할 준비가 된 것입니다.",,
1353,"If you’re working with smaller data, you’ve seen how you can use the same simple techniques of containerization to continue to work with your favorite tools.",더 작은 데이터로 작업하는 경우 컨테이너화의 동일한 간단한 기술을 사용하여 좋아하는 도구로 계속 작업 할 수있는 방법을 확인했습니다.,,
1354,"Either way, you’re almost ready for the next stage in the machine learning pipeline.",어느 쪽이든 머신 러닝 파이프 라인의 다음 단계를 거의 준비했습니다.,,
1355,5.4.,5.4.,,
1356,"Putting It Together in a Pipeline
We have shown how to solve individual problems in data and feature preparation, but now we need to bring it all together.","파이프 라인에 통합
데이터 및 기능 준비에서 개별 문제를 해결하는 방법을 보여 주었지만 이제는 모두 통합해야합니다.",,
1357,"In our local example, we wrote our functions with the types and returned parameters to make it easy to put into a pipeline.",로컬 예제에서는 파이프 라인에 쉽게 넣을 수 있도록 유형과 반환 된 매개 변수를 사용하여 함수를 작성했습니다.,,
1358,"Since we return the path of where our output is in each stage, we can use the function outputs to create the dependency graph for us.",각 단계에서 출력이있는 경로를 반환하므로 함수 출력을 사용하여 종속성 그래프를 생성 할 수 있습니다.,,
1359,Putting these functions together into a pipeline is illustrated in EXAMPLE 5-33.,이러한 함수를 파이프 라인에 통합하는 방법은 예 5-33에 설명되어 있습니다.,,
1360,Example 5-33.,예 5-33.,,
1361,"Putting the functions together
@kfp.dsl.pipeline(name='Simple1', description='Simple1')
def my_pipeline_mini(year: int):
    dvop = dsl.VolumeOp(name=""create_pvc"",
                        resource_name=""my-pvc-2"",
                        size=""5Gi"",
                        modes=dsl.VOLUME_MODE_RWO)
    tldvop = dsl.VolumeOp(name=""create_pvc"",
                          resource_name=""tld-volume-2"",
                          size=""100Mi"",
                          modes=dsl.VOLUME_MODE_RWO)
    download_data_op = kfp.components.func_to_container_op(
        download_data, packages_to_install=['lxml', 'requests'])
    download_tld_info_op = kfp.components.func_to_container_op(
        download_tld_data,
        packages_to_install=['requests', 'pandas>=0.24', 'tables'])
    clean_data_op = kfp.components.func_to_container_op(
        clean_data, packages_to_install=['pandas>=0.24', 'tables'])

    step1 = download_data_op(year).add_pvolumes(
        {""/data_processing"": dvop.volume})
    step2 = clean_data_op(input_path=step1.output).add_pvolumes(
        {""/data_processing"": dvop.volume})
    step3 = download_tld_info_op().add_pvolumes({""/tld_info"": tldvop.volume})


kfp.compiler.Compiler().compile(my_pipeline_mini, 'local-data-prep-2.zip')
You can see that the feature preparation step here follows the same general pattern of all of the local components.","기능 결합
@ kfp.dsl.pipeline (name = 'Simple1', description = 'Simple1')
def my_pipeline_mini (연도 : 정수) :
    dvop = dsl.VolumeOp (name = ""create_pvc"",
                        resource_name = ""my-pvc-2"",
                        size = ""5Gi"",
                        모드 = dsl.VOLUME_MODE_RWO)
    tldvop = dsl.VolumeOp (name = ""create_pvc"",
                          resource_name = ""tld-volume-2"",
                          size = ""100Mi"",
                          모드 = dsl.VOLUME_MODE_RWO)
    download_data_op = kfp.components.func_to_container_op (
        download_data, packages_to_install = [ 'lxml', 'requests'])
    download_tld_info_op = kfp.components.func_to_container_op (
        download_tld_data,
        packages_to_install = [ 'requests', 'pandas> = 0.24', 'tables'])
    clean_data_op = kfp.components.func_to_container_op (
        clean_data, packages_to_install = [ 'pandas> = 0.24', 'tables'])

    1 단계 = download_data_op (연도) .add_pvolumes (
        { ""/ data_processing"": dvop.volume})
    step2 = clean_data_op (input_path = step1.output) .add_pvolumes (
        { ""/ data_processing"": dvop.volume})
    3 단계 = download_tld_info_op (). add_pvolumes ({ ""/ tld_info"": tldvop.volume})


kfp.compiler.Compiler (). compile (my_pipeline_mini, 'local-data-prep-2.zip')
여기서 기능 준비 단계는 모든 로컬 구성 요소의 동일한 일반 패턴을 따르는 것을 볼 수 있습니다.",,
1362,"However, the libraries that we need for our feature 
preparation are a bit different, so we’ve changed the packages_to_install value to install Scikit-learn, as shown in EXAMPLE 5-34.","그러나 기능에 필요한 라이브러리는
준비 과정이 약간 다르기 때문에 예 5-34와 같이 Scikit-learn을 설치하기 위해 packages_to_install 값을 변경했습니다.",,
1363,Example 5-34.,예 5-34.,,
1364,"Installing Scikit-learn
    prepare_features_op = kfp.components.func_to_container_op(
        prepare_features,
        packages_to_install=['pandas>=0.24', 'tables', 'scikit-learn'])
Tip
When you start exploring a new dataset, you may find it easier to use a notebook as usual, without the pipeline components.","Scikit-learn 설치
    prepare_features_op = kfp.components.func_to_container_op (
        준비 _ 기능,
        packages_to_install = [ 'pandas> = 0.24', 'tables', 'scikit-learn'])
팁
새 데이터 세트 탐색을 시작하면 파이프 라인 구성 요소없이 평소처럼 노트북을 사용하는 것이 더 쉬울 수 있습니다.",,
1365,When possible following the same general structure you would with pipelines will make it easier to productionize your exploratory work.,가능한 경우 파이프 라인과 동일한 일반 구조를 따르면 탐색 작업을보다 쉽게 생산할 수 있습니다.,,
1366,These steps don’t specify the container to use.,이 단계는 사용할 컨테이너를 지정하지 않습니다.,,
1367,"For the container with SpamAssassin you’ve just built, you write it as in EXAMPLE 5-35.",방금 빌드 한 SpamAssassin이 포함 된 컨테이너의 경우 예제 5-35와 같이 작성합니다.,,
1368,Example 5-35.,예 5-35.,,
1369,"Specifying a container
clean_data_op = kfp.components.func_to_container_op(
    clean_data,
    base_image=""{0}/kubeflow/spammassisan"".format(container_registry),
    packages_to_install=['pandas>=0.24', 'tables'])
Sometimes the cost of writing our data out in between stages is too expensive.","컨테이너 지정
clean_data_op = kfp.components.func_to_container_op (
    clean_data,
    base_image = ""{0} / kubeflow / spammassisan"".format (container_registry),
    packages_to_install = [ 'pandas> = 0.24', 'tables'])
때로는 단계 사이에 데이터를 쓰는 비용이 너무 비쌉니다.",,
1370,"In our recommender example, unlike in the mailing list example, we’ve chosen to put data and feature prep together into a single pipeline stage.",추천자 예에서는 메일 링리스트 예와 달리 데이터와 기능 준비를 단일 파이프 라인 단계에 통합하도록 선택했습니다.,,
1371,"In our distributed mailing list example, we build one single Spark job as well.",분산 메일 링리스트 예에서 단일 Spark 작업도 빌드합니다.,,
1372,"In these cases, our entire work so far is just one stage.",이 경우 지금까지의 전체 작업은 하나의 단계에 불과합니다.,,
1373,"Using a single stage allows us to avoid having to write the file out in between, but can complicate debugging.",단일 단계를 사용하면 중간에 파일을 작성하지 않아도되지만 디버깅이 복잡해질 수 있습니다.,,
1374,5.5.,5.5.,,
1375,"Using an Entire Notebook as a Data Preparation Pipeline Stage
If you don’t want to turn the individual parts of the data preparation notebook into a pipeline, you can use the entire notebook as one stage.","전체 노트북을 데이터 준비 파이프 라인 단계로 사용
데이터 준비 노트북의 개별 부분을 파이프 라인으로 전환하지 않으려면 전체 노트북을 하나의 단계로 사용할 수 있습니다.",,
1376,You can use the same containers used by JupyterHub to run the notebook programmatically.,JupyterHub에서 사용하는 것과 동일한 컨테이너를 사용하여 노트북을 프로그래밍 방식으로 실행할 수 있습니다.,,
1377,"To do this, you’ll need to make a new Dockerfile, specify that it is based on top of another container using FROM, and then add a COPY directive to package the notebook inside the new container.",이렇게하려면 새 Dockerfile을 만들고 FROM을 사용하여 다른 컨테이너의 상단에 기반하도록 지정한 다음 COPY 지시문을 추가하여 새 컨테이너 내부에 노트북을 패키징해야합니다.,,
1378,"Since the census data example has a preexisting notebook, that’s the approach we’ve taken in EXAMPLE 5-36.",인구 조사 데이터 예에는 기존 노트북이 있으므로 이것이 예 5-36에서 취한 접근 방식입니다.,,
1379,Example 5-36.,예 5-36.,,
1380,"Using an entire notebook as data preparation
FROM gcr.io/kubeflow-images-public/tensorflow-1.6.0-notebook-cpu

COPY ./ /workdir /
If you require additional Python dependencies, you can use the RUN directive to install them.","전체 노트북을 데이터 준비로 사용
gcr.io/kubeflow-images-public/tensorflow-1.6.0-notebook-cpu에서

복사 ./ / workdir /
추가 Python 종속성이 필요한 경우 RUN 지시문을 사용하여 설치할 수 있습니다.",,
1381,"Putting the dependencies in the container can help speed up the pipeline, especially for complicated packages.",컨테이너에 종속성을 배치하면 특히 복잡한 패키지의 경우 파이프 라인 속도를 높일 수 있습니다.,,
1382,"For our mailing list example, the Dockerfile would look like EXAMPLE 5-37.",메일 링리스트 예의 경우 Dockerfile은 예 5-37과 같습니다.,,
1383,Example 5-37.,예 5-37.,,
1384,"Using RUN to add Python dependencies to the container
RUN pip3 install --upgrade lxml pandas
We can use this container like any other in the pipeline with dsl.ContainerOp, as we did with the recommender example in CHAPTER 4.","RUN을 사용하여 컨테이너에 Python 종속성 추가
pip3 install --upgrade lxml pandas 실행
4 장의 추천자 예제에서했던 것처럼 dsl.ContainerOp를 사용하여 파이프 라인의 다른 컨테이너와 마찬가지로이 컨테이너를 사용할 수 있습니다.",,
1385,"Now you have two ways to use notebooks in Kubeflow, and we’ll cover options beyond notebooks next.","이제 Kubeflow에서 노트북을 사용하는 두 가지 방법이 있으며, 다음으로 노트북 이외의 옵션에 대해 다룰 것입니다.",,
1386,"Tip
Does the notebook need GPU resources?","팁
노트북에 GPU 리소스가 필요합니까?",,
1387,"When specifying the dsl.ContainerOp, add a call to set_gpu_limit and specify either nvidia or amd depending on the desired GPU type.",dsl.ContainerOp를 지정할 때 set_gpu_limit에 대한 호출을 추가하고 원하는 GPU 유형에 따라 nvidia 또는 amd를 지정하십시오.,,
1388,5.6.,5.6.,,
1389,"Conclusion
Now you have your data ready to train a model.","결론
이제 모델을 학습 할 데이터가 준비되었습니다.",,
1390,We’ve seen how there is no one-size-fits-all approach to feature and data preparation, our different examples needed different tooling.,기능 및 데이터 준비에 대해 한 가지 방법으로 모든 것을 다룰 수있는 방법은 없습니다.우리의 다른 예는 다른 도구가 필요했습니다.,
1391,"We’ve also seen how the methods can require changing within the same problem, like when we expanded the scope of the mailing list example to include more data.",또한 더 많은 데이터를 포함하도록 메일 링리스트 예제의 범위를 확장 한 경우와 같이 동일한 문제 내에서 방법을 변경해야하는 방법도 살펴 보았습니다.,,
1392,"The amount and quality of the features, and the data to produce them, are critical to the success of the machine learning projects.","기능의 양과 품질, 기능을 생성하는 데 필요한 데이터는 기계 학습 프로젝트의 성공에 매우 중요합니다.",,
1393,You can test this by running the examples with smaller data sizes and comparing the models.,더 작은 데이터 크기로 예제를 실행하고 모델을 비교하여이를 테스트 할 수 있습니다.,,
1394,"It’s also important to remember that data and feature preparation is not a one-and-done activity, and you may want to revisit this step as you develop this model.","또한 데이터 및 기능 준비는 한 번에 한 작업이 아니라는 점을 기억하는 것이 중요하며,이 모델을 개발할 때이 단계를 다시 방문하는 것이 좋습니다.",,
1395,"You may find that there is a feature you wish you had, or that a feature you thought would perform well isn’t suggesting data quality issues.",원하는 기능이 있거나 잘 수행 될 것이라고 생각한 기능이 데이터 품질 문제를 암시하지 않는다는 것을 알 수 있습니다.,,
1396,"In the coming chapters, as we train our models and serve them, feel free to revisit the data and feature preparation.",다음 장에서는 모델을 교육하고 제공 할 때 데이터와 기능 준비를 자유롭게 다시 검토 할 수 있습니다.,,
1397,[1] See the TFX documentation for a good summary if you are new to data  preparation.,[1] 데이터 준비가 처음 인 경우 좋은 요약은 TFX 문서를 참조하십시오.,,
1398,"[2] The positive impact of using more data in training is made clear in A. Halevy et al., “The Unreasonable Effectiveness of Data,” IEEE Intelligent Systems 24, no.","[2] 교육에 더 많은 데이터를 사용하는 것의 긍정적 인 영향은 A. Halevy et al.,“The Unreasonable Effectiveness of Data,”IEEE Intelligent Systems 24, no.",,
1399,"2 (March/April 2009): 8-12, https://oreil.ly/YI820, and T. Schnoebelen, “More Data Beats Better Algorithms,” Data Science Central, September 23, 2016, https://oreil.ly/oLe1R.","2 (2009 년 3 월 / 4 월) : 8-12, https://oreil.ly/YI820 및 T. Schnoebelen, ""More Data Beats Better Algorithms,""Data Science Central, 2016 년 9 월 23 일, https : // oreil.ly / oLe1R.",,
1400,"[3] For the formal definition, see “Six Steps to Master Machine Learning with Data Preparation”.",[3] 공식적인 정의는“데이터 준비로 머신 러닝을 마스터하기위한 6 단계”를 참조하십시오.,,
1401,"[4] There are too many tools to cover here, but this blog post includes many.",[4] 여기에서 다루기에는 너무 많은 도구가 있지만이 블로그 게시물에는 많은 도구가 포함되어 있습니다.,,
1402,"[5] Datasets tend to grow over time rather than shrinking, so starting with distributed tooling can help you scale your work.",[5] 데이터 세트는 줄어들 기보다는 시간이 지남에 따라 증가하는 경향이 있으므로 분산 된 도구로 시작하면 작업을 확장하는 데 도움이 될 수 있습니다.,,
1403,[6] See this blog post on some common techniques for imputing missing data.,[6] 누락 된 데이터를 대치하기위한 몇 가지 일반적인 기술에 대한이 블로그 게시물을 참조하십시오.,,
1404,[7] Have some VB6 code you really need to run?,[7] 실행해야하는 VB6 코드가 있습니까?,,
1405,"Check out CHAPTER 9, on going beyond TensorFlow, and make a small sacrifice of wine.",TensorFlow를 넘어서서 9 장을 확인하고 와인을 조금만 희생하십시오.,,
1406,"[8] There is a compatibility matrix available on this Apache page, although currently Beam’s Python support requires launching an additional Docker container, making support on Kubernetes more complicated.",[8]이 Apache 페이지에서 사용할 수있는 호환성 매트릭스가 있지만 현재 Beam의 Python 지원에는 추가 Docker 컨테이너를 실행해야하므로 Kubernetes에 대한 지원이 더 복잡해집니다.,,
1407,"[9] While TFX automatically installs TFDV, if you have an old installation and you don’t specify tensorflow-data-validation, you may get an error of Could not find a version that satisfies the requirement so we illustrate explicitly installing both here.",[9] TFX는 TFDV를 자동으로 설치하지만 이전 설치가 있고 tensorflow-data-validation을 지정하지 않은 경우 요구 사항을 충족하는 버전을 찾을 수 없습니다.,,
1408,"[10] While technically not a file format, since TFX can accept Pandas dataframes, a common pattern is to load with Pandas first.",[10] 기술적으로는 파일 형식이 아니지만 TFX는 Pandas 데이터 프레임을 허용 할 수 있기 때문에 일반적인 패턴은 먼저 Pandas로로드하는 것입니다.,,
1409,"[11] There is no definitive list, although many vendors list their formats on  this Spark page.",[11] 많은 공급 업체가이 Spark 페이지에 형식을 나열하지만 명확한 목록은 없습니다.,,
1410,"[12] Of course, since most formats have slight variations, they have configuration options if the defaults don’t work.",[12] 물론 대부분의 형식은 약간의 변형이 있기 때문에 기본값이 작동하지 않는 경우 구성 옵션이 있습니다.,,
1411,Chapter 6.,6 장.,,
1412,"Artifact and Metadata Store
Machine learning typically involves dealing with a large amount of raw and intermediate (transformed) data where the ultimate goal is creating and deploying the model.","아티팩트 및 메타 데이터 저장소
기계 학습은 일반적으로 최종 목표가 모델 생성 및 배포 인 대량의 원시 및 중간 (변환 된) 데이터를 처리하는 것을 포함합니다.",,
1413,In order to understand our model it is necessary to be able to explore datasets used for its creation and transformations (data lineage).,모델을 이해하려면 생성 및 변환 (데이터 계보)에 사용되는 데이터 세트를 탐색 할 수 있어야합니다.,,
1414,The collection of these datasets and the transformation applied to them is called the metadata of our model.,이러한 데이터 세트의 컬렉션과 여기에 적용된 변환을 모델의 메타 데이터라고합니다.,,
1415,"[1]
Model metadata is critical for reproducibility in machine learning;[2] reproducibility is critical for reliable production deployments.","[1]
모델 메타 데이터는 머신 러닝의 재현성에 중요합니다. [2] 재현성은 안정적인 프로덕션 배포에 중요합니다.",,
1416,Capturing the metadata allows us to understand variations when rerunning jobs or experiments.,메타 데이터를 캡처하면 작업이나 실험을 다시 실행할 때의 변형을 이해할 수 있습니다.,,
1417,Understanding variations is necessary to iteratively develop and improve our models.,모델을 반복적으로 개발하고 개선하려면 변형을 이해해야합니다.,,
1418,It also provides a solid foundation for model comparisons.,또한 모델 비교를위한 견고한 기반을 제공합니다.,,
1419,"As Pete Warden defined it in this post:

To reproduce results, code, training data, and the overall platform need to be recorded accurately.","Pete Warden이이 게시물에서 정의한대로 :

결과를 재현하려면 코드, 교육 데이터 및 전체 플랫폼을 정확하게 기록해야합니다.",,
1420,"The same information is also required for other common ML operations—model comparison, reproducible model creation, etc.","모델 비교, 재현 가능한 모델 생성 등과 같은 다른 일반적인 ML 작업에도 동일한 정보가 필요합니다.",,
1421,There are many different options for tracking the metadata of models.,모델의 메타 데이터를 추적하기위한 다양한 옵션이 있습니다.,,
1422,Kubeflow has a built-in tool for this called Kubeflow ML Metadata.,Kubeflow에는이를 위해 Kubeflow ML 메타 데이터라는 도구가 내장되어 있습니다.,,
1423,"[3]
The goal of this tool is to help Kubeflow users understand and manage their ML workflows by tracking and managing the metadata that the workflows produce.","[삼]
이 도구의 목표는 워크 플로가 생성하는 메타 데이터를 추적하고 관리하여 Kubeflow 사용자가 ML 워크 플로를 이해하고 관리하도록 돕는 것입니다.",,
1424,Another tool for tracking metadata that we can integrate into our Kubeflow pipelines is MLflow Tracking.,Kubeflow 파이프 라인에 통합 할 수있는 메타 데이터 추적을위한 또 다른 도구는 MLflow 추적입니다.,,
1425,"It provides API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results.","기계 학습 코드를 실행하고 나중에 결과를 시각화 할 때 매개 변수, 코드 버전, 메트릭 및 출력 파일을 로깅하기위한 API 및 UI를 제공합니다.",,
1426,In this chapter we will discuss the capabilities of Kubeflow’s ML Metadata project and show how it can be used.,이 장에서는 Kubeflow의 ML 메타 데이터 프로젝트의 기능에 대해 논의하고 사용 방법을 보여줍니다.,,
1427,We will also consider some shortcomings of this implementation and explore usage of additional third-party software: MLflow.,또한이 구현의 몇 가지 단점을 고려하고 추가적인 타사 소프트웨어 인 MLflow의 사용을 살펴볼 것입니다.,,
1428,"[4]

6.1.","[4]

6.1.",,
1429,"Kubeflow ML Metadata
Kubeflow ML Metadata is a library for recording and retrieving metadata associated with model creation.","Kubeflow ML 메타 데이터
Kubeflow ML 메타 데이터는 모델 생성과 관련된 메타 데이터를 기록하고 검색하기위한 라이브러리입니다.",,
1430,"In the current implementation, Kubeflow Metadata provides only Python APIs.",현재 구현에서 Kubeflow Metadata는 Python API 만 제공합니다.,,
1431,"To use other languages, you need to implement the language-specific Python plug-in to be able to use the library.",다른 언어를 사용하려면 라이브러리를 사용할 수 있도록 언어 별 Python 플러그인을 구현해야합니다.,,
1432,"To understand how it works, we will start with a simple artificial example showing the basic capabilities of Kubeflow Metadata using a very simple notebook (based on this demo).",작동 방식을 이해하기 위해 매우 간단한 노트북 (이 데모 기반)을 사용하여 Kubeflow 메타 데이터의 기본 기능을 보여주는 간단한 인공 예제로 시작합니다.,,
1433,"[5]
Implementation of Kubeflow Metadata starts with required imports, as shown in EXAMPLE 6-1.","[5]
Kubeflow 메타 데이터 구현은 예제 6-1에 표시된대로 필수 가져 오기로 시작됩니다.",,
1434,Example 6-1.,예 6-1.,,
1435,"Required imports
from kfmd import metadata
import pandas
from datetime import datetime
In Kubeflow Metadata, all the information is organized in terms of a workspace, run, and execution.","필수 수입품
kfmd 가져 오기 메타 데이터에서
수입 판다
datetime 가져 오기 datetime에서
Kubeflow 메타 데이터에서 모든 정보는 작업 공간, 실행 및 실행 측면에서 구성됩니다.",,
1436,You need to define a workspace so Kubeflow can track and organize the records.,Kubeflow가 레코드를 추적하고 구성 할 수 있도록 작업 영역을 정의해야합니다.,,
1437,The code in EXAMPLE 6-2 shows how this can be done.,예제 6-2의 코드는이를 수행하는 방법을 보여줍니다.,,
1438,Example 6-2.,예 6-2.,,
1439,"Define a workspace
ws1 = metadata.Workspace(
    # Connect to metadata-service in namespace kubeflow.","작업 공간 정의
ws1 = metadata.Workspace (
    # 네임 스페이스 kubeflow의 metadata-service에 연결합니다.",,
1440,"backend_url_prefix=""metadata-service.kubeflow.svc.cluster.local:8080"",
    name=""ws1"",
    description=""a workspace for testing"",
    labels={""n1"": ""v1""})
r = metadata.Run(
    workspace=ws1,
    name=""run-"" + datetime.utcnow().isoformat(""T"") ,
    description=""a run in ws_1"",
)
exec = metadata.Execution(
    name = ""execution"" + datetime.utcnow().isoformat(""T"") ,
    workspace=ws1,
    run=r,
    description=""execution example"",
)
Tip
Workspace, run, and execution can be defined multiple times in the same or different applications.","backend_url_prefix = ""metadata-service.kubeflow.svc.cluster.local : 8080"",
    name = ""ws1"",
    description = ""테스트를위한 작업 공간"",
    labels = { ""n1"": ""v1""})
r = metadata.Run (
    workspace = ws1,
    name = ""run-""+ datetime.utcnow (). isoformat ( ""T""),
    description = ""a ws_1에서 실행"",
)
exec = metadata.Execution (
    name = ""execution""+ datetime.utcnow (). isoformat ( ""T""),
    workspace = ws1,
    run = r,
    description = ""실행 예"",
)
팁
작업 공간, 실행 및 실행은 동일하거나 다른 응용 프로그램에서 여러 번 정의 할 수 있습니다.",,
1441,"If they do not exist, they will be created; if they already exist, they will be used.",존재하지 않으면 생성됩니다.이미 존재하는 경우 사용됩니다.,,
1442,Kubeflow does not automatically track the datasets used by the application.,Kubeflow는 애플리케이션에서 사용하는 데이터 세트를 자동으로 추적하지 않습니다.,,
1443,They have to be explicitly registered in code.,코드에 명시 적으로 등록해야합니다.,,
1444,Following a classic MNIST example data sets registration in Metadata should be implemented as shown in EXAMPLE 6-3.,클래식 MNIST 예제에 따라 메타 데이터에 등록 된 데이터 세트는 예제 6-3과 같이 구현되어야합니다.,,
1445,Example 6-3.,예 6-3.,,
1446,"Metadata example
data_set = exec.log_input(
        metadata.DataSet(
            description=""an example data"",
            name=""mytable-dump"",
            owner=""owner@my-company.org"",
            uri=""file://path/to/dataset"",
            version=""v1.0.0"",
            query=""SELECT * FROM mytable""))
In addition to data, Kubeflow Metadata allows you to store information about your model and its metrics.","메타 데이터 예
data_set = exec.log_input (
        metadata.DataSet (
            description = ""예제 데이터"",
            name = ""mytable-dump"",
            owner = ""owner@my-company.org"",
            uri = ""file : // path / to / dataset"",
            version = ""v1.0.0"",
            query = ""SELECT * FROM mytable""))
데이터 외에도 Kubeflow 메타 데이터를 사용하면 모델 및 해당 메트릭에 대한 정보를 저장할 수 있습니다.",,
1447,The code implementing it is presented in EXAMPLE 6-4.,이를 구현하는 코드는 예제 6-4에 나와 있습니다.,,
1448,Example 6-4.,예 6-4.,,
1449,"Another metadata example
model = exec.log_output(
    metadata.Model(
            name=""MNIST"",
            description=""model to recognize handwritten digits"",
            owner=""someone@kubeflow.org"",
            uri=""gcs://my-bucket/mnist"",
            model_type=""neural network"",
            training_framework={
                ""name"": ""tensorflow"",
                ""version"": ""v1.0""
            },
            hyperparameters={
                ""learning_rate"": 0.5,
                ""layers"": [10, 3, 1],
                ""early_stop"": True
            },
            version=""v0.0.1"",
            labels={""mylabel"": ""l1""}))
metrics = exec.log_output(
    metadata.Metrics(
            name=""MNIST-evaluation"",
            description=""validating the MNIST model to recognize handwritten digits"",
            owner=""someone@kubeflow.org"",
            uri=""gcs://my-bucket/mnist-eval.csv"",
            data_set_id=data_set.id,
            model_id=model.id,
            metrics_type=metadata.Metrics.VALIDATION,
            values={""accuracy"": 0.95},
            labels={""mylabel"": ""l1""}))
These code snippets will implement all of the main steps for storing model creation metadata:


Define workspace, run, and execution.","또 다른 메타 데이터 예
모델 = exec.log_output (
    metadata.Model (
            name = ""MNIST"",
            description = ""자기 숫자 인식 모델"",
            owner = ""someone@kubeflow.org"",
            uri = ""gcs : // my-bucket / mnist"",
            model_type = ""신경망"",
            training_framework = {
                ""name"": ""텐서 플로우"",
                ""버전"": ""v1.0""
            },
            하이퍼 파라미터 = {
                ""학습률"": 0.5,
                ""레이어"": [10, 3, 1],
                ""early_stop"": 참
            },
            version = ""v0.0.1"",
            labels = { ""mylabel"": ""l1""}))
메트릭 = exec.log_output (
    metadata.Metrics (
            name = ""MNIST- 평가"",
            description = ""수기 숫자 인식을위한 MNIST 모델 검증"",
            owner = ""someone@kubeflow.org"",
            uri = ""gcs : //my-bucket/mnist-eval.csv"",
            data_set_id = data_set.id,
            model_id = model.id,
            metrics_type = metadata.Metrics.VALIDATION,
            values ​​= { ""정확도"": 0.95},
            labels = { ""mylabel"": ""l1""}))
다음 코드 조각은 모델 생성 메타 데이터를 저장하기위한 모든 주요 단계를 구현합니다.


작업 공간, 실행 및 실행을 정의하십시오.",,
1450,Store information about data assets used for model creation.,모델 생성에 사용되는 데이터 자산에 대한 정보를 저장합니다.,,
1451,"Store information about the created model, including its version, type, training framework, and hyperparameters used for its creation.","버전, 유형, 학습 프레임 워크 및 생성에 사용 된 하이퍼 파라미터를 포함하여 생성 된 모델에 대한 정보를 저장합니다.",,
1452,Store information about model evaluation metrics.,모델 평가 지표에 대한 정보를 저장합니다.,,
1453,"In real-world implementations these snippets should be used in the actual code to capture metadata used for data preparation, machine learning, etc.","실제 구현에서 이러한 스 니펫은 데이터 준비, 기계 학습 등에 사용되는 메타 데이터를 캡처하기 위해 실제 코드에 사용되어야합니다.",,
1454,See CHAPTER 7 for examples of where and how this information is captured.,이 정보가 캡처되는 위치와 방법에 대한 예는 7 장을 참조하십시오.,,
1455,Collecting metadata is useful only if there are ways to view it.,메타 데이터 수집은 볼 수있는 방법이있는 경우에만 유용합니다.,,
1456,"Kubeflow Metadata provides two ways of viewing it—programmatically, and using Metadata UI.",Kubeflow 메타 데이터는 프로그래밍 방식과 메타 데이터 UI 사용이라는 두 가지 방법으로이를 볼 수 있습니다.,,
1457,6.1.1.,6.1.1.,,
1458,"Programmatic Query
The following functionality is available for programmatic query.","프로그래밍 방식 쿼리
프로그래밍 방식 쿼리에 다음 기능을 사용할 수 있습니다.",,
1459,"First, we list all the models in the workspace, as shown in EXAMPLE 6-5.",먼저 예제 6-5에 표시된대로 작업 공간의 모든 모델을 나열합니다.,,
1460,Example 6-5.,예 6-5.,,
1461,"List all models
pandas.DataFrame.from_dict(ws1.list(metadata.Model.ARTIFACT_TYPE_NAME))
In our code we created only a single model, which is returned as a result of this query (see TABLE 6-1).","모든 모델 나열
pandas.DataFrame.from_dict (ws1.list (metadata.Model.ARTIFACT_TYPE_NAME))
이 코드에서는이 쿼리의 결과로 반환되는 단일 모델 만 생성했습니다 (표 6-1 참조).",,
1462,Table 6-1.,표 6-1.,,
1463,"List of models


 
id
workspace
run
create_time
description
model_type




0
2
ws1
run-2020-01-10T22:13:20.959882
2020-01-10T22:13:26.324443Z
model to recognize handwritten digits
neural network






name
owner
version
uri
training_framework




MNIST
someone@kubeflow.org
v0.0.1
gcs://my-bucket/mnist
{name: tensorflow, version: v1.0}



Next, we get basic lineage (see EXAMPLE 6-6).","모델 목록



신분증
작업 공간
운영
create_time
기술
모델 _ 유형




0
2
ws1
run-2020-01-10T22 : 13 : 20.959882
2020-01-10T22 : 13 : 26.324443Z
손으로 쓴 숫자를 인식하는 모델
신경망






이름
소유자
버전
uri
training_framework




MNIST
someone@kubeflow.org
v0.0.1
gcs : // my-bucket / mnist
{이름 : tensorflow, 버전 : v1.0}



다음으로 기본 계보를 얻습니다 (예제 6-6 참조).",,
1464,"In our case we created a single model, so the returned lineage will contain only the ID of this model.",우리의 경우 단일 모델을 만들었으므로 반환 된 계보에는이 모델의 ID 만 포함됩니다.,,
1465,Example 6-6.,예 6-6.,,
1466,"Basic lineage
print(""model id is "" + model.id) 


Returns model id is 2.","기본 계보
print ( ""모델 ID는""+ model.id)


모델 ID가 2를 반환합니다.",,
1467,Then we find the execution that produces this model.,그런 다음이 모델을 생성하는 실행을 찾습니다.,,
1468,In our toy application we created a single execution.,장난감 애플리케이션에서 단일 실행을 생성했습니다.,,
1469,"An ID of this execution is returned as a result of this query, as shown in EXAMPLE 6-7.",이 쿼리의 결과로이 실행의 ID가 반환됩니다 (예제 6-7 참조).,,
1470,Example 6-7.,예 6-7.,,
1471,"Find the execution
output_events = ws1.client.list_events2(model.id).events
execution_id = output_events[0].execution_id
print(execution_id) 


Returns 1.","실행 찾기
output_events = ws1.client.list_events2 (model.id) .events
execution_id = output_events [0] .execution_id
print (실행 _ID)


1을 반환합니다.",,
1472,"Finally, we find all events related to that execution, as illustrated in EXAMPLE 6-8.",마지막으로 예제 6-8에 설명 된대로 해당 실행과 관련된 모든 이벤트를 찾습니다.,,
1473,Example 6-8.,예 6-8.,,
1474,"Getting all related events
all_events = ws1.client.list_events(execution_id).events
assert len(all_events) == 3
print(""\nAll events related to this model:"")
pandas.DataFrame.from_dict([e.to_dict() for e in all_events])
In our case we used a single input that was used to create a model and metrics.","모든 관련 이벤트 가져 오기
all_events = ws1.client.list_events (execution_id) .events
len (all_events) == 3 주장
print ( ""\ n이 모델과 관련된 모든 이벤트 :"")
pandas.DataFrame.from_dict ([e.to_dict () for e in all_events])
우리의 경우 모델과 메트릭을 만드는 데 사용 된 단일 입력을 사용했습니다.",,
1475,So the result of this query looks as shown in TABLE 6-2.,따라서이 쿼리의 결과는 표 6-2와 같습니다.,,
1476,Table 6-2.,표 6-2.,,
1477,"Query result as a table



artifact_id
execution_id
path
type
milliseconds_since_epoch




0
1
1
None
INPUT
1578694406318


1
2
1
None
OUTPUT
1578694406338


2
3
1
None
OUTPUT
1578694406358





6.1.2.","테이블로 결과 쿼리



artifact_id
execution_id
통로
유형
milliseconds_since_epoch




0
1
1
없음
입력
1578694406318


1
2
1
없음
산출
1578694406338


2
삼
1
없음
산출
1578694406358





6.1.2.",,
1478,"Kubeflow Metadata UI
In addition to providing APIs for writing code to analyze metadata, the Kubeflow Metadata tool provides a UI, which allows you to view metadata without writing code.","Kubeflow 메타 데이터 UI
Kubeflow 메타 데이터 도구는 메타 데이터를 분석하기위한 코드 작성 용 API를 제공하는 것 외에도 코드를 작성하지 않고도 메타 데이터를 볼 수있는 UI를 제공합니다.",,
1479,"Access to the Metadata UI is done through the main Kubeflow UI, as seen in FIGURE 6-1.",메타 데이터 UI에 대한 액세스는 그림 6-1과 같이 기본 Kubeflow UI를 통해 수행됩니다.,,
1480,Figure 6-1.,그림 6-1.,,
1481,"Accessing Metadata UI

Once you click the Artifact Store, you should see the list of available artifacts (logged metadata events), as in FIGURE 6-2.","메타 데이터 UI 액세스

아티팩트 저장소를 클릭하면 그림 6-2에서와 같이 사용 가능한 아티팩트 (기록 된 메타 데이터 이벤트) 목록이 표시됩니다.",,
1482,Figure 6-2.,그림 6-2.,,
1483,"List of artifacts in the Artifact Store UI

From this view we can click the individual artifact and see its details, as shown in FIGURE 6-3.","아티팩트 저장소 UI의 아티팩트 목록

이보기에서 그림 6-3과 같이 개별 아티팩트를 클릭하고 세부 정보를 볼 수 있습니다.",,
1484,Figure 6-3.,그림 6-3.,,
1485,"Artifact view

Kubeflow Metadata provides some basic capabilities for storing and viewing of machine learning metadata; however, its capabilities are extremely limited, especially in terms of viewing and manipulating stored metadata.","아티팩트보기

Kubeflow 메타 데이터는 기계 학습 메타 데이터를 저장하고보기위한 몇 가지 기본 기능을 제공합니다.그러나 그 기능은 특히 저장된 메타 데이터를보고 조작하는 측면에서 매우 제한적입니다.",,
1486,A more powerful implementation of machine learning metadata management is done by MLflow.,머신 러닝 메타 데이터 관리의보다 강력한 구현은 MLflow에 의해 수행됩니다.,,
1487,"Though MLflow isn’t part of Kubeflow distribution, it’s very easy to deploy it alongside Kubeflow and use it from Kubeflow-based applications, as described in the next section.",MLflow는 Kubeflow 배포의 일부가 아니지만 다음 섹션에 설명 된대로 Kubeflow와 함께 배포하고 Kubeflow 기반 애플리케이션에서 사용하는 것은 매우 쉽습니다.,,
1488,6.2.,6.2.,,
1489,"Using MLflow’s Metadata Tools with Kubeflow
MLflow is an open source platform for managing the end-to-end machine learning life cycle.","Kubeflow와 함께 MLflow의 메타 데이터 도구 사용
MLflow는 종단 간 기계 학습 수명주기를 관리하기위한 오픈 소스 플랫폼입니다.",,
1490,"It includes three primary functions:

MLflow Tracking

Tracking experiments to record and compare parameters and results

MLflow Projects

Packaging ML code in a reusable, reproducible form in order to share with other data scientists or transfer to production

MLflow Models

Managing and deploying models from a variety of ML libraries to a variety of model serving and inference platforms


For the purposes of our Kubeflow metadata discussion we will only discuss deployment and usage of MLflow tracking components—an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for visualizing the results.","여기에는 세 가지 주요 기능이 포함됩니다.

MLflow 추적

매개 변수와 결과를 기록하고 비교하기위한 실험 추적

MLflow 프로젝트

다른 데이터 과학자와 공유하거나 프로덕션으로 이전하기 위해 재사용 가능하고 재현 가능한 형식으로 ML 코드 패키징

MLflow 모델

다양한 ML 라이브러리에서 다양한 모델 제공 및 추론 플랫폼으로 모델 관리 및 배포


Kubeflow 메타 데이터 논의를 위해 머신 러닝 코드를 실행하고 결과를 시각화 할 때 매개 변수, 코드 버전, 메트릭 및 출력 파일을 로깅하기위한 API 및 UI 인 MLflow 추적 구성 요소의 배포 및 사용에 대해서만 논의합니다.",,
1491,"MLflow Tracking lets you log and query experiments using Python, REST, R, and Java APIs, which significantly extends the reach of APIs, allowing you to store and access metadata from different ML 
components.","MLflow 추적을 사용하면 Python, REST, R 및 Java API를 사용하여 실험을 기록하고 쿼리 할 수 있습니다.이 API는 API의 범위를 크게 확장하여 다양한 ML의 메타 데이터를 저장하고 액세스 할 수 있습니다.
구성 요소.",,
1492,"MLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code.",MLflow 추적은 데이터 과학 코드의 일부를 실행하는 실행 개념을 중심으로 구성됩니다.,,
1493,"Each run records the following information:

Code version

Git commit hash used for the run, if it was run from an MLflow Project

Start and end time

Start and end time of the run

Source

Name of the file to launch the run, or the project name and entry point for the run if run from an MLflow Project

Parameters

Key-value input parameters of your choice.","각 실행은 다음 정보를 기록합니다.

코드 버전

MLflow 프로젝트에서 실행 된 경우 실행에 사용 된 Git 커밋 해시

시작 및 종료 시간

실행 시작 및 종료 시간

출처

실행을 시작할 파일의 이름 또는 MLflow 프로젝트에서 실행하는 경우 실행을위한 프로젝트 이름 및 진입 점

매개 변수

선택한 키-값 입력 매개 변수입니다.",,
1494,Both keys and values are strings.,키와 값은 모두 문자열입니다.,,
1495,"Metrics

Key-value metrics, where the value is numeric.","메트릭

값이 숫자 인 키-값 측정 항목입니다.",,
1496,"Each metric can be updated throughout the course of the run (for example, to track how your model’s loss function is converging), and MLflow records and lets you visualize the metric’s full history.",각 측정 항목은 실행 과정에서 업데이트 될 수 있으며 (예 : 모델의 손실 함수가 수렴되는 방식을 추적하기 위해) MLflow가 측정 항목의 전체 기록을 기록하고 시각화 할 수 있습니다.,,
1497,"Artifacts

Output files in any format.","아티팩트

모든 형식의 출력 파일.",,
1498,"Here you can record images (such as PNG files), models (for example, a pickled Scikit-learn model), and data files (for example, a Parquet file) as artifacts.","여기에서 이미지 (예 : PNG 파일), 모델 (예 : 절인 Scikit-learn 모델) 및 데이터 파일 (예 : Parquet 파일)을 아티팩트로 기록 할 수 있습니다.",,
1499,"Most of the MLflow examples use local MLflow installations, which is not appropriate for our purposes.",대부분의 MLflow 예제는 로컬 MLflow 설치를 사용하며 이는 우리의 목적에 적합하지 않습니다.,,
1500,"For our implementation we need a cluster-based installation, allowing us to write metadata from different Docker instances and view them centrally.",구현을 위해 클러스터 기반 설치가 필요하므로 다른 Docker 인스턴스에서 메타 데이터를 작성하고 중앙에서 볼 수 있습니다.,,
1501,"Following the approach outlined in the project MLflow Tracking Server based on Docker and AWS S3, the overall architecture of such MLflow Tracking component deployment is presented in FIGURE 6-4.",Docker 및 AWS S3를 기반으로하는 MLflow 추적 서버 프로젝트에 설명 된 접근 방식에 따라 이러한 MLflow 추적 구성 요소 배포의 전체 아키텍처가 그림 6-4에 나와 있습니다.,,
1502,Figure 6-4.,그림 6-4.,,
1503,"Overall architecture of MLflow components deployment

The main components of this architecture are:


MinIO server, already part of the Kubeflow installation


MLflow tracking server—the MLflow UI component—an additional component that needs to be added to Kubeflow installation to support MLflow usage


User code such as notebook, Python, R, or Java application



6.2.1.","MLflow 구성 요소 배포의 전체 아키텍처

이 아키텍처의 주요 구성 요소는 다음과 같습니다.


이미 Kubeflow 설치의 일부인 MinIO 서버


MLflow 사용을 지원하기 위해 Kubeflow 설치에 추가해야하는 추가 구성 요소 인 MLflow UI 구성 요소 인 MLflow 추적 서버


노트북, Python, R 또는 Java 애플리케이션과 같은 사용자 코드



6.2.1.",,
1504,"Creating and Deploying an MLflow Tracking Server
MLflow Tracking Server allows you to record MLflow runs to local files, to a SQLAlchemy-compatible database, or remotely to a tracking server.","MLflow 추적 서버 생성 및 배포
MLflow 추적 서버를 사용하면 MLflow 실행을 로컬 파일, SQLAlchemy 호환 데이터베이스 또는 추적 서버에 원격으로 기록 할 수 있습니다.",,
1505,In our implementation we are using a remote server.,구현에서 우리는 원격 서버를 사용하고 있습니다.,,
1506,An MLflow Tracking Server has two components for storage: a backend store and an artifact store.,MLflow 추적 서버에는 백엔드 저장소와 아티팩트 저장소의 두 가지 저장소 구성 요소가 있습니다.,,
1507,"The backend store is where MLflow Tracking Server stores experiment and run metadata as well as parameters, metrics, and tags for runs.","백엔드 저장소는 MLflow 추적 서버가 실험 및 실행 메타 데이터와 실행에 대한 매개 변수, 메트릭 및 태그를 저장하는 곳입니다.",,
1508,MLflow supports two types of backend stores: file store and database-backed store.,MLflow는 파일 저장소 및 데이터베이스 지원 저장소의 두 가지 유형의 백엔드 저장소를 지원합니다.,,
1509,For simplicity we will be using a file store.,간단히하기 위해 파일 저장소를 사용합니다.,,
1510,"In our deployment, this file store is part of the Docker image, which means that this data is lost in the case of server restart.",배포에서이 파일 저장소는 Docker 이미지의 일부이므로 서버를 다시 시작하면이 데이터가 손실됩니다.,,
1511,"If you need longer-term storage, you can either use an external filesystem, like NFS server, or a database.",장기 스토리지가 필요한 경우 NFS 서버와 같은 외부 파일 시스템이나 데이터베이스를 사용할 수 있습니다.,,
1512,"The artifact store is a location suitable for large data (such as an S3 bucket or shared NFS filesystem) and is where clients log their artifact output (for example, models).",아티팩트 저장소는 대용량 데이터 (예 : S3 버킷 또는 공유 NFS 파일 시스템)에 적합한 위치이며 클라이언트가 아티팩트 출력 (예 : 모델)을 기록하는 위치입니다.,,
1513,"To make our deployment cloud independent, we decided to use MinIO (part of Kubeflow) as an artifact store.",배포 클라우드를 독립적으로 만들기 위해 우리는 MinIO (Kubflow의 일부)를 아티팩트 저장소로 사용하기로 결정했습니다.,,
1514,"Based on these decisions, a Docker file for building the MLflow Tracking Server looks like EXAMPLE 6-9 (similar to the implementation in this GitHub repo).",이러한 결정에 따라 MLflow 추적 서버를 빌드하기위한 Docker 파일은 예 6-9와 같습니다 (이 GitHub 저장소의 구현과 유사).,,
1515,Example 6-9.,예 6-9.,,
1516,"MLflow Tracking Server
FROM python:3.7

RUN pip3 install --upgrade pip && \
   pip3 install mlflow --upgrade && \
   pip3 install awscli --upgrade  && \
   pip3 install boto3 --upgrade

ENV PORT 5000
ENV AWS_BUCKET bucket
ENV AWS_ACCESS_KEY_ID aws_id
ENV AWS_SECRET_ACCESS_KEY aws_key
ENV FILE_DIR /tmp/mlflow

RUN mkdir -p /opt/mlflow
COPY run.sh /opt/mlflow
RUN chmod -R 777 /opt/mlflow/

ENTRYPOINT [""/opt/mlflow/run.sh""]
Here we first load MLflow code (using pip), set environment variables, and then copy and run the startup script.","MLflow 추적 서버
파이썬에서 : 3.7

실행 pip3 설치 --upgrade pip && \
   pip3 설치 mlflow-업그레이드 && \
   pip3 install awscli --upgrade && \
   pip3 설치 boto3-업그레이드

ENV 포트 5000
ENV AWS_BUCKET 버킷
ENV AWS_ACCESS_KEY_ID aws_id
ENV AWS_SECRET_ACCESS_KEY aws_key
ENV FILE_DIR / tmp / mlflow

mkdir -p / opt / mlflow 실행
run.sh / opt / mlflow 복사
chmod -R 777 / opt / mlflow / 실행

ENTRYPOINT [ ""/opt/mlflow/run.sh""]
여기서는 먼저 MLflow 코드 (pip 사용)를로드하고 환경 변수를 설정 한 다음 시작 스크립트를 복사하고 실행합니다.",,
1517,The start-up script used here looks like EXAMPLE 6-10.,여기에 사용 된 시작 스크립트는 예 6-10과 같습니다.,,
1518,"[6]

Example 6-10.","[6]

예 6-10.",,
1519,"MLflow startup script
#!/bin/sh
mkdir -p $FILE_DIR

mlflow server \
   --backend-store-uri file://$FILE_DIR \
   --default-artifact-root s3://$AWS_BUCKET/mlflow/artifacts \
   --host 0.0.0.0 \
   --port $PORT
This script sets an environment and then verifies that all required environment variables are set.","MLflow 시작 스크립트
#! / bin / sh
mkdir -p $ FILE_DIR

mlflow 서버 \
   --backend-store-uri 파일 : // $ FILE_DIR \
   --default-artifact-root s3 : // $ AWS_BUCKET / mlflow / artifacts \
   --host 0.0.0.0 \
   --port $ PORT
이 스크립트는 환경을 설정 한 다음 모든 필수 환경 변수가 설정되었는지 확인합니다.",,
1520,"Once validation succeeds, an MLflow server is started.",유효성 검사가 성공하면 MLflow 서버가 시작됩니다.,,
1521,"Once the Docker is created, the Helm command in EXAMPLE 6-11 (the Helm chart is located on this book’s GitHub repo) can be used to install the server.",Docker가 생성되면 예 6-11의 Helm 명령 (헬름 차트는이 책의 GitHub 저장소에 있음)을 사용하여 서버를 설치할 수 있습니다.,,
1522,Example 6-11.,예 6-11.,,
1523,"Installing MLflow server with Helm
helm install <location of the Helm chart>
This Helm chart installs three main components implementing the MLflow Tracking Server:

Deployment

Deploying MLflow server itself (single replica).","Helm으로 MLflow 서버 설치
helm install <헬름 차트 위치>
이 Helm 차트는 MLflow 추적 서버를 구현하는 세 가지 주요 구성 요소를 설치합니다.

전개

MLflow 서버 자체 배포 (단일 복제본).",,
1524,"The important parameters here are the environment, including MinIO endpoint, credentials, and bucket used for artifact storage.","여기서 중요한 매개 변수는 MinIO 엔드 포인트, 자격 증명 및 아티팩트 스토리지에 사용되는 버킷을 포함한 환경입니다.",,
1525,"Service

Creating a Kubernetes service exposing MLflow deployment

Virtual service

Exposing MLflow service to users through the Istio ingress gateway used by Kubeflow


Once the server is deployed, we can get access to the UI, but at this point it will say that there are no available experiments.","서비스

MLflow 배포를 노출하는 Kubernetes 서비스 만들기

가상 서비스

Kubeflow에서 사용하는 Istio 인 그레스 게이트웨이를 통해 사용자에게 MLflow 서비스 노출


서버가 배포되면 UI에 액세스 할 수 있지만이 시점에서 사용 가능한 실험이 없다고 표시됩니다.",,
1526,Let’s now look at how this server can be used to capture metadata.,이제이 서버를 사용하여 메타 데이터를 캡처하는 방법을 살펴 보겠습니다.,,
1527,"[7]


6.2.2.","[7]


6.2.2.",,
1528,"Logging Data on Runs
As an example of logging data, let’s look at some simple code.","실행시 데이터 로깅
데이터 로깅의 예로 몇 가지 간단한 코드를 살펴 보겠습니다.",,
1529,"[8] We will start by installing required packages, shown in Examples EXAMPLE 6-11 and EXAMPLE 6-12.",[8] 예제 예제 6-11 및 예제 6-12에 표시된 필수 패키지를 설치하는 것으로 시작합니다.,,
1530,Example 6-12.,예 6-12.,,
1531,"Install required
!pip install pandas --upgrade --user
!pip install mlflow --upgrade --user 
!pip install joblib --upgrade --user
!pip install numpy --upgrade --user
!pip install scipy --upgrade --user
!pip install scikit-learn --upgrade --user
!pip install boto3 --upgrade --user 


Here mlflow and boto3 are the packages required for metadata logging, while the rest are used for machine learning itself.","설치 필요
! pip install pandas --upgrade --user
! pip install mlflow --upgrade --user
! pip install joblib --upgrade --user
! pip install numpy --upgrade --user
! pip install scipy --upgrade --user
! pip install scikit-learn --upgrade --user
! pip install boto3 --upgrade --user


여기서 mlflow 및 boto3는 메타 데이터 로깅에 필요한 패키지이고 나머지는 기계 학습 자체에 사용됩니다.",,
1532,"Once these packages are installed, we can define required imports, as shown in EXAMPLE 6-13.",이러한 패키지가 설치되면 예제 6-13에 표시된대로 필수 가져 오기를 정의 할 수 있습니다.,,
1533,Example 6-13.,예 6-13.,,
1534,"Import required libraries
import time
import json
import os
from joblib import Parallel, delayed

import pandas as pd
import numpy as np
import scipy

from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.metrics import r2_score, explained_variance_score
from sklearn.exceptions import ConvergenceWarning

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from warnings import simplefilter
simplefilter(action='ignore', category = FutureWarning)
simplefilter(action='ignore', category = ConvergenceWarning)
Here again, os and the last three imports are required for MLflow logging, while the rest are used for machine learning.","필수 라이브러리 가져 오기
수입 시간
json 가져 오기
수입 OS
joblib에서 가져 오기 병렬, 지연됨

팬더를 pd로 가져 오기
numpy를 np로 가져 오기
수입 scipy

sklearn.model_selection에서 import train_test_split, KFold
sklearn.metrics에서 import mean_squared_error, mean_absolute_error
sklearn.metrics에서 가져 오기 r2_score, explain_variance_score
sklearn.exceptions에서 가져 오기 ConvergenceWarning

mlflow 가져 오기
mlflow.sklearn 가져 오기
mlflow.tracking import MlflowClient에서

경고에서 가져 오기 simplefilter
simplefilter (action = 'ignore', category = FutureWarning)
simplefilter (action = 'ignore', category = ConvergenceWarning)
여기서도 OS와 마지막 세 개의 가져 오기는 MLflow 로깅에 필요하고 나머지는 기계 학습에 사용됩니다.",,
1535,"Now we need to define the environment variables (see EXAMPLE 6-14) required for proper access to the MinIO server for storing 
artifacts.","이제 저장을 위해 MinIO 서버에 올바르게 액세스하는 데 필요한 환경 변수 (예 6-14 참조)를 정의해야합니다.
인공물.",,
1536,Example 6-14.,예 6-14.,,
1537,"Set environment variables
os.environ['MLFLOW_S3_ENDPOINT_URL'] = \
     'http://minio-service.kubeflow.svc.cluster.local:9000'
os.environ['AWS_ACCESS_KEY_ID'] = 'minio'
os.environ['AWS_SECRET_ACCESS_KEY'] = 'minio123'
Note here that in addition to the tracking server itself, MLFLOW_S3_ENDPOINT_URL is defined not only in the tracking server definition, but also in the code that actually captures the metadata.","환경 변수 설정
os.environ [ 'MLFLOW_S3_ENDPOINT_URL'] = \
     'http : //minio-service.kubeflow.svc.cluster.local : 9000'
os.environ [ 'AWS_ACCESS_KEY_ID'] = 'minio'
os.environ [ 'AWS_SECRET_ACCESS_KEY'] = 'minio123'
여기서 추적 서버 자체 외에도 MLFLOW_S3_ENDPOINT_URL은 추적 서버 정의뿐 아니라 실제로 메타 데이터를 캡처하는 코드에서도 정의됩니다.",,
1538,"This is because, as we mentioned previously, user code writes to the artifact store directly, bypassing the server.",이전에 언급했듯이 사용자 코드가 서버를 우회하여 아티팩트 저장소에 직접 작성하기 때문입니다.,,
1539,Here we skip the majority of the code (the full code can be found on this book’s GitHub repo) and concentrate only on the parts related to the MLflow logging.,여기서는 대부분의 코드를 건너 뛰고 (전체 코드는이 책의 GitHub 저장소에서 찾을 수 있음) MLflow 로깅과 관련된 부분에만 집중합니다.,,
1540,"The next step (see EXAMPLE 6-15) is connecting to the tracking server and creating an 
experiment.","다음 단계 (예 6-15 참조)는 추적 서버에 연결하고
실험.",,
1541,Example 6-15.,예 6-15.,,
1542,"Create experiment
remote_server_uri = ""http://mlflowserver.kubeflow.svc.cluster.local:5000""
mlflow.set_tracking_uri(remote_server_uri)
experiment_name = ""electricityconsumption-forecast""
mlflow.set_experiment(experiment_name)
Once connected to the server and creating (choosing) an experiment, we can start logging data.","실험 만들기
remote_server_uri = ""http : //mlflowserver.kubeflow.svc.cluster.local : 5000""
mlflow.set_tracking_uri (remote_server_uri)
experiment_name = ""전기 소비 예측""
mlflow.set_experiment (experiment_name)
서버에 연결하고 실험을 생성 (선택)하면 데이터 로깅을 시작할 수 있습니다.",,
1543,"As an example, let’s look at the code for storing
KNN regressor information, in EXAMPLE 6-16.","예를 들어 저장 코드를 살펴 보겠습니다.
KNN 회귀 자 정보 (예 6-16).",,
1544,Example 6-16.,예 6-16.,,
1545,"Sample KNN model
def train_knnmodel(parameters, inputs, tags, log = False):
    with mlflow.start_run(nested = True):

……………………………………………….","샘플 KNN 모델
def train_knnmodel (매개 변수, 입력, 태그, 로그 = False) :
    mlflow.start_run (nested = True) 사용 :

……………………………………………….",,
1546,"# Build the model
        tic = time.time()
        model = KNeighborsRegressor(parameters[""nbr_neighbors""],
                                weights = parameters[""weight_method""])
        model.fit(array_inputs_train, array_output_train)
        duration_training = time.time() - tic

        # Make the prediction
        tic1 = time.time()
        prediction = model.predict(array_inputs_test)
        duration_prediction = time.time() - tic1

        # Evaluate the model prediction
        metrics = evaluation_model(array_output_test, prediction)

        # Log in mlflow (parameter)
        mlflow.log_params(parameters)

        # Log in mlflow (metrics)
        metrics[""duration_training""] = duration_training
        metrics[""duration_prediction""] = duration_prediction
        mlflow.log_metrics(metrics)

        # Log in mlflow (model)
        mlflow.sklearn.log_model(model, f""model"")

        # Save model
        #mlflow.sklearn.save_model(model,
                         f""mlruns/1/{uri}/artifacts/model/sklearnmodel"")

        # Tag the model
        mlflow.set_tags(tags)
In this code snippet, we can see how different kinds of data about model creation and prediction test statistics are logged.","# 모델 구축
        tic = time.time ()
        모델 = KNeighborsRegressor (parameters [ ""nbr_neighbors""],
                                가중치 = 매개 변수 [ ""weight_method""])
        model.fit (배열 _ 입력 _ 기차, 배열 _ 출력 _ 기차)
        duration_training = time.time ()-틱

        # 예측하기
        tic1 = time.time ()
        예측 = model.predict (array_inputs_test)
        duration_prediction = time.time ()-tic1

        # 모델 예측 평가
        메트릭 = evaluation_model (array_output_test, 예측)

        # mlflow (매개 변수)에 로그인합니다.
        mlflow.log_params (매개 변수)

        # mlflow (메트릭)에 로그인합니다.
        메트릭 [ ""duration_training""] = duration_training
        메트릭 [ ""duration_prediction""] = duration_prediction
        mlflow.log_metrics (메트릭)

        # mlflow (모델)에 로그인합니다.
        mlflow.sklearn.log_model (모델, f ""모델"")

        # 모델 저장
        # mlflow.sklearn.save_model (model,
                         f ""mlruns / 1 / {uri} / artifacts / model / sklearnmodel"")

        # 모델에 태그 지정
        mlflow.set_tags (태그)
이 코드 스 니펫에서 모델 생성 및 예측 테스트 통계에 대한 다양한 종류의 데이터가 기록되는 방식을 볼 수 있습니다.",,
1547,"The information here is very similar to the information captured by Kubeflow Metadata and includes inputs, models, and metrics.","여기에있는 정보는 Kubeflow 메타 데이터에서 캡처 한 정보와 매우 유사하며 입력, 모델 및 메트릭을 포함합니다.",,
1548,"Finally, similar to Kubeflow Metadata, MLflow allows you to access this metadata programmatically.",마지막으로 Kubeflow 메타 데이터와 유사하게 MLflow를 사용하면이 메타 데이터에 프로그래밍 방식으로 액세스 할 수 있습니다.,,
1549,The main APIs provided by MLflow include what you see in EXAMPLE 6-17.,MLflow에서 제공하는 주요 API에는 예 6-17에 표시된 내용이 포함됩니다.,,
1550,Example 6-17.,예 6-17.,,
1551,"Getting the runs for a given experiment
df_runs = mlflow.search_runs(experiment_ids=""0"") 
print(""Number of runs done : "", len(df_runs))

df_runs.sort_values([""metrics.rmse""], ascending = True, inplace = True) 
df_runs.head()


Getting the the runs for a given experiment

Sorting runs based on the specific parameters

MLflow will sort runs by root mean square error (rmse) and show the best ones.","주어진 실험에 대한 실행 얻기
df_runs = mlflow.search_runs (experiment_ids = ""0"")
print ( ""완료된 실행 횟수 :"", len (df_runs))

df_runs.sort_values ([ ""metrics.rmse""], 오름차순 = True, inplace = True)
df_runs.head ()


주어진 실험에 대한 실행 얻기

특정 매개 변수를 기준으로 실행 정렬

MLflow는 평균 제곱근 오차 (rmse)를 기준으로 실행을 정렬하고 최상의 결과를 표시합니다.",,
1552,"For additional capabilities of the programmatic runs querying, consult the MLflow documentation.",프로그래밍 방식 실행 쿼리의 추가 기능은 MLflow 문서를 참조하세요.,,
1553,"With all the capabilities of running programmatic queries, the most powerful way to evaluate runs’ metadata is through the MLflow UI, which we will cover next.",프로 그래 매틱 쿼리를 실행하는 모든 기능을 갖춘 실행의 메타 데이터를 평가하는 가장 강력한 방법은 MLflow UI를 사용하는 것입니다. 다음에 다룰 것입니다.,,
1554,6.2.3.,6.2.3.,,
1555,"Using the MLflow UI
The Tracking UI in MLflow lets you visualize, search, and compare runs, as well as download run artifacts or metadata for analysis in other tools.","MLflow UI 사용
MLflow의 추적 UI를 사용하면 실행을 시각화, 검색 및 비교할 수있을뿐만 아니라 다른 도구에서 분석 할 실행 아티팩트 또는 메타 데이터를 다운로드 할 수 있습니다.",,
1556,"Because MLflow is not part of Kubeflow, its access is not provided by Kubeflow UI.",MLflow는 Kubeflow의 일부가 아니기 때문에 Kubeflow UI에서 액세스를 제공하지 않습니다.,,
1557,"Based on the provided virtual service, the MLflow UI is available at <Kubeflow Istio ingress gateway URL>/mlflow.",제공된 가상 서비스를 기반으로 MLflow UI는 <Kubeflow Istio 인 그레스 게이트웨이 URL> / mlflow에서 사용할 수 있습니다.,,
1558,FIGURE 6-5 shows the results produced by the run described.,그림 6-5는 설명 된 실행으로 생성 된 결과를 보여줍니다.,,
1559,It is possible to filter results using the search box.,검색 창을 사용하여 결과를 필터링 할 수 있습니다.,,
1560,"For example, if we want to see only results for the KNN model, then the search criteria tags.model=""knn"" can be used.","예를 들어 KNN 모델에 대한 결과 만 보려면 검색 기준 인 tags.model = ""knn""을 사용할 수 있습니다.",,
1561,"You can also use more complex filters, such as tags.model=""knn"" and metrics.duration_prediction < 0.002, which will return results for the KNN model for which prediction duration is less than 0.002 sec.","또한 tags.model = ""knn""및 metrics.duration_prediction <0.002와 같은 더 복잡한 필터를 사용하여 예측 기간이 0.002 초 미만인 KNN 모델에 대한 결과를 반환 할 수 있습니다.",,
1562,Figure 6-5.,그림 6-5.,,
1563,"MLflow main page

By clicking the individual run we can see its details, as shown in FIGURE 6-6.","MLflow 메인 페이지

개별 실행을 클릭하면 그림 6-6과 같이 세부 정보를 볼 수 있습니다.",,
1564,Figure 6-6.,그림 6-6.,,
1565,"View of the individual run

Alternatively, we can compare several runs by picking them and clicking compare, as seen in FIGURE 6-7.","개별 실행보기

또는 그림 6-7과 같이 여러 실행을 선택하고 비교를 클릭하여 비교할 수 있습니다.",,
1566,Figure 6-7.,그림 6-7.,,
1567,"Run comparison view

We can also view metrics comparison for multiple runs, as in FIGURE 6-8.","비교보기 실행

그림 6-8과 같이 여러 실행에 대한 메트릭 비교도 볼 수 있습니다.",,
1568,"[9]


Figure 6-8.","[9]


그림 6-8.",,
1569,"Run metrics comparison view




6.3.","메트릭 비교보기 실행




6.3.",,
1570,"Conclusion
In this chapter we have shown how the Kubeflow Metadata component of the Kubeflow deployment supports storing and viewing ML metadata.","결론
이 장에서는 Kubeflow 배포의 Kubeflow 메타 데이터 구성 요소가 ML 메타 데이터 저장 및보기를 지원하는 방법을 보여주었습니다.",,
1571,"We have also discussed shortcomings of this implementation, including its Python-only support and weak UI.",또한 Python 전용 지원 및 취약한 UI를 포함하여이 구현의 단점에 대해서도 논의했습니다.,,
1572,"Last, we covered how to supplement Kubeflow with components with similar functionality—MLflow and additional capabilities that can be achieved in this case.",마지막으로 유사한 기능 (MLflow 및이 경우 달성 할 수있는 추가 기능)을 가진 구성 요소로 Kubeflow를 보완하는 방법에 대해 설명했습니다.,,
1573,"In CHAPTER 7, we explore using Kubeflow with TensorFlow to train and serve models.",7 장에서는 TensorFlow와 함께 Kubeflow를 사용하여 모델을 학습시키고 제공하는 방법을 살펴 봅니다.,,
1574,"[1] For a good background on metadata for machine learning, and an overview of what to capture refer to this blog post written by Luigi Patruno.",[1] 기계 학습을위한 메타 데이터에 대한 배경 지식과 캡처 대상에 대한 개요는 Luigi Patruno가 작성한이 블로그 게시물을 참조하십시오.,,
1575,"[2] For more on this topic, see this blog post by Jennifer Villa and Yoav Zimmerman.",[2]이 주제에 대한 자세한 내용은 Jennifer Villa와 Yoav Zimmerman의 블로그 게시물을 참조하십시오.,,
1576,"[3] Note that Kubeflow ML Metadata is different from ML Metadata, which is part of TFX.",[3] Kubeflow ML 메타 데이터는 TFX의 일부인 ML 메타 데이터와 다릅니다.,,
1577,[4] MLflow was initially developed by Databricks and currently is part of the Linux Foundation.,[4] MLflow는 처음에 Databricks에서 개발했으며 현재 Linux Foundation의 일부입니다.,,
1578,[5] The complete code for this notebook is located in this book’s GitHub repo.,[5]이 노트북의 전체 코드는이 책의 GitHub 저장소에 있습니다.,,
1579,[6] This is a simplified implementation.,[6] 이것은 단순화 된 구현입니다.,,
1580,"For complete implementation, see this book’s GitHub repo.",전체 구현은이 책의 GitHub 저장소를 참조하세요.,,
1581,[7] Here we are showing usage of Python APIs.,[7] 다음은 Python API의 사용법을 보여줍니다.,,
1582,"For additional APIs (R, Java, REST) refer to the MLflow documentation.","추가 API (R, Java, REST)는 MLflow 문서를 참조하세요.",,
1583,[8] The code here is adapted from this article by Jean-Michel Daignan.,[8] 여기에있는 코드는 Jean-Michel Daignan이이 기사에서 채택한 것입니다.,,
1584,[9] Also see the MLflow documentation for additional UI capabilities.,[9] 추가 UI 기능은 MLflow 문서도 참조하세요.,,
1585,Chapter 7.,7 장.,,
1586,"Training a Machine Learning Model
In CHAPTER 5, we learned how to prepare and clean up our data, which is the first step in the machine learning pipeline.","기계 학습 모델 훈련
5 장에서는 머신 러닝 파이프 라인의 첫 번째 단계 인 데이터를 준비하고 정리하는 방법을 배웠습니다.",,
1587,Now let’s take a deep dive into how to use our data to train a machine learning model.,이제 데이터를 사용하여 기계 학습 모델을 학습시키는 방법에 대해 자세히 알아 보겠습니다.,,
1588,Training is often considered the “bulk” of the work in machine learning.,"훈련은 종종 기계 학습 작업의 ""대량""으로 간주됩니다.",,
1589,Our goal is to create a function (the “model”) that can accurately predict results that it hasn’t seen before.,우리의 목표는 이전에 보지 못했던 결과를 정확하게 예측할 수있는 함수 ( '모델')를 만드는 것입니다.,,
1590,"Intuitively, model training is very much like how humans learn a new skill—we observe, practice, correct our mistakes, and gradually improve.","직관적으로 모델 교육은 인간이 새로운 기술을 배우는 방식과 매우 유사합니다. 우리는 실수를 관찰하고, 연습하고, 수정하고, 점진적으로 개선합니다.",,
1591,"In machine learning, we start with an initial model that might not be very good at its job.",기계 학습에서 우리는 그 작업에 그다지 좋지 않을 수있는 초기 모델로 시작합니다.,,
1592,"We then put the model through a series of training steps, where training data is fed to the model.",그런 다음 일련의 학습 단계를 통해 모델을 배치하여 학습 데이터를 모델에 제공합니다.,,
1593,"At each training step, we compare the prediction results produced by our model with the true results, and see how well our model performed.",각 학습 단계에서 모델에서 생성 된 예측 결과를 실제 결과와 비교하고 모델이 얼마나 잘 수행되었는지 확인합니다.,,
1594,"We then tinker with the parameters to this model (for example, by changing how much weight is given to each feature) to attempt to improve the model’s accuracy.",그런 다음이 모델의 매개 변수를 수정하여 (예 : 각 기능에 부여되는 가중치를 변경하여) 모델의 정확도를 개선합니다.,,
1595,A good model is one that makes accurate predictions without overfitting to a specific set of inputs.,좋은 모델은 특정 입력 세트에 과적 합하지 않고 정확한 예측을하는 모델입니다.,,
1596,"In this chapter, we are going to learn how to train machine learning models using two different libraries—TensorFlow and Scikit-learn.",이 장에서는 TensorFlow와 Scikit-learn이라는 두 가지 라이브러리를 사용하여 기계 학습 모델을 학습시키는 방법을 알아 봅니다.,,
1597,"TensorFlow has native, first-class support in Kubeflow, while Scikit-learn does not.","TensorFlow는 Kubeflow에서 기본, 최고급 지원을 제공하지만 Scikit-learn은 지원하지 않습니다.",,
1598,"But as we will see in this chapter, both libraries can be easily integrated with Kubeflow.",그러나이 장에서 볼 수 있듯이 두 라이브러리는 Kubeflow와 쉽게 통합 될 수 있습니다.,,
1599,"We’ll demonstrate how you can experiment with models in Kubeflow’s notebooks, and how you can deploy these models to production environments.",Kubeflow 노트북에서 모델을 실험하는 방법과 이러한 모델을 프로덕션 환경에 배포하는 방법을 보여 드리겠습니다.,,
1600,7.1.,7.1.,,
1601,"Building a Recommender with TensorFlow
Let us first take a look at TensorFlow—an open source framework for machine learning developed by Google.","TensorFlow로 추천자 빌드
먼저 Google에서 개발 한 머신 러닝을위한 오픈 소스 프레임 워크 인 TensorFlow를 살펴 보겠습니다.",,
1602,"It is currently one of the most popular libraries for machine learning–powered applications, in particular for implementing deep learning.","현재 머신 러닝 기반 애플리케이션, 특히 딥 러닝 구현을위한 가장 인기있는 라이브러리 중 하나입니다.",,
1603,"TensorFlow has great support for computational tasks on a variety of hardware, including CPUs, GPUs, and TPUs.","TensorFlow는 CPU, GPU, TPU를 비롯한 다양한 하드웨어의 계산 작업을 크게 지원합니다.",,
1604,We chose TensorFlow for this tutorial because its high-level APIs are user-friendly and abstract away many of the gory details.,이 튜토리얼에서는 TensorFlow를 선택했습니다. 높은 수준의 API가 사용자 친화적이고 많은 세부 사항을 추상화하기 때문입니다.,,
1605,What Is Deep Learning?,딥 러닝이란?,,
1606,"In recent years, deep learning—a category of algorithms that leverage artificial neural networks to progressively extract higher-level features from input data—has become increasingly popular.",최근에는 인공 신경망을 활용하여 입력 데이터에서 더 높은 수준의 특징을 점진적으로 추출하는 알고리즘 범주 인 딥 러닝이 점점 인기를 얻고 있습니다.,,
1607,Deep learning has the ability to leverage hidden layers in the neural network to learn highly abstract models of the input.,딥 러닝은 신경망의 숨겨진 레이어를 활용하여 입력의 매우 추상적 인 모델을 학습 할 수 있습니다.,,
1608,"Deep learning algorithms can be found in many everyday applications, like image recognition and natural language processing.",딥 러닝 알고리즘은 이미지 인식 및 자연어 처리와 같은 많은 일상 응용 프로그램에서 찾을 수 있습니다.,,
1609,The multiple hidden layers of neural networks allow these algorithms to discover increasingly abstract details from data.,신경망의 여러 숨겨진 계층을 통해 이러한 알고리즘은 데이터에서 점점 더 추상적 인 세부 정보를 발견 할 수 있습니다.,,
1610,"For example, while the initial layer in an image classification neural network might discover only object edges, the deeper layer may learn more complex features and classify the objects in the images.",예를 들어 이미지 분류 신경망의 초기 계층은 객체 가장자리 만 발견 할 수 있지만 더 깊은 계층은 더 복잡한 특징을 학습하고 이미지의 객체를 분류 할 수 있습니다.,,
1611,Let’s get acquainted with TensorFlow with a simple tutorial.,간단한 튜토리얼을 통해 TensorFlow에 대해 알아 보겠습니다.,,
1612,"In CHAPTER 1 we introduced our case studies, one of which is a product recommendation system for customers.",CHAPTER 1에서는 고객을위한 제품 추천 시스템 인 사례 연구를 소개했습니다.,,
1613,"In this chapter, we will be implementing this system with TensorFlow.",이 장에서는 TensorFlow로이 시스템을 구현할 것입니다.,,
1614,"Specifically, we will do two things:


Use TensorFlow to train a model for product recommendation.","특히 다음 두 가지 작업을 수행합니다.


TensorFlow를 사용하여 제품 추천을위한 모델 학습.",,
1615,Use Kubeflow to wrap the training code and deploy it to a production cluster.,Kubeflow를 사용하여 교육 코드를 래핑하고 프로덕션 클러스터에 배포합니다.,,
1616,TensorFlow’s high-level Keras API makes it relatively easy to implement our model.,TensorFlow의 고수준 Keras API를 사용하면 모델을 비교적 쉽게 구현할 수 있습니다.,,
1617,"In fact, the bulk of the model can be implemented with less than 50 lines of Python code.",실제로 모델의 대부분은 50 줄 미만의 Python 코드로 구현할 수 있습니다.,,
1618,"Tip
Keras is the high-level TensorFlow API for deep learning models.","팁
Keras는 딥 러닝 모델을위한 고수준 TensorFlow API입니다.",,
1619,It has a user-friendly interface and high extensibility.,사용자 친화적 인 인터페이스와 높은 확장 성을 가지고 있습니다.,,
1620,"As an added bonus, Keras has many common neural network implementations straight out of the box, so you can get a model up and running right away.",추가 보너스로 Keras는 즉시 사용 가능한 많은 일반적인 신경망 구현을 제공하므로 모델을 즉시 실행하고 실행할 수 있습니다.,,
1621,Let’s begin by selecting a model for our recommender.,추천인의 모델을 선택하는 것부터 시작하겠습니다.,,
1622,"We begin with a simple assumption—that if two people (Alice and Bob) have similar opinions on a set of products, then they are also more likely to think similarly about other products.",우리는 간단한 가정으로 시작합니다. 두 사람 (Alice와 Bob)이 제품 세트에 대해 비슷한 의견을 갖고 있다면 다른 제품에 대해서도 비슷하게 생각할 가능성이 더 높습니다.,,
1623,"In other words, Alice is more likely to have the same preferences as Bob than would a randomly chosen third person.","즉, Alice는 무작위로 선택된 3 인칭보다 Bob과 동일한 선호도를 가질 가능성이 더 높습니다.",,
1624,"Thus, we can build a recommendation model using just the users’ purchase history.",따라서 사용자의 구매 내역만으로 추천 모델을 구축 할 수 있습니다.,,
1625,This is the idea of collaborative filtering—we collect preferential information from many users (hence “collaborative”) and use this data to make selective predictions (hence “filtering”).,"이것이 협업 필터링의 개념입니다. 우리는 많은 사용자로부터 우선적 인 정보를 수집하고 (따라서 ""협동"")이 데이터를 사용하여 선택적 예측 (따라서 ""필터링"")을 수행합니다.",,
1626,"To build this recommender model, we will need a few things:

Users’ purchasing history

We will use the example input data from this GitHub repo.","이 추천자 모델을 구축하려면 몇 가지가 필요합니다.

사용자의 구매 내역

이 GitHub 리포지토리의 예제 입력 데이터를 사용합니다.",,
1627,"Data storage

To make sure that our model works across different platforms, we’ll use MinIO as the storage system.","데이터 저장고

모델이 서로 다른 플랫폼에서 작동하는지 확인하기 위해 MinIO를 스토리지 시스템으로 사용합니다.",,
1628,"Training model

The implementation that we are using is based on a  Keras model on GitHub.","훈련 모델

우리가 사용하는 구현은 GitHub의 Keras 모델을 기반으로합니다.",,
1629,"We will first experiment with this model using Kubeflow’s notebook servers, and then deploy the training job to our cluster using Kubeflow’s TFJob APIs.",먼저 Kubeflow의 노트북 서버를 사용하여이 모델을 실험 한 다음 Kubeflow의 TFJob API를 사용하여 학습 작업을 클러스터에 배포합니다.,,
1630,7.1.1.,7.1.1.,,
1631,"Getting Started
Let’s get started by downloading the prerequisites.","시작하기
필수 구성 요소를 다운로드하여 시작하겠습니다.",,
1632,You can download the notebook from this book’s GitHub repo.,이 책의 GitHub 저장소에서 노트북을 다운로드 할 수 있습니다.,,
1633,"To run the notebook, you will need a running Kubeflow cluster that includes a MinIO service.",노트북을 실행하려면 MinIO 서비스를 포함하는 실행중인 Kubeflow 클러스터가 필요합니다.,,
1634,Review SECTION 3.2 to configure MinIO.,섹션 3.2를 검토하여 MinIO를 구성하십시오.,,
1635,Make sure that MinIO Client (“mc”) is also installed.,"MinIO 클라이언트 ( ""mc"")도 설치되어 있는지 확인하십시오.",,
1636,We also need to prepare the data to facilitate training: you can download the user purchase history data from this GitHub site.,또한 교육을 용이하게하기 위해 데이터를 준비해야합니다.이 GitHub 사이트에서 사용자 구매 내역 데이터를 다운로드 할 수 있습니다.,,
1637,"Then you can use MinIO Client to create the storage objects, as shown in EXAMPLE 7-1.",그런 다음 MinIO Client를 사용하여 예 7-1과 같이 스토리지 개체를 생성 할 수 있습니다.,,
1638,Example 7-1.,예 7-1.,,
1639,"Setting up prerequisites
# Port-forward the MinIO service to http://localhost:9000
kubectl port-forward -n kubeflow svc/minio-service 9000:9000 &

# Configure MinIO host
mc config host add minio http://localhost:9000 minio minio123

# Create storage bucket
mc mb minio/data

# Copy storage objects
mc cp go/src/github.com/medium/items-recommender/data/recommend_1.csv \\
        minio/data/recommender/users.csv
mc cp go/src/github.com/medium/items-recommender/data/trx_data.csv \\
        minio/data/recommender/transactions.csv


7.1.2.","필수 구성 요소 설정
# MinIO 서비스를 http : // localhost : 9000으로 포트 포워드합니다.
kubectl port-forward -n kubeflow svc / minio-service 9000 : 9000 &

# MinIO 호스트 구성
mc 구성 호스트 minio 추가 http : // localhost : 9000 minio minio123

# 스토리지 버킷 생성
mc mb minio / 데이터

# 저장 객체 복사
mc cp go / src / github.com / medium / items-recommender / data / recommend_1.csv \\
        minio / data / recommender / users.csv
mc cp go / src / github.com / medium / items-recommender / data / trx_data.csv \\
        minio / data / recommender / transactions.csv


7.1.2.",,
1640,"Starting a New Notebook Session
Now let’s start by creating a new notebook.","새 노트북 세션 시작
이제 새 노트북을 만들어 보겠습니다.",,
1641,"You can do this by navigating to the “Notebook Servers” panel in your Kubeflow dashboard, then clicking “New Server” and following the instructions.","Kubeflow 대시 보드에서 ""노트북 서버""패널로 이동 한 다음 ""새 서버""를 클릭하고 지침에 따라이를 수행 할 수 있습니다.",,
1642,"For this example,
we use the tensorFlow-1.15.2-notebook-cpu:1.0 image.","이 예에서는
tensorFlow-1.15.2-notebook-cpu : 1.0 이미지를 사용합니다.",,
1643,"[1]
When the notebook server starts up, click the “Upload” button in the top right corner and upload the Recommender_Kubeflow.ipynb file.","[1]
노트북 서버가 시작되면 오른쪽 상단에있는 ""업로드""버튼을 클릭하고 Recommender Kubeflow.ipynb 파일을 업로드합니다.",,
1644,"Click the file to start a new 
session.","새 파일을 시작하려면 파일을 클릭하십시오.
세션.",,
1645,The first few sections of the code involve importing libraries and reading the training data from MinIO.,코드의 처음 몇 섹션에는 라이브러리 가져 오기와 MinIO에서 학습 데이터 읽기가 포함됩니다.,,
1646,Then we normalize the input data so that we are ready to start training.,그런 다음 훈련을 시작할 준비가되도록 입력 데이터를 정규화합니다.,,
1647,"This process is called feature preparation, which we discussed in CHAPTER 5.",이 프로세스를 기능 준비라고하며 5 장에서 논의했습니다.,,
1648,In this chapter we’ll focus on the model training part of the exercise.,이 장에서는 연습의 모델 훈련 부분에 초점을 맞출 것입니다.,,
1649,7.1.3.,7.1.3.,,
1650,"TensorFlow Training
Now that our notebook is set up and the data is prepared, we can create a TensorFlow session, as shown in EXAMPLE 7-2.","TensorFlow 교육
이제 노트북이 설정되고 데이터가 준비되었으므로 예제 7-2와 같이 TensorFlow 세션을 만들 수 있습니다.",,
1651,"[2]

Example 7-2.","[2]

예 7-2.",,
1652,"Creating a TensorFlow session
# Create TF session and set it in Keras
sess = tf.Session()
K.set_session(sess)
K.set_learning_phase(1)
For the model class, we use the code in EXAMPLE 7-3 for collaborative filtering.","TensorFlow 세션 만들기
# TF 세션을 만들고 Keras에서 설정합니다.
sess = tf.Session ()
K.set_session (sess)
K.set_learning_phase (1)
모델 클래스의 경우 협업 필터링을 위해 예제 7-3의 코드를 사용합니다.",,
1653,Example 7-3.,예 7-3.,,
1654,"DeepCollaborativeFiltering learning
class DeepCollaborativeFiltering(Model):
   def__init__(self, n_customers, n_products, n_factors, p_dropout = 0.2):
      x1 = Input(shape = (1,), name=""user"")

      P = Embedding(n_customers, n_factors, input_length = 1)(x1)
      P = Reshape((n_factors,))(P)

      x2 = Input(shape = (1,), name=""product"")

      Q = Embedding(n_products, n_factors, input_length = 1)(x2)
      Q = Reshape((n_factors,))(Q)

      x = concatenate([P, Q], axis=1)
      x = Dropout(p_dropout)(x)

      x = Dense(n_factors)(x)
      x = Activation('relu')(x)
      x = Dropout(p_dropout)(x)

      output = Dense(1)(x)

      super(DeepCollaborativeFiltering, self).__init__([x1, x2], output)

   def rate(self, customer_idxs, product_idxs):
      if (type(customer_idxs) == int and type(product_idxs) == int):
          return self.predict([np.array(customer_idxs).reshape((1,)),\
                  np.array(product_idxs).reshape((1,))])

      if (type(customer_idxs) == str and type(product_idxs) == str):
          return self.predict( \
                 [np.array(customerMapping[customer_idxs]).reshape((1,)),\
                 np.array(productMapping[product_idxs]).reshape((1,))])

      return self.predict([
         np.array([customerMapping[customer_idx] \
                for customer_idx in customer_idxs]),
            np.array([productMapping[product_idx] \
                for product_idx in product_idxs])
      ])
This is the basis of our model class.","DeepCollaborativeFiltering 학습
클래스 DeepCollaborativeFiltering (모델) :
   def__init __ (self, n_customers, n_products, n_factors, p_dropout = 0.2) :
      x1 = 입력 (모양 = (1,), 이름 = ""사용자"")

      P = Embedding (n_customers, n_factors, input_length = 1) (x1)
      P = 모양 변경 ((n_factors,)) (P)

      x2 = 입력 (모양 = (1,), 이름 = ""제품"")

      Q = 임베딩 (n_products, n_factors, input_length = 1) (x2)
      Q = 모양 변경 ((n_factors,)) (Q)

      x = 연결 ([P, Q], 축 = 1)
      x = 드롭 아웃 (p_dropout) (x)

      x = 밀도 (n_factors) (x)
      x = 활성화 ( 'relu') (x)
      x = 드롭 아웃 (p_dropout) (x)

      출력 = Dense (1) (x)

      super (DeepCollaborativeFiltering, self) .__ init __ ([x1, x2], 출력)

   정의 비율 (self, customer_idxs, product_idxs) :
      if (type (customer_idxs) == int 및 type (product_idxs) == int) :
          return self.predict ([np.array (customer_idxs) .reshape ((1,)), \
                  np.array (product_idxs) .reshape ((1,))])

      if (type (customer_idxs) == str 및 type (product_idxs) == str) :
          return self.predict (\
                 [np.array (customerMapping [customer_idxs]). reshape ((1,)), \
                 np.array (productMapping [product_idxs]). reshape ((1,))])

      return self.predict ([
         np.array ([customerMapping [customer_idx] \
                customer_idxs의 customer_idx]),
            np.array ([productMapping [product_idx] \
                product_idxs의 product_idx 용])
      ])
이것이 우리 모델 클래스의 기초입니다.",,
1655,"It includes a constructor with some code to instantiate the collaborative filtering model using Keras APIs, and a “rate” function that we can use to make a prediction using our model—namely, what rating a customer would give to a particular product.","여기에는 Keras API를 사용하여 협업 필터링 모델을 인스턴스화하는 코드가 포함 된 생성자와 모델을 사용하여 예측을 수행하는 데 사용할 수있는 ""rate""함수가 포함되어 있습니다. 즉, 고객이 특정 제품에 부여 할 등급입니다.",,
1656,"We can create an instance of the model, as in EXAMPLE 7-4.",예제 7-4에서와 같이 모델의 인스턴스를 만들 수 있습니다.,,
1657,Example 7-4.,예 7-4.,,
1658,"Model creation
model = DeepCollaborativeFiltering(n_customers, n_products, n_factors)
model.summary()
Now we are ready to start training our model.","모델 생성
모델 = Deep Collaborative Filtering (n customers, n_products, n_factors)
model.summary ()
이제 모델 훈련을 시작할 준비가되었습니다.",,
1659,"We can do this by setting a few hyperparameters, as shown in EXAMPLE 7-5.",예 7-5에 표시된대로 몇 가지 하이퍼 파라미터를 설정하여이를 수행 할 수 있습니다.,,
1660,Example 7-5.,예 7-5.,,
1661,"Setting Training configuration
bs = 64
val_per = 0.25
epochs = 3
These are hyperparameters that control the training process.","교육 구성 설정
bs = 64
val_per = 0.25
에포크 = 3
훈련 프로세스를 제어하는 하이퍼 파라미터입니다.",,
1662,"They are typically set before training begins, unlike model parameters, which are learned from the training process.",일반적으로 학습 프로세스에서 학습 된 모델 매개 변수와 달리 학습이 시작되기 전에 설정됩니다.,,
1663,Setting the right values for hyperparameters can significantly impact the effectiveness of your model.,하이퍼 파라미터에 적합한 값을 설정하면 모델의 효율성에 큰 영향을 미칠 수 있습니다.,,
1664,"For now, let’s just set some default values for them.",지금은 몇 가지 기본값을 설정하겠습니다.,,
1665,In CHAPTER 10 we’ll look at how to use Kubeflow to tune hyperparameters.,10 장에서는 Kubeflow를 사용하여 하이퍼 파라미터를 조정하는 방법을 살펴 보겠습니다.,,
1666,We are now ready to run the training code.,이제 훈련 코드를 실행할 준비가되었습니다.,,
1667,See EXAMPLE 7-6.,예 7-6을 참조하십시오.,,
1668,Example 7-6.,예 7-6.,,
1669,"Fitting model
model.compile(optimizer = 'adam', loss = mean_squared_logarithmic_error)
model.fit(x = [customer_idxs, product_idxs], y = ratings,
        batch_size = bs, epochs = epochs, validation_split = val_per)
print('Done training!')","피팅 모델
model.compile (optimizer = 'adam', loss = mean_squared_logarithmic_error)
model.fit (x = [customer_idxs, product_idxs], y = 등급,
        batch_size = bs, epochs = epochs, validation_split = val_per)
print ( '훈련 완료!')",,
1670,"Once the training is complete, you should see results like in EXAMPLE 7-7.",교육이 완료되면 예 7-7과 같은 결과가 표시됩니다.,,
1671,Example 7-7.,예 7-7.,,
1672,"Model training results
Train on 100188 samples, validate on 33397 samples
Epoch 1/3
100188/100188 [==============================]
- 21s 212us/step - loss: 0.0105 - val_loss: 0.0186
Epoch 2/3
100188/100188 [==============================]
- 20s 203us/step - loss: 0.0092 - val_loss: 0.0188
Epoch 3/3
100188/100188 [==============================]
- 21s 212us/step - loss: 0.0078 - val_loss: 0.0192
Done training!","모델 훈련 결과
100188 개 샘플 학습, 33397 개 샘플 검증
에포크 1/3
100188/100188 [=============================]
-21 초 212us / 단계-손실 : 0.0105-val_loss : 0.0186
에포크 2/3
100188/100188 [=============================]
-20 초 203us / 단계-손실 : 0.0092-val_loss : 0.0188
에포크 3/3
100188/100188 [=============================]
-21 초 212us / 단계-손실 : 0.0078-val_loss : 0.0192
훈련 완료!",,
1673,Congratulations: you’ve successfully trained a TensorFlow model in a Jupyter notebook.,축하합니다. Jupyter 노트북에서 TensorFlow 모델을 성공적으로 학습 시켰습니다.,,
1674,"But we’re not quite done yet—to make use of our model later, we should first export it.",그러나 아직 완료되지 않았습니다. 나중에 모델을 사용하려면 먼저 모델을 내 보내야합니다.,,
1675,"You can do this by setting up the export destination using MinIO Client, as shown in EXAMPLE 7-8.",예 7-8과 같이 MinIO Client를 사용하여 내보내기 대상을 설정하면됩니다.,,
1676,Example 7-8.,예 7-8.,,
1677,"Setting export destination
directorystream = minioClient.get_object('data', 'recommender/directory.txt')
directory = """"
for d in directorystream.stream(32*1024):
    directory += d.decode('utf-8')
arg_version = ""1""
export_path = 's3://models/' + directory + '/' + arg_version + '/'
print ('Exporting trained model to', export_path)
Once you have set up your export destination, you can then export the model, as in EXAMPLE 7-9.","내보내기 대상 설정
directorystream = minioClient.get_object ( 'data', 'recommender / directory.txt')
디렉토리 = """"
directorystream.stream (32 * 1024)의 d의 경우 :
    디렉토리 + = d.decode ( 'utf-8')
arg_version = ""1""
export_path = 's3 : // models /'+ 디렉토리 + '/'+ arg_version + '/'
print ( '학습 된 모델을 다음으로 내보내기', export_path)
내보내기 대상을 설정했으면 예 7-9에서와 같이 모델을 내보낼 수 있습니다.",,
1678,Example 7-9.,예 7-9.,,
1679,"Exporting the model
# Inputs/outputs
tensor_info_users = tf.saved_model.utils.build_tensor_info(model.input[0])
tensor_info_products = tf.saved_model.utils.build_tensor_info(model.input[1])
tensor_info_pred = tf.saved_model.utils.build_tensor_info(model.output)

print (""tensor_info_users"", tensor_info_users.name)
print (""tensor_info_products"", tensor_info_products.name)
print (""tensor_info_pred"", tensor_info_pred.name)

# Signature
prediction_signature = (tf.saved_model.signature_def_utils.build_signature_def(
        inputs={""users"": tensor_info_users, ""products"": tensor_info_products},
        outputs={""predictions"": tensor_info_pred},
        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))
# Export
legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')
builder = tf.saved_model.builder.SavedModelBuilder(export_path)
builder.add_meta_graph_and_variables(
      sess, [tf.saved_model.tag_constants.SERVING],
      signature_def_map={
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
          prediction_signature,
      },
      legacy_init_op=legacy_init_op)
builder.save()
Now we’re ready to use this model to serve predictions, as we’ll learn in CHAPTER 8.","모델 내보내기
# 입력 / 출력
tensor_info_users = tf.saved_model.utils.build_tensor_info (model.input [0])
tensor_info_products = tf.saved_model.utils.build_tensor_info (model.input [1])
tensor_info_pred = tf.saved_model.utils.build_tensor_info (model.output)

print ( ""tensor_info_users"", tensor_info_users.name)
print ( ""tensor_info_products"", tensor_info_products.name)
print ( ""tensor_info_pred"", tensor_info_pred.name)

# 서명
predict_signature = (tf.saved_model.signature_def_utils.build_signature_def (
        inputs = { ""users"": tensor_info_users, ""products"": tensor_info_products},
        outputs = { ""predictions"": tensor_info_pred},
        method_name = tf.saved_model.signature_constants.PREDICT_METHOD_NAME))
# 내보내기
legacy_init_op = tf.group (tf.tables_initializer (), name = 'legacy_init_op')
builder = tf.saved_model.builder.SavedModelBuilder (export_path)
builder.add_meta_graph_and_variables (
      sess, [tf.saved_model.tag_constants.SERVING],
      signature_def_map = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY :
          predict_signature,
      },
      legacy_init_op = legacy_init_op)
builder.save ()
이제 8 장에서 배우게 될 것처럼이 모델을 사용하여 예측을 제공 할 준비가되었습니다.",,
1680,"But before that, let’s look at how to deploy this training job using Kubeflow.",하지만 그 전에 Kubeflow를 사용하여이 학습 작업을 배포하는 방법을 살펴 보겠습니다.,,
1681,7.2.,7.2.,,
1682,"Deploying a TensorFlow Training Job
So far we have done some TensorFlow training using Jupyter notebooks, which is a great way to prototype and experiment.","TensorFlow 학습 작업 배포
지금까지 Jupyter 노트북을 사용하여 TensorFlow 교육을 수행했습니다. 이는 프로토 타입 및 실험을위한 좋은 방법입니다.",,
1683,"But soon we may discover that our prototype is insufficient—perhaps we need to refine the model using more data, or perhaps we need to train the model using specialized hardware.",하지만 곧 프로토 타입이 불충분하다는 사실을 알게 될 것입니다. 더 많은 데이터를 사용하여 모델을 수정해야하거나 특수 하드웨어를 사용하여 모델을 훈련해야 할 수도 있습니다.,,
1684,Sometimes we may even need to continuously run the training job because our model is constantly evolving.,때때로 우리는 모델이 지속적으로 진화하기 때문에 훈련 작업을 지속적으로 실행해야 할 수도 있습니다.,,
1685,"Perhaps most importantly, our model has to be deployable to production, where it can serve actual customer requests.",아마도 가장 중요한 것은 실제 고객 요청을 처리 할 수있는 프로덕션에 모델을 배포 할 수 있어야한다는 것입니다.,,
1686,"In order to handle these requirements, our training code must be easily  packageable and deployable to various different environments.",이러한 요구 사항을 처리하려면 교육 코드를 쉽게 패키지화하고 다양한 환경에 배포 할 수 있어야합니다.,,
1687,One of the ways to achieve this is to use TFJob—a Kubernetes custom resource (implemented using Kubernetes operator tf-operator) that you can use to run TensorFlow training jobs on Kubernetes.,이를 달성하는 방법 중 하나는 Kubernetes에서 TensorFlow 학습 작업을 실행하는 데 사용할 수있는 Kubernetes 커스텀 리소스 (Kubernetes 연산자 tf-operator를 사용하여 구현 됨) 인 TFJob을 사용하는 것입니다.,,
1688,Why Should You Use TFJobs?,TFJobs를 사용해야하는 이유는 무엇입니까?,,
1689,There are many challenges to deploying our training code to a production environment.,프로덕션 환경에 교육 코드를 배포하는 데는 많은 어려움이 있습니다.,,
1690,"To name a few:


What kind of infrastructure do we have to work with?","몇 가지를 예로 들면 :


우리는 어떤 종류의 인프라와 협력해야합니까?",,
1691,Are we running in the cloud or on-premises?,클라우드 또는 온 프레미스에서 실행 중입니까?,,
1692,Who has access to the training job and its data?,교육 작업 및 데이터에 누가 액세스 할 수 있습니까?,,
1693,Can we share a training job with our teammates?,팀원들과 훈련 업무를 공유 할 수 있습니까?,,
1694,How do we scale up the training job?,훈련 작업을 어떻게 확장합니까?,,
1695,How do we clean up the resources when we are done?,완료되면 자원을 어떻게 정리합니까?,,
1696,What do we do with the model after we’ve trained it?,훈련을 마친 후 모델로 무엇을할까요?,,
1697,How do we export the model so we can make use of it?,모델을 사용할 수 있도록 내보내려면 어떻게해야합니까?,,
1698,"Typically, these problems require the user to implement a large amount of “glue code” to work with the underlying infrastructure.","일반적으로 이러한 문제는 사용자가 기본 인프라에서 작업하기 위해 많은 양의 ""접착 코드""를 구현해야합니다.",,
1699,"Such code is likely to differ greatly depending on the environment and the technical constraints, which means that developing this technical stack could be much more time-consuming than the model itself.","이러한 코드는 환경과 기술적 제약에 따라 크게 다를 수 있으며, 이는이 기술 스택을 개발하는 것이 모델 자체보다 훨씬 더 많은 시간이 소요될 수 있음을 의미합니다.",,
1700,These are the problems that Kubeflow aims to solve.,이것이 Kubeflow가 해결하고자하는 문제입니다.,,
1701,"Since Kubeflow’s architecture is entirely based on Kubernetes, all of Kubernetes’ scalable and portable features are available to Kubeflow.",Kubeflow의 아키텍처는 전적으로 Kubernetes를 기반으로하므로 Kubeflow에서 Kubernetes의 확장 가능하고 이식 가능한 기능을 모두 사용할 수 있습니다.,,
1702,Applications in Kubernetes are developed as “cloud native” microservices.,"Kubernetes의 애플리케이션은 ""클라우드 네이티브""마이크로 서비스로 개발됩니다.",,
1703,"In the case of
machine learning training, if you want to scale up a training job, simply increase the number of desired replicas and the underlying system will take care of that for you.","의 경우
머신 러닝 훈련은 훈련 작업을 확장하려는 경우 원하는 복제본의 수를 늘리기 만하면 기본 시스템이이를 처리합니다.",,
1704,"The same Kubeflow job that runs on Amazon Cloud can easily be exported to a different cluster running Google Cloud or even to 
on-premises.","Amazon Cloud에서 실행되는 동일한 Kubeflow 작업을 Google Cloud를 실행하는 다른 클러스터로 쉽게 내보낼 수 있습니다.
온-프레미스.",,
1705,Kubeflow makes it easy to configure TensorFlow jobs on a Kubernetes cluster by orchestrating them as custom resources.,Kubeflow를 사용하면 Kubernetes 클러스터에서 TensorFlow 작업을 커스텀 리소스로 오케스트레이션하여 쉽게 구성 할 수 있습니다.,,
1706,Custom resources are extensions to the core Kubernetes API that store collections of API objects.,사용자 지정 리소스는 API 개체 컬렉션을 저장하는 핵심 Kubernetes API에 대한 확장입니다.,,
1707,"By using custom resources, developers only need to provide a “desired state” of their applications, and the underlying controllers will take care of the rest.","사용자 지정 리소스를 사용하여 개발자는 응용 프로그램의 ""원하는 상태""만 제공하면되고 기본 컨트롤러가 나머지를 처리합니다.",,
1708,We’ll start by deploying our recommender as a single-container TFJob.,추천자를 단일 컨테이너 TFJob으로 배포하는 것부터 시작하겠습니다.,,
1709,"Since we already have a Python notebook, exporting it as a Python file is fairly simple—just select “File,” then “Download as” and select “Python.” This should save your notebook as a ready-to-execute Python file.","이미 Python 노트북이 있으므로 Python 파일로 내보내는 것은 매우 간단합니다. ""파일""을 선택한 다음 ""다른 이름으로 다운로드""를 선택하고 ""Python""을 선택하면됩니다.노트북을 바로 실행할 수있는 Python 파일로 저장해야합니다.",,
1710,The next step is to package the training code in a container.,다음 단계는 컨테이너에 교육 코드를 패키징하는 것입니다.,,
1711,"This can be done with the Dockerfile, as seen in EXAMPLE 7-10.",이것은 예 7-10에서 볼 수 있듯이 Dockerfile을 사용하여 수행 할 수 있습니다.,,
1712,Example 7-10.,예 7-10.,,
1713,"TFJob Dockerfile
FROM  tensorflow/tensorflow:1.15.2-py3
RUN pip3 install --upgrade pip
RUN pip3 install pandas --upgrade
RUN pip3 install keras --upgrade
RUN pip3 install minio --upgrade
RUN mkdir -p /opt/kubeflow
COPY Recommender_Kubeflow.py /opt/kubeflow/
ENTRYPOINT [""python3"", ""/opt/kubeflow/Recommender_Kubeflow.py""]
Next, we need to build this container along with its required libraries, and push the container image to a repository:
docker build -t kubeflow/recommenderjob:1.0 .","TFJob Dockerfile
tensorflow / tensorflow : 1.15.2-py3에서
실행 pip3 설치-pip 업그레이드
pip3 install pandas 실행-업그레이드
pip3 install keras --upgrade 실행
pip3 설치 minio-업그레이드 실행
mkdir -p / opt / kubeflow 실행
복사 Recommender_Kubeflow.py / opt / kubeflow /
ENTRYPOINT [ ""python3"", ""/opt/kubeflow/Recommender_Kubeflow.py""]
다음으로 필요한 라이브러리와 함께이 컨테이너를 빌드하고 컨테이너 이미지를 저장소로 푸시해야합니다.
docker build -t kubeflow / recommenderjob : 1.0.",,
1714,"docker push kubeflow/recommenderjob:1.0
Once that’s done, we are ready to create the specification for a TFJob, as in EXAMPLE 7-11.","도커 푸시 kubeflow / recommenderjob : 1.0
완료되면 예 7-11에서와 같이 TFJob에 대한 사양을 만들 준비가 된 것입니다.",,
1715,Example 7-11.,예 7-11.,,
1716,"Single-container TFJob example
apiVersion: ""kubeflow.org/v1""   
kind: ""TFJob""                   
metadata:
  name: ""recommenderjob""        
spec:
  tfReplicaSpecs:               
    Worker:
      replicas: 1
    restartPolicy: Never
    template:
      spec:
        containers:
        - name: tensorflow image: kubeflow/recommenderjob:1.0


The apiVersion field specifies which version of the TFJob custom resource you are using.","단일 컨테이너 TFJob 예
apiVersion : ""kubeflow.org/v1""
종류 : ""TFJob""
메타 데이터 :
  이름 : ""recommenderjob""
투기:
  tfReplicaSpecs :
    노동자:
      복제본 : 1
    restartPolicy : 없음
    주형:
      투기:
        용기 :
        -이름 : tensorflow 이미지 : kubeflow / recommenderjob : 1.0


apiVersion 필드는 사용중인 TFJob 사용자 지정 리소스의 버전을 지정합니다.",,
1717,The corresponding version (in this case v1) needs to be installed in your Kubeflow cluster.,Kubeflow 클러스터에 해당 버전 (이 경우 v1)을 설치해야합니다.,,
1718,The kind field identifies the type of the custom resource—in this case a TFJob.,kind 필드는 사용자 지정 리소스의 유형 (이 경우 TFJob)을 식별합니다.,,
1719,"The metadata field is common to all Kubernetes objects and is used to uniquely identify the object in the cluster—you can add fields like name, namespace, and labels here.","메타 데이터 필드는 모든 Kubernetes 객체에 공통이며 클러스터에서 객체를 고유하게 식별하는 데 사용됩니다. 여기에 이름, 네임 스페이스, 라벨과 같은 필드를 추가 할 수 있습니다.",,
1720,The most important part of the schema is tfReplicaSpecs.,스키마에서 가장 중요한 부분은 tfReplicaSpecs입니다.,,
1721,This is the actual description of your TensorFlow training cluster and its desired state.,이것은 TensorFlow 학습 클러스터 및 원하는 상태에 대한 실제 설명입니다.,,
1722,"For this example, we just have a single worker replica.",이 예에서는 작업자 복제본이 하나뿐입니다.,,
1723,"In the following section, we’ll examine this field further.",다음 섹션에서는이 필드를 자세히 살펴 보겠습니다.,,
1724,"There are a few other optional configurations for your TFJob, including:

activeDeadlineSeconds

How long to keep this job active before the system can terminate it.","다음을 포함하여 TFJob에 대한 몇 가지 다른 선택적 구성이 있습니다.

activeDeadlineSeconds

시스템이 종료하기 전에이 작업을 활성 상태로 유지하는 기간입니다.",,
1725,"If this is set, the system will kill the job after the deadline expires.",이것이 설정되면 시스템은 기한이 만료 된 후 작업을 종료합니다.,,
1726,"backoffLimit 

How many times to keep retrying this job before marking it as failed.","backoffLimit

실패로 표시하기 전에이 작업을 계속 재 시도 할 횟수입니다.",,
1727,"For example, setting this to 3 means that if a job fails 3 times, the system will stop retrying.",예를 들어이 값을 3으로 설정하면 작업이 3 번 실패하면 시스템이 재 시도를 중지합니다.,,
1728,"cleanPodPolicy

Configures whether or not to clean up the Kubernetes pods after the job completes.","cleanPodPolicy

작업이 완료된 후 Kubernetes 포드를 정리할지 여부를 구성합니다.",,
1729,Setting this policy can be useful to keep pods for debugging purposes.,이 정책을 설정하면 디버깅 목적으로 포드를 유지하는 데 유용 할 수 있습니다.,,
1730,"This can be set to All (all pods are cleaned up), Running (only running pods are cleaned up), or None (no pods are cleaned up).","모두 (모든 포드가 정리 됨), 실행 중 (실행중인 포드 만 정리 됨) 또는 없음 (포드가 정리되지 않음)으로 설정할 수 있습니다.",,
1731,"Now deploy the TFJob to your cluster, as in EXAMPLE 7-12.",이제 예 7-12에서와 같이 TFJob을 클러스터에 배포합니다.,,
1732,Example 7-12.,예 7-12.,,
1733,"Deploying TFJob
kubectl apply -f recommenderjob.yaml
You can monitor the status of the TFJob with the command in EXAMPLE 7-13.","TFJob 배포
kubectl apply -f Recommendederjob.yaml
예 7-13의 명령을 사용하여 TFJob의 상태를 모니터링 할 수 있습니다.",,
1734,Example 7-13.,예 7-13.,,
1735,"Viewing the state of TFJob
kubectl describe tfjob recommenderjob
This should display something like EXAMPLE 7-14.","TFJob 상태보기
kubectl describe tfjob suggesterjob
예 7-14와 같이 표시되어야합니다.",,
1736,Example 7-14.,예 7-14.,,
1737,"TF Recommender job description
Status:
  Completion Time:  2019-05-18T00:58:27Z
  Conditions:
    Last Transition Time:  2019-05-18T02:34:24Z
    Last Update Time:      2019-05-18T02:34:24Z
    Message:               TFJob recommenderjob is created.","TF 추천자 직무 설명
상태:
  완료 시간 : 2019-05-18T00 : 58 : 27Z
  정황:
    마지막 전환 시간 : 2019-05-18T02 : 34 : 24Z
    마지막 업데이트 시간 : 2019-05-18T02 : 34 : 24Z
    메시지 : TFJob 권장 작업이 생성되었습니다.",,
1738,"Reason:                TFJobCreated
    Status:                True
    Type:                  Created
    Last Transition Time:  2019-05-18T02:38:28Z
    Last Update Time:      2019-05-18T02:38:28Z
    Message:               TFJob recommenderjob is running.","이유 : TFJobCreated
    상태 : 참
    유형 : 생성됨
    마지막 전환 시간 : 2019-05-18T02 : 38 : 28Z
    마지막 업데이트 시간 : 2019-05-18T02 : 38 : 28Z
    메시지 : TFJob 권장 작업이 실행 중입니다.",,
1739,"Reason:                TFJobRunning
    Status:                False
    Type:                  Running
    Last Transition Time:  2019-05-18T02:38:29Z
    Last Update Time:      2019-05-18T02:38:29Z
    Message:               TFJob recommenderjob successfully completed.","이유 : TFJobRunning
    상태 : 거짓
    유형 : 달리기
    마지막 전환 시간 : 2019-05-18T02 : 38 : 29Z
    마지막 업데이트 시간 : 2019-05-18T02 : 38 : 29Z
    메시지 : TFJob 권장 작업이 성공적으로 완료되었습니다.",,
1740,"Reason:                TFJobSucceeded
    Status:                True
    Type:                  Succeeded
  Replica Statuses:
    Worker:
      Succeeded:  1
Note that the status field contains a list of job conditions, which represent when the job transitioned into each state.","이유 : TFJobSucceeded
    상태 : 참
    유형 : 성공
  복제본 상태 :
    노동자:
      성공 : 1
상태 필드에는 작업이 각 상태로 전환 된시기를 나타내는 작업 조건 목록이 포함되어 있습니다.",,
1741,"This is useful for debugging—if the job failed, the reason for the job’s failure would appear here.",이는 디버깅에 유용합니다. 작업이 실패한 경우 작업 실패 이유가 여기에 표시됩니다.,,
1742,So far we have trained a fairly simple and straightforward model with a modest number of training samples.,지금까지 우리는 적당한 수의 훈련 샘플로 상당히 간단하고 간단한 모델을 훈련했습니다.,,
1743,"In real life, learning more complex models may require significantly more training samples or model parameters.",실제 생활에서 더 복잡한 모델을 학습하려면 훨씬 더 많은 학습 샘플 또는 모델 매개 변수가 필요할 수 있습니다.,,
1744,Such models can be too large and computationally complex to be handled by one machine.,이러한 모델은 하나의 기계로 처리하기에는 너무 크고 계산적으로 복잡 할 수 있습니다.,,
1745,This is where distributed training comes in.,여기에서 분산 교육이 시작됩니다.,,
1746,7.3.,7.3.,,
1747,"Distributed Training
By now we’ve deployed a single-worker TensorFlow job with Kubeflow.","분산 교육
지금까지 Kubeflow를 사용하여 단일 작업자 TensorFlow 작업을 배포했습니다.",,
1748,It is called “single-worker” because everything from hosting the data to executing the actual training steps is done on a single machine.,"데이터 호스팅에서 실제 교육 단계 실행에 이르기까지 모든 것이 단일 머신에서 수행되기 때문에 ""단일 작업자""라고합니다.",,
1749,"However, as models become more complex, a single machine is often insufficient—we may need to distribute the model or the training samples over several networked machines.",그러나 모델이 더 복잡 해짐에 따라 단일 머신만으로는 부족한 경우가 많습니다. 여러 네트워크 머신에 모델 또는 학습 샘플을 배포해야 할 수도 있습니다.,,
1750,"TensorFlow supports a distributed training mode, in which training is performed in parallel over several worker nodes.",TensorFlow는 학습이 여러 작업자 노드에서 병렬로 수행되는 분산 학습 모드를 지원합니다.,,
1751,Distributed training typically comes in two flavors: data parallelism and model parallelism.,분산 학습은 일반적으로 데이터 병렬성과 모델 병렬성의 두 가지 유형으로 제공됩니다.,,
1752,"In data parallelism, the training data is partitioned into chunks, and the same training code runs on each chunk.",데이터 병렬화에서 훈련 데이터는 청크로 분할되고 동일한 훈련 코드가 각 청크에서 실행됩니다.,,
1753,"At the end of each training step, each worker communicates its updates to all other nodes.",각 훈련 단계가 끝날 때 각 작업자는 업데이트를 다른 모든 노드에 전달합니다.,,
1754,"Model parallelism is the opposite—the same training data is used in all workers, but the model itself is partitioned.",모델 병렬 처리는 그 반대입니다. 동일한 학습 데이터가 모든 작업자에 사용되지만 모델 자체는 분할됩니다.,,
1755,"At the end of each step, each worker is responsible for synchronizing the shared parts of the model.",각 단계의 끝에서 각 작업자는 모델의 공유 부분을 동기화해야합니다.,,
1756,"Distribution Strategies in TensorFlow
TensorFlow supports a number of different strategies for distributed training.","TensorFlow의 배포 전략
TensorFlow는 분산 학습을위한 다양한 전략을 지원합니다.",,
1757,"These include:

Mirrored strategy

This is a synchronous strategy, which means the training steps and gradients are synced across replicas.","여기에는 다음이 포함됩니다.

미러링 된 전략

이것은 동기식 전략으로, 훈련 단계와 기울기가 복제본간에 동기화됨을 의미합니다.",,
1758,Copies of all variables in the model are replicated on each device across all workers.,모델의 모든 변수 사본은 모든 작업자의 각 장치에 복제됩니다.,,
1759,"TPU strategy

Similar to mirrored strategy, but allows you to train on Google’s TPUs.","TPU 전략

미러링 전략과 비슷하지만 Google의 TPU에서 학습 할 수 있습니다.",,
1760,"Multiworker mirrored strategy

Also similar to mirrored strategy, but uses CollectiveOps multiworker all-reduce to keep variables in sync.","다중 작업자 미러링 전략

또한 미러링 된 전략과 유사하지만 CollectiveOps 다중 작업자 all-reduce를 사용하여 변수를 동기화 상태로 유지합니다.",,
1761,"Central storage strategy

Instead of replicating variables across all workers, this strategy stores variables on a central CPU while replicating computational work across workers.","중앙 스토리지 전략

이 전략은 모든 작업자에 걸쳐 변수를 복제하는 대신 중앙 CPU에 변수를 저장하는 동시에 작업자간에 계산 작업을 복제합니다.",,
1762,"Parameter server strategy

Nodes are classified as either workers or parameter servers.","매개 변수 서버 전략

노드는 작업자 또는 매개 변수 서버로 분류됩니다.",,
1763,"Each model parameter is stored on one parameter server, while computational work is replicated among workers.",각 모델 매개 변수는 하나의 매개 변수 서버에 저장되고 계산 작업은 작업자간에 복제됩니다.,,
1764,The TFJob interface supports multiworker distributed training.,TFJob 인터페이스는 다중 작업자 분산 교육을 지원합니다.,,
1765,"Conceptually, a TFJob is a logical grouping of all resources related to a training job, including pods and services.",개념적으로 TFJob은 포드 및 서비스를 포함하여 학습 작업과 관련된 모든 리소스의 논리적 그룹입니다.,,
1766,"In Kubeflow, each replicated worker or parameter server is scheduled on its own single-container pod.",Kubeflow에서 복제 된 각 작업자 또는 매개 변수 서버는 자체 단일 컨테이너 포드에서 예약됩니다.,,
1767,"In order for the replicas to synchronize with each other, each replica needs to expose itself through an endpoint, which is a Kubernetes internal service.",복제본이 서로 동기화 되려면 각 복제본이 Kubernetes 내부 서비스 인 엔드 포인트를 통해 자신을 노출해야합니다.,,
1768,Grouping these resources logically under a parent resource (which is the TFJob) allows these resources to be co-scheduled and garbage collected together.,이러한 리소스를 부모 리소스 (TFJob) 아래에 논리적으로 그룹화하면 이러한 리소스를 함께 예약하고 가비지 수집 할 수 있습니다.,,
1769,In this section we’ll deploy a simple MNIST example with distributed training.,이 섹션에서는 분산 교육을 통해 간단한 MNIST 예제를 배포합니다.,,
1770,The TensorFlow training code is provided for you at this GitHub repo.,TensorFlow 학습 코드는이 GitHub 저장소에서 제공됩니다.,,
1771,Let’s take a look at the YAML file for the distributed TensorFlow job in EXAMPLE 7-15.,예제 7-15에서 분산 형 TensorFlow 작업에 대한 YAML 파일을 살펴 보겠습니다.,,
1772,Example 7-15.,예 7-15.,,
1773,"Distributed TFJob example
apiVersion: ""kubeflow.org/v1""
kind: ""TFJob""
metadata:
  name: ""mnist""
  namespace: kubeflow
spec:
  cleanPodPolicy: None
  tfReplicaSpecs:
    Worker:
      replicas: 2
      restartPolicy: Never
      template:
        spec:
          containers:
            - name: tensorflow
              image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
              command:
                - ""python""
                - ""/var/tf_mnist/mnist_with_summaries.py""
                - ""--log_dir=/train/logs""
                - ""--learning_rate=0.01""
                - ""--batch_size=150""
              volumeMounts:
                - mountPath: ""/train""
                  name: ""training""
          volumes:
            - name: ""training""
              persistentVolumeClaim:
                claimName: ""tfevent-volume""
Note that the tfReplicaSpecs field now contains a few different replica types.","분산 TFJob 예
apiVersion : ""kubeflow.org/v1""
종류 : ""TFJob""
메타 데이터 :
  이름 : ""mnist""
  네임 스페이스 : kubeflow
투기:
  cleanPodPolicy : 없음
  tfReplicaSpecs :
    노동자:
      복제본 : 2
      restartPolicy : 없음
      주형:
        투기:
          용기 :
            -이름 : tensorflow
              이미지 : gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
              명령:
                - ""파이썬""
                - ""/var/tf_mnist/mnist_with_summaries.py""
                - ""--log_dir = / train / logs""
                - ""--learning_rate = 0.01""
                - ""--batch_size = 150""
              volumeMounts :
                -mountPath : ""/ train""
                  이름 : ""훈련""
          볼륨 :
            -이름 : ""훈련""
              persistenceVolumeClaim :
                claimName : ""tfevent-volume""
이제 tfReplicaSpecs 필드에 몇 가지 다른 복제본 유형이 포함됩니다.",,
1774,"In a typical TensorFlow training cluster, there are a few possible possibilities:

Chief

Responsible for orchestrating computational tasks, emitting events, and checkpointing the model

Parameter servers

Provide a distributed data store for the model parameters

Worker

This is where the computations and training actually happen.","일반적인 TensorFlow 학습 클러스터에는 몇 가지 가능한 가능성이 있습니다.

주요한

계산 작업 조정, 이벤트 생성 및 모델 체크 포인트를 담당합니다.

매개 변수 서버

모델 매개 변수에 대한 분산 데이터 저장소 제공

노동자

이것은 계산과 훈련이 실제로 일어나는 곳입니다.",,
1775,"When a chief node is not explicitly defined (as in the preceding example), one of the workers acts as the chief node.",수석 노드가 명시 적으로 정의되지 않은 경우 (이전 예제에서와 같이) 작업자 중 하나가 수석 노드로 작동합니다.,,
1776,"Evaluator

The evaluators can be used to compute evaluation metrics as the model is trained.","평가자

평가자는 모델이 학습 될 때 평가 지표를 계산하는 데 사용할 수 있습니다.",,
1777,"Note also that a replica spec contains a number of properties that describe its desired state:

replicas

How many replicas should be spawned for this replica type

template

A PodTemplateSpec that describes the pod to create for each replica

restartPolicy

Determines whether pods will be restarted when they exit.","복제본 사양에는 원하는 상태를 설명하는 여러 속성이 포함되어 있습니다.

복제본

이 복제본 유형에 대해 생성되어야하는 복제본 수

주형

각 복제본에 대해 생성 할 포드를 설명하는 PodTemplateSpec

restartPolicy

포드가 종료 될 때 다시 시작할지 여부를 결정합니다.",,
1778,"The allowed values are as follows:

Always

Means the pod will always be restarted.","허용되는 값은 다음과 같습니다.

항상

포드가 항상 다시 시작됨을 의미합니다.",,
1779,This policy is good for parameter servers since they never exit and should always be restarted in the event of failure.,이 정책은 매개 변수 서버가 종료되지 않고 오류 발생시 항상 다시 시작해야하기 때문에 유용합니다.,,
1780,"OnFailure

Means the pod will be restarted if the pod exits due to failure.","OnFailure

실패로 인해 포드가 종료되면 포드가 다시 시작됨을 의미합니다.",,
1781,A nonzero exit code indicates a failure.,0이 아닌 종료 코드는 실패를 나타냅니다.,,
1782,An exit code of 0 indicates success and the pod will not be restarted.,종료 코드 0은 성공을 나타내며 포드가 다시 시작되지 않습니다.,,
1783,This policy is good for the chief and workers.,이 정책은 장과 근로자에게 좋습니다.,,
1784,"ExitCode

Means the restart behavior is dependent on the exit code of the TensorFlow container as follows:


0 indicates the process completed successfully and will not be restarted.","ExitCode

다시 시작 동작이 다음과 같이 TensorFlow 컨테이너의 종료 코드에 따라 달라짐을 의미합니다.


0은 프로세스가 성공적으로 완료되었으며 다시 시작되지 않음을 나타냅니다.",,
1785,"1–127 indicates a permanent error and that the container will not be 
restarted.","1–127은 영구적 인 오류를 나타내며 컨테이너가
다시 시작되었습니다.",,
1786,128–255 indicates a retryable error and the container will be restarted.,128–255는 재시도 가능한 오류를 나타내며 컨테이너가 다시 시작됩니다.,,
1787,This policy is good for the chief and workers.,이 정책은 장과 근로자에게 좋습니다.,,
1788,"Never

This means pods that terminate will never be restarted.","못

이는 종료되는 포드가 다시 시작되지 않음을 의미합니다.",,
1789,"This policy should rarely be used, because Kubernetes will terminate pods for any number of reasons (e.g., node becomes unhealthy) and this will prevent the job from recovering.",Kubernetes는 여러 가지 이유로 (예 : 노드가 비정상 상태가 됨) 포드를 종료하고 이로 인해 작업이 복구되지 않기 때문에이 정책은 거의 사용되지 않아야합니다.,,
1790,"Once you have the TFJob spec written, deploy it to your Kubeflow cluster:
kubectl apply -f dist-mnist.yaml
Monitoring the job status is similar to a single-container job:
kubectl describe tfjob mnist
This should output something like EXAMPLE 7-16.","TFJob 사양을 작성했으면 Kubeflow 클러스터에 배포합니다.
kubectl apply -f dist-mnist.yaml
작업 상태 모니터링은 단일 컨테이너 작업과 유사합니다.
kubectl describe tfjob mnist
이것은 EXAMPLE 7-16과 같은 것을 출력해야합니다.",,
1791,Example 7-16.,예 7-16.,,
1792,"TFJob execution result
Status:
  Completion Time:  2019-05-12T00:58:27Z
  Conditions:
    Last Transition Time:  2019-05-12T00:57:31Z
    Last Update Time:      2019-05-12T00:57:31Z
    Message:               TFJob dist-mnist-example is created.","TFJob 실행 결과
상태:
  완료 시간 : 2019-05-12T00 : 58 : 27Z
  정황:
    마지막 전환 시간 : 2019-05-12T00 : 57 : 31Z
    마지막 업데이트 시간 : 2019-05-12T00 : 57 : 31Z
    메시지 : TFJob dist-mnist-example이 생성되었습니다.",,
1793,"Reason:                TFJobCreated
    Status:                True
    Type:                  Created
    Last Transition Time:  2019-05-12T00:58:21Z
    Last Update Time:      2019-05-12T00:58:21Z
    Message:               TFJob dist-mnist-example is running.","이유 : TFJobCreated
    상태 : 참
    유형 : 생성됨
    마지막 전환 시간 : 2019-05-12T00 : 58 : 21Z
    마지막 업데이트 시간 : 2019-05-12T00 : 58 : 21Z
    메시지 : TFJob dist-mnist-example이 실행 중입니다.",,
1794,"Reason:                TFJobRunning
    Status:                False
    Type:                  Running
    Last Transition Time:  2019-05-12T00:58:27Z
    Last Update Time:      2019-05-12T00:58:27Z
    Message:               TFJob dist-mnist-example successfully completed.","이유 : TFJobRunning
    상태 : 거짓
    유형 : 달리기
    마지막 전환 시간 : 2019-05-12T00 : 58 : 27Z
    마지막 업데이트 시간 : 2019-05-12T00 : 58 : 27Z
    메시지 : TFJob dist-mnist-example이 성공적으로 완료되었습니다.",,
1795,"Reason:                TFJobSucceeded
    Status:                True
    Type:                  Succeeded
  Replica Statuses:
    Worker:
      Succeeded:  2
Notice that the Replica Statuses field shows a breakdown of status by each replica type.","이유 : TFJobSucceeded
    상태 : 참
    유형 : 성공
  복제본 상태 :
    노동자:
      성공 : 2
Replica Statuses 필드에는 각 복제본 유형별 상태 분석이 표시됩니다.",,
1796,The TFJob is successfully completed when all of its workers complete.,모든 작업자가 완료되면 TFJob이 성공적으로 완료됩니다.,,
1797,"If any worker has failed, then the TFJob’s status would be failed as well.",작업자가 실패하면 TFJob의 상태도 실패합니다.,,
1798,7.3.1.,7.3.1.,,
1799,"Using GPUs
GPUs are processors that are composed of many smaller and specialized cores.","GPU 사용
GPU는 더 작고 특수한 코어로 구성된 프로세서입니다.",,
1800,"Originally designed to render graphics, GPUs are increasingly used for massively parallel computational tasks, such as machine learning.",원래 그래픽을 렌더링하도록 설계된 GPU는 기계 학습과 같은 대규모 병렬 계산 작업에 점점 더 많이 사용됩니다.,,
1801,"Unlike CPUs, GPUs are ideal for distributing large workloads over its many cores and executing them concurrently.",CPU와 달리 GPU는 많은 코어에 대규모 워크로드를 분산하고 동시에 실행하는 데 이상적입니다.,,
1802,"To use GPUs for training, your Kubeflow cluster needs to be preconfigured to enable GPUs.",훈련에 GPU를 사용하려면 GPU를 활성화하도록 Kubeflow 클러스터를 사전 구성해야합니다.,,
1803,Refer to your cloud provider’s documentation on enabling GPU usage.,GPU 사용 활성화에 대한 클라우드 제공 업체의 문서를 참조하세요.,,
1804,"After enabling GPUs on the cluster, you can enable GPUs on the specific replica type in the training spec by modifying the command-line arguments, as in EXAMPLE 7-17.",클러스터에서 GPU를 활성화 한 후 예제 7-17에서와 같이 명령 줄 인수를 수정하여 훈련 사양의 특정 복제본 유형에서 GPU를 활성화 할 수 있습니다.,,
1805,Example 7-17.,예 7-17.,,
1806,"TFJob with GPU example
    Worker:
      replicas: 4
      restartPolicy: Never
      template:
        spec:
          containers:
            - name: tensorflow
              image: kubeflow/tf-dist-mnist-test:1.0
              args:
            - python
            - /var/tf_dist_mnist/dist_mnist.py
            - --num_gpus=1


7.3.2.","GPU를 사용한 TFJob 예제
    노동자:
      복제본 : 4
      restartPolicy : 없음
      주형:
        투기:
          용기 :
            -이름 : tensorflow
              이미지 : kubeflow / tf-dist-mnist-test : 1.0
              인수 :
            -파이썬
            -/var/tf_dist_mnist/dist_mnist.py
            ---num_gpus = 1


7.3.2.",,
1807,"Using Other Frameworks for Distributed Training
Kubeflow is designed to be a multiframework machine learning platform.","분산 교육에 다른 프레임 워크 사용
Kubeflow는 멀티 프레임 워크 머신 러닝 플랫폼으로 설계되었습니다.",,
1808,That means the schema for distributed training can easily be extended to other frameworks.,"즉, 분산 교육을위한 스키마를 다른 프레임 워크로 쉽게 확장 할 수 있습니다.",,
1809,"As of the time of this writing, there are a number of operators written to provide first-class support for other frameworks, including PyTorch and Caffe2.",이 글을 쓰는 시점에서 PyTorch 및 Caffe2를 포함하여 다른 프레임 워크에 대한 최고 수준의 지원을 제공하기 위해 작성된 여러 연산자가 있습니다.,,
1810,EXAMPLE 7-18 shows what a PyTorch training job spec looks like.,예 7-18은 PyTorch 학습 작업 사양이 어떻게 보이는지 보여줍니다.,,
1811,Example 7-18.,예 7-18.,,
1812,"Pytorch Distributed Training Example
apiVersion: ""kubeflow.org/v1""
kind: ""PyTorchJob""
metadata:
  name: ""pytorch-dist""
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - name: pytorch
              image: gcr.io/kubeflow-ci/pytorch-dist-sendrecv-test:1.0
    Worker:
      replicas: 3
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - name: pytorch
              image: gcr.io/kubeflow-ci/pytorch-dist-sendrecv-test:1.0
As you can see, the format is very similar to that of TFJobs.","Pytorch 분산 교육 예제
apiVersion : ""kubeflow.org/v1""
종류 : ""PyTorchJob""
메타 데이터 :
  이름 : ""pytorch-dist""
투기:
  pytorchReplicaSpecs :
    석사:
      복제본 : 1
      restartPolicy : OnFailure
      주형:
        투기:
          용기 :
            -이름 : pytorch
              이미지 : gcr.io/kubeflow-ci/pytorch-dist-sendrecv-test:1.0
    노동자:
      복제본 : 3
      restartPolicy : OnFailure
      주형:
        투기:
          용기 :
            -이름 : pytorch
              이미지 : gcr.io/kubeflow-ci/pytorch-dist-sendrecv-test:1.0
보시다시피 형식은 TFJobs의 형식과 매우 유사합니다.",,
1813,The only difference is in the replica types.,유일한 차이점은 복제본 유형입니다.,,
1814,7.4.,7.4.,,
1815,"Training a Model Using Scikit-Learn
Thus far we have seen how to use the built-in operators in Kubeflow to train machine learning models.","Scikit-Learn을 사용하여 모델 훈련
지금까지 Kubeflow의 기본 제공 연산자를 사용하여 기계 학습 모델을 학습하는 방법을 살펴 보았습니다.",,
1816,"However, there are many frameworks and libraries for which there are no Kubeflow operators.",그러나 Kubeflow 연산자가없는 많은 프레임 워크와 라이브러리가 있습니다.,,
1817,In these cases you can still use your favorite frameworks in Jupyter notebooks[3] or in custom Docker images.,이러한 경우 Jupyter 노트북 [3] 또는 사용자 지정 Docker 이미지에서 선호하는 프레임 워크를 계속 사용할 수 있습니다.,,
1818,Scikit-learn is an open source Python library for machine learning built on top of NumPy for high-performance linear algebra and array operations.,Scikit-learn은 고성능 선형 대수 및 배열 작업을 위해 NumPy를 기반으로 구축 된 기계 학습용 오픈 소스 Python 라이브러리입니다.,,
1819,"The project started as scikits.learn, a Google Summer of Code project by David Cournapeau.",이 프로젝트는 David Cournapeau의 Google Summer of Code 프로젝트 인 scikits.learn으로 시작되었습니다.,,
1820,"Its name stems from the notion that it is a “SciKit” (SciPy Toolkit), a separately developed and distributed third-party extension to SciPy.","그 이름은 SciPy에 대해 별도로 개발 및 배포 된 타사 확장 프로그램 인 ""SciKit""(SciPy Toolkit)이라는 개념에서 유래되었습니다.",,
1821,"Scikit-learn is one of the most popular machine learning libraries on GitHub, and one of the best-maintained.",Scikit-learn은 GitHub에서 가장 인기있는 기계 학습 라이브러리 중 하나이며 가장 잘 관리되는 라이브러리 중 하나입니다.,,
1822,"Training models with Scikit-learn is supported in Kubeflow as generic Python code, with no specific operators for distributed training.",Scikit-learn을 사용한 학습 모델은 분산 학습을위한 특정 연산자없이 일반 Python 코드로 Kubeflow에서 지원됩니다.,,
1823,"The library supports state-of-the-art algorithms such as KNN, XGBoost, Random Forest, and SVM.","라이브러리는 KNN, XGBoost, Random Forest 및 SVM과 같은 최첨단 알고리즘을 지원합니다.",,
1824,Scikit-learn is widely used in Kaggle competitions and by prominent tech companies.,Scikit-learn은 Kaggle 대회와 저명한 기술 회사에서 널리 사용됩니다.,,
1825,"Scikit-learn helps in preprocessing, dimensionality reduction (parameter selection), classification, regression, clustering, and model selection.","Scikit-learn은 전처리, 차원 축소 (파라미터 선택), 분류, 회귀, 클러스터링 및 모델 선택을 지원합니다.",,
1826,"In this section, we will explore how to train models in Kubeflow by using Scikit-learn on the 1994 US Census dataset.",이 섹션에서는 1994 년 미국 인구 조사 데이터 세트에서 Scikit-learn을 사용하여 Kubeflow에서 모델을 학습시키는 방법을 살펴 봅니다.,,
1827,"This example is based on this implementation of Anchor explanations for income prediction, and leverages an extract from the 1994 census dataset.",이 예는 소득 예측에 대한 앵커 설명 구현을 기반으로하며 1994 년 인구 조사 데이터 세트에서 발췌 한 내용을 활용합니다.,,
1828,"The dataset includes several categorical variables and continuous features, including age, education, marital status, occupation, salary, relationship, race, sex, native country, and capital gains and losses.","데이터 세트에는 연령, 교육, 결혼 상태, 직업, 급여, 관계, 인종, 성별, 모국, 자본 이득 및 손실을 비롯한 여러 범주 변수와 연속 기능이 포함됩니다.",,
1829,"We will use a Random Forest algorithm—an ensemble learning method for classification, regression, and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.","우리는 Random Forest 알고리즘을 사용할 것입니다. 분류, 회귀 및 학습 시간에 다수의 의사 결정 트리를 구성하고 클래스 (분류) 또는 평균 예측 (회귀).",,
1830,You can download the notebook from this book’s GitHub repo.,이 책의 GitHub 저장소에서 노트북을 다운로드 할 수 있습니다.,,
1831,7.4.1.,7.4.1.,,
1832,"Starting a New Notebook Session
Let’s start by creating a new notebook.","새 노트북 세션 시작
새 노트북을 만들어 보겠습니다.",,
1833,"Similar to TensorFlow training, you can do this by navigating to the “Notebook Servers” panel in your Kubeflow dashboard, then clicking “New Server” and following the instructions.","TensorFlow 교육과 유사하게 Kubeflow 대시 보드의 ""Notebook Servers""패널로 이동 한 다음 ""New Server""를 클릭하고 지침에 따라이를 수행 할 수 있습니다.",,
1834,"For this example, we can use the tensorFlow-1.15.2-notebook-cpu:1.0 image.",이 예에서는 tensorFlow-1.15.2-notebook-cpu : 1.0 이미지를 사용할 수 있습니다.,,
1835,"Tip
When working in Kubeflow, an easy way to take advantage of GPU resources to accelerate your Scikit model is to switch to GPU type.","팁
Kubeflow에서 작업 할 때 GPU 리소스를 활용하여 Scikit 모델을 가속화하는 쉬운 방법은 GPU 유형으로 전환하는 것입니다.",,
1836,"When the notebook server starts up, click the “Upload” button in the top right corner and upload the IncomePrediction.ipynb file.",노트북 서버가 시작되면 오른쪽 상단의“업로드”버튼을 클릭하고 IncomePrediction.ipynb 파일을 업로드합니다.,,
1837,Click the file to start a new session.,새 세션을 시작하려면 파일을 클릭하십시오.,,
1838,7.4.2.,7.4.2.,,
1839,"Data Preparation
The first few sections of the notebook involve importing libraries and reading the data.","데이터 준비
노트북의 처음 몇 섹션에는 라이브러리 가져 오기 및 데이터 읽기가 포함됩니다.",,
1840,Then we proceed to feature preparation.,그런 다음 기능 준비를 진행합니다.,,
1841,[4] For feature transformation we are using Scikit-learn pipelines.,[4] 기능 변환을 위해 Scikit-learn 파이프 라인을 사용합니다.,,
1842,The pipeline makes it easier to feed the model with consistent data.,파이프 라인을 사용하면 일관된 데이터로 모델을 더 쉽게 공급할 수 있습니다.,,
1843,"For our Random Forest training, we need to define ordinal (standardize data) and categorical (one-hot encoding) features, as in EXAMPLE 7-19.",Random Forest 훈련의 경우 예 7-19에서와 같이 서수 (데이터 표준화) 및 범주 (원-핫 인코딩) 기능을 정의해야합니다.,,
1844,Example 7-19.,예 7-19.,,
1845,"Feature preparation
ordinal_features = [x for x in range(len(feature_names))
                if x not in list(category_map.keys())]
ordinal_transformer = Pipeline(steps=[
    ('imputer',  SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_features = list(category_map.keys())
categorical_transformer = Pipeline(steps=[('imputer',
    SimpleImputer(strategy='median')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])
Tip
Many real-world datasets contain missing values, which are encoded by data-specific placeholders, such as blanks and NaNs.","기능 준비
ordinal_features = [x for x in range (len (feature_names))
                x가 목록에없는 경우 (category_map.keys ())]
ordinal_transformer = 파이프 라인 (단계 = [
    ( 'imputer', SimpleImputer (전략 = 'median')),
    ( '스케일러', StandardScaler ())])

categorical_features = list (category_map.keys ())
categorical_transformer = 파이프 라인 (단계 = [( 'imputer',
    SimpleImputer (전략 = 'median')),
    ( 'onehot', OneHotEncoder (handle_unknown = 'ignore'))])
팁
많은 실제 데이터 세트에는 공백 및 NaN과 같은 데이터 별 플레이스 홀더로 인코딩 된 누락 된 값이 포함되어 있습니다.",,
1846,"Such datasets are typically incompatible with Scikit-learn estimators, which assume that all values are numerical.",이러한 데이터 세트는 일반적으로 모든 값이 숫자라고 가정하는 Scikit-learn 추정기와 호환되지 않습니다.,,
1847,There are multiple strategies to deal with such missing data.,이러한 누락 된 데이터를 처리하기위한 여러 전략이 있습니다.,,
1848,"One basic strategy would be to discard entire rows and/or columns containing missing values, which comes at the price of losing data.",하나의 기본 전략은 누락 된 값을 포함하는 전체 행 및 / 또는 열을 삭제하는 것입니다.이 경우 데이터 손실의 대가가 따릅니다.,,
1849,A better strategy is to impute the missing values—to infer them from the known part of the data.,더 나은 전략은 누락 된 값을 대치하여 데이터의 알려진 부분에서 추론하는 것입니다.,,
1850,Simple imputer is a Scikit-learn class that allows you to handle the missing data in the predictive model dataset by replacing the NaN values with specified predefined values.,Simple imputer는 NaN 값을 지정된 미리 정의 된 값으로 대체하여 예측 모델 데이터 세트에서 누락 된 데이터를 처리 할 수있는 Scikit-learn 클래스입니다.,,
1851,"Once features are defined, we can use a column transformer to combine them, as shown in EXAMPLE 7-20.",특성이 정의되면 예 7-20에 표시된대로 열 변환기를 사용하여 결합 할 수 있습니다.,,
1852,Example 7-20.,예 7-20.,,
1853,"Combining columns using column transformer
preprocessor = ColumnTransformer(transformers=[
    ('num', ordinal_transformer, ordinal_features),
    ('cat', categorical_transformer, categorical_features)])
preprocessor.fit(X_train)
Tip
Scikit-learn one-hot encoding is used to encode categorical features as a one-hot numeric array.","컬럼 변환기를 사용하여 컬럼 결합
전 처리기 = ColumnTransformer (transformers = [
    ( 'num', ordinal_transformer, ordinal_features),
    ( '고양이', categorical_transformer, categorical_features)])
전 처리기 .fit (X_train)
팁
Scikit-learn 원-핫 인코딩은 범주 기능을 원-핫 숫자 배열로 인코딩하는 데 사용됩니다.",,
1854,"The encoder transforms an array of integers or strings, replacing the values by categorical (discrete) features.",인코더는 정수 또는 문자열 배열을 변환하여 값을 범주 (이산) 기능으로 대체합니다.,,
1855,"The features are encoded using a one-hot (aka, one-of-K or dummy) encoding scheme.","기능은 원-핫 (일명, one-of-K 또는 더미) 인코딩 체계를 사용하여 인코딩됩니다.",,
1856,This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse parameter).,이렇게하면 각 범주에 대한 이진 열이 생성되고 희소 행렬 또는 조밀 배열이 반환됩니다 (희소 매개 변수에 따라 다름).,,
1857,The transformer itself looks like EXAMPLE 7-21.,변압기 자체는 예제 7-21과 같습니다.,,
1858,Example 7-21.,예 7-21.,,
1859,"Data transformer
ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,
  transformer_weights=None,
  transformers=[('num',
    Pipeline(memory=None,
      steps=[
        ('imputer', SimpleImputer(add_indicator=False,
          copy=True,
          fill_value=None,
          missing_values=nan,
          strategy='median',
          verbose=0)),
        ('scaler', StandardScaler(copy=True,
          with_mean=True,
          with_std=True))],
        verbose=False),
      [0, 8, 9, 10]),
    ('cat',
     Pipeline(memory=None,
       steps=[('imputer', SimpleImputer(add_indicator=False,
         copy=True,
         fill_value=None,
         missing_values=nan,
         strategy='median',
         verbose=0)),
       ('onehot', OneHotEncoder(categories='auto',
         drop=None,
         dtype=<class 'numpy.float64'>,
         handle_unknown='ignore',
         sparse=True))],
       verbose=False),
       [1, 2, 3, 4, 5, 6, 7, 11])],
    verbose=False)
As a result of this transformation, we have our data in the form of features ready for training.","데이터 변환기
ColumnTransformer (n_jobs = None, 나머지 = 'drop', sparse_threshold = 0.3,
  Transformer_weights = 없음,
  변환기 = [( 'num',
    Pipeline (memory = None,
      steps = [
        ( 'imputer', SimpleImputer (add_indicator = False,
          copy = True,
          fill_value = 없음,
          missing_values ​​= nan,
          전략 = 'median',
          verbose = 0)),
        ( 'scaler', StandardScaler (copy = True,
          with_mean = 참,
          with_std = True))],
        verbose = False),
      [0, 8, 9, 10]),
    ('고양이',
     Pipeline (memory = None,
       steps = [( 'imputer', SimpleImputer (add_indicator = False,
         copy = True,
         fill_value = 없음,
         missing_values ​​= nan,
         전략 = 'median',
         verbose = 0)),
       ( 'onehot', OneHotEncoder (categories = 'auto',
         drop = 없음,
         dtype = <class 'numpy.float64'>,
         handle_unknown = '무시',
         sparse = True))],
       verbose = False),
       [1, 2, 3, 4, 5, 6, 7, 11])],
    verbose = 거짓)
이 변환의 결과로 우리는 훈련 할 준비가 된 기능의 형태로 데이터를 얻었습니다.",,
1860,7.4.3.,7.4.3.,,
1861,"Scikit-Learn Training
Once we have our features prepared we can proceed with the training.","Scikit-Learn 교육
기능이 준비되면 교육을 진행할 수 있습니다.",,
1862,"Here we will use RandomForestClassifier, provided by the Scikit-learn library, as shown in EXAMPLE 7-22.",여기에서는 Scikit-learn 라이브러리에서 제공하는 RandomForestClassifier를 사용합니다 (예제 7-22 참조).,,
1863,Example 7-22.,예 7-22.,,
1864,"Using RandomForestClassifier
np.random.seed(0)
clf = RandomForestClassifier(n_estimators=50)
clf.fit(preprocessor.transform(X_train), Y_train)
Tip
The set and specific features of machine learning algorithm(s) is one of the main drivers behind picking a specific framework for machine learning implementation.","RandomForestClassifier 사용
np.random.seed (0)
clf = RandomForestClassifier (n_estimators = 50)
clf.fit (전 처리기. 변환 (X_train), Y_train)
팁
기계 학습 알고리즘의 집합 및 특정 기능은 기계 학습 구현을위한 특정 프레임 워크를 선택하는 주요 동인 중 하나입니다.",,
1865,Even the same algorithm implementation in different frameworks provides slightly different features that might (or might not) be important for your specific dataset.,다른 프레임 워크에서 동일한 알고리즘을 구현하더라도 특정 데이터 세트에 중요하거나 중요하지 않을 수있는 약간 다른 기능을 제공합니다.,,
1866,"Once prediction is done, we can evaluate training results, as shown in EXAMPLE 7-23.",예측이 완료되면 예제 7-23에 표시된대로 훈련 결과를 평가할 수 있습니다.,,
1867,Example 7-23.,예 7-23.,,
1868,"Evaluating training results
predict_fn = lambda x: clf.predict(preprocessor.transform(x))
print('Train accuracy: ', accuracy_score(Y_train, predict_fn(X_train)))
print('Test accuracy: ', accuracy_score(Y_test, predict_fn(X_test)))
Which returns the results in EXAMPLE 7-24.","훈련 결과 평가
predict_fn = 람다 x : clf.predict (preprocessor.transform (x))
print ( '기차 정확도 :', 정확도 _ 점수 (Y_train, predict_fn (X_train)))
print ( '테스트 정확도 :', 정확도 _ 점수 (Y_test, predict_fn (X_test)))
예 7-24의 결과를 반환합니다.",,
1869,Example 7-24.,예 7-24.,,
1870,"Training results
Train accuracy:  0.9655333333333334
Test accuracy:  0.855859375
At this point the model is created and can be directly used by exporting it (see the next section).","훈련 결과
열차 정확도 : 0.9655333333333334
테스트 정확도 : 0.855859375
이 시점에서 모델이 생성되고 내보내기를 통해 직접 사용할 수 있습니다 (다음 섹션 참조).",,
1871,One of the most important attributes of a model is its explainability.,모델의 가장 중요한 속성 중 하나는 설명 가능성입니다.,,
1872,"Although model explainability is mostly used in model serving, it is also important for model creation, for two main reasons:


If explainability is important for model serving during model creation, we often need to validate that the model that was created is explainable.","모델 설명 가능성은 주로 모델 제공에 사용되지만 다음 두 가지 주요 이유로 모델 생성에도 중요합니다.


모델 생성 중 모델 제공에 대해 설명 가능성이 중요한 경우 생성 된 모델이 설명 가능한지 종종 검증해야합니다.",,
1873,Many of the model explanation methods require additional calculations during model creation.,많은 모델 설명 방법은 모델 생성 중에 추가 계산이 필요합니다.,,
1874,"Based on this, we will show how to implement model explainability[5] during model creation.",이를 바탕으로 모델 생성시 모델 설명 가능성 [5]을 구현하는 방법을 보여줍니다.,,
1875,7.4.4.,7.4.4.,,
1876,"Explaining the Model
For model explanation, we are using anchors, which are part of Seldon’s Alibi project.","모델 설명
모델 설명을 위해 Seldon의 Alibi 프로젝트의 일부인 앵커를 사용하고 있습니다.",,
1877,"The algorithm provides model-agnostic (black box) and human-interpretable explanations suitable for classification models applied to images, text, and tabular data.","이 알고리즘은 이미지, 텍스트 및 표 형식 데이터에 적용되는 분류 모델에 적합한 모델에 구애받지 않는 (블랙 박스) 및 사람이 해석 할 수있는 설명을 제공합니다.",,
1878,"The continuous features are discretized into quantiles (e.g., deciles), so they become more interpretable.",연속 특성은 분위수 (예 : 십 분위수)로 이산화되므로 더 쉽게 해석 할 수 있습니다.,,
1879,"The features in a candidate anchor are kept constant (same category or bin for discretized features) while we sample the other features from a training set, as in EXAMPLE 7-25.","후보 앵커의 특성은 일정하게 유지되며 (이산화 된 특성에 대해 동일한 범주 또는 빈), 예제 7-25에서와 같이 학습 세트에서 다른 특성을 샘플링합니다.",,
1880,Example 7-25.,예 7-25.,,
1881,"Defining the tabular anchor
explainer = AnchorTabular(
    predict_fn, feature_names, categorical_names=category_map, seed=1)
explainer.fit(X_train, disc_perc=[25, 50, 75])
This creates the tabular anchor (EXAMPLE 7-26).","테이블 형식 앵커 정의
설명자 = AnchorTabular (
    predict_fn, feature_names, categorical_names = category_map, seed = 1)
explainer.fit (X_train, disc_perc = [25, 50, 75])
이렇게하면 테이블 형식 앵커가 생성됩니다 (예 7-26).",,
1882,Example 7-26.,예 7-26.,,
1883,"Tabular anchor
AnchorTabular(meta={
    'name': 'AnchorTabular',
    'type': ['blackbox'],
    'explanations': ['local'],
    'params': {'seed': 1, 'disc_perc': [25, 50, 75]}
})
Now we can get an anchor for the prediction of the first observation in the test set.","테이블 형식 앵커
AnchorTabular (meta = {
    'name': 'AnchorTabular',
    '유형': [ '블랙 박스'],
    '설명': [ '지역'],
    'params': { 'seed': 1, 'disc_perc': [25, 50, 75]}
})
이제 테스트 세트에서 첫 번째 관측치의 예측을위한 앵커를 얻을 수 있습니다.",,
1884,"An anchor is a sufficient condition—that is, when the anchor holds, the prediction should be the same as the prediction for this instance in EXAMPLE 7-27.","앵커는 충분한 조건입니다. 즉, 앵커가 유지 될 때 예측은 예 7-27의이 인스턴스에 대한 예측과 동일해야합니다.",,
1885,Example 7-27.,예 7-27.,,
1886,"Prediction calculation
idx = 0
class_names = adult.target_names
print('Prediction: ', class_names[explainer.predictor( \
                X_test[idx].reshape(1, -1))[0]])
Which returns a prediction calculation result as shown in EXAMPLE 7-28.","예측 계산
idx = 0
class_names = adult.target_names
print ( '예측 :', class_names [explainer.predictor (\
                X_test [idx] .reshape (1, -1)) [0]])
예 7-28에 표시된 예측 계산 결과를 반환합니다.",,
1887,Example 7-28.,예 7-28.,,
1888,"Prediction calculation result
Prediction:  <=50K
We set the precision threshold to 0.95.","예측 계산 결과
예측 : <= 50,000
정밀도 임계 값을 0.95로 설정했습니다.",,
1889,This means that predictions on observations where the anchor holds will be the same as the prediction on the explained instance at least 95% of the time.,이는 앵커가 보유한 관측치에 대한 예측이 설명 된 인스턴스에 대한 예측과 적어도 95 %의 시간 동안 동일하다는 것을 의미합니다.,,
1890,"Now we can get an explanation (EXAMPLE 7-29) for this 
prediction.","이제 이에 대한 설명 (예 7-29)을 얻을 수 있습니다.
예측.",,
1891,Example 7-29.,예 7-29.,,
1892,"Model explanation
explanation = explainer.explain(X_test[idx], threshold=0.95)
print('Anchor: %s' % (' AND '.join(explanation.anchor)))
print('Precision: %.2f' % explanation.precision)
print('Coverage: %.2f' % explanation.coverage)
Which returns a model explanation result as shown in EXAMPLE 7-30.","모델 설명
설명 = explainer.explain (X_test [idx], 임계 값 = 0.95)
print ( '앵커 : % s'% ( 'AND'.join (explanation.anchor)))
print ( '정밀도 : % .2f'% 설명. 정밀도)
print ( '범위 : % .2f'% 설명. 범위)
예 7-30과 같이 모델 설명 결과를 반환합니다.",,
1893,Example 7-30.,예 7-30.,,
1894,"Model explanation result
Anchor: Marital Status = Separated AND Sex = Female
Precision: 0.95
Coverage: 0.18
This tells us that the main factors for decision are marital status (Separated) and sex (Female).","모델 설명 결과
앵커 : 결혼 상태 = 별거 AND 성별 = 여성
정밀도 : 0.95
범위 : 0.18
이는 결정의 주요 요인이 결혼 상태 (별거)와 성별 (여성)임을 알려줍니다.",,
1895,Anchors might not be found for all points.,모든 포인트에 대한 앵커를 찾지 못할 수 있습니다.,,
1896,"Let’s try getting an anchor for a different observation in the test set—one for which the prediction is >50K, shown in EXAMPLE 7-31.",테스트 세트에서 다른 관측치에 대한 앵커를 가져와 보겠습니다. 예 7-31에 표시된 것과 같이 예측값이 50K를 초과하는 관측치입니다.,,
1897,Example 7-31.,예 7-31.,,
1898,"Model explanation
idx = 6
class_names = adult.target_names
print('Prediction: ', class_names[explainer.predictor( \
                X_test[idx].reshape(1, -1))[0]])

explanation = explainer.explain(X_test[idx], threshold=0.95)
print('Anchor: %s' % (' AND '.join(explanation.anchor)))
print('Precision: %.2f' % explanation.precision)
print('Coverage: %.2f' % explanation.coverage)
Which returns a model explanation result as shown in EXAMPLE 7-32.","모델 설명
idx = 6
class_names = adult.target_names
print ( '예측 :', class_names [explainer.predictor (\
                X_test [idx] .reshape (1, -1)) [0]])

설명 = explainer.explain (X_test [idx], 임계 값 = 0.95)
print ( '앵커 : % s'% ( 'AND'.join (explanation.anchor)))
print ( '정밀도 : % .2f'% 설명. 정밀도)
print ( '범위 : % .2f'% 설명. 범위)
예 7-32에 표시된대로 모델 설명 결과를 반환합니다.",,
1899,Example 7-32.,예 7-32.,,
1900,"Model explanation result
Prediction:  >50K
Could not find a result satisfying the 0.95 precision constraint.","모델 설명 결과
예측 :> 50,000
0.95 정밀도 제약을 만족하는 결과를 찾을 수 없습니다.",,
1901,Now returning the best non-eligible result.,이제 부적합한 최상의 결과를 반환합니다.,,
1902,"Anchor: Capital Loss > 0.00 AND Relationship = Husband AND
    Marital Status = Married AND Age > 37.00 AND
    Race = White AND Country = United-States AND Sex = Male
Precision: 0.71
Coverage: 0.05
Due to the imbalanced dataset (roughly 25:75 high:low earner proportion), during the sampling stage feature ranges corresponding to low earners will be oversampled.","앵커 : 자본 손실> 0.00 AND 관계 = 남편 AND
    결혼 상태 = 결혼 및 연령> 37.00 및
    인종 = 백인 및 국가 = 미국 및 성별 = 남성
정밀도 : 0.71
범위 : 0.05
불균형 데이터 세트 (약 25:75 고소득자 비율)로 인해 샘플링 단계 동안 저소득자에 해당하는 기능 범위가 오버 샘플링됩니다.",,
1903,"As a result, the anchor in this case is not found.",결과적으로이 경우 앵커를 찾을 수 없습니다.,,
1904,"This is a feature because it can point out an imbalanced dataset, but it can also be fixed by producing balanced datasets to enable anchors to be found for either class.","이것은 불균형 데이터 세트를 지적 할 수 있기 때문에 기능이지만, 균형 데이터 세트를 생성하여 두 클래스 중 하나에 대한 앵커를 찾을 수 있도록하여 수정할 수도 있습니다.",,
1905,7.4.5.,7.4.5.,,
1906,"Exporting Model
In order to use the created model for serving, we need to export the model.","모델 내보내기
생성 된 모델을 서빙에 사용하려면 모델을 내 보내야합니다.",,
1907,"This is done using Scikit-learn functionality, as in EXAMPLE 7-33.",이는 예제 7-33에서와 같이 Scikit-learn 기능을 사용하여 수행됩니다.,,
1908,Example 7-33.,예 7-33.,,
1909,"Exporting model
dump(clf, '/tmp/job/income.joblib')
This exports a model in Scikit-learn format, that can be used by, for example, Scikit-learn server for inference.","모델 내보내기
덤프 (clf, '/tmp/job/income.joblib')
예를 들어 추론을 위해 Scikit-learn 서버에서 사용할 수있는 Scikit-learn 형식의 모델을 내 보냅니다.",,
1910,7.4.6.,7.4.6.,,
1911,"Integration into Pipelines
Regardless of which Python-based machine learning library you want to use, if Kubeflow doesn’t have an operator for it, you can simply write your code as normal and then containerize it.","파이프 라인에 통합
사용하려는 Python 기반 기계 학습 라이브러리에 관계없이 Kubeflow에 연산자가없는 경우 코드를 정상적으로 작성한 다음 컨테이너화하면됩니다.",,
1912,"To take the notebook we built in this chapter and use it as a pipeline stage, see SECTION 5.5.",이 장에서 구축 한 노트북을 파이프 라인 단계로 사용하려면 SECTION 5.5를 참조하십시오.,,
1913,"Here we can use file_output to upload the resulting model to our artifact tracking system, but you can also use the persistent volume mechanism.",여기서 file_output을 사용하여 결과 모델을 아티팩트 추적 시스템에 업로드 할 수 있지만 영구 볼륨 메커니즘을 사용할 수도 있습니다.,,
1914,7.5.,7.5.,,
1915,"Conclusion
In this chapter, we have taken a look at how to train machine learning models in Kubeflow using two very different frameworks: TensorFlow and Scikit-learn.","결론
이 장에서는 두 가지 매우 다른 프레임 워크 인 TensorFlow와 Scikit-learn을 사용하여 Kubeflow에서 기계 학습 모델을 학습시키는 방법을 살펴 보았습니다.",,
1916,We learned how to build a collaborative filtering recommendation system using TensorFlow.,TensorFlow를 사용하여 협업 필터링 추천 시스템을 구축하는 방법을 배웠습니다.,,
1917,"We used Kubeflow to create a notebook session, where we’ve prototyped a TensorFlow model with Keras APIs, and then used the TFJob APIs to deploy our training job to a Kubernetes cluster.",Kubeflow를 사용하여 Keras API로 TensorFlow 모델의 프로토 타입을 만든 노트북 세션을 만든 다음 TFJob API를 사용하여 Kubernetes 클러스터에 학습 작업을 배포했습니다.,,
1918,"Finally, we’ve looked at how to use TFJob for distributed training.",마지막으로 분산 교육에 TFJob을 사용하는 방법을 살펴 보았습니다.,,
1919,"We also learned how to train a generic Python model using Scikit-learn, a framework that is not natively supported by Kubeflow.",또한 Kubeflow에서 기본적으로 지원하지 않는 프레임 워크 인 Scikit-learn을 사용하여 일반 Python 모델을 학습시키는 방법도 배웠습니다.,,
1920,"CHAPTER 9 looks at how to integrate nonsupported non-Python machine learning systems, which is a bit more complicated.",9 장은 지원되지 않는 비 Python 기계 학습 시스템을 통합하는 방법을 살펴 봅니다. 이는 좀 더 복잡합니다.,,
1921,"While Kubeflow’s first-party training operators can simplify your work, it’s important to remember you aren’t limited by this.",Kubeflow의 자사 교육 운영자는 작업을 단순화 할 수 있지만 이것으로 제한되지 않는다는 점을 기억하는 것이 중요합니다.,,
1922,In CHAPTER 8 we will look at how to serve the model that we’ve trained in this chapter.,8 장에서는이 장에서 학습 한 모델을 제공하는 방법을 살펴 보겠습니다.,,
1923,"[1] Currently Kubeflow provides CPU and GPU images with TensorFlow 1.15.2 and 2.1.0, or you can use a custom image.",[1] 현재 Kubeflow는 TensorFlow 1.15.2 및 2.1.0과 함께 CPU 및 GPU 이미지를 제공하거나 사용자 지정 이미지를 사용할 수 있습니다.,,
1924,[2] The examples in this chapter use TensorFlow 1.15.2.,[2]이 장의 예제에서는 TensorFlow 1.15.2를 사용합니다.,,
1925,Examples with TensorFlow 2.1.0 can be found on this Kubeflow GitHub site.,TensorFlow 2.1.0의 예제는이 Kubeflow GitHub 사이트에서 찾을 수 있습니다.,,
1926,"[3] The languages currently supported by Jupyter notebooks include Python, R, Julia, and Scala.","[3] 현재 Jupyter 노트북에서 지원하는 언어에는 Python, R, Julia 및 Scala가 있습니다.",,
1927,[4] See CHAPTER 5 for an in-depth discussion of feature preparation.,[4] 기능 준비에 대한 자세한 내용은 5 장을 참조하십시오.,,
1928,[5] Refer to this blog post by Rui Aguiar for more information on model explainability.,[5] 모델 설명 가능성에 대한 자세한 내용은 Rui Aguiar의이 블로그 게시물을 참조하십시오.,,
1929,Chapter 8.,8 장.,,
1930,"Model Inference
Note
We would like to acknowledge Clive Cox and Alejandro Saucedo from Seldon for their great contributions to this chapter.","모델 추론
노트
이 장에 큰 공헌을 한 Seldon의 Clive Cox와 Alejandro Saucedo에게 감사드립니다.",,
1931,Most of the attention paid to machine learning has been devoted to algorithm development.,기계 학습에 대한 대부분의 관심은 알고리즘 개발에 집중되었습니다.,,
1932,"However, models are not created for the sake of their creation, they are created to be put into production.",그러나 모델은 생성을 위해 생성되지 않고 프로덕션에 투입되도록 생성됩니다.,,
1933,"Usually when people talk about taking a model “to production,” they mean performing inference.","일반적으로 사람들이 모델을 ""프로덕션으로""가져가는 것에 대해 이야기 할 때는 추론을 수행하는 것을 의미합니다.",,
1934,"As introduced in CHAPTER 1 and illustrated in FIGURE 1-1, a complete inference solution seeks to provide serving, monitoring, and updating functionality.","1 장에 소개되고 그림 1-1에 설명 된 것처럼 완전한 추론 솔루션은 서비스, 모니터링 및 업데이트 기능을 제공하려고합니다.",,
1935,"Model serving

Puts a trained model behind a service that can handle prediction requests

Model monitoring

Monitors the model server for any irregularities in performance—as well as the underlying model’s accuracy

Model updating

Fully manages the versioning of your models and simplifies the promotion and rollback between versions


This chapter will explore each of these core components and define expectations for their functionality.","모델 제공

예측 요청을 처리 할 수있는 서비스 뒤에 훈련 된 모델을 배치합니다.

모델 모니터링

모델 서버에서 성능의 불규칙성과 기본 모델의 정확성을 모니터링합니다.

모델 업데이트

모델의 버전 관리를 완전히 관리하고 버전 간 승격 및 롤백을 단순화합니다.


이 장에서는 이러한 각 핵심 구성 요소를 살펴보고 해당 기능에 대한 기대치를 정의합니다.",,
1936,"Given concrete expectations, we will establish a list of requirements that your ideal inference solution will satisfy.",구체적인 기대치를 감안할 때 이상적인 추론 솔루션이 충족 할 요구 사항 목록을 설정합니다.,,
1937,"Lastly, we will discuss Kubeflow-supported inference offerings and how you can use them to satisfy your inference requirements.",마지막으로 Kubeflow에서 지원하는 추론 제품과이를 사용하여 추론 요구 사항을 충족하는 방법에 대해 설명합니다.,,
1938,8.1.,8.1.,,
1939,"Model Serving
The first step of model inference is model serving, which is hosting your model behind a service that you can interface with.","모델 서빙
모델 추론의 첫 번째 단계는 인터페이스 할 수있는 서비스 뒤에서 모델을 호스팅하는 모델 제공입니다.",,
1940,"Two fundamental approaches to model serving are embedded, where the models are deployed directly into the application, and model serving as a service (MaaS), where a separate service dedicated to model serving can be used from any application in the enterprise.",모델 서비스에 대한 두 가지 기본 접근 방식이 내장되어 있습니다. 모델은 애플리케이션에 직접 배포되고 모델 서비스로서의 서비스 (MaaS)는 모델 서비스 전용의 별도 서비스를 기업의 모든 애플리케이션에서 사용할 수 있습니다.,,
1941,TABLE 8-1 provides a comparison of these approaches.,표 8-1은 이러한 접근 방식을 비교 한 것입니다.,,
1942,Table 8-1.,표 8-1.,,
1943,"Comparing embedded with MaaS


Serving types
Advantages
Disadvantages




Embedded



Delivers maximum performance


Features the simplest infrastructure


No need to plan for aberrant user behavior





Model has to be deployed in every application using it


Application updates are required when the model type changes


All deployment strategies, for example blue-green, must be explicitly implemented




MaaS



Simplifies integration with other technologies and organizational processes


Reuses model deployment across multiple stream-processing applications


Allows model serving on lower-power devices (e.g., phones)
incapable of running complex models


Enables mini-batching for requests from multiple clients


Makes it easier to provide built-in capabilities, including model updates, explainability, drift detection, etc.","MaaS와 임베디드 비교


서빙 유형
장점
단점




임베디드



최대 성능 제공


가장 단순한 인프라 특징


비정상적인 사용자 행동을 계획 할 필요가 없습니다.





모델을 사용하는 모든 애플리케이션에 모델을 배포해야합니다.


모델 유형이 변경되면 애플리케이션 업데이트가 필요합니다.


모든 배포 전략 (예 : 청록색)은 명시 적으로 구현되어야합니다.




MaaS



다른 기술 및 조직 프로세스와의 통합을 단순화합니다.


여러 스트림 처리 애플리케이션에서 모델 배포를 재사용합니다.


저전력 기기 (예 : 전화)에서 모델 서비스를 허용합니다.
복잡한 모델을 실행할 수 없음


여러 클라이언트의 요청에 대해 미니 일괄 처리 가능


모델 업데이트, 설명 가능성, 드리프트 감지 등 기본 제공 기능을 더 쉽게 제공 할 수 있습니다.",,
1944,"Enables advanced model deployment strategies like ensembles and multi-armed bandit, which require decoupling from application


Allows for separate scaling between application and model server, or running them on different devices like CPU and GPU





Additional network hops decrease performance


Tight temporal coupling to the model server can impact overall service-level agreement





Kubeflow only supports a MaaS approach.","애플리케이션과의 분리가 필요한 앙상블 및 다중 슬롯 머신과 같은 고급 모델 배포 전략을 지원합니다.


애플리케이션과 모델 서버간에 별도의 확장이 가능하거나 CPU 및 GPU와 같은 다른 장치에서 실행 가능





추가 네트워크 홉으로 인해 성능 저하


모델 서버에 대한 긴밀한 시간적 결합은 전체 서비스 수준 계약에 영향을 미칠 수 있습니다.





Kubeflow는 MaaS 접근 방식 만 지원합니다.",,
1945,"As a result, we will not be discussing model embedding in this book.",따라서이 책에서 모델 임베딩에 대해 논의하지 않을 것입니다.,,
1946,"[1]
There are two main approaches for implementing MaaS: model as code, and model as data.","[1]
MaaS를 구현하기위한 두 가지 주요 접근 방식이 있습니다 : 코드로서의 모델과 데이터로서의 모델.",,
1947,Model as code uses model code directly in a service’s implementation.,코드 형 모델은 서비스 구현에서 직접 모델 코드를 사용합니다.,,
1948,"Model as data uses a generic implementation that is driven by a model in an intermediate model format like PMML,  PFA, ONNX, or TensorFlow’s native format.","데이터 형 모델은 PMML, PFA, ONNX 또는 TensorFlow의 기본 형식과 같은 중간 모델 형식의 모델에 의해 구동되는 일반 구현을 사용합니다.",,
1949,Both approaches are used in different model server implementations in Kubeflow.,두 접근 방식 모두 Kubeflow의 서로 다른 모델 서버 구현에서 사용됩니다.,,
1950,"When determining which implementation to use, we recommended using model as data, as it allows for the exchange of models between serving instances to be standardized,
thus providing portability across systems and the enablement of generic model serving solutions.","사용할 구현을 결정할 때 모델을 데이터로 사용하는 것이 좋습니다. 이는 제공 인스턴스 간의 모델 교환을 표준화 할 수 있기 때문입니다.
따라서 시스템간에 이식성을 제공하고 일반 모델 서비스 솔루션을 사용할 수 있습니다.",,
1951,"Most common serving implementations, like TFServing, ONNX Runtime, Triton, and TorchServe, use a model-as-data approach and leverage an intermediate model format.","TFServing, ONNX Runtime, Triton 및 TorchServe와 같은 가장 일반적인 서비스 구현은 데이터로서의 모델 접근 방식을 사용하고 중간 모델 형식을 활용합니다.",,
1952,"Some of these implementations support only one framework, while others support multiple.",이러한 구현 중 일부는 하나의 프레임 워크 만 지원하고 다른 일부는 여러 프레임 워크를 지원합니다.,,
1953,"Unfortunately, each of these solutions uses different model formats and exposes unique proprietary serving APIs.",불행히도 이러한 각 솔루션은 서로 다른 모델 형식을 사용하며 고유 한 독점 제공 API를 노출합니다.,,
1954,None of these interfaces meet everyone’s needs.,이러한 인터페이스는 모든 사람의 요구를 충족하지 못합니다.,,
1955,The complexity and divergence of these API interfaces result in a differing UX and an inability to share features effectively.,이러한 API 인터페이스의 복잡성과 차이로 인해 UX가 달라지고 기능을 효과적으로 공유 할 수 없게됩니다.,,
1956,"Furthermore, there is increased friction in swapping between model frameworks, as the interfaces behind these implementations are different.",또한 이러한 구현의이면에있는 인터페이스가 다르기 때문에 모델 프레임 워크 간 스와핑시 마찰이 증가합니다.,,
1957,There are a few strong industry players attempting to unify the open source community of model servers and decrease the friction between toggling model frameworks.,모델 서버의 오픈 소스 커뮤니티를 통합하고 모델 프레임 워크 전환 간의 마찰을 줄이려는 몇 가지 강력한 업계 플레이어가 있습니다.,,
1958,Seldon is pioneering graph inferencing with Seldon Core, Bloomberg and IBM are investigating serverless model serving using solutions like Knative, and Google is further hardening its serving implementation for TensorFlow models.,Seldon은 Seldon Core로 그래프 추론을 개척하고 있습니다.Bloomberg와 IBM은 Knative와 같은 솔루션을 사용하여 서버리스 모델 서비스를 조사하고 있습니다.Google은 TensorFlow 모델에 대한 서비스 구현을 더욱 강화하고 있습니다.
1959,"In SECTION 8.5, we will discuss the serving solutions that Kubeflow offers and the work that has been done to unify these solutions into a single interface.",섹션 8.5에서는 Kubeflow가 제공하는 서빙 솔루션과 이러한 솔루션을 단일 인터페이스로 통합하기 위해 수행 한 작업에 대해 설명합니다.,,
1960,8.1.1.,8.1.1.,,
1961,"Model Serving Requirements
Model serving requires you to understand and manage the developmental operations (DevOps) and handle the analysis, experimentation, and governance of your models.","모델 제공 요구 사항
모델 제공을 위해서는 개발 작업 (DevOps)을 이해 및 관리하고 모델의 분석, 실험 및 거버넌스를 처리해야합니다.",,
1962,"This scope is wide, complicated, and universal among data scientists.",이 범위는 데이터 과학자들 사이에서 광범위하고 복잡하며 보편적입니다.,,
1963,We will now start scoping out the expectations you might want from a serving solution.,이제 서빙 솔루션에서 원하는 기대치를 범위 지정하기 시작합니다.,,
1964,"First, you want framework flexibility.","첫째, 프레임 워크 유연성을 원합니다.",,
1965,"Solutions like Kubeflow allow for your training to be implementation-agnostic (i.e., TensorFlow versus PyTorch).",Kubeflow와 같은 솔루션을 사용하면 교육이 구현에 구애받지 않을 수 있습니다 (예 : TensorFlow 대 PyTorch).,,
1966,"If you write an image classification inference service,
it should not matter if the underlying model was trained using PyTorch, Scikit-learn, or TensorFlow—the service interface should be shared so that the user’s API remains consistent.","이미지 분류 추론 서비스를 작성하면
기본 모델이 PyTorch, Scikit-learn 또는 TensorFlow를 사용하여 학습되었는지 여부는 중요하지 않습니다. 사용자의 API가 일관되게 유지되도록 서비스 인터페이스를 공유해야합니다.",,
1967,"Second, you want the ability to leverage hardware optimizers that match the needs of the algorithm.","둘째, 알고리즘의 요구 사항에 맞는 하드웨어 최적화 프로그램을 활용할 수있는 기능을 원합니다.",,
1968,"Sometimes fully fitted and tuned neural nets are quite deep, which means that even in the evaluation phase, you would benefit from hardware optimizers like GPUs or TPUs to infer the models.","때로는 완전히 장착되고 조정 된 신경망이 매우 깊습니다. 즉, 평가 단계에서도 GPU 또는 TPU와 같은 하드웨어 최적화 도구를 통해 모델을 추론 할 수 있습니다.",,
1969,"Third, your model server should seamlessly interact with other components in an inference graph.","셋째, 모델 서버는 추론 그래프의 다른 구성 요소와 원활하게 상호 작용해야합니다.",,
1970,"An inference graph could comprise feature transformers, predictors, explainers, and drift detectors—all of which we will cover later.","추론 그래프는 특성 변환기, 예측 자, 설명자 및 드리프트 감지기로 구성 될 수 있으며, 모두 나중에 다룰 것입니다.",,
1971,"Fourth, you should also have options to scale your serving instance, both explicitly and using autoscalers, regardless of the underlying hardware—i.e., cost per inference, latency.","넷째, 기본 하드웨어 (예 : 추론 당 비용, 지연 시간)에 관계없이 명시 적으로 또는 자동 확장 처리를 사용하여 제공 인스턴스를 확장 할 수있는 옵션도 있어야합니다.",,
1972,"This is particularly important and difficult because GPU autoscaling relies on a combination of factors including: GPU/CPU utilization metrics, duty cycles, and more, and knowing which metric to use for autoscaling is not obvious.","GPU 자동 확장은 GPU / CPU 사용률 메트릭, 듀티 사이클 등을 포함한 요소의 조합에 의존하고 자동 확장에 사용할 메트릭을 아는 것이 명확하지 않기 때문에 이는 특히 중요하고 어렵습니다.",,
1973,"Also, the scaling of each of the components in your inference graph should be done separately due to differing algorithmic needs.",또한 추론 그래프의 각 구성 요소의 크기 조정은 알고리즘 요구 사항이 다르기 때문에 별도로 수행해야합니다.,,
1974,"Fifth, you want a serving instance that exposes representational state transfer (REST) requests or general-purpose remote procedure calls (gRPC).","다섯째, REST (Representational State Transfer) 요청 또는 범용 원격 프로 시저 호출 (gRPC)을 노출하는 제공 인스턴스가 필요합니다.",,
1975,"If you have streaming inputs, you may want to support a streaming interface like Kafka.",스트리밍 입력이있는 경우 Kafka와 같은 스트리밍 인터페이스를 지원할 수 있습니다.,,
1976,8.2.,8.2.,,
1977,"Model Monitoring
Once you have a model served, you must monitor the model server in production.","모델 모니터링
모델이 제공되면 프로덕션에서 모델 서버를 모니터링해야합니다.",,
1978,"When we are talking about monitoring of the model server, we are talking not only about model serving insights but also about general monitoring used for any Kubernetes-based applications, including memory, CPU, networking, etc.","모델 서버 모니터링에 대해 이야기 할 때 모델 제공 인사이트뿐만 아니라 메모리, CPU, 네트워킹 등을 포함한 모든 Kubernetes 기반 애플리케이션에 사용되는 일반 모니터링에 대해서도 이야기하고 있습니다.",,
1979,We will explore model monitoring and model insight in more detail in SECTION 8.7.4.,섹션 8.7.4에서 모델 모니터링과 모델 통찰력을 더 자세히 살펴볼 것입니다.,,
1980,8.2.1.,8.2.1.,,
1981,"Model Accuracy, Drift, and Explainability
In generating model serving insights, the most common ML attributes to monitor are model accuracy, model drift, and explainability.","모델 정확도, 드리프트 및 설명 가능성
모델 제공 인사이트를 생성 할 때 모니터링 할 가장 일반적인 ML 속성은 모델 정확도, 모델 드리프트 및 설명 가능성입니다.",,
1982,Model accuracy refers to the validation accuracy of your training data.,모델 정확도는 훈련 데이터의 검증 정확도를 나타냅니다.,,
1983,"But as live data distributions begin to deviate from those of the original training data, this tends to result in model drift.",그러나 라이브 데이터 분포가 원래 학습 데이터의 분포에서 벗어나기 시작하면 모델 드리프트가 발생하는 경향이 있습니다.,,
1984,"In other words, model drift occurs when the feature distribution of the data sent to the model begins to significantly differ from the
data used to train the model, causing the model to perform suboptimally.","즉, 모델에 전송 된 데이터의 특성 분포가 데이터와 크게 다르기 시작하면 모델 드리프트가 발생합니다.
모델을 훈련시키는 데 사용되는 데이터로 인해 모델이 차선책으로 수행됩니다.",,
1985,"ML insight systems implement effective techniques for analyzing and detecting changes—concept drift—that might happen to your input data,
and the detection of these drifts is critical for models running in production systems.","ML 인사이트 시스템은 입력 데이터에 발생할 수있는 변화 (개념 드리프트)를 분석하고 감지하는 효과적인 기술을 구현합니다.
이러한 드리프트의 감지는 프로덕션 시스템에서 실행되는 모델에 중요합니다.",,
1986,"Another form of model insight that is increasingly gaining attention today is model explainability, or the ability to explain why a certain result was produced.",오늘날 점점 더 주목을 받고있는 또 다른 형태의 모델 통찰력은 모델 설명 가능성 또는 특정 결과가 생성 된 이유를 설명하는 능력입니다.,,
1987,"More precisely, it answers:


What features in the data did the model think are most important?","보다 정확하게는 다음과 같이 대답합니다.


모델이 가장 중요하다고 생각한 데이터의 특징은 무엇입니까?",,
1988,"For any single prediction from a model, how did each feature in the data affect that particular prediction?",모델의 단일 예측에 대해 데이터의 각 특성이 특정 예측에 어떤 영향을 미쳤습니까?,,
1989,"What interactions between features have the greatest effects on a model’s 
predictions?","피쳐 간의 상호 작용이 모델에 가장 큰 영향을 미치는
예측?",,
1990,"Beyond model insight, application monitoring traditionally relates to network observability, or telemetry, the enablement of log aggregation, and service-mesh-related metrics collection.","모델 인사이트 외에도 애플리케이션 모니터링은 전통적으로 네트워크 관찰 성 또는 원격 측정, 로그 집계 활성화 및 서비스 메시 관련 메트릭 수집과 관련됩니다.",,
1991,These tools are useful in capturing data from a live serving instance.,이러한 도구는 라이브 제공 인스턴스에서 데이터를 캡처하는 데 유용합니다.,,
1992,"This infrastructure exposes enough queryable information for troubleshooting and alerting, should things go awry regarding reachability, utilization, or latency.","이 인프라는 도달 가능성, 사용률 또는 대기 시간과 관련하여 문제가 발생할 경우 문제 해결 및 경고를위한 충분한 쿼리 가능한 정보를 제공합니다.",,
1993,8.2.2.,8.2.2.,,
1994,"Model Monitoring Requirements
Monitoring model accuracy and model drift is hard.","모델 모니터링 요구 사항
모델 정확도 및 모델 드리프트를 모니터링하는 것은 어렵습니다.",,
1995,"Luckily, this is a very active research space with a variety of open source solutions.",다행스럽게도 다양한 오픈 소스 솔루션을 갖춘 매우 활발한 연구 공간입니다.,,
1996,"[2]
Your inference solution should enable you to plug in solutions that provide your desired functionality out of the box.","[2]
추론 솔루션을 사용하면 원하는 기능을 즉시 제공하는 솔루션을 연결할 수 있습니다.",,
1997,"Now, we will see what you may wish to have from your model monitoring component.",이제 모델 모니터링 구성 요소에서 원하는 것을 볼 수 있습니다.,,
1998,"First, you want your inference service to provide ML insight out of the box and run in a microservice-based architecture in order to simplify the experimentation of drift detection and model explanation solutions.","먼저, 추론 서비스가 드리프트 감지 및 모델 설명 솔루션의 실험을 단순화하기 위해 기본적으로 ML 인사이트를 제공하고 마이크로 서비스 기반 아키텍처에서 실행되기를 원합니다.",,
1999,"Second, you want to enable the monitoring, logging, and tracing of your service.","둘째, 서비스의 모니터링, 로깅 및 추적을 활성화하려고합니다.",,
2000,"It should also support solutions like Prometheus, Kibana, and Zipkin, respectively, but then also be able to seamlessly support their alternatives.","또한 각각 Prometheus, Kibana 및 Zipkin과 같은 솔루션을 지원해야하지만 대안을 원활하게 지원할 수도 있습니다.",,
2001,8.3.,8.3.,,
2002,"Model Updating
If you wish to update your model and roll out a newer version or roll back to a previous version, you will want to deploy and run this updated version.","모델 업데이트
모델을 업데이트하고 새 버전을 롤아웃하거나 이전 버전으로 롤백하려면이 업데이트 된 버전을 배포하고 실행해야합니다.",,
2003,"However, the relationship between your current deployment and the new deployment can be defined in a variety of ways.",그러나 현재 배포와 새 배포 간의 관계는 다양한 방법으로 정의 할 수 있습니다.,,
2004,"When your inference system introduces multiple versions of your model serving instance, you can use either shadow or competing models:

Shadow models

These are useful when considering the replacement of a model in production.","추론 시스템에서 모델 제공 인스턴스의 여러 버전을 도입하면 섀도우 또는 경쟁 모델을 사용할 수 있습니다.

그림자 모델

이는 프로덕션에서 모델 교체를 고려할 때 유용합니다.",,
2005,You can deploy the new model alongside the current one and send the same production traffic to gather data on how the shadow model performs before promoting it.,새 모델을 현재 모델과 함께 배포하고 동일한 프로덕션 트래픽을 전송하여 섀도우 모델을 승격하기 전에 수행하는 방식에 대한 데이터를 수집 할 수 있습니다.,,
2006,"Competing models

These are a slightly more complex scenario, where you are trying multiple versions of a model in production to find out which one is better through tools like A/B testing.","경쟁 모델

이는 A / B 테스트와 같은 도구를 통해 어떤 것이 더 나은지 찾기 위해 프로덕션에서 여러 버전의 모델을 시도하는 약간 더 복잡한 시나리오입니다.",,
2007,"Let’s discuss the three main deployment strategies:

Blue-green deployments

These reduce downtime and risk relating to version rollouts by having only one live environment, which serves all production traffic.","세 가지 주요 배포 전략에 대해 살펴 보겠습니다.

청록색 배포

이는 모든 프로덕션 트래픽을 처리하는 하나의 라이브 환경 만 보유함으로써 버전 롤아웃과 관련된 다운 타임 및 위험을 줄입니다.",,
2008,"Canary deployments

These enable rollout releases by allowing you to do percentage-based traffic between versions.","카나리아 배포

이를 통해 버전 간 백분율 기반 트래픽을 수행 할 수 있으므로 출시 릴리스가 가능합니다.",,
2009,"Pinned deployments

These allow you to expose experimental traffic to a newer version, while keeping production traffic against the current version.","고정 된 배포

이를 통해 현재 버전에 대해 프로덕션 트래픽을 유지하면서 실험 트래픽을 최신 버전에 노출 할 수 있습니다.",,
2010,The added complexity of canary and pinned over blue-green comes from the infrastructure and routing rules required to ensure that traffic is being redirected to the right models.,카나리아의 복잡성이 추가되고 청록색 위에 고정 된 것은 트래픽이 올바른 모델로 리디렉션되도록하는 데 필요한 인프라 및 라우팅 규칙에서 비롯됩니다.,,
2011,"With this enablement, you can then gather data to make statistically significant decisions about when to start moving traffic.",이 기능을 사용하면 데이터를 수집하여 트래픽 이동을 시작할시기에 대해 통계적으로 중요한 결정을 내릴 수 있습니다.,,
2012,One statistical approach for traffic movement is A/B testing.,트래픽 이동에 대한 한 가지 통계적 접근 방식은 A / B 테스트입니다.,,
2013,"Another popular approach for evaluating multiple competing models is multi-armed bandits,
which requires you to define a score or reward for each model and to promote models relative to their respective score.","여러 경쟁 모델을 평가하는 또 다른 인기있는 접근 방식은 다중 슬롯 머신 도적입니다.
이를 위해서는 각 모델에 대한 점수 또는 보상을 정의하고 각 점수와 관련된 모델을 홍보해야합니다.",,
2014,8.3.1.,8.3.1.,,
2015,"Model Updating Requirements
Upgrading your model must be simple, so the deployment strategy that you use for upgrading should be easy to configure and simple to change (i.e., from pinned to canary).","모델 업데이트 요구 사항
모델 업그레이드는 간단해야하므로 업그레이드에 사용하는 배포 전략은 구성 및 변경 (예 : 고정에서 카나리아로)이 간단해야합니다.",,
2016,Your inference solution should also offer more-complex graph inferencing in its design.,추론 솔루션은 또한 설계에서 더 복잡한 그래프 추론을 제공해야합니다.,,
2017,"We will elaborate on what you need from your inference solution:
First, the toggle of deployment strategies—i.e., from pinned to canary—should be trivial.","추론 솔루션에서 필요한 사항에 대해 자세히 설명하겠습니다.
첫째, 배포 전략의 전환 (예 : 고정에서 카나리아로)은 사소해야합니다.",,
2018,"You can enable traffic-level routing in an abstracted way by abstracting the service plane, which will be defined in SECTION 8.8.1.",섹션 8.8.1에서 정의 할 서비스 플레인을 추상화하여 추상화 된 방식으로 트래픽 수준 라우팅을 활성화 할 수 있습니다.,,
2019,"Second, version changes should be tested and validated before promotion, and the corresponding upgrade should be logged.","둘째, 승격 전에 버전 변경을 테스트하고 유효성을 검사하고 해당 업그레이드를 기록해야합니다.",,
2020,"Third, the underlying stack should enable you to configure the more complex deployment strategies common to graph inferencing literature.","셋째, 기본 스택을 사용하면 그래프 추론 문헌에 일반적으로 사용되는보다 복잡한 배포 전략을 구성 할 수 있습니다.",,
2021,8.4.,8.4.,,
2022,"Summary of Inference Requirements
With the requirements of model serving, monitoring, and updating all satisfied, you now have an inference solution that completes your model development life cycle (MDLC) story.","추론 요구 사항 요약
모델 제공, 모니터링 및 업데이트의 요구 사항이 모두 충족되었으므로 이제 MDLC (Model Development Life Cycle) 스토리를 완성하는 추론 솔루션을 갖게되었습니다.",,
2023,"This enables you to bring a model all the way from lab to production, and even handle the updating of this model should you want to tune or modify its construction.",이를 통해 실험실에서 프로덕션까지 모델을 가져올 수 있으며 구성을 조정하거나 수정하려는 경우이 모델의 업데이트도 처리 할 수 있습니다.,,
2024,Now we will discuss the inference solutions that Kubeflow offers.,이제 Kubeflow가 제공하는 추론 솔루션에 대해 설명하겠습니다.,,
2025,"Tip
Some ML practitioners believe that continuous learning (CL) is fundamental in their production ML systems.","팁
일부 ML 실무자는 지속적 학습 (CL)이 프로덕션 ML 시스템의 기본이라고 생각합니다.",,
2026,CL is the ability of a model to learn continually from streaming data.,CL은 스트리밍 데이터에서 지속적으로 학습하는 모델의 기능입니다.,,
2027,"In essence, the model will autonomously learn and adapt in production as new data comes in.",본질적으로 모델은 새로운 데이터가 들어 오면 생산 과정에서 자율적으로 학습하고 적응합니다.,,
2028,Some even call this AutoML.,일부는이를 AutoML이라고도합니다.,,
2029,"With a complete MDLC solution that enables pipelines and canary deployments, you can design such a system using the tools available in Kubeflow.",파이프 라인 및 카나리아 배포를 지원하는 완전한 MDLC 솔루션을 사용하면 Kubeflow에서 제공되는 도구를 사용하여 이러한 시스템을 설계 할 수 있습니다.,,
2030,8.5.,8.5.,,
2031,"Model Inference in Kubeflow
Model serving, monitoring, and updating within inference can be quite tricky because
you need a solution that manages all of these expectations in a way that provides abstraction for first-time users and customizability for power users.","Kubeflow의 모델 추론
추론 내에서 모델 제공, 모니터링 및 업데이트는 매우 까다로울 수 있습니다.
처음 사용하는 사용자에게는 추상화를 제공하고 고급 사용자에게는 사용자 정의 기능을 제공하는 방식으로 이러한 모든 기대치를 관리하는 솔루션이 필요합니다.",,
2032,Kubeflow provides many options for model inference solutions.,Kubeflow는 모델 추론 솔루션을위한 다양한 옵션을 제공합니다.,,
2033,"In this section, we will describe some of them, including TensorFlow Serving, Seldon Core, and KFServing.","이 섹션에서는 TensorFlow Serving, Seldon Core 및 KFServing을 포함하여 그중 일부를 설명합니다.",,
2034,"TABLE 8-2 presents a quick comparison of these 
solutions.","표 8-2는 이들의 빠른 비교를 보여줍니다.
솔루션.",,
2035,Table 8-2.,표 8-2.,,
2036,"Comparing different model inference approaches


Solution
Approach




TensorFlow Serving



Single model type (TensorFlow) support


Some support for monitoring metrics (Prometheus)


With version 2.3, support for canarying via model version labels


Simplest infrastructure dependencies




Seldon Core



Optimized Docker containers for popular libraries like TensorFlow, H2O, XGBoost, MXNet, etc.","다양한 모델 추론 접근 방식 비교


해결책
접근하다




TensorFlow Serving



단일 모델 유형 (TensorFlow) 지원


메트릭 모니터링에 대한 일부 지원 (Prometheus)


버전 2.3에서는 모델 버전 레이블을 통한 카나리아 화 지원


가장 단순한 인프라 종속성




셀던 코어



TensorFlow, H2O, XGBoost, MXNet 등과 같은 인기있는 라이브러리에 최적화 된 Docker 컨테이너",,
2037,"Language wrappers that convert a Python file or a Java JAR into a fully fledged microservice


Support for inference pipelines that can consist of models, transformers, combiners and routers


Support for monitoring metrics and auditable request logs


Support for advanced deployment techniques—canary, blue-green, etc.","Python 파일 또는 Java JAR을 완전한 마이크로 서비스로 변환하는 언어 래퍼


모델, 변환기, 결합기 및 라우터로 구성 될 수있는 추론 파이프 라인 지원


모니터링 메트릭 및 감사 가능한 요청 로그 지원


고급 배포 기술 지원 (카나리아, 블루-그린 등)",,
2038,"Support for advanced ML insights: explainers, outlier detectors, and adversarial attack detectors


More complex infrastructure dependencies




KFServing



Adding serverless (Knative) and a standardized inference experience to Seldon Core, while providing extensibility for other model servers


Most complex infrastructure dependencies







8.6.","고급 ML 인사이트 지원 : 설명자, 이상치 탐지기, 적대적 공격 탐지기


더 복잡한 인프라 종속성




KFServing



서버리스 (Knative) 및 표준화 된 추론 경험을 Seldon Core에 추가하는 동시에 다른 모델 서버에 대한 확장 성을 제공합니다.


가장 복잡한 인프라 종속성







8.6.",,
2039,"TensorFlow Serving
One of the most popular serving implementations is TensorFlow Serving (TFServing), a model-serving implementation based on the TensorFlow export format.","TensorFlow Serving
가장 인기있는 제공 구현 중 하나는 TensorFlow 내보내기 형식을 기반으로하는 모델 제공 구현 인 TensorFlow Serving (TFServing)입니다.",,
2040,"TFServing implements a flexible, high-performance serving system for ML models, designed for production environments.",TFServing은 프로덕션 환경을 위해 설계된 ML 모델을위한 유연한 고성능 서빙 시스템을 구현합니다.,,
2041,The TFServing architecture is shown in FIGURE 8-1.,TFServing 아키텍처는 그림 8-1에 나와 있습니다.,,
2042,Figure 8-1.,그림 8-1.,,
2043,"TFServing architecture

TFServing uses exported TensorFlow models as inputs and supports running predictions on them using HTTP or gRPC.","TFServing 아키텍처

TFServing은 내 보낸 TensorFlow 모델을 입력으로 사용하고 HTTP 또는 gRPC를 사용하여 예측 실행을 지원합니다.",,
2044,"TFServing can be configured to use either:


A single (latest) version of the model


Multiple, specific versions of the model


TensorFlow can be used both locally[3] and in Kubernetes.","TFServing은 다음 중 하나를 사용하도록 구성 할 수 있습니다.


모델의 단일 (최신) 버전


모델의 여러 특정 버전


TensorFlow는 로컬 [3]과 Kubernetes 모두에서 사용할 수 있습니다.",,
2045,"[4] A typical TFServing implementation within Kubeflow includes the following components:


A Kubernetes deployment running the required amount of replicas


A Kubernetes service providing access to the deployment


An Istio virtual service that exposes the service through the Istio ingress gateway


An Istio DestinationRule that defines policies for traffic routed to the service (These rules can specify configurations for load balancing, connection pool size, and outlier detection settings so that you can detect and evict unhealthy hosts from the load balancing pool.)","[4] Kubeflow 내의 일반적인 TFServing 구현에는 다음 구성 요소가 포함됩니다.


필요한 양의 복제본을 실행하는 Kubernetes 배포


배포에 대한 액세스를 제공하는 Kubernetes 서비스


Istio 인 그레스 게이트웨이를 통해 서비스를 노출하는 Istio 가상 서비스


서비스로 라우팅되는 트래픽에 대한 정책을 정의하는 Istio DestinationRule (이러한 규칙은 부하 분산 풀에서 비정상 호스트를 감지하고 제거 할 수 있도록 부하 분산, 연결 풀 크기 및 이상 값 감지 설정에 대한 구성을 지정할 수 있습니다.)",,
2046,We will walk through an example of how these components are implemented by extending our recommender example.,권장 사항 예제를 확장하여 이러한 구성 요소를 구현하는 방법에 대한 예제를 살펴 보겠습니다.,,
2047,"To simplify your initial inference service, your example TFServing instance will be scoped to a deployment and a service that enables HTTP access.",초기 추론 서비스를 단순화하기 위해 예제 TFServing 인스턴스의 범위가 배포 및 HTTP 액세스를 활성화하는 서비스로 지정됩니다.,,
2048,The Helm chart for this example can be found in  the GitHub repo for this book.,이 예제에 대한 Helm 차트는이 책의 GitHub 저장소에서 찾을 수 있습니다.,,
2049,The chart defines a Kubernetes deployment and service.,차트는 Kubernetes 배포 및 서비스를 정의합니다.,,
2050,"The deployment uses the “standard” TFServing Docker image and, in its configuration spec, points to a serialized model at an S3 source location.","배포는 ""표준""TFServing Docker 이미지를 사용하며 구성 사양에서 S3 소스 위치의 직렬화 된 모델을 가리 킵니다.",,
2051,This S3 bucket is managed by a local MinIO instance.,이 S3 버킷은 로컬 MinIO 인스턴스에서 관리합니다.,,
2052,The service exposes this deployment inside the Kubernetes cluster.,서비스는 Kubernetes 클러스터 내에서이 배포를 노출합니다.,,
2053,"The chart can be deployed using the following command (assuming you are running Helm 3):
helm install <chart_location>
Now that you have the chart deployed, you need a way to interface with your inference solution.","다음 명령을 사용하여 차트를 배포 할 수 있습니다 (Helm 3을 실행 중이라고 가정).
helm install <chart_location>
이제 차트를 배포 했으므로 추론 솔루션과 인터페이스 할 방법이 필요합니다.",,
2054,"One method is to port forward your service, so that the traffic can be redirected to your localhost for testing.",한 가지 방법은 테스트를 위해 트래픽을 로컬 호스트로 리디렉션 할 수 있도록 서비스를 포워딩하는 것입니다.,,
2055,You can port-forward your service with EXAMPLE 8-1.,예 8-1을 사용하여 서비스를 포트 포워드 할 수 있습니다.,,
2056,Example 8-1.,예 8-1.,,
2057,"Port-forwarding TFServing services
kubectl port-forward service/recommendermodelserver 8501:8501
The resulting traffic will be rerouted to localhost:8051.","포트 포워딩 TFServing 서비스
kubectl 포트 포워드 서비스 / recommendermodelserver 8501 : 8501
결과 트래픽은 localhost : 8051로 다시 라우팅됩니다.",,
2058,You are now ready to interact with your TFServing inference solution.,이제 TFServing 추론 솔루션과 상호 작용할 준비가되었습니다.,,
2059,"To start, you should validate the deployment by requesting model deployment information from your service:
curl http://localhost:8501/v1/models/recommender/versions/1
The expected output is shown in EXAMPLE 8-2.","시작하려면 서비스에서 모델 배포 정보를 요청하여 배포의 유효성을 검사해야합니다.
컬 http : // localhost : 8501 / v1 / models / recommender / versions / 1
예상 출력은 예제 8-2에 나와 있습니다.",,
2060,Example 8-2.,예 8-2.,,
2061,"TFServing Recommender model version status
{
 ""model_version_status"": [
  {
   ""version"": ""1"",
   ""state"": ""AVAILABLE"",
   ""status"": {
    ""error_code"": ""OK"",
    ""error_message"": """"
   }
  }
 ]
}
You can also get the model’s metadata, including its signature definition, by issuing the following curl command:
curl http://localhost:8501/v1/models/recommender/versions/1/metadata
Now that your model is available and has the correct signature definition, you can predict against the service with the command seen in EXAMPLE 8-3.","TFServing Recommender 모델 버전 상태
{
 ""model_version_status"": [
  {
   ""버전"": ""1"",
   ""state"": ""AVAILABLE"",
   ""상태"": {
    ""error_code"": ""OK"",
    ""에러 메시지"": """"
   }
  }
 ]
}
다음 curl 명령을 실행하여 서명 정의를 포함한 모델의 메타 데이터를 가져올 수도 있습니다.
곱슬 http : // localhost : 8501 / v1 / models / recommender / versions / 1 / metadata
이제 모델을 사용할 수 있고 올바른 서명 정의가 있으므로 예 8-3에 표시된 명령을 사용하여 서비스에 대해 예측할 수 있습니다.",,
2062,Example 8-3.,예 8-3.,,
2063,"Sending a request to your TFServing Recommender service
curl -X POST http://localhost:8501/v1/models/recommender/versions/1:predict\
-d '{""signature_name"":""serving_default"",""inputs"":\
{""products"": [[1],[2]],""users"" : [[25], [3]]}}'
The result from executing EXAMPLE 8-3 is shown in EXAMPLE 8-4.","TFServing Recommender 서비스에 요청 보내기
curl -X POST http : // localhost : 8501 / v1 / models / recommender / versions / 1 : predict \
-d '{ ""signature_name"": ""serving_default"", ""inputs"": \
{ ""제품"": [[1], [2]], ""사용자"": [[25], [3]]}} '
예제 8-3을 실행 한 결과는 예제 8-4에 나와 있습니다.",,
2064,Example 8-4.,예 8-4.,,
2065,"Output from your TFServing Recommender service
{
    ""outputs"": {
        ""model-version"": [
            ""1""
        ],
        ""recommendations"": [
            [
                0.140973762
            ],
            [
                0.0441606939
            ]
        ]
    }
}
Your TensorFlow model is now behind a live inference solution.","TFServing Recommender 서비스의 출력
{
    ""출력"": {
        ""모델 버전"": [
            ""1""
        ],
        ""권장 사항"": [
            [
                0.140973762
            ],
            [
                0.0441606939
            ]
        ]
    }
}
이제 TensorFlow 모델이 실시간 추론 솔루션 뒤에 있습니다.",,
2066,"TFServing makes it easy to deploy new TensorFlow algorithms and experiments, while keeping the same server architecture and APIs.",TFServing을 사용하면 동일한 서버 아키텍처와 API를 유지하면서 새로운 TensorFlow 알고리즘과 실험을 쉽게 배포 할 수 있습니다.,,
2067,But the journey does not end there.,그러나 여정은 여기서 끝나지 않습니다.,,
2068,"For one, these deployment instructions create a service but do not enable access from outside of the cluster.","첫째, 이러한 배포 지침은 서비스를 생성하지만 클러스터 외부에서 액세스를 활성화하지 않습니다.",,
2069,"[5]
But we will now take a further look into all the capabilities of this particular solution against your inference requirements.","[5]
그러나 이제 추론 요구 사항에 대한이 특정 솔루션의 모든 기능을 자세히 살펴 보겠습니다.",,
2070,"8.6.1. Review
If you are looking to deploy your TensorFlow model with the lowest infrastructure requirement, TFServing is your solution.","8.6.1.리뷰
인프라 요구 사항이 가장 낮은 TensorFlow 모델을 배포하려는 경우 TFServing이 솔루션입니다.",,
2071,"However, this has limitations when you consider your inference requirements.",그러나 이것은 추론 요구 사항을 고려할 때 제한이 있습니다.,,
2072,8.6.1.1.,8.6.1.1.,,
2073,"Model serving
Because TFServing only has production-level support for TensorFlow, it does not have the desired flexibility you would expect from a framework-agnostic inference service.","모델 제공
TFServing은 TensorFlow에 대한 프로덕션 수준 지원 만 제공하므로 프레임 워크에 구애받지 않는 추론 서비스에서 기대할 수있는 원하는 유연성이 없습니다.",,
2074,"It does, however, support REST, gRPC, GPU acceleration, mini-batching, and “lite” versions for serving on edge devices.","그러나 에지 기기에서 제공하기 위해 REST, gRPC, GPU 가속, 미니 배치, '라이트'버전을 지원합니다.",,
2075,"Regardless of the underlying hardware, this support does not extend to streaming inputs or to built-in auto scaling.",기본 하드웨어에 관계없이이 지원은 스트리밍 입력 또는 내장 자동 확장으로 확장되지 않습니다.,,
2076,"[6]
Furthermore, the ability to extend the inference graph—beyond a Fairness Indicator—to include more advanced ML insights isn’t supported in a first-class way.","[6]
또한 공정성 지표를 넘어서 추론 그래프를 확장하여 고급 ML 인사이트를 포함하는 기능은 일류 방식으로 지원되지 않습니다.",,
2077,"Despite providing basic serving and model analysis features for TensorFlow models, this inference solution does not satisfy your more advanced serving requirements.",TensorFlow 모델에 대한 기본 제공 및 모델 분석 기능을 제공 함에도 불구하고이 추론 솔루션은 고급 제공 요구 사항을 충족하지 않습니다.,,
2078,8.6.1.2.,8.6.1.2.,,
2079,"Model monitoring
TFServing supports traditional monitoring via its integration with Prometheus.","모델 모니터링
TFServing은 Prometheus와의 통합을 통해 기존 모니터링을 지원합니다.",,
2080,"This exposes both system information—such as CPU, memory, and networking—and TFServing-specific metrics; unfortunately, there is very little documentation (see the best source, on the  TensorFlow site).","이는 CPU, 메모리 및 네트워킹과 같은 시스템 정보와 TFServing 관련 메트릭을 모두 노출합니다.안타깝게도 문서가 거의 없습니다 (TensorFlow 사이트에서 최고의 소스 참조).",,
2081,"Also, there is no first-class integration with data visualization tools like Kibana or distributed tracing libraries like Jaeger.",또한 Kibana와 같은 데이터 시각화 도구 또는 Jaeger와 같은 분산 추적 라이브러리와의 최고 수준의 통합이 없습니다.,,
2082,"As such, TFServing does not provide the managed network observability capabilities you desire.",따라서 TFServing은 원하는 관리 네트워크 관찰 기능을 제공하지 않습니다.,,
2083,"When it comes to advanced model serving insights, including model drift and explainability, some of them are available in TensorFlow 2.0.",모델 드리프트 및 설명 가능성을 포함하여 인사이트를 제공하는 고급 모델의 경우 일부는 TensorFlow 2.0에서 사용할 수 있습니다.,,
2084,"Furthermore, the vendor lock-in to a proprietary serving solution complicates the plugability of model insight components.",또한 독점 제공 솔루션에 대한 공급 업체 종속은 모델 통찰력 구성 요소의 플러그 가능성을 복잡하게 만듭니다.,,
2085,"Since the deployment strategy of TFServing uses Kubeflow’s infrastructure stack, it leverages a microservice approach.",TFServing의 배포 전략은 Kubeflow의 인프라 스택을 사용하므로 마이크로 서비스 접근 방식을 활용합니다.,,
2086,This allows TFServing deployments to be easily coupled with auxiliary ML components.,이를 통해 TFServing 배포를 보조 ML 구성 요소와 쉽게 결합 할 수 있습니다.,,
2087,8.6.1.3.,8.6.1.3.,,
2088,"Model updating
TFServing is quite advanced in that it enables canary, pinned, and even rollback deployment strategies.","모델 업데이트
TFServing은 카나리아, 고정 및 롤백 배포 전략을 지원한다는 점에서 상당히 발전했습니다.",,
2089,"[7]
However, the strategies are limited to the manual labeling of existing model versions and do not include support for the introduction of in-flight model versions.","[7]
그러나 전략은 기존 모델 버전의 수동 레이블 지정으로 제한되며 기내 모델 버전 도입에 대한 지원을 포함하지 않습니다.",,
2090,So version promotion does not have a safe-rollout guarantee.,따라서 버전 승격에는 안전한 출시가 보장되지 않습니다.,,
2091,"Lastly, the strategies are embedded in the server and aren’t extensible for other deployment strategies that might exist outside of TFServing.","마지막으로, 전략은 서버에 내장되어 있으며 TFServing 외부에있을 수있는 다른 배포 전략으로 확장 할 수 없습니다.",,
2092,8.6.1.4.,8.6.1.4.,,
2093,"Summary
TFServing provides extremely performant and sophisticated out-of-the-box integration for TensorFlow models,
but it falls short on enabling more advanced features like framework extensibility, advanced telemetry, and plugable deployment strategies.","요약
TFServing은 TensorFlow 모델에 대해 매우 성능이 뛰어나고 정교한 즉시 사용 가능한 통합을 제공합니다.
그러나 프레임 워크 확장 성, 고급 원격 측정 및 플러그 형 배포 전략과 같은 고급 기능을 활성화하는 데는 부족합니다.",,
2094,"Seeing these requirements unsatisfied, we will now look at how Seldon Core attempts to fill these gaps.",이러한 요구 사항이 만족스럽지 않은 것을 확인하고 이제 Seldon Core가 이러한 격차를 메우려는 방법을 살펴 보겠습니다.,,
2095,8.7.,8.7.,,
2096,"Seldon Core
Instead of just serving up single models behind an endpoint, Seldon Core enables data scientists to compose complex runtime
inference graphs—by converting their machine learning code or artifacts into microservices.","셀던 코어
엔드 포인트 뒤에서 단일 모델을 제공하는 대신 Seldon Core를 사용하면 데이터 과학자가 복잡한 런타임을 구성 할 수 있습니다.
추론 그래프-기계 학습 코드 또는 아티팩트를 마이크로 서비스로 변환합니다.",,
2097,"An inference graph, as visualized in FIGURE 8-2, can be composed of:

Models

Runtime inference executable for one or more ML models

Routers

Route requests to subgraphs, i.e., enabling A/B tests or multi-armed bandits

Combiners

Combine the responses from subgraphs, i.e., model ensemble

Transformers

Transform requests or responses, i.e., transform feature requests




Figure 8-2.","그림 8-2에 시각화 된 추론 그래프는 다음으로 구성 될 수 있습니다.

모델

하나 이상의 ML 모델에 대해 실행 가능한 런타임 추론

라우터

요청을 하위 그래프로 라우팅 (예 : A / B 테스트 또는 다중 슬롯 머신 밴디트 활성화)

결합기

하위 그래프, 즉 모델 앙상블의 응답을 결합합니다.

변압기

변환 요청 또는 응답, 즉 변환 기능 요청




그림 8-2.",,
2098,"Seldon inference graph example

To understand how Seldon achieves this, we will explore its core components and feature set:

Prepackaged model servers

Optimized Docker containers for popular libraries such as TensorFlow, XGBoost, H2O, etc., which can load and serve model artifacts/binaries

Language wrappers

Tools to enable more custom machine learning models to be wrapped using a
set of CLIs, which allow data scientists to convert a Python file or a Java JAR into a fully fledged microservice

Standardized API

Out-of-the-box APIs that can be REST or gRPC

Out of the box observability

Monitoring metrics and auditable request logs

Advanced machine learning insights

Complex ML concepts such as explainers, outlier detectors, and adversarial attack detectors abstracted into infrastructural components that can be extended when desired


Using all of these components, we walk through how to design an inference graph using Seldon.","셀던 추론 그래프 예제

Seldon이이를 달성하는 방법을 이해하기 위해 핵심 구성 요소와 기능 세트를 살펴 보겠습니다.

사전 패키징 된 모델 서버

모델 아티팩트 / 바이너리를로드하고 제공 할 수있는 TensorFlow, XGBoost, H2O 등과 같은 인기 라이브러리에 최적화 된 Docker 컨테이너

언어 래퍼

더 많은 사용자 지정 기계 학습 모델을 사용하여 래핑 할 수있는 도구
데이터 과학자가 Python 파일 또는 Java JAR을 완전한 마이크로 서비스로 변환 할 수있는 CLI 세트

표준화 된 API

REST 또는 gRPC가 될 수있는 즉시 사용 가능한 API

즉시 사용 가능한 관찰 가능성

측정 항목 및 감사 가능한 요청 로그 모니터링

고급 기계 학습 통찰력

설명자, 이상치 탐지기 및 적대적 공격 탐지기와 같은 복잡한 ML 개념은 원하는 경우 확장 할 수있는 인프라 구성 요소로 추상화


이러한 모든 구성 요소를 사용하여 Seldon을 사용하여 추론 그래프를 설계하는 방법을 살펴 봅니다.",,
2099,8.7.1.,8.7.1.,,
2100,"Designing a Seldon Inference Graph
First, you will need to decide what components you want your inference graph to consist of.","셀던 추론 그래프 설계
먼저 추론 그래프를 구성 할 구성 요소를 결정해야합니다.",,
2101,"Will it be just a model server, or will you add a set of transformers, explainers, or outlier detectors to the model server?","모델 서버일까요, 아니면 모델 서버에 변환기, 설명자 또는 이상치 감지기 세트를 추가할까요?",,
2102,"Luckily, it’s really easy to add or remove components as you see fit,
so we will start with just a simple model server.","다행히도 적합하다고 생각되는 구성 요소를 추가하거나 제거하는 것은 정말 쉽습니다.
그래서 우리는 단순한 모델 서버로 시작할 것입니다.",,
2103,"Second, you need to containerize your processing steps.","둘째, 처리 단계를 컨테이너화해야합니다.",,
2104,You can build each step of your inference graph with model as data or model as code.,모델을 데이터로 또는 모델을 코드로 사용하여 추론 그래프의 각 단계를 작성할 수 있습니다.,,
2105,"For model as data, you could use a prepackaged model server to load your model artifacts/binaries and avoid building a Docker container every time your model changes.",데이터 형 모델의 경우 사전 패키징 된 모델 서버를 사용하여 모델 아티팩트 / 바이너리를로드하고 모델이 변경 될 때마다 Docker 컨테이너를 빌드하지 않을 수 있습니다.,,
2106,"For model as code, you would build your own prepackaged model server based on a custom implementation.",코드 형 모델의 경우 사용자 정의 구현을 기반으로 사전 패키징 된 자체 모델 서버를 빌드합니다.,,
2107,Your implementation is enabled via a language wrapper that would containerize your code by exposing a high-level interface to your model’s logic.,모델의 로직에 상위 수준 인터페이스를 노출하여 코드를 컨테이너화하는 언어 래퍼를 통해 구현이 활성화됩니다.,,
2108,"This can be used for more complex cases, even use cases that may require custom OS-specific, or even external-system dependencies.","이는보다 복잡한 경우, 심지어 사용자 지정 OS 별 또는 외부 시스템 종속성이 필요할 수있는 사용 사례에도 사용할 수 있습니다.",,
2109,"Next, you need to test your implementation.",다음으로 구현을 테스트해야합니다.,,
2110,"You can run your implementation locally, leveraging
Seldon tools to verify that it works correctly.","구현을 로컬에서 실행할 수 있습니다.
Seldon 도구가 올바르게 작동하는지 확인합니다.",,
2111,Local development is enabled by the underlying portability of Kubernetes and by Seldon’s compatibility with Kubeflow’s infrastructure stack.,로컬 개발은 Kubernetes의 기본 이식성과 Kubeflow의 인프라 스택과의 Seldon의 호환성을 통해 가능합니다.,,
2112,"Then, you can enable Seldon Core extensions.",그런 다음 Seldon Core 확장을 활성화 할 수 있습니다.,,
2113,"Some extensions include: Jaeger tracing integration, ELK request logging integration,
Seldon Core analytics integration, or Istio/Ambassador ingress integration, to name a few.","일부 확장에는 Jaeger 추적 통합, ELK 요청 로깅 통합,
Seldon Core 분석 통합 또는 Istio / Ambassador Ingress 통합이 있습니다.",,
2114,"[8]
After enabling extensions, you can promote your local graph deployment to be hosted against a live Kubernetes cluster.","[8]
확장을 활성화 한 후 라이브 Kubernetes 클러스터에 대해 호스팅되도록 로컬 그래프 배포를 승격 할 수 있습니다.",,
2115,"Lastly, you can hook up your inference graph into a continuous integration/continuous delivery (CI/CD) pipeline.",마지막으로 추론 그래프를 CI / CD (지속적 통합 / 지속적 배포) 파이프 라인에 연결할 수 있습니다.,,
2116,"Seldon components allow you to integrate seamlessly into CI/CD workflows, which enables you to use your preferred CI tool to connect your model sources into Seldon Core.",Seldon 구성 요소를 사용하면 CI / CD 워크 플로에 원활하게 통합 할 수 있으므로 선호하는 CI 도구를 사용하여 모델 소스를 Seldon Core에 연결할 수 있습니다.,,
2117,"Now that you have scoped out a rather robust inference graph, we will walk through some examples after getting set up with Seldon on your Kubeflow cluster.",이제 다소 강력한 추론 그래프의 범위를 지정 했으므로 Kubeflow 클러스터에서 Seldon을 설정 한 후 몇 가지 예를 살펴 보겠습니다.,,
2118,8.7.1.1.,8.7.1.1.,,
2119,"Setting up Seldon Core
Seldon Core 1.0 comes prepackaged with Kubeflow, so it should already be available to you.","Seldon Core 설정
Seldon Core 1.0은 Kubeflow와 함께 사전 패키지로 제공되므로 이미 사용할 수 있습니다.",,
2120,The Seldon Core installation will create a Kubernetes operator which will watch for SeldonDeployment resources that describe your inference graph.,Seldon Core 설치는 추론 그래프를 설명하는 SeldonDeployment 리소스를 감시 할 Kubernetes 연산자를 생성합니다.,,
2121,"However, you can install a custom version of Seldon Core, as per the installation instructions, with EXAMPLE 8-5.",그러나 설치 지침에 따라 예제 8-5를 사용하여 Seldon Core의 사용자 지정 버전을 설치할 수 있습니다.,,
2122,Example 8-5.,예 8-5.,,
2123,"Helm install for a custom Seldon Core version
helm install seldon-core-operator \
    --repo https://storage.googleapis.com/seldon-charts  \
    --namespace default \
    --set istio.gateway=istio-system/seldon-gateway \
    --set istio.enabled=true
You must ensure that the namespace where your models will be served has an Istio gateway and an InferenceServing namespace label.","맞춤 Seldon Core 버전 용 Helm 설치
helm install seldon-core-operator \
    --repo https://storage.googleapis.com/seldon-charts \
    -네임 스페이스 기본값 \
    --set istio.gateway = istio-system / seldon-gateway \
    --set istio.enabled = true
모델이 제공 될 네임 스페이스에 Istio 게이트웨이 및 InferenceServing 네임 스페이스 레이블이 있는지 확인해야합니다.",,
2124,"An example label application would be:
kubectl label namespace kubeflow serving.kubeflow.org/inferenceservice=enabled
An example Istio gateway is shown in EXAMPLE 8-6.","라벨 애플리케이션의 예는 다음과 같습니다.
kubectl 라벨 네임 스페이스 kubeflow serving.kubeflow.org/inferenceservice=enabled
Istio 게이트웨이의 예가 예 8-6에 나와 있습니다.",,
2125,Example 8-6.,예 8-6.,,
2126,"Seldon Core Istio Gateway
kind: Gateway
metadata:
  name: seldon-gateway
  namespace: istio-system
spec:
  selector:
    istio: ingressgateway
  servers:
  - hosts:
    - '*'
    port:
      name: http
      number: 80
      protocol: HTTP
You should save EXAMPLE 8-6 to a file and apply it using kubectl.","Seldon Core Istio 게이트웨이
종류 : 게이트웨이
메타 데이터 :
  이름 : seldon-gateway
  네임 스페이스 : istio-system
투기:
  선택자:
    istio : ingressgateway
  서버 :
  -호스트 :
    - '*'
    포트:
      이름 : http
      번호 : 80
      프로토콜 : HTTP
예제 8-6을 파일에 저장하고 kubectl을 사용하여 적용해야합니다.",,
2127,8.7.1.2.,8.7.1.2.,,
2128,"Packaging your model
As mentioned before, to run a model with Seldon Core you can either
package it using a prepackaged model server[9] or a language wrapper.","모델 패키징
앞서 언급했듯이 Seldon Core로 모델을 실행하려면 다음 중 하나를 수행 할 수 있습니다.
미리 패키징 된 모델 서버 [9] 또는 언어 래퍼를 사용하여 패키징합니다.",,
2129,"[10]


8.7.1.3.","[10]


8.7.1.3.",,
2130,"Creating a SeldonDeployment
After packaging your model you need to define an inference graph that connects a set of model components into a
single inference system.","SeldonDeployment 생성
모델을 패키징 한 후에는 일련의 모델 구성 요소를 연결하는 추론 그래프를 정의해야합니다.
단일 추론 시스템.",,
2131,Each of the model components can be one of the two options outlined in SECTION 8.7.1.2.,각 모델 구성 요소는 섹션 8.7.1.2에 설명 된 두 가지 옵션 중 하나 일 수 있습니다.,,
2132,Some example graphs are shown in FIGURE 8-3.,그림 8-3에는 몇 가지 예제 그래프가 나와 있습니다.,,
2133,Figure 8-3.,그림 8-3.,,
2134,"Seldon graph examples

The following list expands on the example inference graphs (a) to (e), as shown in FIGURE 8-3:


(a) A single model


(b) Two models in sequence.","셀던 그래프 예제

다음 목록은 그림 8-3에 표시된대로 예제 추론 그래프 (a)에서 (e)까지 확장됩니다.


(a) 단일 모델


(b) 두 가지 모델이 차례로 나타납니다.",,
2135,The output of the first will be fed into the input of the second.,첫 번째의 출력은 두 번째의 입력으로 공급됩니다.,,
2136,"(c) A model with input and output transformers: the input transformer will be called, then the model and the response will be transformed by the output transformer


(d) A router that will choose whether to send to model A or B


(e) A combiner that takes the response from model A and B and combines into a single response[11]


In addition, SeldonDeployment can specify methods for each component.","(c) 입력 및 출력 트랜스포머가있는 모델 : 입력 트랜스포머가 호출 된 다음 모델과 응답이 출력 트랜스포머에 의해 변환됩니다.


(d) 모델 A 또는 B로 전송할지 여부를 선택할 라우터


(e) 모델 A와 B에서 응답을 받아 단일 응답으로 결합하는 결합기 [11]


또한 SeldonDeployment는 각 구성 요소에 대한 메서드를 지정할 수 있습니다.",,
2137,"When your SeldonDeployment is deployed, Seldon Core adds a service orchestrator to manage the request and response flow through your graph.",SeldonDeployment가 배포되면 Seldon Core는 서비스 오케 스트레이터를 추가하여 그래프를 통한 요청 및 응답 흐름을 관리합니다.,,
2138,"An example SeldonDeployment, for inference graph (a) in FIGURE 8-3, appears in EXAMPLE 8-7 as an example of what a prepackaged model server looks like.",그림 8-3의 추론 그래프 (a)에 대한 SeldonDeployment의 예는 사전 패키징 된 모델 서버의 모습에 대한 예로서 예 8-7에 나와 있습니다.,,
2139,Example 8-7.,예 8-7.,,
2140,"Simple Seldon Core prepackaged model server
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
 name: seldon-model
spec:
 name: test-deployment
 predictors:
 - componentSpecs:
   graph:
     name: classifier
     type: SKLEARN_SERVER
     modelUri: gs://seldon-models/sklearn/income/model
     children: []
   name: example
   replicas: 1
In the example you see that the SeldonDeployment has a list of predictors, each of which describes an inference graph.","Simple Seldon Core 사전 패키지 모델 서버
apiVersion : machinelearning.seldon.io/v1
종류 : SeldonDeployment
메타 데이터 :
 이름 : 셀던 모델
투기:
 이름 : 테스트 배포
 예측 자 :
 -구성 요소 사양 :
   그래프:
     이름 : 분류 자
     유형 : SKLEARN_SERVER
     modelUri : gs : // seldon-models / sklearn / income / model
     어린이 : []
   이름 : 예
   복제본 : 1
이 예에서 SeldonDeployment에 예측 자 목록이 있으며 각 예측자는 추론 그래프를 설명합니다.",,
2141,"Each predictor has some core fields:

componentSpecs

A list of Kubernetes PodSpecs, each of which will be used for a Kubernetes deployment.","각 예측 변수에는 몇 가지 핵심 필드가 있습니다.

componentSpecs

Kubernetes 배포에 사용되는 Kubernetes PodSpecs 목록입니다.",,
2142,"graph

A representation of the inference graph containing the name of each component, its type, and the protocol it respects.","그래프

각 구성 요소의 이름, 유형 및 준수하는 프로토콜이 포함 된 추론 그래프의 표현입니다.",,
2143,"The name must match one container name from the componentSpecs section, unless it is a prepackaged model server (see subsequent examples).",이름은 사전 패키징 된 모델 서버가 아닌 경우 componentSpecs 섹션의 하나의 컨테이너 이름과 일치해야합니다 (다음 예제 참조).,,
2144,"Name

The name of the predictor.","이름

예측 자의 이름입니다.",,
2145,"Replicas

The number of replicas to create for each deployment in the predictor.","복제본

예측 자의 각 배포에 대해 생성 할 복제본 수입니다.",,
2146,"Type

The detail on whether it is a prepackaged model server or a custom language wrapper model.","유형

사전 패키징 된 모델 서버인지 사용자 지정 언어 래퍼 모델인지에 대한 세부 정보입니다.",,
2147,"modelUri

A URL where the model binary or weight are stored, which would be relevant for the respective prepackaged model server.","modelUri

모델 바이너리 또는 가중치가 저장되는 URL로, 사전 패키징 된 각 모델 서버와 관련이 있습니다.",,
2148,"Another example for SeldonDeployment for (a) is shown in EXAMPLE 8-8, using in this instance a custom language wrapper model.",(a)에 대한 SeldonDeployment의 또 다른 예는이 경우 사용자 지정 언어 래퍼 모델을 사용하여 예제 8-8에 나와 있습니다.,,
2149,Example 8-8.,예 8-8.,,
2150,"Simple Seldon Core custom language wrapper
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
 name: seldon-model
spec:
 name: test-deployment
 predictors:
 - componentSpecs:
   - spec:
       containers:
       - image: seldonio/mock_classifier_rest:1.3
         name: classifier
   graph:
     children: []
     endpoint:
       type: REST
     name: classifier
     type: MODEL
   name: example
   replicas: 1
In this example you have a small set of new sections:

Containers

This is your Kubernetes container definition, where you are able to provide overrides to the details of your container, together with your Docker image and tag.","간단한 Seldon Core 사용자 정의 언어 래퍼
apiVersion : machinelearning.seldon.io/v1
종류 : SeldonDeployment
메타 데이터 :
 이름 : 셀던 모델
투기:
 이름 : 테스트 배포
 예측 자 :
 -구성 요소 사양 :
   -사양 :
       용기 :
       -이미지 : seldonio / mock_classifier_rest : 1.3
         이름 : 분류 자
   그래프:
     어린이 : []
     끝점 :
       유형 : REST
     이름 : 분류 자
     유형 : 모델
   이름 : 예
   복제본 : 1
이 예에는 작은 새 섹션 세트가 있습니다.

컨테이너

이것은 Docker 이미지 및 태그와 함께 컨테이너의 세부 정보에 대한 재정의를 제공 할 수있는 Kubernetes 컨테이너 정의입니다.",,
2151,"Endpoint

In this case you can specify if the endpoint of your model will be REST or gRPC.","끝점

이 경우 모델의 엔드 포인트가 REST인지 gRPC인지 지정할 수 있습니다.",,
2152,The definition of your inference graph is now complete.,이제 추론 그래프의 정의가 완료되었습니다.,,
2153,We will now discuss how to test your components individually or in unison on the cluster.,이제 구성 요소를 개별적으로 또는 클러스터에서 한꺼번에 테스트하는 방법에 대해 설명합니다.,,
2154,8.7.2.,8.7.2.,,
2155,"Testing Your Model
In order to test your components, you must interface with each using some request input.","모델 테스트
구성 요소를 테스트하려면 일부 요청 입력을 사용하여 각 구성 요소와 인터페이스해야합니다.",,
2156,"You can send requests directly using curl, grpcurl, or a similar utility, as well as by using the Python SeldonClient SDK.","curl, grpcurl 또는 유사한 유틸리티를 사용하거나 Python SeldonClient SDK를 사용하여 직접 요청을 보낼 수 있습니다.",,
2157,There are several options for testing your model before deploying it.,모델을 배포하기 전에 테스트 할 수있는 몇 가지 옵션이 있습니다.,,
2158,"Running your model directly with the Python client

This allows for easy local testing outside of a cluster.","Python 클라이언트로 직접 모델 실행

이를 통해 클러스터 외부에서 쉽게 로컬 테스트를 수행 할 수 있습니다.",,
2159,"Running your model as a Docker container

This can be used for all language wrappers—but not prepackaged inference servers—to test that your image has the required dependencies and behaves as you would expect.","Docker 컨테이너로 모델 실행

이것은 모든 언어 래퍼 (사전 패키징 된 추론 서버는 아님)에 사용하여 이미지에 필요한 종속성이 있고 예상대로 작동하는지 테스트 할 수 있습니다.",,
2160,"Running your SeldonDeployment in a Kubernetes dev client such as KIND

This can be used for any models and is a final test that your model will run as expected.","KIND와 같은 Kubernetes 개발 클라이언트에서 SeldonDeployment 실행

이것은 모든 모델에 사용할 수 있으며 모델이 예상대로 실행될 것이라는 최종 테스트입니다.",,
2161,8.7.2.1.,8.7.2.1.,,
2162,"Python client for Python language wrapped models
You can define your Python model in a file called MyModel.py, as seen in EXAMPLE 8-9.","Python 언어 래핑 모델 용 Python 클라이언트
예제 8-9에서 볼 수 있듯이 MyModel.py라는 파일에서 Python 모델을 정의 할 수 있습니다.",,
2163,Example 8-9.,예 8-9.,,
2164,"Seldon Core Python model class
class MyModel:
    def __init__(self):
      pass
    def predict(*args, **kwargs):
      return [""hello, ""world""]
You are able to test your model by running the microservice CLI that is provided by the Python module.","Seldon Core Python 모델 클래스
MyModel 클래스 :
    def __init __ (자체) :
      통과하다
    def predict (* args, ** kwargs) :
      return [ ""hello,""world ""]
Python 모듈에서 제공하는 마이크로 서비스 CLI를 실행하여 모델을 테스트 할 수 있습니다.",,
2165,"Once you install the Python seldon-core module you will be able to run the model with the following command:
> seldon-core-microservice MyModel REST --service-type MODEL
...
2020-03-23 16:59:17,366 - werkzeug:_log:122
- INFO: * Running on http://0.0.0.0:5000/
(Press CTRL+C to quit)
Now that your model microservice is running, you can send a request using curl, as seen in EXAMPLE 8-10.","Python seldon-core 모듈을 설치하면 다음 명령으로 모델을 실행할 수 있습니다.
> seldon-core-microservice MyModel REST-서비스 유형 MODEL
...
2020-03-23 16 : 59 : 17,366-werkzeug : _log : 122
-정보 : * http://0.0.0.0:5000/에서 실행 중
(종료하려면 Ctrl + C를 누릅니다)
이제 모델 마이크로 서비스가 실행 중이므로 예제 8-10에 표시된 것처럼 curl을 사용하여 요청을 보낼 수 있습니다.",,
2166,Example 8-10.,예 8-10.,,
2167,"Sending a request to your Seldon Core custom microservice
> curl -X POST \
> 	-H 'Content-Type: application/json' \
> 	-d '{""data"": { ""ndarray"": [[1,2,3,4]]}}' \
>     	http://localhost:5000/api/v1.0/predictions
{""data"":{""names"":[],""ndarray"":[""hello"",""world""]},""meta"":{}}
You can see that the output of the model is returned through the API.","Seldon Core 사용자 지정 마이크로 서비스에 요청 보내기
> 컬 -X POST \
> -H '콘텐츠 유형 : application / json'\
> -d '{ ""data"": { ""ndarray"": [[1,2,3,4]]}}'\
> http : // localhost : 5000 / api / v1.0 / predictions
{ ""data"": { ""names"": [], ""ndarray"": [ ""hello"", ""world""]}, ""meta"": {}}
모델의 출력이 API를 통해 반환되는 것을 볼 수 있습니다.",,
2168,"[12]


8.7.2.2.","[12]


8.7.2.2.",,
2169,"Local testing with Docker
If you are building language models with other wrappers, you can run the containers you build through your local Docker client.","Docker를 사용한 로컬 테스트
다른 래퍼를 사용하여 언어 모델을 빌드하는 경우 로컬 Docker 클라이언트를 통해 빌드 한 컨테이너를 실행할 수 있습니다.",,
2170,A good tool for building Docker containers from source code is S2I.,소스 코드에서 Docker 컨테이너를 빌드하기위한 좋은 도구는 S2I입니다.,,
2171,"For this, you just have to run the Docker client with the command seen in EXAMPLE 8-11.",이를 위해서는 예제 8-11에 표시된 명령으로 Docker 클라이언트를 실행하기 만하면됩니다.,,
2172,Example 8-11.,예 8-11.,,
2173,"Exposing Seldon Core microservice in a local Docker client
docker run --rm --name mymodel -p 5000:5000 mymodel:0.1
This will run the model and export it on port 5000, so now you can send a request using curl, as seen in EXAMPLE 8-12.","로컬 Docker 클라이언트에서 Seldon Core 마이크로 서비스 노출
docker run --rm --name mymodel -p 5000 : 5000 mymodel : 0.1
이렇게하면 모델이 실행되고 포트 5000에서 내보낼 수 있으므로 이제 예제 8-12와 같이 curl을 사용하여 요청을 보낼 수 있습니다.",,
2174,Example 8-12.,예 8-12.,,
2175,"Sending a request to your local Seldon Core microservice
> curl -X POST \
> 	-H 'Content-Type: application/json' \
> 	-d '{""data"": { ""ndarray"": [[1,2,3,4]]}}' \
>     	http://localhost:5000/api/v1.0/predictions

{""data"":{""names"":[],""ndarray"":[""hello"",""world""]},""meta"":{}}
With this environment, you can rapidly prototype and effectively test, before serving your model in a live cluster.","로컬 Seldon Core 마이크로 서비스에 요청 보내기
> 컬 -X POST \
> -H '콘텐츠 유형 : application / json'\
> -d '{ ""data"": { ""ndarray"": [[1,2,3,4]]}}'\
> http : // localhost : 5000 / api / v1.0 / predictions

{ ""data"": { ""names"": [], ""ndarray"": [ ""hello"", ""world""]}, ""meta"": {}}
이 환경에서는 라이브 클러스터에서 모델을 제공하기 전에 신속하게 프로토 타입을 만들고 효과적으로 테스트 할 수 있습니다.",,
2176,8.7.3.,8.7.3.,,
2177,"Serving Requests
Seldon Core supports two ingress gateways, Istio and Ambassador.","서비스 요청
Seldon Core는 Istio와 Ambassador의 두 가지 수신 게이트웨이를 지원합니다.",,
2178,"Because  Kubeflow’s installation uses Istio, we will focus on how Seldon Core works with the Istio Ingress Gateway.",Kubeflow의 설치는 Istio를 사용하기 때문에 Seldon Core가 Istio Ingress Gateway와 작동하는 방식에 초점을 맞출 것입니다.,,
2179,We will assume that the Istio gateway is at <istioGateway> and has a SeldonDeployment name <deploymentName> in namespace <namespace>.,Istio 게이트웨이가 <istioGateway>에 있고 네임 스페이스 <namespace>에 SeldonDeployment 이름 <deploymentName>이 있다고 가정합니다.,,
2180,"This means a REST endpoint will be exposed at:
http://<istioGateway>/seldon/<namespace>/<deploymentName>/api/v1.0/predictions.","이는 REST 엔드 포인트가 다음에 노출됨을 의미합니다.
http : // <istioGateway> / seldon / <네임 스페이스> / <배포 이름> /api/v1.0/predictions.",,
2181,"A gRPC endpoint will be exposed at <istioGateway> and you should send header metadata in your request with:


Key seldon and value <deploymentName>.","gRPC 엔드 포인트는 <istioGateway>에 노출되며 다음을 사용하여 요청에 헤더 메타 데이터를 전송해야합니다.


키 셀돈 및 값 <deploymentName>.",,
2182,Key namespace and value <namespace>.,키 네임 스페이스 및 값 <namespace>.,,
2183,The payload for these requests will be a SeldonMessage.,이러한 요청의 페이로드는 SeldonMessage입니다.,,
2184,"[13]
A sample SeldonMessage, say for a simple ndarray representation, is shown in EXAMPLE 8-13.","[13]
간단한 ndarray 표현에 대한 샘플 SeldonMessage가 예제 8-13에 나와 있습니다.",,
2185,Example 8-13.,예 8-13.,,
2186,"SeldonMessage containing an ndarray
{
   ""data"": {
   ""ndarray"":[[1.0, 2.0, 5.0]]
   }
}
Payloads can also include simple tensors, TFTensors, as well as binary, string, or JSON data.","ndarray를 포함하는 SeldonMessage
{
   ""데이터"": {
   ""ndarray"": [[1.0, 2.0, 5.0]]
   }
}
페이로드에는 단순 텐서, TFTensor, 바이너리, 문자열 또는 JSON 데이터도 포함될 수 있습니다.",,
2187,An example request containing JSON data is shown in EXAMPLE 8-14.,JSON 데이터를 포함하는 예제 요청은 예제 8-14에 나와 있습니다.,,
2188,Example 8-14.,예 8-14.,,
2189,"SeldonMessage containing JSON data
{
   ""jsonData"": {
     ""field1"": ""some text"",
     ""field2"": 3
   }
}
Now that your inference graph is defined, tested, and running, you will want to get predictions back from it,
and you also might want to monitor it in production to ensure it is running as expected.","JSON 데이터를 포함하는 SeldonMessage
{
   ""jsonData"": {
     ""field1"": ""일부 텍스트"",
     ""field2"": 3
   }
}
추론 그래프가 정의, 테스트 및 실행되었으므로 이제 예측을 다시 가져오고 싶을 것입니다.
예상대로 실행되는지 확인하기 위해 프로덕션에서 모니터링 할 수도 있습니다.",,
2190,8.7.4.,8.7.4.,,
2191,"Monitoring Your Models
In Seldon Core’s design, deploying ML models is not treated differently from how one would deploy traditional applications.","모델 모니터링
Seldon Core의 설계에서 ML 모델 배포는 기존 애플리케이션을 배포하는 방법과 다르게 취급되지 않습니다.",,
2192,The same applies to monitoring and governance once the deployments are live.,배포가 활성화되면 모니터링 및 거버넌스에도 동일하게 적용됩니다.,,
2193,"Traditional application monitoring metrics like request latency, load, and status code distribution are provided by exposing Prometheus metrics in Grafana.","요청 지연 시간,로드 및 상태 코드 배포와 같은 기존 애플리케이션 모니터링 메트릭은 Grafana에서 Prometheus 메트릭을 노출하여 제공됩니다.",,
2194,"[14]
However, as data scientists we are mostly interested in how well the models are performing—the relationship between the live data coming in and the data the model was trained on and the reasons why specific predictions were made.","[14]
그러나 데이터 과학자로서 우리는 모델이 얼마나 잘 수행되고 있는지, 즉 들어오는 라이브 데이터와 모델이 학습 된 데이터 간의 관계 및 특정 예측이 이루어진 이유에 주로 관심이 있습니다.",,
2195,"To address these concerns, Seldon Core provides the additional open source projects Alibi:Explain and
Alibi:Detect, which focus specifically on advanced ML insights.","이러한 문제를 해결하기 위해 Seldon Core는 추가 오픈 소스 프로젝트 Alibi : Explain 및
Alibi : Detect는 특히 고급 ML 인사이트에 중점을 둡니다.",,
2196,"These two projects implement the core algorithms for model explainability, outlier detection, data drift, and adversarial attack detection, respectively.","이 두 프로젝트는 각각 모델 설명 가능성, 이상치 탐지, 데이터 드리프트 및 적대적 공격 탐지를위한 핵심 알고리즘을 구현합니다.",,
2197,"We will now walk through examples of how Seldon Core enables model explainability and drift detection, via its integration of Alibi:Explain and Alibi:Detect.",이제 Seldon Core가 Alibi : Explain 및 Alibi : Detect의 통합을 통해 모델 설명 및 드리프트 감지를 지원하는 방법에 대한 예제를 살펴 보겠습니다.,,
2198,8.7.4.1.,8.7.4.1.,,
2199,"Model explainability
Model explainability algorithms seek to answer the question:
“Why did my model make this prediction on this instance?” The answer can come in many shapes, i.e., the most important features contributing to the model’s prediction or the minimum change to features necessary to induce a different prediction.","모델 설명 가능성
모델 설명 가능성 알고리즘은 다음 질문에 대한 답을 찾습니다.
""내 모델이이 인스턴스에서이 예측을 수행 한 이유는 무엇입니까?""대답은 다양한 형태, 즉 모델의 예측에 기여하는 가장 중요한 기능 또는 다른 예측을 유도하는 데 필요한 기능에 대한 최소 변경으로 올 수 있습니다.",,
2200,Explainability algorithms are also distinguished by how much access to the underlying model they have.,설명 가능성 알고리즘은 기본 모델에 얼마나 많은 액세스 권한을 가지고 있는지에 따라 구별됩니다.,,
2201,On one end of the spectrum there are “black box” algorithms that only have access to the model prediction endpoint and nothing else.,"스펙트럼의 한쪽 끝에는 모델 예측 끝점에만 액세스 할 수있는 ""블랙 박스""알고리즘이 있습니다.",,
2202,"In contrast, you have “white box” algorithms that have full access to the internal model architecture and allow for much greater insight (such as taking gradients).","반대로 내부 모델 아키텍처에 대한 전체 액세스 권한이 있고 훨씬 더 큰 통찰력 (예 : 그래디언트 가져 오기)을 허용하는 ""화이트 박스""알고리즘이 있습니다.",,
2203,"In the production scenario, however, the black-box case is much more prominent, so we will focus on that here.",그러나 프로덕션 시나리오에서는 블랙 박스 케이스가 훨씬 더 두드러 지므로 여기서 중점적으로 살펴 보겠습니다.,,
2204,"Before discussing an example, we will describe the integration patterns that would arise from the use of black-box explanation algorithms.",예제를 논의하기 전에 블랙 박스 설명 알고리즘을 사용하여 발생할 수있는 통합 패턴을 설명합니다.,,
2205,"These algorithms typically work by generating a lot of similar-looking instances to the one being explained and then send both batch and
sequential requests to the model to map out a picture of the model’s decision-making process in the vicinity of the original instance.","이러한 알고리즘은 일반적으로 설명중인 것과 유사한 모양의 인스턴스를 많이 생성 한 다음 배치 및
원래 인스턴스 근처에서 모델의 의사 결정 프로세스 그림을 매핑하기 위해 모델에 순차적으로 요청합니다.",,
2206,"Thus, an explainer component will communicate with the underlying model, as the explanation is being computed.",따라서 설명이 계산되는 동안 설명자 구성 요소는 기본 모델과 통신합니다.,,
2207,FIGURE 8-4 shows how this pattern is implemented.,그림 8-4는이 패턴이 구현되는 방법을 보여줍니다.,,
2208,"A model configured as a SeldonDeployment sits alongside an explainer component, which comes with its own endpoint.",SeldonDeployment로 구성된 모델은 자체 엔드 포인트와 함께 제공되는 Explainer 구성 요소와 함께 있습니다.,,
2209,When the explainer endpoint is called internally the explainer communicates with the model to produce an explanation.,Explainer 엔드 포인트가 내부적으로 호출되면 Explainer는 모델과 통신하여 설명을 생성합니다.,,
2210,Figure 8-4.,그림 8-4.,,
2211,"Seldon explainer component

Warning
In FIGURE 8-4, the explainer communicates directly with the production model.","Seldon Explainer 구성 요소

경고
그림 8-4에서 설명자는 프로덕션 모델과 직접 통신합니다.",,
2212,"However, in a more realistic scenario, the underlying model would be a separate but identical deployment (i.e., in staging) to ensure that calls to the explainer don’t degrade the performance of the production inference system.",그러나보다 현실적인 시나리오에서 기본 모델은 설명자 호출이 프로덕션 추론 시스템의 성능을 저하시키지 않도록 별도의 동일한 배포 (예 : 스테이징)가됩니다.,,
2213,To illustrate these techniques we will show a few examples.,이러한 기술을 설명하기 위해 몇 가지 예를 보여 드리겠습니다.,,
2214,8.7.4.2.,8.7.4.2.,,
2215,"Sentiment prediction model
Our first example is a sentiment prediction model that is
trained on movie review data hosted by Cornell University.","감정 예측 모델
첫 번째 예는 감성 예측 모델입니다.
Cornell University에서 호스팅하는 영화 리뷰 데이터에 대한 교육을 받았습니다.",,
2216,"You can launch this with an associated anchors explainer, using a SeldonDeployment like in EXAMPLE 8-15.",예 8-15에서와 같이 SeldonDeployment를 사용하여 연결된 앵커 설명자와 함께이를 시작할 수 있습니다.,,
2217,Example 8-15.,예 8-15.,,
2218,"SeldonDeployment with Anchor Explainers
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: movie
spec:
  name: movie
  annotations:
    seldon.io/rest-timeout: ""10000""
  predictors:
  - graph:
      children: []
      implementation: SKLEARN_SERVER
      modelUri: gs://seldon-models/sklearn/moviesentiment
      name: classifier
    explainer:
      type: AnchorText
    name: default
    replicas: 1
Once deployed, this model can be queried via the Istio ingress as usual.","앵커 설명자를 사용한 Seldon 배포
apiVersion : machinelearning.seldon.io/v1
종류 : SeldonDeployment
메타 데이터 :
  이름 : 영화
투기:
  이름 : 영화
  주석 :
    seldon.io/rest-timeout : ""10000""
  예측 자 :
  -그래프 :
      어린이 : []
      구현 : SKLEARN_SERVER
      modelUri : gs : // seldon-models / sklearn / moviesentiment
      이름 : 분류 자
    설명자:
      유형 : AnchorText
    이름 : 기본값
    복제본 : 1
일단 배포되면이 모델은 평소처럼 Istio 수신을 통해 쿼리 할 수 있습니다.",,
2219,"You can then send the simple review ""This film has great actors"" to the model, as in EXAMPLE 8-16.","그런 다음 예제 8-16에서와 같이 간단한 리뷰 ""이 영화에는 훌륭한 배우가 있습니다""를 모델에 보낼 수 있습니다.",,
2220,Example 8-16.,예 8-16.,,
2221,"Sending a prediction request to your Seldon Core movie sentiment model
curl -d '{""data"": {""ndarray"":[""This film has great actors""]}}' \
   -X POST http://<istio-ingress>/seldon/seldon/movie/api/v1.0/predictions \
   -H ""Content-Type: application/json""
The response to the prediction request in EXAMPLE 8-16 is seen in EXAMPLE 8-17.","Seldon Core 영화 감정 모델에 예측 요청 보내기
curl -d '{ ""data"": { ""ndarray"": [ ""이 영화에는 훌륭한 배우가 있습니다.""]}}'\
   -X POST http : // <istio-ingress> /seldon/seldon/movie/api/v1.0/predictions \
   -H ""콘텐츠 유형 : application / json""
예 8-16의 예측 요청에 대한 응답은 예 8-17에서 볼 수 있습니다.",,
2222,Example 8-17.,예 8-17.,,
2223,"Prediction response from your Seldon Core movie sentiment model
{
  ""data"": {
    ""names"": [""t:0"",""t:1""],
    ""ndarray"": [[0.21266916924914636,0.7873308307508536]]
  },
  ""meta"": {}
}
The model is a classifier and it is predicting with 78% accuracy that this is a positive
review, which is correct.","Seldon Core 영화 감정 모델의 예측 응답
{
  ""데이터"": {
    ""이름"": [ ""t : 0"", ""t : 1""],
    ""ndarray"": [[0.21266916924914636,0.7873308307508536]]
  },
  ""메타"": {}
}
모델은 분류기이며 78 %의 정확도로 이것이 긍정적 인 것으로 예측합니다.
올바른 검토입니다.",,
2224,"You can now try to explain the request, as seen in EXAMPLE 8-18.",이제 예제 8-18에서 볼 수 있듯이 요청을 설명 할 수 있습니다.,,
2225,Example 8-18.,예 8-18.,,
2226,"Sending an explanation request to your Seldon Core movie sentiment model
curl -d '{""data"": {""ndarray"":[""This movie has great actors""]}}' \
   -X POST http://<istio-ingress>/seldon/seldon/movie/explainer/api/v1.0/explain \
   -H ""Content-Type: application/json""
The response to the explanation request in EXAMPLE 8-18 is seen in EXAMPLE 8-19 (curtailed without the examples section).","Seldon Core 영화 감성 모델에 설명 요청 보내기
curl -d '{ ""data"": { ""ndarray"": [ ""이 영화에는 훌륭한 배우가 있습니다.""]}}'\
   -X POST http : // <istio-ingress> /seldon/seldon/movie/explainer/api/v1.0/explain \
   -H ""콘텐츠 유형 : application / json""
예제 8-18의 설명 요청에 대한 응답은 예제 8-19에서 볼 수 있습니다 (예제 섹션없이 축소됨).",,
2227,Example 8-19.,예 8-19.,,
2228,"Explanation response from your Seldon Core movie sentiment model
{
  ""names"": [
    ""great""
  ],
  ""precision"": 1,
  ""coverage"": 0.5007,
  ...
  ""instance"": ""This movie has great actors"",
  ""prediction"": 1
  },
  ""meta"": {
    ""name"": ""AnchorText""
  }
}
The key element in this example is that the explainer has identified the word great as being the reason the model predicted positive sentiment and suggests that this would occur 100% of the time for this model if a sentence contains the word great (reflected by the precision value).","Seldon Core 영화 감성 모델의 설명 응답
{
  ""이름"": [
    ""큰""
  ],
  ""정밀도"": 1,
  ""범위"": 0.5007,
  ...
  ""instance"": ""이 영화에는 훌륭한 배우가 있습니다"",
  ""예측"": 1
  },
  ""meta"": {
    ""name"": ""AnchorText""
  }
}
이 예의 핵심 요소는 설명자가 great라는 단어를 모델이 긍정적 인 감정을 예측 한 이유로 식별하고 문장에 great라는 단어가 포함 된 경우이 모델의 경우 100 % 발생한다고 제안한다는 것입니다 (정밀도에 의해 반영됨).값).",,
2229,8.7.4.3.,8.7.4.3.,,
2230,"US Census income predictor model example
Here is a second example, trained on the 1996 US Census data, which predicts whether a person will have high or low income.","미국 인구 조사 소득 예측 모델의 예
다음은 1996 년 미국 인구 조사 데이터로 훈련 된 두 번째 예입니다.이 데이터는 개인의 소득이 높거나 낮을 지 여부를 예측합니다.",,
2231,"[15]
For this example, you also need to have an Alibi explainer sample the input dataset and identify categorical features to allow the explainer to give more intuitive results.","[15]
이 예에서는 Alibi 설명자가 입력 데이터 세트를 샘플링하고 설명자가보다 직관적 인 결과를 제공 할 수 있도록 범주 기능을 식별해야합니다.",,
2232,The details for configuring an Alibi explainer can be found in the  Alibi documentation along with an in-depth review of the following data science example.,Alibi Explainer 구성에 대한 세부 사항은 다음 데이터 과학 예제에 대한 심층 검토와 함께 Alibi 문서에서 찾을 수 있습니다.,,
2233,The SeldonDeployment resource is defined in EXAMPLE 8-20.,SeldonDeployment 리소스는 예제 8-20에 정의되어 있습니다.,,
2234,Example 8-20.,예 8-20.,,
2235,"SeldonDeployment for income predictor
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: income
spec:
  name: income
  annotations:
    seldon.io/rest-timeout: ""100000""
  predictors:
  - graph:
      children: []
      implementation: SKLEARN_SERVER
      modelUri: gs://seldon-models/sklearn/income/model
      name: classifier
    explainer:
      type: AnchorTabular
      modelUri: gs://seldon-models/sklearn/income/explainer
    name: default
    replicas: 1
Once deployed, you can ask for a prediction with a curl request seen in EXAMPLE 8-21.","소득 예측자를위한 SeldonDeployment
apiVersion : machinelearning.seldon.io/v1
종류 : SeldonDeployment
메타 데이터 :
  이름 : 수입
투기:
  이름 : 수입
  주석 :
    seldon.io/rest-timeout : ""100000""
  예측 자 :
  -그래프 :
      어린이 : []
      구현 : SKLEARN_SERVER
      modelUri : gs : // seldon-models / sklearn / income / model
      이름 : 분류 자
    설명자:
      유형 : AnchorTabular
      modelUri : gs : // seldon-models / sklearn / income / explainer
    이름 : 기본값
    복제본 : 1
배포가 완료되면 예제 8-21에 표시된 curl 요청으로 예측을 요청할 수 있습니다.",,
2236,Example 8-21.,예 8-21.,,
2237,"Sending a prediction request to your Seldon Core income predictor model
curl -d '{""data"": {""ndarray"":[[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]]}}' \
   -X POST http://<istio-ingress>/seldon/seldon/income/api/v1.0/predictions \
   -H ""Content-Type: application/json""
The response to the prediction request in EXAMPLE 8-21 is seen in EXAMPLE 8-22.","Seldon Core 소득 예측기 모델에 예측 요청 보내기
curl -d '{ ""data"": { ""ndarray"": [[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]]}}'\
   -X POST http : // <istio-ingress> /seldon/seldon/income/api/v1.0/predictions \
   -H ""콘텐츠 유형 : application / json""
예 8-21의 예측 요청에 대한 응답은 예 8-22에서 볼 수 있습니다.",,
2238,Example 8-22.,예 8-22.,,
2239,"Prediction response from your Seldon Core income predictor model
{
    ""data"": {
      ""names"":[""t:0"",""t:1""],
      ""ndarray"":[[1.0,0.0]]
     },
     ""meta"":{}
 }
The model is predicting low income for this person.","Seldon Core 소득 예측기 모델의 예측 응답
{
    ""데이터"": {
      ""이름"": [ ""t : 0"", ""t : 1""],
      ""ndarray"": [[1.0,0.0]]
     },
     ""메타"": {}
 }
모델은이 사람의 저소득을 예측하고 있습니다.",,
2240,You can now get an explanation for this prediction with EXAMPLE 8-23.,이제 예제 8-23을 통해이 예측에 대한 설명을 얻을 수 있습니다.,,
2241,Example 8-23.,예 8-23.,,
2242,"Sending a explanation request to your Seldon Core income predictor model
curl -d '{""data"": {""ndarray"":[[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]]}}' \
   -X POST http://<istio-ingress>/seldon/seldon/income/explainer/api/v1.0/explain \
   -H ""Content-Type: application/json""
The response to the explanation request in EXAMPLE 8-23 is seen in EXAMPLE 8-24, which we have shortened to not show all the examples returned.","Seldon Core 소득 예측 모델에 설명 요청 보내기
curl -d '{ ""data"": { ""ndarray"": [[39, 7, 1, 1, 1, 1, 4, 1, 2174, 0, 40, 9]]}}'\
   -X POST http : // <istio-ingress> /seldon/seldon/income/explainer/api/v1.0/explain \
   -H ""콘텐츠 유형 : application / json""
예제 8-23의 설명 요청에 대한 응답은 반환 된 모든 예제를 표시하지 않도록 단축 한 예제 8-24에서 볼 수 있습니다.",,
2243,Example 8-24.,예 8-24.,,
2244,"Explanation response from your Seldon Core income predictor model
{
  ""names"": [
    ""Marital Status = Never-Married"",
    ""Occupation = Admin"",
    ""Relationship = Not-in-family""
  ],
  ""precision"": 0.9766081871345029,
  ""coverage"": 0.022,
  ...
}
The key takeaway is that this model will predict a low income classification 97% of the time if the input features are ""Marital Status = Never-Married"", ""Occupation = Admin"", and ""Relationship = Not-in-family"".","Seldon Core 소득 예측 모델의 설명 응답
{
  ""이름"": [
    ""혼인 상태 = 미혼"",
    ""직업 = 관리자"",
    ""관계 = 비 가족""
  ],
  ""정밀도"": 0.9766081871345029,
  ""범위"": 0.022,
  ...
}
핵심 사항은 입력 기능이 ""혼인 상태 = 미혼"", ""직업 = 관리자""및 ""관계 = 비 가족""인 경우이 모델이 97 %의 저소득 분류를 예측한다는 것입니다.",,
2245,So these are the key features from the input that influenced the model.,따라서 이것이 모델에 영향을 준 입력의 주요 기능입니다.,,
2246,8.7.4.4.,8.7.4.4.,,
2247,"Outlier and drift detection
ML models traditionally do not extrapolate well outside of the training data distribution, and that impacts model drift.","이상 값 및 드리프트 감지
ML 모델은 전통적으로 학습 데이터 분포 외부에서 잘 외삽하지 않으며 이는 모델 드리프트에 영향을 미칩니다.",,
2248,"In order to trust and reliably act on model predictions, you must monitor the distribution of incoming requests via different types of detectors.",모델 예측을 신뢰하고 안정적으로 조치하려면 다양한 유형의 감지기를 통해 수신 요청의 배포를 모니터링해야합니다.,,
2249,Outlier detectors aim to flag individual instances that do not follow the original training distribution.,이상치 감지기는 원래 학습 분포를 따르지 않는 개별 인스턴스에 플래그를 지정하는 것을 목표로합니다.,,
2250,An adversarial detector tries to spot and correct a carefully crafted attack with the intent to fool the model.,적대적 탐지기는 모델을 속이려는 의도로 신중하게 제작 된 공격을 발견하고 수정하려고합니다.,,
2251,"Drift detectors check when the distribution of the incoming requests is diverging from a reference distribution, such as that of the training data.",드리프트 감지기는 수신 요청의 분포가 학습 데이터의 분포와 같은 참조 분포에서 벗어날 때 확인합니다.,,
2252,"If data drift occurs, the model performance can deteriorate, and it should be retrained.",데이터 드리프트가 발생하면 모델 성능이 저하 될 수 있으므로 다시 학습해야합니다.,,
2253,The ML model predictions on instances flagged by any of the detectors we’ve looked at should be verified before being used in real-life applications.,우리가 살펴본 감지기에 의해 플래그가 지정된 인스턴스에 대한 ML 모델 예측은 실제 애플리케이션에서 사용되기 전에 확인되어야합니다.,,
2254,Detectors typically return an outlier score at the instance or even the feature level.,감지기는 일반적으로 인스턴스 또는 기능 수준에서 이상치 점수를 반환합니다.,,
2255,"If the score is above a predefined threshold, the instance is flagged.",점수가 사전 정의 된 임계 값을 초과하면 인스턴스에 플래그가 지정됩니다.,,
2256,Outlier and drift detection are usually done asynchronously to the actual prediction request.,이상치 및 드리프트 감지는 일반적으로 실제 예측 요청과 비동기식으로 수행됩니다.,,
2257,"In Seldon Core you can activate payload logging and send the requests to an external service that will do the outlier and drift
detection outside the main request/response flow.","Seldon Core에서 페이로드 로깅을 활성화하고 이상 값 및 드리프트를 수행 할 외부 서비스에 요청을 보낼 수 있습니다.
기본 요청 / 응답 흐름 외부에서 감지.",,
2258,"An example architecture is shown in FIGURE 8-5, where Seldon Core’s payload logger passes requests to components that process them asynchronously.",그림 8-5에는 Seldon Core의 페이로드 로거가 요청을 비동기 적으로 처리하는 구성 요소에 전달하는 아키텍처의 예가 나와 있습니다.,,
2259,"The components that do the processing and alerting are managed via Knative Eventing, which is described in
SECTION 8.8.4.5.","처리 및 경고를 수행하는 구성 요소는 다음에 설명 된 Knative Eventing을 통해 관리됩니다.
섹션 8.8.4.5.",,
2260,"The use of Knative Eventing here is to provide late-binding event sources and event consumers, enabling asynchronous processing.",여기서 Knative Eventing을 사용하면 지연 바인딩 이벤트 소스 및 이벤트 소비자를 제공하여 비동기 처리를 사용할 수 있습니다.,,
2261,The results can be passed on to alerting systems.,결과는 경고 시스템에 전달할 수 있습니다.,,
2262,Figure 8-5.,그림 8-5.,,
2263,"Data science monitoring of models with Seldon Core and Knative

Note
Following are some examples that leverage outlier and drift detection using the architecture in FIGURE 8-5:


An outlier detection example for CIFAR10


A drift detection example for CIFAR10






8.7.5. Review
Seldon Core is a solid choice as an inference solution when building an inference graph and hoping to simultaneously achieve model serving, monitoring, and updating guarantees.","Seldon Core 및 Knative를 사용한 모델의 데이터 과학 모니터링

노트
다음은 그림 8-5의 아키텍처를 사용하여 이상 값 및 드리프트 감지를 활용하는 몇 가지 예입니다.


CIFAR10에 대한 이상 값 감지 예제


CIFAR10의 드리프트 감지 예






8.7.5.리뷰
Seldon Core는 추론 그래프를 작성하고 동시에 모델 제공, 모니터링 및 업데이트 보장을 달성하고자 할 때 추론 솔루션으로 확실한 선택입니다.",,
2264,It sufficiently fills most of the gaps of TFServing while enabling data scientists to organically grow their inference graph as their use cases become more complex.,데이터 과학자가 사용 사례가 더 복잡 해짐에 따라 추론 그래프를 유기적으로 확장 할 수 있도록하면서 TFServing의 대부분의 격차를 충분히 채 웁니다.,,
2265,"It also allows many more features outside the scope of this overview, such as Canaries, Shadows, and powerful multistage inference pipelines.","또한 Canaries, Shadows 및 강력한 다단계 추론 파이프 라인과 같이이 개요의 범위를 벗어나는 더 많은 기능을 허용합니다.",,
2266,"[16]
However, we will take a look at how it satisfies your inference requirements.","[16]
그러나 추론 요구 사항을 어떻게 충족하는지 살펴 보겠습니다.",,
2267,8.7.5.1.,8.7.5.1.,,
2268,"Model serving
Seldon Core clearly provides the functionality to extend an inference graph and support advanced ML insights in a first-class way.","모델 제공
Seldon Core는 추론 그래프를 확장하고 고급 ML 인사이트를 일류 방식으로 지원하는 기능을 명확하게 제공합니다.",,
2269,The architecture is also flexible enough to leverage other advanced ML insights outside of its managed offering.,이 아키텍처는 관리 형 제품 외부의 다른 고급 ML 인사이트를 활용할 수있을만큼 유연합니다.,,
2270,"And Seldon Core is quite versatile, providing the expected serving flexibility because it is framework-agnostic.",그리고 Seldon Core는 프레임 워크에 구애받지 않기 때문에 예상되는 서비스 유연성을 제공하는 매우 다재다능합니다.,,
2271,"It provides support for both REST and gRPC, and GPU acceleration.",REST 및 gRPC와 GPU 가속을 모두 지원합니다.,,
2272,It also can interface with streaming inputs using Knative Eventing.,또한 Knative Eventing을 사용하여 스트리밍 입력과 인터페이스 할 수 있습니다.,,
2273,"However, because the SeldonDeployment is running as a bare Kubernetes deployment, it does not provide GPU autoscaling, which we
expect from hardware-agnostic autoscaling.","그러나 SeldonDeployment는 베어 Kubernetes 배포로 실행되기 때문에 GPU 자동 확장을 제공하지 않습니다.
하드웨어에 구애받지 않는 자동 확장에서 기대합니다.",,
2274,8.7.5.2.,8.7.5.2.,,
2275,"Model monitoring
Seldon Core seems to satisfy all of your model monitoring needs.","모델 모니터링
Seldon Core는 모든 모델 모니터링 요구를 충족하는 것 같습니다.",,
2276,"Seldon Core’s deployment strategy also uses Kubeflow’s infrastructure stack, so it leverages a microservice approach.",Seldon Core의 배포 전략은 Kubeflow의 인프라 스택도 사용하므로 마이크로 서비스 접근 방식을 활용합니다.,,
2277,This is especially noticeable with Seldon Core’s explainers and detectors being represented as separate microservices within a flexible inference graph.,이는 Seldon Core의 설명자 및 감지기가 유연한 추론 그래프 내에서 별도의 마이크로 서비스로 표시되는 경우 특히 두드러집니다.,,
2278,"Seldon Core makes monitoring first-class by enabling monitoring, logging, and tracing with its support of Prometheus and Zipkin.","Seldon Core는 Prometheus 및 Zipkin의 지원을 통해 모니터링, 로깅 및 추적을 활성화하여 모니터링을 최고 수준으로 만듭니다.",,
2279,8.7.5.3.,8.7.5.3.,,
2280,"Model updating
Seldon Core is advanced in that it supports a variety of deployment strategies, including canary, pinned, and even multi-armed bandits.","모델 업데이트
Seldon Core는 카나리아, 고정 및 다중 슬롯 머신 도적을 포함한 다양한 배포 전략을 지원한다는 점에서 발전했습니다.",,
2281,"However, similar to TFServing, revision or version management isn’t managed in a first-class way.",그러나 TFServing과 유사하게 수정 또는 버전 관리는 일류 방식으로 관리되지 않습니다.,,
2282,"This, again, means that version promotion does not have a safe-rollout guarantee.","다시 말해서, 버전 프로모션에는 안전한 출시가 보장되지 않습니다.",,
2283,"Lastly, as you can see by the options available for graph inferencing, in FIGURE 8-3,
Seldon Core provides complete flexibility in growing your inference graph to support more complex deployment strategies.","마지막으로, 그래프 추론에 사용할 수있는 옵션에서 볼 수 있듯이 그림 8-3에서
Seldon Core는 더 복잡한 배포 전략을 지원하기 위해 추론 그래프를 확장하는 데 완벽한 유연성을 제공합니다.",,
2284,8.7.5.4.,8.7.5.4.,,
2285,"Summary
Seldon Core works to fill in the gaps by providing extensibility and sophisticated out-of-the-box support for complex inference graphs and model insight.","요약
Seldon Core는 복잡한 추론 그래프 및 모델 통찰력에 대한 확장 성과 정교한 기본 지원을 제공하여 격차를 채우기 위해 노력합니다.",,
2286,"But it falls short with regards to the autoscaling of GPUs, its scale-to-zero capabilities, and revision management for safe model updating—features that are common to serverless applications.","그러나 GPU의 자동 확장, 0으로 확장하는 기능, 안전한 모델 업데이트를위한 개정 관리 (서버리스 애플리케이션에 공통적 인 기능)에 대해서는 부족합니다.",,
2287,"We will now explore how KFServing works to fill this gap by adding some recent Kubernetes additions, provided by Knative, to enable serverless workflows for TFServing, Seldon Core, and many more serving solutions.","이제 TFServing, Seldon Core 및 더 많은 서비스 솔루션을위한 서버리스 워크 플로를 활성화하기 위해 Knative에서 제공하는 최근 Kubernetes 추가 기능을 추가하여 KFServing이이 격차를 채우기 위해 어떻게 작동하는지 살펴볼 것입니다.",,
2288,8.8.,8.8.,,
2289,"KFServing
As seen with TFServing and Seldon Core, the production-grade serving of ML models is not a unique problem to any one research team or company.","KFServing
TFServing 및 Seldon Core에서 볼 수 있듯이 ML 모델의 프로덕션 등급 제공은 어느 한 연구 팀이나 회사에 고유 한 문제가 아닙니다.",,
2290,"Unfortunately, this means that every in-house solution will use different model formats and expose unique proprietary serving APIs.",불행히도 이는 모든 사내 솔루션이 서로 다른 모델 형식을 사용하고 고유 한 독점 제공 API를 노출한다는 것을 의미합니다.,,
2291,"Another problem facing both TFServing and Seldon Core is the lack of serverless primitives, like revision management and more sophisticated forms of autoscaling.",TFServing과 Seldon Core 모두가 직면 한 또 다른 문제는 개정 관리 및보다 정교한 자동 확장 형식과 같은 서버리스 기본 요소가 없다는 것입니다.,,
2292,These shortcomings are also found in most inference services.,이러한 단점은 대부분의 추론 서비스에서도 발견됩니다.,,
2293,"In order to unify the open source community of model servers, while filling the gaps that each model server had, Seldon, Google, Bloomberg, and IBM engaged with the open source community to collaboratively develop KFServing.","모델 서버의 오픈 소스 커뮤니티를 통합하는 동시에 각 모델 서버의 격차를 메우기 위해 Seldon, Google, Bloomberg, IBM은 오픈 소스 커뮤니티와 협력하여 KFServing을 개발했습니다.",,
2294,"KFServing is a serverless inferencing solution that provides performant, high-abstraction interfaces for common ML frameworks like TensorFlow, XGBoost, Scikit-learn, PyTorch, and ONNX.","KFServing은 TensorFlow, XGBoost, Scikit-learn, PyTorch 및 ONNX와 같은 일반적인 ML 프레임 워크를위한 고성능의 고추 상 인터페이스를 제공하는 서버리스 추론 솔루션입니다.",,
2295,"By placing Knative on top of Kubeflow’s cloud native stack, KFServing encapsulates the complexity of autoscaling, networking, health checking, and server configuration and brings cutting-edge serving features like GPU autoscaling, scale to zero, and canary rollouts to ML prediction services.","Knative를 Kubeflow의 클라우드 네이티브 스택 위에 배치함으로써 KFServing은 자동 확장, 네트워킹, 상태 확인 및 서버 구성의 복잡성을 캡슐화하고 GPU 자동 확장, 0으로 확장, 카나리아 출시와 같은 최첨단 서비스 기능을 ML 예측 서비스에 제공합니다.",,
2296,"This allows ML engineers to focus on critical data-science–related tooling like prediction services, transformers, explainability, and drift detectors.","이를 통해 ML 엔지니어는 예측 서비스, 변환기, 설명 가능성 및 드리프트 감지기와 같은 중요한 데이터 과학 관련 도구에 집중할 수 있습니다.",,
2297,8.8.1.,8.8.1.,,
2298,"Serverless and the Service Plane
KFServing’s design primarily borrows from serverless web development.","서버리스 및 서비스 플레인
KFServing의 디자인은 주로 서버리스 웹 개발에서 차용합니다.",,
2299,"Serverless allows you to build and run applications and services without provisioning, scaling, or managing any servers.","서버리스를 사용하면 서버를 프로비저닝, 확장 또는 관리하지 않고도 애플리케이션과 서비스를 구축하고 실행할 수 있습니다.",,
2300,"These server configurations are commonly referred to as the service plane, or control plane.",이러한 서버 구성을 일반적으로 서비스 플레인 또는 컨트롤 플레인이라고합니다.,,
2301,"Naturally, serverless abstractions come with deployment simplicity and fluidity as there is limited infrastructure administration.",당연히 서버리스 추상화는 인프라 관리가 제한되어 있기 때문에 배포 단순성과 유동성과 함께 제공됩니다.,,
2302,"However, serverless architecture depends heavily on event-based triggers for scaling its replicas, which we will talk about in SECTION 8.8.4.2.",그러나 서버리스 아키텍처는 복제본을 확장하기 위해 이벤트 기반 트리거에 크게 의존합니다. 이에 대해서는 섹션 8.8.4.2에서 설명합니다.,,
2303,It allows you to focus solely on your application code.,이를 통해 애플리케이션 코드에만 집중할 수 있습니다.,,
2304,One of the primary tenancies of KFServing is extending serverless application development to model serving.,KFServing의 기본 테넌트 중 하나는 서버리스 애플리케이션 개발을 모델 서비스로 확장하는 것입니다.,,
2305,"This is particularly advantageous for data scientists, as you want to only focus on the ML model that you are developing and the resulting input and output layers.",이는 개발중인 ML 모델과 결과 입력 및 출력 레이어에만 집중하려는 데이터 과학자에게 특히 유용합니다.,,
2306,8.8.2.,8.8.2.,,
2307,"Data Plane
KFServing defines the data plane, which links all of the standard model serving components together and uses Knative to provide serverless abstractions for the service plane.","데이터 플레인
KFServing은 모든 표준 모델 서비스 구성 요소를 함께 연결하고 Knative를 사용하여 서비스 플레인에 대한 서버리스 추상화를 제공하는 데이터 플레인을 정의합니다.",,
2308,"A data plane is the protocol for how packets and requests are forwarded from one interface to another while also providing agency over service discovery, health checking, routing, load balancing, authentication/authorization, and KFServing’s data plane architecture consists of a static graph of components—similar to Seldon Core’s InferenceGraph—to coordinate requests for a single model.","데이터 플레인은 패킷과 요청이 한 인터페이스에서 다른 인터페이스로 전달되는 방식에 대한 프로토콜이며 서비스 검색, 상태 확인, 라우팅,로드 밸런싱, 인증 / 승인 및 KFServing의 데이터 플레인 아키텍처는 구성 요소의 정적 그래프로 구성됩니다.Seldon Core의 InferenceGraph와 유사하며 단일 모델에 대한 요청을 조정합니다.",,
2309,"Advanced features like ensembling, A/B testing, and multi-armed bandits connect these services together, again taking inspiration from Seldon Core’s deployment extensibility.","앙상블 링, A / B 테스트 및 다중 슬롯 머신과 같은 고급 기능은 이러한 서비스를 함께 연결하여 Seldon Core의 배포 확장 성에서 영감을 얻었습니다.",,
2310,"In order to understand the data plane’s static graph, let’s review some terminology used in FIGURE 8-6.",데이터 플레인의 정적 그래프를 이해하기 위해 그림 8-6에서 사용 된 몇 가지 용어를 살펴 보겠습니다.,,
2311,Figure 8-6.,그림 8-6.,,
2312,"KFServing data plane


Endpoint

KFServing instances are divided into two endpoints: default and canary.","KFServing 데이터 플레인


끝점

KFServing 인스턴스는 기본 및 카나리아의 두 끝점으로 나뉩니다.",,
2313,The endpoints allow users to safely make changes using the pinned and canary rollout strategies.,엔드 포인트를 통해 사용자는 고정 및 카나리아 롤아웃 전략을 사용하여 안전하게 변경할 수 있습니다.,,
2314,"Canarying is completely optional, enabling users to simply deploy with a blue-green deployment strategy against the default endpoint.",Canarying은 완전히 선택 사항이므로 사용자는 기본 엔드 포인트에 대한 청록색 배포 전략으로 간단히 배포 할 수 있습니다.,,
2315,"Component

Each endpoint has multiple components: predictor, explainer, and transformer.","구성 요소

각 엔드 포인트에는 예측 자, 설명자 및 변환기와 같은 여러 구성 요소가 있습니다.",,
2316,"The only required component is the predictor, which is the core of the system.",유일한 필수 구성 요소는 시스템의 핵심 인 예측 변수입니다.,,
2317,"As KFServing evolves, it can seamlessly increase the number of supported components to enable use cases like Seldon Core’s outlier detection.",KFServing이 발전함에 따라 지원되는 구성 요소의 수를 원활하게 늘려 Seldon Core의 이상 값 감지와 같은 사용 사례를 지원할 수 있습니다.,,
2318,"If you want, you can even introduce your own components and wire them together using the power of Knative’s abstractions.",원하는 경우 고유 한 구성 요소를 도입하고 Knative의 추상화 기능을 사용하여 함께 연결할 수도 있습니다.,,
2319,"Predictor

The predictor is the workhorse of the KFServing instance.","예언자

예측자는 KFServing 인스턴스의 핵심 요소입니다.",,
2320,It is simply a model and a model server that is made available at a network endpoint.,네트워크 엔드 포인트에서 사용할 수있는 모델이자 모델 서버입니다.,,
2321,"Explainer

The explainer enables an optional alternative data plane that provides  model explanations in addition to predictions.","설명자

Explainer는 예측 외에도 모델 설명을 제공하는 선택적 대체 데이터 플레인을 활성화합니다.",,
2322,"Users may define their own explanation container, which KFServing configures with relevant environment variables like a prediction endpoint.",사용자는 KFServing이 예측 끝점과 같은 관련 환경 변수로 구성하는 자체 설명 컨테이너를 정의 할 수 있습니다.,,
2323,"For common use cases, KFServing provides out-of-the-box explainers like Seldon Core’s Alibi:Explain, which we learned about earlier.",일반적인 사용 사례의 경우 KFServing은 앞서 살펴본 Seldon Core의 Alibi : Explain과 같은 즉시 사용 가능한 설명자를 제공합니다.,,
2324,"Transformer

The transformer enables users to define a pre- and postprocessing step before the prediction and explanation workflows.","변신 로봇

변환기를 사용하면 사용자가 예측 및 설명 워크 플로 전에 사전 및 사후 처리 단계를 정의 할 수 있습니다.",,
2325,"Like the explainer, it is configured with relevant environment variables.",Explainer와 마찬가지로 관련 환경 변수로 구성됩니다.,,
2326,The last portion of the data plane is the prediction protocol[17] that KFServing uses.,데이터 플레인의 마지막 부분은 KFServing이 사용하는 예측 프로토콜 [17]입니다.,,
2327,KFServing worked to define a set of HTTP/REST and gRPC APIs that must be implemented by compliant inference/prediction services.,KFServing은 규정을 준수하는 추론 / 예측 서비스로 구현해야하는 HTTP / REST 및 gRPC API 세트를 정의하기 위해 노력했습니다.,,
2328,"It is worth noting that KFServing standardized this prediction workflow, described in TABLE 8-3, across all model 
frameworks.","KFServing이 모든 모델에서 표 8-3에 설명 된이 예측 워크 플로우를 표준화했다는 점은 주목할 가치가 있습니다.
프레임 워크.",,
2329,Table 8-3.,표 8-3.,,
2330,"KFServing V1 data plane


API
Verb
Path
Payload




Readiness
GET

/v1/models/<model_name>

{
  Response:{""name"":<model_name>,""ready"": true/false}
}


Predict
POST

/v1/models/<model_name>:predict

{
  Request:{""instances"": []},
  Response:{""predictions"": []}
}


Explain
POST

/v1/models/<model_name>:explain

{
  Request:{""instances"": []},
  Response:{""predictions"": [],""explanations"": []}
}





8.8.3.","KFServing V1 데이터 플레인


API
동사
통로
유효 탑재량




준비
가져 오기

/ v1 / models / <모델 _ 이름>

{
  응답 : { ""name"": <model_name>, ""ready"": true / false}
}


예측
우편

/ v1 / models / <모델 _ 이름> : 예측

{
  요청 : { ""instances"": []},
  응답 : { ""예측"": []}
}


설명
우편

/ v1 / models / <모델 _ 이름> : 설명

{
  요청 : { ""instances"": []},
  응답 : { ""예측"": [], ""설명"": []}
}





8.8.3.",,
2331,"Example Walkthrough
With the data plane defined, we will now walk through an example of how you can interface with a model served by KFServing.","예제 연습
데이터 플레인이 정의되었으므로 이제 KFServing에서 제공하는 모델과 인터페이스 할 수있는 방법의 예를 살펴 보겠습니다.",,
2332,8.8.3.1.,8.8.3.1.,,
2333,"Setting up KFServing
KFServing provides InferenceService, a serverless inference resource that describes your static graph, by providing a Kubernetes CRD for serving ML models on arbitrary frameworks.","KFServing 설정
KFServing은 임의의 프레임 워크에서 ML 모델을 제공하기위한 Kubernetes CRD를 제공하여 정적 그래프를 설명하는 서버리스 추론 리소스 인 InferenceService를 제공합니다.",,
2334,"KFServing comes prepackaged with Kubeflow, so it should already be available.",KFServing은 Kubeflow와 함께 사전 패키지로 제공되므로 이미 사용할 수 있습니다.,,
2335,"The KFServing installation[18] will create a Kubernetes operator in the kubeflow namespace, which will watch for InferenceService resources.",KFServing 설치 [18]는 kubeflow 네임 스페이스에 Kubernetes 연산자를 생성하여 InferenceService 리소스를 감시합니다.,,
2336,"Warning
Because Kubeflow’s Kubernetes minimal requirement is 1.14, which does not support object selector, ENABLE_WEBHOOK_NAMESPACE_SELECTOR is enabled in the Kubeflow installation by default.","경고
Kubeflow의 Kubernetes 최소 요구 사항은 객체 선택기를 지원하지 않는 1.14이므로 Kubeflow 설치에서 ENABLE_WEBHOOK_NAMESPACE_SELECTOR가 기본적으로 사용 설정됩니다.",,
2337,"If you are using Kubeflow’s dashboard or profile controller to create user namespaces, labels are automatically added to enable KFServing to deploy models.",Kubeflow의 대시 보드 또는 프로필 컨트롤러를 사용하여 사용자 네임 스페이스를 만드는 경우 KFServing에서 모델을 배포 할 수 있도록 레이블이 자동으로 추가됩니다.,,
2338,"If you are creating namespaces manually, you will need to run:
kubectl label namespace \
my-namespace serving.kubeflow.org/inferenceservice=enabled
to allow KFServing to deploy InferenceService in the namespace my-namespace, for example.","네임 스페이스를 수동으로 생성하는 경우 다음을 실행해야합니다.
kubectl 레이블 네임 스페이스 \
my-namespace serving.kubeflow.org/inferenceservice=enabled
예를 들어 KFServing이 네임 스페이스 my-namespace에 InferenceService를 배포하도록 허용합니다.",,
2339,"To check whether the KFServing controller is installed correctly, run the following command:
kubectl get pods -n kubeflow | grep kfserving
You can confirm that the controller is running by seeing a pod in the Running state.","KFServing 컨트롤러가 올바르게 설치되었는지 확인하려면 다음 명령을 실행하십시오.
kubectl get pods -n kubeflow |grep kfserving
실행 중 상태의 포드를 확인하여 컨트롤러가 실행 중인지 확인할 수 있습니다.",,
2340,There is also a detailed troubleshooting guide you can follow on  this Kubeflow GitHub site.,이 Kubeflow GitHub 사이트에서 따를 수있는 자세한 문제 해결 가이드도 있습니다.,,
2341,8.8.3.2.,8.8.3.2.,,
2342,"Simplicity and extensibility
KFServing was fashioned to be simple for day-one users and customizable for seasoned data scientists.","단순성과 확장 성
KFServing은 첫날 사용자를 위해 간단하게 만들어졌으며 노련한 데이터 과학자를 위해 사용자 정의 할 수 있습니다.",,
2343,This is enabled via the interface that KFServing designed.,이것은 KFServing이 설계 한 인터페이스를 통해 활성화됩니다.,,
2344,Now we will take a look at three examples of InferenceService.,이제 InferenceService의 세 가지 예를 살펴 보겠습니다.,,
2345,EXAMPLE 8-25 is for sklearn.,예 8-25는 sklearn 용입니다.,,
2346,Example 8-25.,예 8-25.,,
2347,"Simple sklearn KFServing InferenceService
apiVersion: ""serving.kubeflow.org/v1alpha2""
kind: ""InferenceService""
metadata:
  name: ""sklearn-iris""
spec:
  default:
    predictor:
      sklearn:
        storageUri: ""gs://kfserving-samples/models/sklearn/iris""
EXAMPLE 8-26 is for tensorflow.","간단한 sklearn KFServing InferenceService
apiVersion : ""serving.kubeflow.org/v1alpha2""
종류 : ""InferenceService""
메타 데이터 :
  이름 : ""sklearn-iris""
투기:
  기본:
    예언자:
      sklearn :
        storageUri : ""gs : // kfserving-samples / models / sklearn / iris""
예제 8-26은 tensorflow를위한 것입니다.",,
2348,Example 8-26.,예 8-26.,,
2349,"Simple TensorFlow KFServing InferenceService
apiVersion: ""serving.kubeflow.org/v1alpha2""
kind: ""InferenceService""
metadata:
  name: ""flowers-sample""
spec:
  default:
    predictor:
      tensorflow:
        storageUri: ""gs://kfserving-samples/models/tensorflow/flowers""
EXAMPLE 8-27 is for pytorch.","간단한 TensorFlow KFServing InferenceService
apiVersion : ""serving.kubeflow.org/v1alpha2""
종류 : ""InferenceService""
메타 데이터 :
  이름 : ""꽃 샘플""
투기:
  기본:
    예언자:
      tensorflow :
        storageUri : ""gs : // kfserving-samples / models / tensorflow / flowers""
예 8-27은 pytorch에 대한 것입니다.",,
2350,Example 8-27.,예 8-27.,,
2351,"Simple PyTorch KFServing InferenceService
apiVersion: ""serving.kubeflow.org/v1alpha2""
kind: ""InferenceService""
metadata:
  name: ""pytorch-cifar10""
spec:
  default:
    predictor:
      pytorch:
        storageUri: ""gs://kfserving-samples/models/pytorch/cifar10/""
        modelClassName: ""Net""
Each of these will give you a serving instance—with an HTTP endpoint—that will serve a model using a requested framework server type.","간단한 PyTorch KFServing InferenceService
apiVersion : ""serving.kubeflow.org/v1alpha2""
종류 : ""InferenceService""
메타 데이터 :
  이름 : ""pytorch-cifar10""
투기:
  기본:
    예언자:
      pytorch :
        storageUri : ""gs : // kfserving-samples / models / pytorch / cifar10 /""
        modelClassName : ""Net""
이들 각각은 요청 된 프레임 워크 서버 유형을 사용하여 모델을 제공하는 HTTP 엔드 포인트가있는 제공 인스턴스를 제공합니다.",,
2352,"In each of these examples, a storageUri points to a serialized asset.",이러한 각 예에서 storageUri는 직렬화 된 자산을 가리 킵니다.,,
2353,The interface is mostly consistent across different models.,인터페이스는 대부분 다른 모델에서 일관됩니다.,,
2354,"The differences are in the framework specifications, i.e., tensorflow and pytorch.","차이점은 프레임 워크 사양, 즉 tensorflow 및 pytorch에 있습니다.",,
2355,"These framework specifications are common enough in that they share information like storageUri and Kubernetes resources requests, but they’re also extensible in that they can enable framework-specific information like PyTorch’s 
ModelClassName.","이러한 프레임 워크 사양은 storageUri 및 Kubernetes 리소스 요청과 같은 정보를 공유한다는 점에서 충분히 일반적이지만 PyTorch와 같은 프레임 워크 별 정보를 활성화 할 수 있다는 점에서 확장 가능합니다.
ModelClassName.",,
2356,"Clearly, this interface is simple enough to get started quite easily, but how extensible is it toward more complex deployment configurations and strategies?",분명히이 인터페이스는 아주 쉽게 시작할 수있을만큼 간단하지만 더 복잡한 배포 구성 및 전략을 위해 얼마나 확장 할 수 있습니까?,,
2357,EXAMPLE 8-28 exhibits some of the features that KFServing has to offer.,예 8-28은 KFServing이 제공해야하는 일부 기능을 보여줍니다.,,
2358,Example 8-28.,예 8-28.,,
2359,"Sophisticated Canary KFServing InferenceService
apiVersion: ""serving.kubeflow.org/v1alpha2""
kind: ""InferenceService""
metadata:
  name: ""my-model""
spec:
  default:
    predictor:
      # 90% of traffic is sent to this model
      tensorflow:
        storageUri: ""gs://kfserving-samples/models/tensorflow/flowers""
        serviceAccount: default
        minReplicas: 2
        maxReplicas: 10
        resources:
          requests:
            cpu: 1
            gpu: 1
            memory: 8Gi
  canaryTrafficPercent: 10
  canary:
    predictor:
      # 10% of traffic is sent to this model
      tensorflow:
        storageUri: ""gs://kfserving-samples/models/tensorflow/flowers-2""
        serviceAccount: default
        minReplicas: 1
        maxReplicas: 5
        resources:
          requests:
            cpu: 1
            gpu: 1
            memory: 8Gi
The first extension is the ServiceAccount, which is used for authentication in the form of managed identities.","정교한 카나리아 KFServing 추론 서비스
apiVersion : ""serving.kubeflow.org/v1alpha2""
종류 : ""InferenceService""
메타 데이터 :
  이름 : ""내 모델""
투기:
  기본:
    예언자:
      # 90 %의 트래픽이이 모델로 전송됩니다.
      tensorflow :
        storageUri : ""gs : // kfserving-samples / models / tensorflow / flowers""
        serviceAccount : 기본값
        minReplicas : 2
        maxReplicas : 10
        자원:
          요청 :
            CPU : 1
            GPU : 1
            메모리 : 8Gi
  canaryTrafficPercent : 10
  카나리아:
    예언자:
      # 10 %의 트래픽이이 모델로 전송됩니다.
      tensorflow :
        storageUri : ""gs : // kfserving-samples / models / tensorflow / flowers-2""
        serviceAccount : 기본값
        minReplicas : 1
        maxReplicas : 5
        자원:
          요청 :
            CPU : 1
            GPU : 1
            메모리 : 8Gi
첫 번째 확장은 ServiceAccount이며 관리 ID 형식으로 인증에 사용됩니다.",,
2360,"If you wish to authenticate to S3 because your S3 should not be public, you need an identity attached to your InferenceService that validates you as a user.",S3가 퍼블릭이 아니어야하기 때문에 S3에 인증하려면 사용자 자격을 검증하는 InferenceService에 연결된 ID가 필요합니다.,,
2361,KFServing allows you to pass an identity mounted on the container and wires up the credentials through the ServiceAccount in a managed way.,KFServing을 사용하면 컨테이너에 탑재 된 ID를 전달하고 관리되는 방식으로 ServiceAccount를 통해 자격 증명을 연결할 수 있습니다.,,
2362,"For example, say you are trying to access a model that may be stored on Minio.",예를 들어 Minio에 저장되어있을 수있는 모델에 액세스하려고한다고 가정 해보십시오.,,
2363,"You would use your Minio identity information to create a secret beforehand, and then attach it to the service account.",Minio ID 정보를 사용하여 미리 비밀을 만든 다음 서비스 계정에 연결합니다.,,
2364,"If you recall, we created a secret in MinIO in SECTION 3.2.1, so we just need to include KFServing-related annotations like in EXAMPLE 8-29.",기억 나시면 섹션 3.2.1에서 MinIO에 비밀을 만들었으므로 예 8-29와 같이 KFServing 관련 주석을 포함하면됩니다.,,
2365,Example 8-29.,예 8-29.,,
2366,"KFServing-annotated MinIO secret
apiVersion: v1
data:
 awsAccessKeyID: xxxx
 awsSecretAccessKey: xxxxxxxxx
kind: Secret
metadata:
 annotations:
   serving.kubeflow.org/s3-endpoint: minio-service.kubeflow.svc.cluster.local:9000
   serving.kubeflow.org/s3-verifyssl: ""0""
   serving.kubeflow.org/s3-usehttps: ""0""
   serving.kubeflow.org/s3-region: us-east-1
 name: minioaccess
 namespace: my-namespace
And attach it to a service account like the one seen in EXAMPLE 8-30.","KFServing 주석이 달린 MinIO 비밀
apiVersion : v1
데이터:
 awsAccessKeyID : xxxx
 awsSecretAccessKey : xxxxxxxxx
종류 : 비밀
메타 데이터 :
 주석 :
   serving.kubeflow.org/s3-endpoint : minio-service.kubeflow.svc.cluster.local : 9000
   serving.kubeflow.org/s3-verifyssl : ""0""
   serving.kubeflow.org/s3-usehttps : ""0""
   serving.kubeflow.org/s3-region : us-east-1
 이름 : minioaccess
 네임 스페이스 : my-namespace
그리고 예 8-30에 표시된 것과 같은 서비스 계정에 연결합니다.",,
2367,Example 8-30.,예 8-30.,,
2368,"Service Account with attached MinIO secret
apiVersion: v1
kind: ServiceAccount
metadata:
  name: default
  namespace: my-namespace
secrets:
- name: default-token-rand6
- name: minioaccess
The second extension to notice is the min and max replicas.","MinIO 암호가 연결된 서비스 계정
apiVersion : v1
종류 : ServiceAccount
메타 데이터 :
  이름 : 기본값
  네임 스페이스 : my-namespace
비밀:
-이름 : default-token-rand6
-이름 : minioaccess
주목할 두 번째 확장은 최소 및 최대 복제본입니다.",,
2369,"You would use these to control provisioning to allow you to meet demand, neither dropping requests nor overallocating.",이를 사용하여 프로비저닝을 제어하여 요청을 삭제하거나 초과 할당하지 않고 수요를 충족 할 수 있습니다.,,
2370,"The third extension is resource requests, which have preset defaults that
you will almost always need to customize for your model.","세 번째 확장은 리소스 요청입니다.
거의 항상 모델에 맞게 사용자 정의해야합니다.",,
2371,"As you can see, this interface enables the use of hardware accelerators, like GPUs.",보시다시피이 인터페이스를 통해 GPU와 같은 하드웨어 가속기를 사용할 수 있습니다.,,
2372,The last extension showcases the mechanism that KFServing uses to enable canary deployments.,마지막 확장은 KFServing이 카나리아 배포를 활성화하는 데 사용하는 메커니즘을 보여줍니다.,,
2373,"This deployment strategy assumes that you only want to focus on a two-way traffic split, as opposed to an n-way traffic split.",이 배포 전략에서는 n 방향 트래픽 분할이 아닌 양방향 트래픽 분할에만 집중하려고한다고 가정합니다.,,
2374,"In order to customize your deployment strategy, do the following:


If you use just the default, like in your initial template,
you get a standard blue-green deployment that comes with a Kubernetes deployment resource.","배포 전략을 사용자 지정하려면 다음을 수행하십시오.


초기 템플릿 에서처럼 기본값 만 사용하는 경우
Kubernetes 배포 리소스와 함께 제공되는 표준 블루-그린 배포가 제공됩니다.",,
2375,"If you include a canary, with canaryTrafficPercent == 0, you get a pinned deployment where you have an addressable default and canary endpoint.",canaryTrafficPercent == 0 인 카나리아를 포함하면 주소 지정이 가능한 기본 및 카나리아 엔드 포인트가있는 고정 된 배포가 생성됩니다.,,
2376,"This is useful if you wish to send experimental traffic to your new endpoint, while keeping your production traffic pointed to your old endpoint.",이는 프로덕션 트래픽이 이전 엔드 포인트를 가리 키도록 유지하면서 실험 트래픽을 새 엔드 포인트로 전송하려는 경우에 유용합니다.,,
2377,"If you include canary, with canaryTrafficPercent > 0, you get a canary deployment that enables you to slowly increment traffic to your canary deployment, in a transparent way.",canary를 포함하고 canaryTrafficPercent> 0을 사용하면 투명한 방식으로 카나리아 배포에 대한 트래픽을 천천히 증가시킬 수있는 카나리아 배포를 얻을 수 있습니다.,,
2378,"In the previous example, you are experimenting with flowers-2, and as you slowly increment this canaryTrafficPercentage
you can gain confidence that your new model will not break your current users.","이전 예에서는 flowers-2를 실험하고 있으며이 canaryTrafficPercentage를 천천히 증가시키면서
새 모델이 현재 사용자에게 영향을주지 않을 것이라는 확신을 가질 수 있습니다.",,
2379,"[19] Eventually, you would go to 100, thereby flipping the canary and default, and you should then delete your old version.",[19] 결국 100으로 이동하여 카나리아와 기본값을 뒤집은 다음 이전 버전을 삭제해야합니다.,,
2380,"Now that we understand some of the powerful abstractions that KFServing offers, let’s use KFServing to host your product recommender example.",이제 KFServing이 제공하는 몇 가지 강력한 추상화를 이해 했으므로 KFServing을 사용하여 제품 추천 예제를 호스팅 해 보겠습니다.,,
2381,8.8.3.3.,8.8.3.3.,,
2382,"Recommender example
We will now put your product recommender example, from SECTION 7.1, behind an InferenceService.","추천자 예
이제 섹션 7.1의 제품 추천 예제를 InferenceService 뒤에 넣겠습니다.",,
2383,"Warning
Because the kubeflow namespace is a system namespace, you are unable to create an InferenceService in the kubeflow namespace.","경고
kubeflow 네임 스페이스는 시스템 네임 스페이스이기 때문에 kubeflow 네임 스페이스에서 InferenceService를 생성 할 수 없습니다.",,
2384,"As such, you must deploy your InferenceService in another namespace.",따라서 다른 네임 스페이스에 InferenceService를 배포해야합니다.,,
2385,"First, you’ll define your InferenceService with the following 11 lines of YAML, as seen in EXAMPLE 8-31.","먼저, 예제 8-31에 표시된대로 다음 11 줄의 YAML을 사용하여 InferenceService를 정의합니다.",,
2386,Example 8-31.,예 8-31.,,
2387,"KFServing Recommender InferenceService
apiVersion: ""serving.kubeflow.org/v1alpha2""
kind: ""InferenceService""
metadata:
 name: ""recommender""
 namespace: my-namespace
spec:
 default:
   predictor:
     tensorflow:
       serviceAccount: default
       storageUri: ""s3://models/recommender""
After running kubectl apply and waiting until your InferenceService is Ready, you should see:
$ kubectl get inferenceservices -n my-namespace
NAME        URL                                                               READY DEFAULT
recommender http://recommender.my-namespace.example.com/v1/models/recommender True  100
You can then curl your InferenceService as in EXAMPLE 8-32.","KFServing Recommender InferenceService
apiVersion : ""serving.kubeflow.org/v1alpha2""
종류 : ""InferenceService""
메타 데이터 :
 이름 : ""추천자""
 네임 스페이스 : my-namespace
투기:
 기본:
   예언자:
     tensorflow :
       serviceAccount : 기본값
       storageUri : ""s3 : // models / recommender""
kubectl apply를 실행하고 InferenceService가 준비 될 때까지 기다린 후 다음이 표시되어야합니다.
$ kubectl get inferenceservices -n my-namespace
이름 URL READY DEFAULT
추천자 http://recommender.my-namespace.example.com/v1/models/recommender True 100
그런 다음 예 8-32에서와 같이 InferenceService를 컬링 할 수 있습니다.",,
2388,Example 8-32.,예 8-32.,,
2389,"Sending a prediction request to your KFServing Recommender InferenceService
kubectl port-forward --namespace istio-system \
 $(kubectl get pod --namespace istio-system \
 --selector=""app=istio-ingressgateway"" \
 --output jsonpath='{.items[0].metadata.name}') \
 8080:80

curl -v -H ""Host: recommender.my-namespace.example.com"" \
http://localhost:8080/v1/models/recommender:predict -d \
'{""signature_name"":""serving_default"",
  ""inputs"": {""products"": [[1],[2]],""users"" : [[25], [3]]}}'
Warning
If your curl returns a 404 Not Found error, this is a known Istio gateway issue that is
present in Kubeflow 1.0.x.","KFServing Recommender InferenceService에 예측 요청 보내기
kubectl port-forward --namespace istio-system \
 $ (kubectl get pod --namespace istio-system \
 --selector = ""app = istio-ingressgateway""\
 --output jsonpath = '{. items [0] .metadata.name}') \
 8080 : 80

curl -v -H ""호스트 : recommendeder.my-namespace.example.com""\
http : // localhost : 8080 / v1 / models / recommender : predict -d \
'{ ""signature_name"": ""serving_default"",
  ""inputs"": { ""products"": [[1], [2]], ""users"": [[25], [3]]}} '
경고
컬이 404 찾을 수 없음 오류를 반환하는 경우 이는 알려진 Istio 게이트웨이 문제이며
Kubeflow 1.0.x에 있습니다.",,
2390,We recommend that you use Kubeflow 1.1 or above.,Kubeflow 1.1 이상을 사용하는 것이 좋습니다.,,
2391,A possible workaround is described in this GitHub issue.,가능한 해결 방법은이 GitHub 문제에 설명되어 있습니다.,,
2392,"As an alternative to curl, you can also use the KFServing PythonSDK to send requests in Python.",curl의 대안으로 KFServing PythonSDK를 사용하여 Python으로 요청을 보낼 수도 있습니다.,,
2393,"[20] In addition to an HTTP endpoint, this simple interface also provides all the serverless features that come with Kubeflow’s stack and Knative, among them:


Scale to zero


GPU autoscaling


Revision management (safe rollouts)


Optimized containers


Network policy and authentication


Tracing


Metrics


As such, with only a few lines of YAML, KFServing provides production ML features,
while also allowing data scientists to scale their deployments into the future.","[20] HTTP 엔드 포인트 외에도이 간단한 인터페이스는 Kubeflow의 스택 및 Knative와 함께 제공되는 모든 서버리스 기능을 제공합니다.


0으로 확장


GPU 자동 확장


개정 관리 (안전한 출시)


최적화 된 컨테이너


네트워크 정책 및 인증


트레이싱


메트릭


따라서 YAML 몇 줄만으로 KFServing은 프로덕션 ML 기능을 제공하고,
또한 데이터 과학자가 향후 배포를 확장 할 수 있습니다.",,
2394,But how does KFServing enable these features in such an abstracted way?,그러나 KFServing은 어떻게 이러한 기능을 추상화 된 방식으로 가능하게할까요?,,
2395,"We will now look at KFServing’s underlying infrastructure stack and see how it promotes serverless, how its layers can be further customized, and what additional features exist.","이제 KFServing의 기본 인프라 스택을 살펴보고 서버리스를 촉진하는 방법, 계층을 추가로 사용자 정의 할 수있는 방법, 추가 기능이 무엇인지 살펴 보겠습니다.",,
2396,8.8.4.,8.8.4.,,
2397,"Peeling Back the Underlying Infrastructure
By dissecting its infrastructure stack, you can see how KFServing enables serverless ML while also educating you on how to debug your inference solutions.","기반 인프라 제거
인프라 스택을 분석하면 KFServing이 어떻게 서버리스 ML을 지원하는지 확인하는 동시에 추론 솔루션을 디버깅하는 방법을 교육 할 수 있습니다.",,
2398,"KFServing is built in a cloud native way, as is Kubeflow.",KFServing은 Kubeflow와 마찬가지로 클라우드 네이티브 방식으로 구축됩니다.,,
2399,It benefits from the features of every layer below it.,그 아래 모든 레이어의 기능을 활용합니다.,,
2400,"As seen in FIGURE 8-7, KFServing is built on the same stack as Kubeflow but is one of the few Kubeflow solutions
that leverage Istio and Knative functionality quite heavily.","그림 8-7에서 볼 수 있듯이 KFServing은 Kubeflow와 동일한 스택에 구축되지만 몇 안되는 Kubeflow 솔루션 중 하나입니다.
Istio 및 Knative 기능을 상당히 많이 활용합니다.",,
2401,"We will now walk through the role of each of these components, in greater detail than we did in previous chapters,
to see what parts of these layers KFServing utilizes.","이제 이러한 각 구성 요소의 역할을 이전 장에서했던 것보다 더 자세히 살펴 보겠습니다.
이러한 계층의 KFServing이 활용하는 부분을 확인합니다.",,
2402,Figure 8-7.,그림 8-7.,,
2403,"KFServing infrastructure stack


8.8.4.1.","KFServing 인프라 스택


8.8.4.1.",,
2404,"Going layer by layer
Hardware that runs your compute cluster is the base-building block for all the layers above.","레이어별로 진행
컴퓨팅 클러스터를 실행하는 하드웨어는 위의 모든 계층에 대한 기본 구성 요소입니다.",,
2405,"Your cluster could run a variety of hardware devices including CPUs, GPUs, or even TPUs.","클러스터는 CPU, GPU 또는 TPU를 포함한 다양한 하드웨어 기기를 실행할 수 있습니다.",,
2406,It is the responsibility of the layers above to simplify the toggling of hardware types and to abstract as much complexity as possible.,하드웨어 유형의 토글을 단순화하고 가능한 한 많은 복잡성을 추상화하는 것은 위 계층의 책임입니다.,,
2407,"Kubernetes is the critical layer, right above the compute cluster, that manages, orchestrates, and deploys a variety of resources—successfully abstracting the underlying hardware.","Kubernetes는 컴퓨팅 클러스터 바로 위에있는 중요한 계층으로, 다양한 리소스를 관리, 조정 및 배포하여 기본 하드웨어를 성공적으로 추상화합니다.",,
2408,"The main resources we will focus on are deployments, horizontal pod autoscalers (HPA), and ingresses.","우리가 집중할 주요 리소스는 배포, 수 평형 포드 자동 확장 처리 (HPA) 및 수신입니다.",,
2409,"And since Kubernetes abstracts the underlying hardware, upon which deployments are run, this enables you to use hardware optimizers like GPUs within the upper levels of the stack.",Kubernetes는 배포가 실행되는 기본 하드웨어를 추상화하므로 스택의 상위 수준에서 GPU와 같은 하드웨어 최적화 프로그램을 사용할 수 있습니다.,,
2410,"Istio has been alluded to throughout this book, but we will talk about a few of its features that are particularly relevant to KFServing.",Istio는이 책 전체에서 언급되었지만 특히 KFServing과 관련된 몇 가지 기능에 대해 이야기 할 것입니다.,,
2411,Istio is an open source service mesh that layers transparently onto the Kubernetes cluster.,Istio는 Kubernetes 클러스터에 투명하게 계층화되는 오픈 소스 서비스 메시입니다.,,
2412,"It integrates into any logging platform, telemetry system, or policy system and promotes a uniform way to secure, connect, and monitor microservices.","모든 로깅 플랫폼, 원격 측정 시스템 또는 정책 시스템에 통합되며 마이크로 서비스를 보호, 연결 및 모니터링하는 일관된 방법을 촉진합니다.",,
2413,But what is a service mesh?,하지만 서비스 메시 란 무엇입니까?,,
2414,"Traditionally, each service instance is co-located with a sidecar network proxy.",전통적으로 각 서비스 인스턴스는 사이드카 네트워크 프록시와 함께 배치됩니다.,,
2415,"All network traffic (HTTP, REST, gRPC, etc.)","모든 네트워크 트래픽 (HTTP, REST, gRPC 등)",,
2416,from an individual service instance flows via its local sidecar proxy to the appropriate destination.,개별 서비스 인스턴스에서 로컬 사이드카 프록시를 통해 적절한 대상으로 흐릅니다.,,
2417,"Thus, the service instance is not aware of the network at large and only knows about its local proxy.",따라서 서비스 인스턴스는 네트워크 전체를 인식하지 못하고 로컬 프록시 만 알고 있습니다.,,
2418,"In effect, the distributed system network has been abstracted away from the service programmer.",실제로 분산 시스템 네트워크는 서비스 프로그래머로부터 추상화되었습니다.,,
2419,"Primarily, Istio expands upon Kubernetes resources, like ingresses, to provides service mesh fundamentals like:


Authentication/Access control


Ingress and egress policy management


Distributed tracing


Federation via multicluster ingress and routing


Intelligent traffic management


These tools are all critical for production inference applications that require administration, security, and monitoring.","주로 Istio는 수신과 같은 Kubernetes 리소스를 확장하여 다음과 같은 서비스 메시 기본 사항을 제공합니다.


인증 / 접근 제어


수신 및 송신 정책 관리


분산 추적


다중 클러스터 수신 및 라우팅을 통한 페더레이션


지능형 교통 관리


이러한 도구는 모두 관리, 보안 및 모니터링이 필요한 프로덕션 추론 애플리케이션에 중요합니다.",,
2420,"The last component of the KFServing infrastructure stack is Knative, which takes advantage of the abstractions that Istio provides.",KFServing 인프라 스택의 마지막 구성 요소는 Istio가 제공하는 추상화를 활용하는 Knative입니다.,,
2421,"The KFServing project primarily borrows from Knative Serving and Eventing, the latter of which will be expanded on in SECTION 8.8.4.5.","KFServing 프로젝트는 주로 Knative Serving 및 Eventing에서 차용하며, 후자는 섹션 8.8.4.5에서 확장됩니다.",,
2422,"As we described in SECTION 3.2.3, Knative Serving builds on Kubernetes and Istio to support deploying and serving serverless applications.",섹션 3.2.3에서 설명했듯이 Knative Serving은 Kubernetes 및 Istio를 기반으로 구축되어 서버리스 애플리케이션 배포 및 서비스를 지원합니다.,,
2423,"By building atop Kubernetes resources like deployments and HPAs, and Istio resources, like virtual services, Knative Serving provides:


An abstracted service mesh


CPU/GPU autoscaling (either queries per second (QPS) or metric-based)


Revision management for safe rollouts and canary/pinned deployment strategies


These offerings are desirable for data scientists who want to limit their focus and energy to model development, and have scaling and versioning be handled for them in a managed way.","Knative Serving은 배포 및 HPA와 같은 Kubernetes 리소스와 가상 서비스와 같은 Istio 리소스를 기반으로 다음을 제공합니다.


추상화 된 서비스 메시


CPU / GPU 자동 확장 (QPS (초당 쿼리) 또는 메트릭 기반)


안전한 롤아웃 및 카나리아 / 고정 된 배포 전략을위한 개정 관리


이러한 오퍼링은 모델 개발에 초점과 에너지를 제한하고 관리 방식으로 확장 및 버전 관리를 처리하려는 데이터 과학자에게 바람직합니다.",,
2424,8.8.4.2.,8.8.4.2.,,
2425,"Escape hatches
KFServing’s extensibility features escape hatches to the underlying layers of its stack.","탈출 해치
KFServing의 확장 성 기능은 해치를 스택의 기본 계층으로 이스케이프합니다.",,
2426,"By building escape hatches into the InferenceService CRD, data scientists can further tune their production inference
offering for security at the Istio level and their performance at the Knative level.","InferenceService CRD에 탈출 해치를 구축함으로써 데이터 과학자는 생산 추론을 추가로 조정할 수 있습니다.
Istio 수준의 보안과 Knative 수준의 성능을 제공합니다.",,
2427,"We will now walk through one example of how you can leverage these escape hatches, by tuning the autoscaling of your InferenceService.",이제 InferenceService의 자동 확장을 조정하여 이러한 이스케이프 해치를 활용할 수있는 방법에 대한 한 가지 예를 살펴 보겠습니다.,,
2428,"To understand how to use this escape hatch, you need to understand how Knative enables autoscaling.",이 이스케이프 해치를 사용하는 방법을 이해하려면 Knative가 자동 확장을 활성화하는 방법을 이해해야합니다.,,
2429,"There is a proxy in Knative Serving Pods called the queue proxy, which is responsible for enforcing request queue parameters (concurrency limits),
and reporting concurrent client metrics to the autoscaler.","Knative Serving Pod에는 요청 대기열 매개 변수 (동시성 제한)를 적용하는 대기열 프록시라는 프록시가 있습니다.
동시 클라이언트 메트릭을 자동 확장 처리에보고합니다.",,
2430,"The autoscaler, in turn, reacts to these metrics by bringing pods up and down.",그러면 자동 확장 처리는 포드를 위아래로 가져와 이러한 측정 항목에 반응합니다.,,
2431,"Every second, the queue proxy publishes the observed number of concurrent requests in that time period.",큐 프록시는 매초 해당 기간 동안 관찰 된 동시 요청 수를 게시합니다.,,
2432,KFServing by default sets the target concurrency (average number of in-flight requests per pod) to one.,KFServing은 기본적으로 대상 동시성 (팟당 평균 진행중인 요청 수)을 1로 설정합니다.,,
2433,"If we were to load the service with five concurrent requests, the autoscaler would try to scale up to five pods.",5 개의 동시 요청으로 서비스를로드하는 경우 자동 확장 처리는 최대 5 개의 포드로 확장을 시도합니다.,,
2434,You can customize the target concurrency by adding the example annotation autoscaling.knative.dev/target.,autoscaling.knative.dev/target 주석 예제를 추가하여 대상 동시성을 사용자 정의 할 수 있습니다.,,
2435,"Let’s look again at your InferenceService from EXAMPLE 8-31.
apiVersion: ""serving.kubeflow.org/v1alpha2""
kind: ""InferenceService""
metadata:
 name: ""recommender""
 namespace: my-namespace
spec:
 default:
   predictor:
     tensorflow:
       serviceAccount: default
       storageUri: ""s3://models/recommender""
If you test this service by sending traffic in 30-second spurts while maintaining 5 in-flight requests,
you will see that the autoscaler scales up your inference services to 5 pods.","예 8-31의 InferenceService를 다시 살펴 보겠습니다.
apiVersion : ""serving.kubeflow.org/v1alpha2""
종류 : ""InferenceService""
메타 데이터 :
 이름 : ""추천자""
 네임 스페이스 : my-namespace
투기:
 기본:
   예언자:
     tensorflow :
       serviceAccount : 기본값
       storageUri : ""s3 : // models / recommender""
5 개의 기내 요청을 유지하면서 30 초 동안 트래픽을 전송하여이 서비스를 테스트하면
자동 확장 처리가 추론 서비스를 5 개 포드로 확장하는 것을 볼 수 있습니다.",,
2436,"[21]
Note
There will be a cold-start time cost as a result of initially spawning pods and downloading the model, before being ready to serve.","[21]
노트
제공 할 준비가되기 전에 포드를 처음 생성하고 모델을 다운로드하면 콜드 스타트 시간 비용이 발생합니다.",,
2437,The cold start may take longer (to pull the serving image) if the image is not cached on the node that the pod is scheduled on.,팟 (Pod)이 예약 된 노드에 이미지가 캐시되지 않은 경우 콜드 스타트 (제공 이미지를 가져 오는 데)가 더 오래 걸릴 수 있습니다.,,
2438,"By applying the annotation autoscaling.knative.dev/target, as seen in EXAMPLE 8-33, the target concurrency will be set to five.",예 8-33에 표시된대로 autoscaling.knative.dev/target 주석을 적용하면 대상 동시성이 5로 설정됩니다.,,
2439,Example 8-33.,예 8-33.,,
2440,"Custom target concurrency via annotations in KFServing InferenceService
apiVersion: ""serving.kubeflow.org/v1alpha2""
kind: ""InferenceService""
metadata:
 name: ""recommender""
 namespace: my-namespace
 annotations:
   autoscaling.knative.dev/target: ""5""
spec:
 default:
   predictor:
     tensorflow:
       serviceAccount: default
       storageUri: ""s3://models/recommender""
Which means, that if you load the service with five concurrent requests,
you will see that you only need one pod for your inference service.","KFServing InferenceService의 주석을 통한 사용자 지정 대상 동시성
apiVersion : ""serving.kubeflow.org/v1alpha2""
종류 : ""InferenceService""
메타 데이터 :
 이름 : ""추천자""
 네임 스페이스 : my-namespace
 주석 :
   autoscaling.knative.dev/target : ""5""
투기:
 기본:
   예언자:
     tensorflow :
       serviceAccount : 기본값
       storageUri : ""s3 : // models / recommender""
즉, 5 개의 동시 요청으로 서비스를로드하면
추론 서비스를 위해 하나의 포드 만 필요하다는 것을 알 수 있습니다.",,
2441,8.8.4.3.,8.8.4.3.,,
2442,"Debugging an InferenceService
With a fully abstracted interface, InferenceService enables many features while giving minimal exposure to the complexity under the hood.","InferenceService 디버깅
완전히 추상화 된 인터페이스를 사용하는 InferenceService는 내부의 복잡성에 대한 노출을 최소화하면서 많은 기능을 지원합니다.",,
2443,"To properly debug your InferenceService, let’s look at the request flow upon hitting your InferenceService.",InferenceService를 올바르게 디버깅하기 위해 InferenceService에 도달 할 때의 요청 흐름을 살펴 보겠습니다.,,
2444,"The request flow when hitting your inference service, illustrated in FIGURE 8-8, is as follows:


Traffic arrives through the Istio ingress gateway when traffic is external and through the Istio cluster local gateway when traffic is internal.","추론 서비스에 도달 할 때의 요청 흐름 (그림 8-8 참조)은 다음과 같습니다.


트래픽이 외부인 경우 Istio 수신 게이트웨이를 통해, 내부 트래픽 인 경우 Istio 클러스터 로컬 게이트웨이를 통해 트래픽이 도착합니다.",,
2445,KFServing creates an Istio VirtualService to specify its top-level routing rules for all of its components.,KFServing은 Istio VirtualService를 생성하여 모든 구성 요소에 대한 최상위 라우팅 규칙을 지정합니다.,,
2446,"As such, traffic routes to that top-level VirtualService from the gateway.",따라서 트래픽은 게이트웨이에서 해당 최상위 VirtualService로 라우팅됩니다.,,
2447,Knative creates an Istio virtual service to configure the gateway to route the user traffic to the desired revision.,Knative는 Istio 가상 서비스를 생성하여 사용자 트래픽을 원하는 개정으로 라우팅하도록 게이트웨이를 구성합니다.,,
2448,"Upon opening up the destination rules, you will see that the destination is a Kubernetes service for the latest ready Knative revision.",대상 규칙을 열면 대상이 준비된 최신 Knative 개정에 대한 Kubernetes 서비스임을 알 수 있습니다.,,
2449,"Once the revision pods are ready, the Kubernetes service will send the request to the queue-proxy.",개정 포드가 준비되면 Kubernetes 서비스가 요청을 큐 프록시로 보냅니다.,,
2450,"If the queue proxy has more requests than it can handle, based on the concurrency of the KFServing container, then the autoscaler will create more pods to handle the additional requests.",대기열 프록시에 KFServing 컨테이너의 동시성을 기반으로 처리 할 수있는 것보다 많은 요청이있는 경우 자동 확장 처리는 추가 요청을 처리하기 위해 더 많은 포드를 만듭니다.,,
2451,"Lastly, the queue proxy will send traffic to the KFServing controller.",마지막으로 큐 프록시는 트래픽을 KFServing 컨트롤러로 보냅니다.,,
2452,Figure 8-8.,그림 8-8.,,
2453,"KFServing request flow

Where does this come in handy?","KFServing 요청 흐름

이것은 어디에서 유용합니까?",,
2454,"Well, say you create your InferenceService but the Ready status is false:
kubectl get inferenceservice -n my-namespace recommender
NAME          URL   READY   DEFAULT TRAFFIC   CANARY TRAFFIC   AGE
recommender         False                                      3s
You can step through the resources that are created in the request flow and view each of their status objects to understand what the blocker is.","InferenceService를 생성했지만 Ready 상태가 false라고 가정 해 보겠습니다.
kubectl get inferenceservice -n 내 네임 스페이스 추천자
이름 URL 준비 기본 교통 카나리아 교통 연령
추천인 False 3s
요청 흐름에서 생성 된 리소스를 단계별로 살펴보고 각 상태 개체를보고 차단기가 무엇인지 이해할 수 있습니다.",,
2455,"[22]


8.8.4.4.","[22]


8.8.4.4.",,
2456,"Debugging performance
What if you deployed your InferenceService but its performance does not meet your expectations?","디버깅 성능
InferenceService를 배포했지만 성능이 기대에 미치지 못하는 경우 어떻게됩니까?",,
2457,KFServing provides various dashboards and tools to help investigate such issues.,KFServing은 이러한 문제를 조사하는 데 도움이되는 다양한 대시 보드와 도구를 제공합니다.,,
2458,"Using Knative, KFServing has many resources in its “debugging performance issues” guide.","Knative를 사용하는 KFServing은 ""디버깅 성능 문제""가이드에 많은 리소스를 제공합니다.",,
2459,You can also follow this Knative guide to access Prometheus and Grafana.,이 Knative 가이드를 따라 Prometheus 및 Grafana에 액세스 할 수도 있습니다.,,
2460,"Lastly, you can use request tracing, also known as distributed tracing, to see how much time is spent in each step of KFServing’s request flow in FIGURE 8-8.",마지막으로 분산 추적이라고도하는 요청 추적을 사용하여 그림 8-8에서 KFServing 요청 흐름의 각 단계에서 소요 된 시간을 확인할 수 있습니다.,,
2461,You can use this Knative guide to access request traces.,이 Knative 가이드를 사용하여 요청 추적에 액세스 할 수 있습니다.,,
2462,8.8.4.5.,8.8.4.5.,,
2463,"Knative Eventing
By bringing Knative into its stack, KFServing enabled serverless via Knative Serving and the use of event sources and event consumers via Knative Eventing.","Knative Eventing
Knative를 스택으로 가져옴으로써 KFServing은 Knative Serving을 통해 서버리스를 활성화하고 Knative Eventing을 통해 이벤트 소스 및 이벤트 소비자를 사용할 수있게되었습니다.",,
2464,"[23]
We will take a look at how Knative Eventing works, and how you can extend your inference service with an event source.","[23]
Knative Eventing의 작동 방식과 이벤트 소스를 사용하여 추론 서비스를 확장하는 방법을 살펴 보겠습니다.",,
2465,"Knative Eventing enforces a lambda-style architecture of event sources and event consumers with the following design principles:


Knative Eventing services are loosely coupled.","Knative Eventing은 다음과 같은 디자인 원칙에 따라 이벤트 소스 및 이벤트 소비자의 람다 스타일 아키텍처를 적용합니다.


Knative Eventing 서비스는 느슨하게 결합됩니다.",,
2466,Event producers and event consumers are independent.,이벤트 생산자와 이벤트 소비자는 독립적입니다.,,
2467,Any producer or Source can generate events before there are active event consumers listening.,모든 생산자 또는 소스는 청취중인 활성 이벤트 소비자가 있기 전에 이벤트를 생성 할 수 있습니다.,,
2468,Any event consumer can express interest in an event before there are producers that are creating those events.,이벤트 소비자는 이벤트를 생성하는 생산자가 있기 전에 이벤트에 대한 관심을 표현할 수 있습니다.,,
2469,"Other services can be connected to any Eventing system that:


Creates new applications without modifying the event producer or event-consumer.","다른 서비스는 다음과 같은 이벤트 시스템에 연결할 수 있습니다.


이벤트 생성자 또는 이벤트 소비자를 수정하지 않고 새 응용 프로그램을 만듭니다.",,
2470,Selects and targets specific subsets of events from their producers.,생산자로부터 이벤트의 특정 하위 집합을 선택하고 타겟팅합니다.,,
2471,"Knative Eventing delivers events in two flavors: direct delivery from a source to a single service and fan-out delivery
from a source to multiple endpoints using channels and subscriptions.","Knative Eventing은 소스에서 단일 서비스로의 직접 전달 및 팬 아웃 전달의 두 가지 유형으로 이벤트를 제공합니다.
채널 및 구독을 사용하여 소스에서 여러 엔드 포인트로.",,
2472,"There are a variety of sources[24] that come out-of-the-box when installing Knative Eventing, one of which is KafkaSource.","Knative Eventing을 설치할 때 기본적으로 제공되는 다양한 소스 [24]가 있으며, 그중 하나가 KafkaSource입니다.",,
2473,"[25] If you look at EXAMPLE 8-34, you will see how you would use KafkaSource to send events, received by Kafka, to your recommender example.",[25] 예 8-34를 보면 Kafka가 수신 한 이벤트를 추천자 예로 보내기 위해 KafkaSource를 사용하는 방법을 알 수 있습니다.,,
2474,Example 8-34.,예 8-34.,,
2475,"KafkaSource that sends events to a KFServing Recommender InferenceService
apiVersion: sources.knative.dev/v1alpha1
kind: KafkaSource
metadata:
  name: kafka-source
spec:
  consumerGroup: knative-group
  # Broker URL.","KFServing Recommender InferenceService에 이벤트를 보내는 KafkaSource
apiVersion : sources.knative.dev/v1alpha1
종류 : KafkaSource
메타 데이터 :
  이름 : kafka-source
투기:
  consumerGroup : 나이프 그룹
  # 브로커 URL.",,
2476,"Replace this with the URLs for your Kafka cluster, which
  # is in the format of my-cluster-kafka-bootstrap.my-kafka-namespace:9092.
  bootstrapServers: my-cluster-kafka-bootstrap.my-kafka-namespace:9092.
  topics: recommender
  sink:
    ref:
      apiVersion: serving.kubeflow.org/v1alpha2
      kind: InferenceService
      name: recommender
As you can see by the simplicity of this specification, after setting up your Kafka resources, hooking Kafka into
your InferenceService is as simple as 13 lines of YAML.","이것을 Kafka 클러스터의 URL로 바꾸십시오.
  #은 my-cluster-kafka-bootstrap.my-kafka-namespace : 9092 형식입니다.
  부트 스트랩 서버 : my-cluster-kafka-bootstrap.my-kafka-namespace : 9092.
  주제 : 추천자
  싱크대:
    심판 :
      apiVersion : serving.kubeflow.org/v1alpha2
      종류 : InferenceService
      이름 : 추천인
이 사양의 단순함에서 알 수 있듯이 Kafka 리소스를 설정 한 후 Kafka를
InferenceService는 YAML의 13 줄만큼 간단합니다.",,
2477,You can find a more advanced end-to-end example with MinIO and Kafka on this Kubeflow GitHub site.,이 Kubeflow GitHub 사이트에서 MinIO 및 Kafka를 사용하는 고급 엔드 투 엔드 예제를 찾을 수 있습니다.,,
2478,8.8.4.6.,8.8.4.6.,,
2479,"Additional features
KFServing contains a host of features that are continuously being improved.","추가 기능
KFServing에는 지속적으로 개선되고있는 다양한 기능이 포함되어 있습니다.",,
2480,"A comprehensive list of its capabilities can be found
on this GitHub site.","전체 기능 목록을 찾을 수 있습니다.
이 GitHub 사이트에서.",,
2481,8.8.4.7.,8.8.4.7.,,
2482,"API documentation
For more on the APIs, consult the references for the KFServing Kubernetes APIs and the KFServing Python KFServing Python APIs.","API 문서
API에 대한 자세한 내용은 KFServing Kubernetes API 및 KFServing Python KFServing Python API에 대한 참조를 참조하십시오.",,
2483,"8.8.5. Review
Building serverless on top of Seldon Core’s graph inferencing, KFServing has produced a complete inference solution
that sufficiently fills all the gaps of TFServing and Seldon Core.","8.8.5.리뷰
Seldon Core의 그래프 추론을 기반으로 서버리스를 구축 한 KFServing은 완벽한 추론 솔루션을 생성했습니다.
TFServing과 Seldon Core의 모든 격차를 충분히 채 웁니다.",,
2484,KFServing works to unify the entire community of model servers by running model servers as Knative components.,KFServing은 모델 서버를 Knative 구성 요소로 실행하여 전체 모델 서버 커뮤니티를 통합합니다.,,
2485,"With all of its functionality and promise, we will take a look at how KFServing manages to satisfy all your inference requirements.",모든 기능과 약속을 바탕으로 KFServing이 모든 추론 요구 사항을 충족하도록 관리하는 방법을 살펴 보겠습니다.,,
2486,8.8.5.1.,8.8.5.1.,,
2487,"Model serving
KFServing makes graph inference and advanced ML insights first-class while also defining a data plane that is extremely extensible for pluggable components.","모델 제공
KFServing은 그래프 추론 및 고급 ML 인사이트를 최고 수준으로 만드는 동시에 플러그 형 구성 요소에 대해 매우 확장 가능한 데이터 플레인을 정의합니다.",,
2488,This flexibility allows data scientists to focus on ML insights without having to strain over how to include them in the graph.,이러한 유연성 덕분에 데이터 과학자는 ML 인사이트를 그래프에 포함하는 방법에 부담을주지 않고도 ML 인사이트에 집중할 수 있습니다.,,
2489,"KFServing is not only versatile in that it provides serving flexibility for a variety of frameworks, but it also standardizes the data plane across differing frameworks to reduce complexity in switching between model servers.",KFServing은 다양한 프레임 워크에 대한 서비스 유연성을 제공한다는 점에서 다재다능 할뿐만 아니라 서로 다른 프레임 워크에서 데이터 플레인을 표준화하여 모델 서버 간 전환의 복잡성을 줄입니다.,,
2490,"It codifies the Kubernetes design pattern by moving common functionalities like request batching, logging, and pipelining into a sidecar.","요청 일괄 처리, 로깅 및 파이프 라이닝과 같은 공통 기능을 사이드카로 이동하여 Kubernetes 디자인 패턴을 코드화합니다.",,
2491,"This, in turn, slims down the model server and creates a separation of concerns, as model services without these features can immediately benefit from deploying onto KFServing.",결과적으로 이러한 기능이없는 모델 서비스는 KFServing에 배포하면 즉시 이점을 얻을 수 있기 때문에 모델 서버를 줄이고 문제를 분리합니다.,,
2492,"It also provides support for REST, gRPC, and GPU acceleration and can interface with streaming inputs using Knative Eventing.","또한 REST, gRPC 및 GPU 가속을 지원하고 Knative Eventing을 사용하여 스트리밍 입력과 인터페이스 할 수 있습니다.",,
2493,"And lastly, thanks to Knative Serving, KFServing provides GPU autoscaling, which you expect from  hardware-agnostic autoscaling.",마지막으로 Knative Serving 덕분에 KFServing은 하드웨어에 구애받지 않는 자동 확장에서 기대하는 GPU 자동 확장을 제공합니다.,,
2494,8.8.5.2.,8.8.5.2.,,
2495,"Model monitoring
By taking from Seldon Core and its infrastructure stack, KFServing meets all of your model monitoring needs.","모델 모니터링
Seldon Core 및 인프라 스택에서 가져옴으로써 KFServing은 모든 모델 모니터링 요구를 충족합니다.",,
2496,"KFServing leverages the sophisticated model explainers and drift detectors of Seldon Core in a first-class way,
while also paving a way for developers to define their own monitoring components in a highly flexible yet powerful data plane.","KFServing은 Seldon Core의 정교한 모델 설명자와 드리프트 감지기를 일류 방식으로 활용합니다.
또한 개발자가 매우 유연하면서도 강력한 데이터 플레인에서 자체 모니터링 구성 요소를 정의 할 수있는 방법을 제공합니다.",,
2497,"Furthermore, with all the networking capabilities enabled by having Istio and Knative in its infrastructure stack, KFServing provides extensible network monitoring and telemetry with support for Prometheus, Grafana, Kibana, Zipkin, and Jaeger, to name a few.","또한 인프라 스택에 Istio 및 Knative를 포함하여 모든 네트워킹 기능이 활성화 된 KFServing은 Prometheus, Grafana, Kibana, Zipkin 및 Jaeger를 지원하는 확장 가능한 네트워크 모니터링 및 원격 측정을 제공합니다.",,
2498,These all satisfy your needs to monitor for Kubernetes metrics (memory/CPU container limits) and server metrics (queries per second and distributed tracing).,이것들은 모두 Kubernetes 메트릭 (메모리 / CPU 컨테이너 제한) 및 서버 메트릭 (초당 쿼리 및 분산 추적)을 모니터링해야하는 요구 사항을 충족합니다.,,
2499,8.8.5.3.,8.8.5.3.,,
2500,"Model updating
KFServing’s use of Knative was strategic in providing sophisticated model updating features.","모델 업데이트
KFServing의 Knative 사용은 정교한 모델 업데이트 기능을 제공하는 데있어 전략적이었습니다.",,
2501,"As such, KFServing satisfies all of your requirements regarding deployment strategies and version rollouts.",따라서 KFServing은 배포 전략 및 버전 롤아웃과 관련된 모든 요구 사항을 충족합니다.,,
2502,"By leveraging Istio’s virtual services and the simplicity of an abstracted CRD, KFServing makes the toggling of deployment strategies
simple.","Istio의 가상 서비스와 추상화 된 CRD의 단순성을 활용하여 KFServing은 배포 전략을 전환합니다.
단순한.",,
2503,It makes the flow from blue-green → pinned → canary as simple as changing a few lines of YAML.,파란색-녹색 → 고정 → 카나리아의 흐름을 YAML 몇 줄을 변경하는 것처럼 간단하게 만듭니다.,,
2504,"Furthermore, with the diverse and ever-expanding features of its underlying stack, KFServing is easily extensible to support more-complicated deployment strategies like multi-armed bandits.",또한 기본 스택의 다양하고 지속적으로 확장되는 기능을 통해 KFServing은 다중 슬롯 머신과 같은 더 복잡한 배포 전략을 지원하도록 쉽게 확장 할 수 있습니다.,,
2505,"[26]
By using Knative Serving, KFServing adopts revision management that makes Kubernetes deployment immutable.","[26]
Knative Serving을 사용함으로써 KFServing은 Kubernetes 배포를 변경 불가능하게 만드는 개정 관리를 채택합니다.",,
2506,This ensures safe rollout by health checking the new revisions pods before moving over the traffic.,이렇게하면 트래픽을 이동하기 전에 새 개정 포드의 상태를 확인하여 안전한 롤아웃을 보장합니다.,,
2507,"A revision enables:


Automated and safe rollouts


Bookkeeping for all revisions previously created


Rollbacks to known, good configurations


This sufficiently satisfies your versioning requirements for models in development, in flight, and in production.","개정은 다음을 가능하게합니다.


자동화되고 안전한 롤아웃


이전에 생성 된 모든 개정에 대한 부기


알려진 양호한 구성으로 롤백


이는 개발, 비행 및 생산중인 모델에 대한 버전 관리 요구 사항을 충분히 충족합니다.",,
2508,8.8.5.4.,8.8.5.4.,,
2509,"Summary
KFServing has developed a sophisticated inference solution that abstracts its complexity for day-one users while
also enabling power users to take advantage of its diverse feature set.","요약
KFServing은 1 일 사용자를위한 복잡성을 추상화하는 정교한 추론 솔루션을 개발했습니다.
또한 고급 사용자가 다양한 기능 세트를 활용할 수 있습니다.",,
2510,"Building cloud native, KFServing seamlessly sits atop Kubeflow and finalizes the MDLC with its inference solution.",클라우드 네이티브를 구축하는 KFServing은 Kubeflow 위에 매끄럽게 자리 잡고 추론 솔루션으로 MDLC를 마무리합니다.,,
2511,8.9.,8.9.,,
2512,"Conclusion
In this chapter we investigated various inference solutions that can be used within Kubeflow.","결론
이 장에서는 Kubeflow 내에서 사용할 수있는 다양한 추론 솔루션을 조사했습니다.",,
2513,"Based on what inference requirements you wish to prioritize and how deep you want your infrastructure stack to be, each of the solutions described has distinctive advantages.",우선 순위를 지정하려는 추론 요구 사항과 원하는 인프라 스택의 깊이에 따라 설명 된 각 솔루션에는 고유 한 이점이 있습니다.,,
2514,"Having reviewed each of the offerings in detail, it might be worthwhile to reconsider TABLE 8-2 and see which inference solution is appropriate for your use case:


TFServing provides extremely performant and sophisticated out-of-the-box integration for TensorFlow models.","각 오퍼링을 자세히 검토 한 후 표 8-2를 재고하고 사용 사례에 적합한 추론 솔루션을 확인하는 것이 좋습니다.


TFServing은 TensorFlow 모델에 대해 매우 성능이 뛰어나고 정교한 기본 통합을 제공합니다.",,
2515,Seldon Core provides extensibility and sophisticated out-of-the-box support for complex inference graphs and model insight.,Seldon Core는 복잡한 추론 그래프 및 모델 통찰력에 대한 확장 성과 정교한 기본 지원을 제공합니다.,,
2516,KFServing provides a simpler opinionated deployment definition with serverless capabilities.,KFServing은 서버리스 기능과 함께보다 단순하고 독자적인 배포 정의를 제공합니다.,,
2517,"However, technology and development are shared between all these projects, and looking to the future, Seldon Core will even support the
new KFServing data plane with the goal to provide easy interoperability and conversion.","그러나 기술과 개발은이 모든 프로젝트간에 공유되며 미래를 내다 보며 Seldon Core는
쉬운 상호 운용성과 변환을 제공하는 것을 목표로하는 새로운 KFServing 데이터 플레인.",,
2518,"Other exciting features to expect from KFServing include multi-model serving, progressive rollouts, and more advanced graph
inferencing techniques like pipelines and multi-armed bandit.","KFServing에서 기대할 수있는 다른 흥미로운 기능으로는 다중 모델 제공, 점진적 롤아웃 및 고급 그래프가 있습니다.
파이프 라인 및 다중 슬롯 머신과 같은 추론 기술.",,
2519,"Now that you have completed the final step in your MDLC story, we will see how you can further customize Kubeflow to enable more advanced features in the next 
chapter.","MDLC 스토리의 마지막 단계를 완료 했으므로 이제 Kubeflow를 추가로 사용자 지정하여 다음에서 더 고급 기능을 활성화하는 방법을 살펴 보겠습니다.
장.",,
2520,"[1] If you are interested in learning more about model embedding, we suggest reading Serving Machine Learning Models by Boris Lublinsky (O’Reilly).",[1] 모델 임베딩에 대해 더 자세히 알고 싶다면 Boris Lublinsky (O’Reilly)의 Serving Machine Learning Models를 읽어 보시기 바랍니다.,,
2521,"[2] Some references include: “Failing Loudly: An Empirical Study of Methods for Detecting Dataset Shift”, “Detecting and Correcting for Label Shift with Black Box Predictors”, “A Kernel Two-Sample Test”, and “Monitoring and Explainability of Models in Production”.","[2] 일부 참고 자료에는 ""큰 소리로 실패 : 데이터 세트 이동 감지 방법에 대한 경험적 연구"", ""블랙 박스 예측자를 사용한 레이블 이동 감지 및 수정"", ""커널 2- 샘플 테스트""및 ""모니터링 및 설명 가능성""이 포함됩니다.생산중인 모델”.",,
2522,[3] Refer to the TensorFlow documentation for details on using TFServing locally.,[3] TFServing을 로컬에서 사용하는 방법에 대한 자세한 내용은 TensorFlow 문서를 참조하세요.,,
2523,[4] Refer to the TensorFlow documentation for details on using TFServing on Kubernetes.,[4] Kubernetes에서 TFServing을 사용하는 방법에 대한 자세한 내용은 TensorFlow 문서를 참조하세요.,,
2524,"[5] If you are using Istio as a service mesh, follow these instructions to add a virtual service.",[5] Istio를 서비스 메시로 사용하는 경우 다음 지침에 따라 가상 서비스를 추가하십시오.,,
2525,"[6] You can, of course, scale it manually by changing the amount of deployed instances.",물론 배포 된 인스턴스의 양을 변경하여 수동으로 확장 할 수 있습니다.,,
2526,[7] See TFServing’s deployment strategy configuration for more information.,[7] 자세한 내용은 TFServing의 배포 전략 구성을 참조하십시오.,,
2527,"[8] Refer to the Seldon documentation for integration with Prometheus, ELK, and Jaeger.","[8] Prometheus, ELK 및 Jaeger와의 통합은 Seldon 문서를 참조하십시오.",,
2528,"[9] Currently supported prepackaged servers include MLflow server, SKLearn server, TensorFlow serving, and XGBoost server.","[9] 현재 지원되는 사전 패키지 서버에는 MLflow 서버, SKLearn 서버, TensorFlow 서비스 및 XGBoost 서버가 포함됩니다.",,
2529,[10] Currently supported is a language server for Python.,[10] 현재 지원되는 것은 Python 용 언어 서버입니다.,,
2530,"Incubating are Java, R, NodeJS, and Go.","인큐베이팅은 Java, R, NodeJS 및 Go입니다.",,
2531,"[11] Because Seldon implements the computational structure as a tree, the combiner executes in reverse order to combine output from all children.",Seldon은 계산 구조를 트리로 구현하기 때문에 결합기는 역순으로 실행되어 모든 자식의 출력을 결합합니다.,,
2532,[12] You can also send requests using the Python client.,[12] Python 클라이언트를 사용하여 요청을 보낼 수도 있습니다.,,
2533,[13] A SeldonMessage can be defined as both an OpenAPI specification and a protobuffer definition.,SeldonMessage는 OpenAPI 사양과 프로토 버퍼 정의로 정의 할 수 있습니다.,,
2534,"[14] For more on how to enable this, see this Seldon documentation page.",이를 활성화하는 방법에 대한 자세한 내용은이 Seldon 문서 페이지를 참조하십시오.,,
2535,[15] See SECTION 7.4 for more information on this model and how it is built.,[15]이 모델과 모델 제작 방법에 대한 자세한 내용은 섹션 7.4를 참조하십시오.,,
2536,[16] See the Seldon Core documentation for further details.,[16] 자세한 내용은 Seldon Core 문서를 참조하십시오.,,
2537,"[17] KFServing is continuously evolving, as is its protocol.",KFServing은 프로토콜과 마찬가지로 지속적으로 발전하고 있습니다.,,
2538,You can preview the V2 protocol on this Kubeflow GitHub site.,이 Kubeflow GitHub 사이트에서 V2 프로토콜을 미리 볼 수 있습니다.,,
2539,"The second version of the data plane protocol addresses several issues found in the V1 data plane protocol, including performance and generality across a large number of model frameworks and servers.",데이터 플레인 프로토콜의 두 번째 버전은 V1 데이터 플레인 프로토콜에서 발견 된 여러 가지 문제를 해결합니다. 여기에는 수많은 모델 프레임 워크 및 서버의 성능과 일반성이 포함됩니다.,,
2540,[18] KFServing also supports standalone installation without Kubeflow.,[18] KFServing은 또한 Kubeflow없이 독립형 설치를 지원합니다.,,
2541,"In fact, most production users of KFServing run it as a standalone installation.",실제로 KFServing의 대부분의 프로덕션 사용자는 독립 실행 형 설치로 실행합니다.,,
2542,[19] You can still predict against a certain version by passing in a Host-Header in your request.,[19] 요청에 Host-Header를 전달하여 특정 버전에 대해 예측할 수 있습니다.,,
2543,"For more information on rollouts, see this GitHub repo.",롤아웃에 대한 자세한 내용은이 GitHub 저장소를 참조하세요.,,
2544,[20] You can install the SDK by running pip install kfserving.,[20] pip install kfserving을 실행하여 SDK를 설치할 수 있습니다.,,
2545,"You can get the KFServing SDK documentation on this GitHub site and examples on this GitHub site for creating, rolling out, promoting, and deleting an InferenceService.","이 GitHub 사이트에서 KFServing SDK 설명서를,이 GitHub 사이트에서 InferenceService 생성, 롤아웃, 승격 및 삭제에 대한 예제를 얻을 수 있습니다.",,
2546,[21] You can further explore load testing on this Kubeflow GitHub site.,[21]이 Kubeflow GitHub 사이트에서 부하 테스트를 자세히 살펴볼 수 있습니다.,,
2547,Two great load-testing frameworks are Hey and Vegeta.,두 가지 훌륭한로드 테스트 프레임 워크는 Hey와 Vegeta입니다.,,
2548,[22] A detailed debugging guide can be found on  this Kubeflow GitHub site.,[22] 자세한 디버깅 가이드는이 Kubeflow GitHub 사이트에서 찾을 수 있습니다.,,
2549,"[23] To learn more about Knative Eventing, see the documentation.",[23] Knative Eventing에 대한 자세한 내용은 설명서를 참조하십시오.,,
2550,[24] Knative has a nonexhaustive list of event sources.,Knative에는 이벤트 소스의 전체 목록이 없습니다.,,
2551,"[25] To learn more about KafkaSource, see the documentation.",KafkaSource에 대한 자세한 내용은 설명서를 참조하십시오.,,
2552,[26] Check out examples of how ML Graph can be used to build complex graphs of ML components on this Seldon GitHub site.,[26]이 Seldon GitHub 사이트에서 ML Graph를 사용하여 복잡한 ML 구성 요소 그래프를 구축하는 방법에 대한 예를 확인하세요.,,
2553,Chapter 9.,9 장.,,
2554,"Case Study Using Multiple Tools
In this chapter we’re going to discuss what to do if you need to use “other” tools for your particular data science pipeline.","여러 도구를 사용한 사례 연구
이 장에서는 특정 데이터 과학 파이프 라인에 ""기타""도구를 사용해야하는 경우 수행 할 작업에 대해 설명합니다.",,
2555,Python has a plethora of tools for handling a wide array of data formats.,Python에는 다양한 데이터 형식을 처리 할 수있는 수많은 도구가 있습니다.,,
2556,RStats has a large repository of advanced math functions.,RStats에는 고급 수학 함수의 대규모 저장소가 있습니다.,,
2557,Scala is the default language of big data processing engines such as Apache Spark and Apache Flink.,Scala는 Apache Spark 및 Apache Flink와 같은 빅 데이터 처리 엔진의 기본 언어입니다.,,
2558,Legacy programs that would be costly to reproduce exist in any number of languages.,재현하는 데 비용이 많이 드는 레거시 프로그램은 여러 언어로 존재합니다.,,
2559,"A very important benefit of Kubeflow is that users no longer need to choose which language is best for their entire pipeline
but can instead use the best language for each job (as long as the language and code are containerizable).","Kubeflow의 매우 중요한 이점은 사용자가 더 이상 전체 파이프 라인에 가장 적합한 언어를 선택할 필요가 없다는 것입니다.
대신 각 작업에 가장 적합한 언어를 사용할 수 있습니다 (언어와 코드가 컨테이너화 가능한 경우).",,
2560,We will demonstrate these concepts through a comprehensive example denoising CT scans.,우리는 CT 스캔 노이즈를 제거하는 포괄적 인 예제를 통해 이러한 개념을 설명합니다.,,
2561,"Low-dose CT scans allow clinicians to use the scans as a diagnostic tool by delivering a fraction of the radiation dose—however, these scans often
suffer from an increase in white noise.","저선량 CT 스캔을 통해 임상의는 방사선 량의 일부를 제공하여 스캔을 진단 도구로 사용할 수 있습니다. 그러나 이러한 스캔은 자주 사용됩니다.
백색 소음의 증가로 고통받습니다.",,
2562,"CT scans come in a format known as DICOM, and we’ll use a container with a specialized library called pydicom to load and process the data into a numpy matrix.",CT 스캔은 DICOM이라는 형식으로 제공되며 pydicom이라는 특수 라이브러리가있는 컨테이너를 사용하여 데이터를 numpy 행렬로로드하고 처리합니다.,,
2563,"Several methods for denoising CT scans exist; however, they often focus on the mathematical justification, not the implementation.",CT 스캔 노이즈를 제거하는 몇 가지 방법이 있습니다.그러나 그들은 종종 구현이 아닌 수학적 정당화에 초점을 맞 춥니 다.,,
2564,"We will present an open source method that uses a singular value decomposition (SVD) to break the image into components, the “least important” of which are often the noise.","SVD (singular value decomposition)를 사용하여 이미지를 구성 요소로 나누는 오픈 소스 방법을 제시 할 것입니다. 그 중에서 ""가장 덜 중요한""요소는 종종 노이즈입니다.",,
2565,We use Apache Spark with the Apache Mahout library to do a singular value decomposition.,Apache Mahout 라이브러리와 함께 Apache Spark를 사용하여 특이 값 분해를 수행합니다.,,
2566,"Finally, we use Python again to denoise the CT scans and visualize the results.",마지막으로 Python을 다시 사용하여 CT 스캔의 노이즈를 제거하고 결과를 시각화합니다.,,
2567,9.1.,9.1.,,
2568,"The Denoising CT Scans Example
Computed tomography (CT) scans are used for a wide array of medical purposes.","노이즈 제거 CT 스캔 예
컴퓨터 단층 촬영 (CT) 스캔은 다양한 의료 목적으로 사용됩니다.",,
2569,The scans work by taking X-rays from multiple angles and forming image “slices” that can then be stacked to create a 3D image of a person’s insides.,"스캔은 여러 각도에서 X- 레이를 촬영하고 이미지 ""슬라이스""를 형성하여 쌓여서 사람 내부의 3D 이미지를 생성합니다.",,
2570,"In the United States, health experts recommend a person receive no more than 100 milliSieverts (mSv) of radiation throughout their lives, which is equivalent to about 25 chest CT scans (at ~7 mSv each).",미국의 건강 전문가들은 환자가 평생 동안 100 밀리 시버트 (mSv) 이하의 방사선을받을 것을 권장합니다. 이는 약 25 회의 흉부 CT 스캔 (각각 ~ 7mSv)에 해당하는 것과 같습니다.,,
2571,"In the late twentieth and early twenty-first century, much research was done on what are known as “low-dose” CT scans.",20 세기 말과 21 세기 초에“저선량”CT 스캔으로 알려진 것에 대해 많은 연구가 이루어졌습니다.,,
2572,"A low-dose chest CT scan only delivers 1 to 2 mSv of radiation, but at a cost of a much noisier image, which can be harder to read.",저선량 흉부 CT 스캔은 1 ~ 2mSv의 방사선 만 전달하지만 훨씬 더 노이즈가 많은 이미지를 제공하므로 읽기가 더 어려울 수 있습니다.,,
2573,These scans are popular tools for screening for lung cancer among habitual smokers.,이러한 스캔은 습관적인 흡연자들 사이에서 폐암 검사를위한 인기있는 도구입니다.,,
2574,"The cost of this low-dose CT scan is that the resultant image is lower quality, or noisier.",이 저선량 CT 스캔의 비용은 결과 이미지의 품질이 낮거나 노이즈가 더 크다는 것입니다.,,
2575,"In the 2000s, much research was done on denoising these low-dose CT scans.",2000 년대에는 이러한 저선량 CT 스캔의 노이즈 제거에 대한 많은 연구가 수행되었습니다.,,
2576,Most of the papers present methods and results only (no code).,대부분의 논문은 방법과 결과 만 제시합니다 (코드 없음).,,
2577,"Further, the FDA restricts what methods can be used for denoising CT scans, which has led to almost all solutions being proprietary and expensive.",또한 FDA는 CT 스캔 노이즈 제거에 사용할 수있는 방법을 제한하므로 거의 모든 솔루션이 독점적이고 비용이 많이 듭니다.,,
2578,Denoising seeks to improve image quality by removing the white noise that is often present in these low-dose CT scans.,노이즈 제거는 이러한 저선량 CT 스캔에 자주 나타나는 백색 노이즈를 제거하여 이미지 품질을 개선합니다.,,
2579,"At the time of the writing of this book, the novel coronavirus more popularly known as COVID-19 has escalated into a global pandemic.",이 책을 쓰는 시점에서 COVID-19로 더 널리 알려진 신종 코로나 바이러스는 전 세계적으로 확산되었습니다.,,
2580,"It has been shown that chest CT scans are a more sensitive early-detection test than the reverse transcription polymerase chain reaction (RT-PCR) test, especially at early stages of infection.",흉부 CT 스캔은 특히 감염 초기 단계에서 역전사 중합 효소 연쇄 반응 (RT-PCR) 검사보다 더 민감한 조기 발견 검사 인 것으로 나타났습니다.,,
2581,"As multiple repositories of CT scans are coming online and asking AI researchers to assist in fighting the pandemic, we have sought to add a method for denoising CT scans based entirely on off-the-shelf open source components.",CT 스캔의 여러 리포지토리가 온라인에 등장하고 AI 연구자들에게 전염병 퇴치에 도움을 요청함에 따라 우리는 기성품 오픈 소스 구성 요소를 전적으로 기반으로 CT 스캔 노이즈를 제거하는 방법을 추가하려고했습니다.,,
2582,"Namely we will use Python, Apache Spark, Apache Mahout (a Spark library specializing in distributed linear algebra), and Kubeflow.","즉, Python, Apache Spark, Apache Mahout (분산 선형 대수 전문 Spark 라이브러리) 및 Kubeflow를 사용합니다.",,
2583,"We will not delve into the math of what we are doing here, but we strongly encourage you to consult this paper.",여기서 우리가하는 일에 대한 수학을 탐구하지는 않겠지 만이 문서를 참조하는 것이 좋습니다.,,
2584,"[1]
In this example, we will instead focus on the “how” of doing this technique with Kubeflow, and encourage readers to add their own steps at the end of this pipeline, which can then be freely shared with other researchers.","[1]
이 예에서는 대신 Kubeflow에서이 기술을 수행하는 ""방법""에 초점을 맞추고 독자가이 파이프 라인 끝에 자신의 단계를 추가하여 다른 연구자와 자유롭게 공유 할 수 있도록 권장합니다.",,
2585,9.1.1.,9.1.1.,,
2586,"Data Prep with Python
CT scan images are commonly stored in the DICOM format.","Python을 사용한 데이터 준비
CT 스캔 이미지는 일반적으로 DICOM 형식으로 저장됩니다.",,
2587,"In this format each “slice” of the image is stored in its own file, along with some metadata about the image, such as space between pixels, and space between slices.","이 형식에서 이미지의 각 ""슬라이스""는 픽셀 간 공간 및 슬라이스 간 공간과 같은 이미지에 대한 일부 메타 데이터와 함께 자체 파일에 저장됩니다.",,
2588,We want to read all of these files and create a 3D tensor of the pixel values.,이 모든 파일을 읽고 픽셀 값의 3D 텐서를 만들고 싶습니다.,,
2589,"Then we want to “flatten” that tensor into a two-dimensional matrix, on which we can then perform a singular value decomposition.","그런 다음 해당 텐서를 2 차원 행렬로 ""평탄화""하여 특이 값 분해를 수행 할 수 있습니다.",,
2590,There are several places where you can get DICOM file sets.,DICOM 파일 세트를 얻을 수있는 여러 위치가 있습니다.,,
2591,"For the paper, we retrieved some from https://coronacases.org (though downloading the
DICOMs can be a bit tricky).","논문의 경우 https://coronacases.org에서 일부를 검색했습니다 (
DICOM은 약간 까다로울 수 있습니다.)",,
2592,"Other places you can find DICOM files are CT scans from the Public Lung Image Database, a CD you may have received from the doctor if you’ve ever had a CT scan, and other places online.","DICOM 파일을 찾을 수있는 다른 위치로는 Public Lung Image Database의 CT 스캔, CT 스캔을받은 적이있는 경우 의사로부터받은 CD 및 기타 온라인 위치가 있습니다.",,
2593,"[2] The important thing is, we need one directory of DICOM files that comprise a single CT scan.",[2] 중요한 것은 단일 CT 스캔을 구성하는 DICOM 파일의 디렉토리 하나가 필요하다는 것입니다.,,
2594,We will assume there exists some DICOM file set comprising a single CT scan in the directory /data/dicom.,/ data / dicom 디렉토리에 단일 CT 스캔으로 구성된 일부 DICOM 파일 세트가 있다고 가정합니다.,,
2595,"Converting a DICOM image into a tensor is shockingly easy, if you have the right dependencies in place.",적절한 종속성이있는 경우 DICOM 이미지를 텐서로 변환하는 것은 놀랍도록 쉽습니다.,,
2596,"We will use pydicom, which is a well-supported Python interface for working with DICOM images.",DICOM 이미지 작업을 위해 잘 지원되는 Python 인터페이스 인 pydicom을 사용합니다.,,
2597,"Unfortunately, the pydicom Docker images do not include Grassroots DICOM (GDCM), which is required for converting the DICOM into a pixel array.",불행히도 pydicom Docker 이미지에는 DICOM을 픽셀 배열로 변환하는 데 필요한 GDCM (Grassroots DICOM)이 포함되어 있지 않습니다.,,
2598,"Our solution to this problem was to use the pydicom Docker container as a base image, then build a compatible GDCM version.",이 문제에 대한 해결책은 pydicom Docker 컨테이너를 기본 이미지로 사용한 다음 호환 가능한 GDCM 버전을 빌드하는 것이 었습니다.,,
2599,The resulting image we’ve named rawkintrevo/covid-prep-dicom.,결과 이미지는 rawkintrevo / covid-prep-dicom으로 명명되었습니다.,,
2600,With pydicom and GDCM it’s easy to convert DICOM images into tensors, we will use a Lightweight Python Function to do the rest (see EXAMPLE 9-1).,pydicom 및 GDCM을 사용하면 DICOM 이미지를 텐서로 쉽게 변환 할 수 있습니다.나머지는 경량 Python 함수를 사용하여 수행합니다 (예제 9-1 참조).,
2601,Example 9-1.,예 9-1.,,
2602,"Lightweight Python function converts DICOMs to tensors
def dicom_to_matrix(input_dir: str, output_file: str) -> output_type:
    import pydicom 
    import numpy as np

    def dicom_to_tensor(path): 
        dicoms = [pydicom.dcmread(f""{path}/{f}"") for f in listdir(path)]
        slices = [d for d in dicoms if hasattr(d, ""SliceLocation"")]
        slices = sorted(slices, key=lambda s: s.SliceLocation)

        img_shape = list(slices[0].pixel_array.shape)
        img_shape.append(len(slices))
        img3d = np.zeros(img_shape)

        for i, s in enumerate(slices):
            img2d = s.pixel_array
            img3d[:, :, i] = img2d

        return {""img3d"": img3d, ""img_shape"": img_shape}

    m = dicom_to_tensor(f""{input_dir}"")
    np.savetxt(output_file, m['img3d'].reshape((-1,m['img_shape'][2])), delimiter="","") 
    return None


dicom_to_matrix_op = comp.func_to_container_op(
        dicom_to_matrix,
        base_image='rawkintrevo/covid-prep-dicom:0.8.0.0')


Our imports must occur within the function (not globally).","경량 Python 함수는 DICOM을 텐서로 변환합니다.
def dicom_to_matrix (input_dir : str, output_file : str)-> output_type :
    pydicom 가져 오기
    numpy를 np로 가져 오기

    def dicom_to_tensor (경로) :
        dicoms = [pydicom.dcmread (f ""{path} / {f}"") for f in listdir (path)]
        슬라이스 = [d for d in dicoms if hasattr (d, ""SliceLocation"")]
        slices = sorted (slices, key = lambda s : s.SliceLocation)

        img_shape = list (slices [0] .pixel_array.shape)
        img_shape.append (len (slices))
        img3d = np.zeros (img_shape)

        i의 경우 s in enumerate (slices) :
            img2d = s.pixel_array
            img3d [:, :, i] = img2d

        return { ""img3d"": img3d, ""img_shape"": img_shape}

    m = dicom_to_tensor (f ""{input_dir}"")
    np.savetxt (output_file, m [ 'img3d']. reshape ((-1, m [ 'img_shape'] [2])), delimiter = "","")
    반환 없음


dicom_to_matrix_op = comp.func_to_container_op (
        dicom_to_matrix,
        base_image = 'rawkintrevo / covid-prep-dicom : 0.8.0.0')


가져 오기는 함수 내에서 발생해야합니다 (전역 적으로는 아님).",,
2603,"This function reads the list of “slices,” which themselves are 2D images, and stacks them into a 3D tensor.","이 함수는 자체적으로 2D 이미지 인 ""슬라이스""목록을 읽고이를 3D 텐서로 스택합니다.",,
2604,We use numpy to reshape the 3D tensor into a 2D matrix.,numpy를 사용하여 3D 텐서를 2D 매트릭스로 재구성합니다.,,
2605,"Next, let’s consider denoising our CT scan using Apache Spark and Apache Mahout.",다음으로 Apache Spark 및 Apache Mahout을 사용하여 CT 스캔 노이즈를 제거하는 것을 고려해 보겠습니다.,,
2606,9.1.2.,9.1.2.,,
2607,"DS-SVD with Apache Spark
The mathematics behind distributed stochastic singular value decomposition (DS-SVD) are well beyond the scope of this book; however, we direct you to learn more in Apache Mahout: Beyond MapReduce, on the Apache Mahout website, or in the aforementioned paper.","Apache Spark를 사용한 DS-SVD
분산 확률 적 특이 값 분해 (DS-SVD) 뒤에있는 수학은이 책의 범위를 훨씬 벗어납니다.그러나 Apache Mahout : Beyond MapReduce, Apache Mahout 웹 사이트 또는 앞서 언급 한 문서에서 자세히 알아 보도록 안내합니다.",,
2608,"We seek to decompose our CT scan into a set of features, and then drop the least important features, as these are probably noise.",우리는 CT 스캔을 기능 집합으로 분해 한 다음 가장 덜 중요한 기능을 삭제하려고합니다.,,
2609,So let’s jump into decomposing a CT scan with Apache Spark and Apache Mahout.,이제 Apache Spark 및 Apache Mahout을 사용하여 CT 스캔을 분해 해 보겠습니다.,,
2610,"A significant feature of Apache Mahout is its “R-Like” domain-specific language, which makes math code written in Scala easy to read.","Apache Mahout의 중요한 기능은 Scala로 작성된 수학 코드를 쉽게 읽을 수있는 ""R-Like""도메인 별 언어입니다.",,
2611,"In EXAMPLE 9-2 we load our data into a Spark RDD, wrap that RDD in a Mahout distributed row matrix (DRM), and perform the DS-SVD on the matrix, which yields three matrices that we will then save.",예 9-2에서는 데이터를 Spark RDD로로드하고 해당 RDD를 Mahout 분산 행 행렬 (DRM)에 래핑 한 다음 행렬에서 DS-SVD를 수행하여 세 개의 행렬을 저장합니다.,,
2612,Example 9-2.,예 9-2.,,
2613,"Decomposing a CT scan with Spark and Mahout
val pathToMatrix = ""gs://covid-dicoms/s.csv"" 

val voxelRDD:DrmRdd[Int]  = sc.textFile(pathToMatrix)
  .map(s => dvec( s.split("","")
  .map(f => f.toDouble)))
  .zipWithIndex
  .map(o => (o._2.toInt, o._1))

val voxelDRM = drmWrap(voxelRDD) 

// k, p, q should all be cli parameters
// k is rank of the output, e.g., the number of eigenfaces we want out.","Spark 및 Mahout으로 CT 스캔 분해
val pathToMatrix = ""gs : //covid-dicoms/s.csv""

val voxelRDD : DrmRdd [Int] = sc.textFile (pathToMatrix)
  .map (s => dvec (s.split ( "","")
  .map (f => f.toDouble)))
  .zipWithIndex
  .map (o => (o._2.toInt, o._1))

발 voxelDRM = drmWrap (voxelRDD)

// k, p, q는 모두 cli 매개 변수 여야합니다.
// k는 출력의 순위, 예를 들어 우리가 원하는 고유면의 수입니다.",,
2614,"// p is oversampling parameter,
// and q is the number of additional power iterations
// Read https://mahout.apache.org/users/dim-reduction/ssvd.html
val k = args(0).toInt
val p = args(1).toInt
val q = args(2).toInt

val(drmU, drmV, s) = dssvd(voxelDRM.t, k, p, q) 

val V = drmV.checkpoint().rdd.saveAsTextFile(""gs://covid-dicoms/drmV"")
val U = drmU.t.checkpoint().rdd.saveAsTextFile(""gs://covid-dicoms/drmU"")

sc.parallelize(s.toArray,1).saveAsTextFile(""gs://covid-dicoms/s"") 


Load the data.","// p는 오버 샘플링 매개 변수입니다.
// 및 q는 추가 전력 반복 횟수입니다.
// https://mahout.apache.org/users/dim-reduction/ssvd.html 읽기
val k = args (0) .toInt
발 p = args (1) .toInt
val q = args (2) .toInt

val (drmU, drmV, s) = dssvd (voxelDRM.t, k, p, q)

val V = drmV.checkpoint (). rdd.saveAsTextFile ( ""gs : // covid-dicoms / drmV"")
val U = drmU.t.checkpoint (). rdd.saveAsTextFile ( ""gs : // covid-dicoms / drmU"")

sc.parallelize (s.toArray, 1) .saveAsTextFile ( ""gs : // covid-dicoms / s"")


데이터를로드합니다.",,
2615,Wrap the RDD in a DRM.,RDD를 DRM으로 감 쌉니다.,,
2616,Perform the DS-SVD.,DS-SVD를 수행합니다.,,
2617,Save the output.,출력을 저장하십시오.,,
2618,And so in just a few lines of Scala we are able to execute an out-of-core singular value decomposition.,그래서 단지 몇 줄의 Scala만으로 우리는 out-of-core 특이 값 분해를 실행할 수 있습니다.,,
2619,9.1.3.,9.1.3.,,
2620,"Visualization
There are lots of good libraries for visualization in R and Python, and we want to use one of these for visualizing our denoised DICOMs.","심상
R과 Python에서 시각화를위한 좋은 라이브러리가 많이 있으며, 우리는 이들 중 하나를 사용하여 denoised DICOM을 시각화하려고합니다.",,
2621,"We also want to save our final images to somewhere more persistent than a persistent volume container (PVC), so that we can come back later to view our images.",또한 최종 이미지를 영구 볼륨 컨테이너 (PVC)보다 더 영구적 인 위치에 저장하여 나중에 다시 이미지를 볼 수 있도록합니다.,,
2622,"This phase of the pipeline will have three steps:


Download the DRMs that resulted from the DS-SVD.","파이프 라인의이 단계는 세 단계로 구성됩니다.


DS-SVD에서 생성 된 DRM을 다운로드합니다.",,
2623,"Recombine the matrices into a DICOM, denoised by setting some of the diagonal values of the matrix s to zero.",행렬 s의 대각선 값 중 일부를 0으로 설정하여 잡음이 제거 된 DICOM으로 행렬을 다시 결합합니다.,,
2624,Render a slice of the resulting DICOM visually.,결과 DICOM 조각을 시각적으로 렌더링합니다.,,
2625,"Note
Visualization could be easily accomplished in R or Python.","노트
시각화는 R 또는 Python으로 쉽게 수행 할 수 있습니다.",,
2626,"We will proceed in Python, but using the oro.dicom package in R.  We have chosen Python because Google officially supports a Python API for interacting with Cloud Storage.",Python으로 진행하지만 R에서 oro.dicom 패키지를 사용합니다. Google은 Cloud Storage와 상호 작용하기 위해 공식적으로 Python API를 지원하기 때문에 Python을 선택했습니다.,,
2627,9.1.3.1.,9.1.3.1.,,
2628,"Downloading DRMs
Recall the DRM is really just a wrapper around an RDD.","DRM 다운로드
DRM은 실제로 RDD를 둘러싼 래퍼라는 것을 상기하십시오.",,
2629,"In the cloud storage bucket, it will be represented as a directory
full of “parts” of the matrix.","클라우드 스토리지 버킷에서는 디렉토리로 표시됩니다.
매트릭스의 ""부분""으로 가득 차 있습니다.",,
2630,To download these files we use the helper function shown in EXAMPLE 9-3.,이러한 파일을 다운로드하려면 예제 9-3에 표시된 도우미 기능을 사용합니다.,,
2631,Example 9-3.,예 9-3.,,
2632,"Helper function to download a directory from GCS
def download_folder(bucket_name = 'your-bucket-name',
                    bucket_dir = 'your-bucket-directory/',
                    dl_dir= ""local-dir/""):
    storage_client = storage.Client()
    bucket = storage_client.get_bucket(bucket_name)
    blobs = bucket.list_blobs(prefix=bucket_dir)  # Get list of files
    for blob in blobs:
        filename = blob.name.replace('/', '_')
        blob.download_to_filename(dl_dir + filename)  # Download
At the time of writing, Mahout’s integration with Python is sparse (there is no PySpark equivalent to this code).","GCS에서 디렉토리를 다운로드하는 도우미 기능
def download_folder (bucket_name = '버킷 이름',
                    bucket_dir = 'your-bucket-directory /',
                    dl_dir = ""local-dir /"") :
    storage_client = storage.Client ()
    버킷 = storage_client.get_bucket (bucket_name)
    blobs = bucket.list_blobs (prefix = bucket_dir) # 파일 목록 가져 오기
    blob의 blob :
        파일 이름 = blob.name.replace ( '/', '_')
        blob.download_to_filename (dl_dir + filename) # 다운로드
작성 당시 Mahout과 Python의 통합은 드물다 (이 코드에 해당하는 PySpark는 없음).",,
2633,"Also, there are no helper functions for reading Mahout DRMs into Python NumPy arrays, so we must write another helper function to assist us with that (shown in EXAMPLE 9-4).",또한 Mahout DRM을 Python NumPy 배열로 읽어들이는 도우미 함수가 없으므로이를 지원하기 위해 다른 도우미 함수를 작성해야합니다 (예제 9-4 참조).,,
2634,Example 9-4.,예 9-4.,,
2635,"Helper function to read Mahout DRMs into NumPy matrices
def read_mahout_drm(path):
    data = {}
    counter = 0
    parts = [p for p in os.listdir(path) if ""part""] 
    for p in parts:
        with open(f""{path}/{p}"", 'r') as f:
            lines = f.read().split(""\n"")
            for l in lines[:-1]:
                counter +=1
                t = literal_eval(l)
                arr = np.array([t[1][i] for i in range(len(t[1].keys()))])
                data[t[0]] = arr
    print(f""read {counter} lines from {path}"")
    return data


Remember, most Mahout DRMs will be in “parts” of files, so we must iterate through the parts to reconstruct the matrix.","Mahout DRM을 NumPy 행렬로 읽어들이는 도우미 기능
def read_mahout_drm (경로) :
    데이터 = {}
    카운터 = 0
    parts = [p for p in os.listdir (path) if ""part""]
    부분에있는 p의 경우 :
        open (f ""{path} / {p}"", 'r')을 f로 사용 :
            줄 = f.read (). split ( ""\ n"")
            l 라인 [: -1] :
                카운터 + = 1
                t = literal_eval (l)
                arr = np.array ([t [1] [i] for i in range (len (t [1] .keys ()))])
                데이터 [t [0]] = arr
    print (f ""{path}에서 {counter} 줄 읽기"")
    반환 데이터


대부분의 Mahout DRM은 파일의 ""부분""에 있으므로 매트릭스를 재구성하기 위해 부분을 반복해야합니다.",,
2636,9.1.3.2.,9.1.3.2.,,
2637,"Recomposing the matrix into denoised images
In a singular value decomposition, the diagonal matrix of singular values are typically denoted with a sigma.","행렬을 노이즈 제거 이미지로 재구성
특이 값 분해에서 특이 값의 대각 행렬은 일반적으로 시그마로 표시됩니다.",,
2638,"In our code,
however, we use the letter s. By convention, these values are typically ordered from most important to least important,
and happily, this convention is followed in the Mahout implementation.","우리 코드에서
그러나 우리는 문자 s를 사용합니다.관례 상 이러한 값은 일반적으로 가장 중요한 것부터 가장 덜 중요한 것 순으로 정렬됩니다.
다행스럽게도이 규칙은 Mahout 구현에서 따릅니다.",,
2639,"To denoise the images, we simply set the last few values of the diagonals to zero.",이미지를 노이즈 제거하기 위해 대각선의 마지막 몇 개 값을 0으로 설정하기 만하면됩니다.,,
2640,The idea is that the least important basis vectors probably represent noise which we seek to get rid of (see EXAMPLE 9-5).,아이디어는 가장 덜 중요한 기저 벡터가 아마도 제거하려는 노이즈를 나타낼 것이라는 것입니다 (예 9-5 참조).,,
2641,Example 9-5.,예 9-5.,,
2642,"A loop to write several images
percs = [0.001, 0.01, 0.05, 0.1, 0.3]

for p in range(len(percs)):
    perc = percs[p]
    diags = [diags_orig[i]
             if i < round(len(diags) - (len(diags) * perc))
             else 0
             for i in range(len(diags))] 
    recon = drmU_p5 @ np.diag(diags) @ drmV_p5.transpose() 
    composite_img = recon.transpose().reshape((512,512,301)) 
    a1 = plt.subplot(1,1,1)
    plt.imshow(composite_img[:, :, 150], cmap=plt.cm.bone) 
    plt.title(f""{perc*100}% denoised.","여러 이미지를 쓰는 루프
퍼크 = [0.001, 0.01, 0.05, 0.1, 0.3]

범위 내 p의 경우 (len (percs)) :
    퍼크 = 퍼크 [p]
    diags = [diags_orig [i]
             if i <round (len (diags)-(len (diags) * perc))
             그렇지 않으면 0
             for i in range (len (diags))]
    recon = drmU_p5 @ np.diag (diags) @ drmV_p5.transpose ()
    Composite_img = recon.transpose (). reshape ((512,512,301))
    a1 = plt.subplot (1,1,1)
    plt.imshow (composite_img [:, :, 150], cmap = plt.cm.bone)
    plt.title (f ""{perc * 100} % 노이즈 제거.",,
2643,"(k={len(diags)}, oversample=15, power_iters=2)"")
    a1.set_aspect(1.0)
    plt.axis('off')
    fname = f""{100-(perc*100)}%-denoised-img.png""
    plt.savefig(f""/tmp/{fname}"")
    upload_blob(bucket_name, f""/tmp/{fname}"", f""/output/{fname}"") 


Set the last p% of the singular values to equal zero.","(k = {len (diags)}, 오버 샘플 = 15, power_iters = 2) "")
    a1.set_aspect (1.0)
    plt.axis ( 'off')
    fname = f ""{100- (perc * 100)} %-denoised-img.png""
    plt.savefig (f ""/ tmp / {fname}"")
    upload_blob (bucket_name, f ""/ tmp / {fname}"", f ""/ output / {fname}"")


특이 값의 마지막 p %를 0으로 설정합니다.",,
2644,@ is the “matrix multiplication” operator.,"@는 ""행렬 곱셈""연산자입니다.",,
2645,"We’re presuming our original image was 512 x 512 x 301 slices, which may or may not be correct for your case.","원본 이미지가 512 x 512 x 301 조각이라고 가정하고 있으며, 이는 귀하의 경우에 맞을 수도 있고 그렇지 않을 수도 있습니다.",,
2646,Take the 150th slice.,150 번째 슬라이스를 가져갑니다.,,
2647,We’ll talk about this function in the next section.,이 기능에 대해서는 다음 섹션에서 설명하겠습니다.,,
2648,"Now in our bucket, we will have several images in the /output/ folder, named for what percentage of denoising they have been through.","이제 버킷에는 / output / 폴더에 몇 개의 이미지가 있으며,이 이미지는 통과 한 노이즈 제거 비율에 따라 이름이 지정됩니다.",,
2649,Our output was an image of one slice of the DICOM.,우리의 출력은 DICOM의 한 조각 이미지였습니다.,,
2650,"Instead, we could have output several full DICOM files (one for each level of denoising) that could then be viewed in a DICOM viewer, though the full example is a bit involved and out of scope for this text.",대신 DICOM 뷰어에서 볼 수있는 여러 전체 DICOM 파일 (각 노이즈 제거 수준에 대해 하나씩)을 출력 할 수 있습니다. 전체 예제는 약간 관련이 있고이 텍스트의 범위를 벗어납니다.,,
2651,We encourage you to read pydicom’s documentation if you are interested in this output.,이 출력에 관심이 있다면 pydicom의 문서를 읽어 보시기 바랍니다.,,
2652,9.1.4.,9.1.4.,,
2653,"The CT Scan Denoising Pipeline
To create our pipeline, we will first create a manifest for our Spark job, which will specify what image to use, what secrets
to use to mount what buckets, and a wide array of other information.","CT 스캔 노이즈 제거 파이프 라인
파이프 라인을 생성하기 위해 먼저 Spark 작업에 대한 매니페스트를 생성하여 사용할 이미지와 비밀을 지정합니다.
어떤 버킷과 다양한 기타 정보를 마운트하는 데 사용할 수 있습니다.",,
2654,"Then we will create a pipeline using our containers from earlier steps and the manifest we define, which will output a PNG of one slice of the DICOM image with varying levels of noise removed.",그런 다음 이전 단계의 컨테이너와 정의한 매니페스트를 사용하여 파이프 라인을 생성하여 다양한 수준의 노이즈가 제거 된 DICOM 이미지 한 조각의 PNG를 출력합니다.,,
2655,9.1.4.1.,9.1.4.1.,,
2656,"Spark operation manifest
Spark read/wrote the files from GCS because it has issues with ReadWriteOnce (RWO) PVCs.","Spark 작업 매니페스트
Spark는 RWO (ReadWriteOnce) PVC에 문제가 있으므로 GCS에서 파일을 읽거나 썼습니다.",,
2657,"We’ll need to download output from GCS, then upload.",GCS에서 출력을 다운로드 한 다음 업로드해야합니다.,,
2658,The Apache Spark operator does not like to read from ReadWriteOnce PVCs.,Apache Spark 연산자는 ReadWriteOnce PVC에서 읽는 것을 좋아하지 않습니다.,,
2659,"If your
Kubernetes is using these operators, and you can’t request ReadWriteMany (as, for example, is the case on GCP), then you
will need to use some other storage for the original matrix which is to be decomposed.","귀하의
Kubernetes는 이러한 연산자를 사용하고 있으며 ReadWriteMany를 요청할 수 없습니다 (예 : GCP의 경우).
분해 할 원래 매트릭스에 대해 다른 저장소를 사용해야합니다.",,
2660,Most of our containers to this point have used ContainerOp.,지금까지 대부분의 컨테이너는 ContainerOp를 사용했습니다.,,
2661,"As a Spark job may actually consist of several containers,
we will use a more generic ResourceOp.","Spark 작업은 실제로 여러 컨테이너로 구성 될 수 있으므로
보다 일반적인 ResourceOp를 사용합니다.",,
2662,"Defining ResourceOps gives us much more power and control, but this comes at
the cost of the pretty Python API.","ResourceOps를 정의하면 훨씬 더 많은 권한과 제어가 가능하지만
예쁜 Python API의 비용.",,
2663,"To define a ResourceOp we must define a manifest (see EXAMPLE 9-6) and pass that to the ResourceOp
creation (see the next section).","ResourceOp를 정의하려면 매니페스트를 정의하고 (예 9-6 참조)이를 ResourceOp에 전달해야합니다.
생성 (다음 섹션 참조).",,
2664,Example 9-6.,예 9-6.,,
2665,"Spark operation manifest
container_manifest = {
    ""apiVersion"": ""sparkoperator.k8s.io/v1beta2"",
    ""kind"": ""SparkApplication"",
    ""metadata"": {
        ""name"": ""spark-app"", 
        ""namespace"": ""kubeflow""
    },
    ""spec"": {
        ""type"": ""Scala"",
        ""mode"": ""cluster"",
        ""image"": ""docker.io/rawkintrevo/covid-basis-vectors:0.2.0"",
        ""imagePullPolicy"": ""Always"",
        ""hadoopConf"": { 
            ""fs.gs.project.id"": ""kubeflow-hacky-hacky"",
            ""fs.gs.system.bucket"": ""covid-dicoms"",
            ""fs.gs.impl"" : ""com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"",
            ""google.cloud.auth.service.account.enable"": ""true"",
            ""google.cloud.auth.service.account.json.keyfile"": ""/mnt/secrets/user-gcp-sa.json"",
        },
        ""mainClass"": ""org.rawkintrevo.covid.App"",
        ""mainApplicationFile"": ""local:///covid-0.1-jar-with-dependencies.jar"",
        # See the Dockerfile
        ""arguments"": [""245"", ""15"", ""1""],
        ""sparkVersion"": ""2.4.5"",
        ""restartPolicy"": {
            ""type"": ""Never""
        },
        ""driver"": {
            ""cores"": 1,
            ""secrets"": [ 
                {""name"": ""user-gcp-sa"",
                 ""path"": ""/mnt/secrets"",
                 ""secretType"": ""GCPServiceAccount""
                 }
            ],

            ""coreLimit"": ""1200m"",
            ""memory"": ""512m"",
            ""labels"": {
                ""version"": ""2.4.5"",
            },
            ""serviceAccount"": ""spark-operatoroperator-sa"", # also try spark-operatoroperator-sa
        },
        ""executor"": {
            ""cores"": 1,
            ""secrets"": [ 
                {""name"": ""user-gcp-sa"",
                 ""path"": ""/mnt/secrets"",
                 ""secretType"": ""GCPServiceAccount""
                 }
            ],
            ""instances"": 4, 
            ""memory"": ""4084m""
        },
        ""labels"": {
            ""version"": ""2.4.5""
        },

    }
}


Name of the app: you can check on progress in the console with kubectl logs spark-app-driver.","Spark 작업 매니페스트
container_manifest = {
    ""apiVersion"": ""sparkoperator.k8s.io/v1beta2"",
    ""kind"": ""SparkApplication"",
    ""metadata"": {
        ""name"": ""spark-app"",
        ""네임 스페이스"": ""kubeflow""
    },
    ""spec"": {
        ""type"": ""스칼라"",
        ""모드"": ""클러스터"",
        ""image"": ""docker.io/rawkintrevo/covid-basis-vectors:0.2.0"",
        ""imagePullPolicy"": ""항상"",
        ""hadoopConf"": {
            ""fs.gs.project.id"": ""kubeflow-hacky-hacky"",
            ""fs.gs.system.bucket"": ""covid-dicoms"",
            ""fs.gs.impl"": ""com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"",
            ""google.cloud.auth.service.account.enable"": ""true"",
            ""google.cloud.auth.service.account.json.keyfile"": ""/mnt/secrets/user-gcp-sa.json"",
        },
        ""mainClass"": ""org.rawkintrevo.covid.App"",
        ""mainApplicationFile"": ""local : ///covid-0.1-jar-with-dependencies.jar"",
        # Dockerfile보기
        ""인수"": [ ""245"", ""15"", ""1""],
        ""sparkVersion"": ""2.4.5"",
        ""restartPolicy"": {
            ""type"": ""안함""
        },
        ""드라이버"": {
            ""코어"": 1,
            ""비밀"": [
                { ""name"": ""user-gcp-sa"",
                 ""경로"": ""/ mnt / secrets"",
                 ""secretType"": ""GCPServiceAccount""
                 }
            ],

            ""coreLimit"": ""1200m"",
            ""메모리"": ""512m"",
            ""labels"": {
                ""버전"": ""2.4.5"",
            },
            ""serviceAccount"": ""spark-operatoroperator-sa"", # spark-operatoroperator-sa도 사용해보세요
        },
        ""실행자"": {
            ""코어"": 1,
            ""비밀"": [
                { ""name"": ""user-gcp-sa"",
                 ""경로"": ""/ mnt / secrets"",
                 ""secretType"": ""GCPServiceAccount""
                 }
            ],
            ""인스턴스"": 4,
            ""메모리"": ""4084m""
        },
        ""labels"": {
            ""버전"": ""2.4.5""
        },

    }
}


앱 이름 : kubectl logs spark-app-driver를 사용하여 콘솔에서 진행 상황을 확인할 수 있습니다.",,
2666,Different cloud providers use slightly different configurations here.,클라우드 제공 업체마다 여기에서 약간 다른 구성을 사용합니다.,,
2667,We’re doing a decomposition on a very large matrix—you may want to give even more resources than this if you can spare them.,우리는 매우 큰 매트릭스에 대해 분해를 수행하고 있습니다. 여유가 있다면 이보다 더 많은 리소스를 제공 할 수 있습니다.,,
2668,"Note
Because we are accessing GCP, we need to base our image from gcr.io/spark-operator/spark:v2.4.5-gcs-prometheus,
which has additional included JARs for accessing GCP (otherwise we would use gcr.io/spark-operator/spark:v2.4.5).","노트
GCP에 액세스하고 있으므로 gcr.io/spark-operator/spark:v2.4.5-gcs-prometheus의 이미지를 기반으로해야합니다.
여기에는 GCP 액세스를위한 추가 JAR이 포함되어 있습니다 (그렇지 않으면 gcr.io/spark-operator/spark:v2.4.5를 사용합니다).",,
2669,"While this is tuned for GCP, with a very minimal change in configuration, specifically around the secrets, this could easily be ported to AWS or Azure.",이는 특히 보안 비밀과 관련된 구성 변경을 매우 최소화하여 GCP에 맞게 조정되었지만 AWS 또는 Azure로 쉽게 이식 할 수 있습니다.,,
2670,"If you are familiar with Kubernetes, you are probably used to seeing manifests represented as YAML files.",Kubernetes에 익숙하다면 YAML 파일로 표시되는 매니페스트를 보는 데 익숙 할 것입니다.,,
2671,"Here we have
created a manifest with a Python dictionary.","여기 우리는
Python 사전으로 매니페스트를 만들었습니다.",,
2672,Next we will use this dictionary in our pipeline definition to create a ResourceOp.,다음으로 파이프 라인 정의에서이 사전을 사용하여 ResourceOp를 생성합니다.,,
2673,9.1.4.2.,9.1.4.2.,,
2674,"The pipeline
Finally, we have all of our necessary components.","파이프 라인
마지막으로 필요한 모든 구성 요소가 있습니다.",,
2675,We will create a pipeline that strings them together into a repeatable operation for us.,반복 가능한 작업으로 연결하는 파이프 라인을 생성합니다.,,
2676,"To review, EXAMPLE 9-7 does the following:


Downloads CT scans from GCP to a local PVC.","검토하기 위해 예제 9-7은 다음을 수행합니다.


GCP에서 로컬 PVC로 CT 스캔을 다운로드합니다.",,
2677,Converts the CT scans (DICOM files) into a matrix (s.csv).,CT 스캔 (DICOM 파일)을 매트릭스 (s.csv)로 변환합니다.,,
2678,A Spark job does a distributed stochastic singular value decomposition and writes the output to GCP.,Spark 작업은 분산 확률 적 특이 값 분해를 수행하고 출력을 GCP에 씁니다.,,
2679,The decomposed matrix is recomposed with some of the singular values set to zero—thus denoising the image.,분해 된 행렬은 일부 특이 값이 0으로 설정된 상태로 재구성되어 이미지 노이즈가 제거됩니다.,,
2680,Example 9-7.,예 9-7.,,
2681,"CT scan denoising pipeline
from kfp.gcp import use_gcp_secret
@kfp.dsl.pipeline(
    name=""Covid DICOM Pipe v2"",
    description=""Visualize Denoised CT Scans""
)
def covid_dicom_pipeline():
    vop = kfp.dsl.VolumeOp(
        name=""requisition-PVC"",
        resource_name=""datapvc"",
        size=""20Gi"", #10 Gi blows up...
        modes=kfp.dsl.VOLUME_MODE_RWO
    )
    step1 = kfp.dsl.ContainerOp( 
        name=""download-dicom"",
        image=""rawkintrevo/download-dicom:0.0.0.4"",
        command=[""/run.sh""],
        pvolumes={""/data"": vop.volume}
    )
    step2 = kfp.dsl.ContainerOp( 
        name=""convert-dicoms-to-vectors"",
        image=""rawkintrevo/covid-prep-dicom:0.9.5"",
        arguments=[
            '--bucket_name', ""covid-dicoms"",
        ],
        command=[""python"", ""/program.py""],
        pvolumes={""/mnt/data"": step1.pvolume}
    ).apply(kfp.gcp.use_gcp_secret(secret_name='user-gcp-sa')) 
    rop = kfp.dsl.ResourceOp( 
        name=""calculate-basis-vectors"",
        k8s_resource=container_manifest,
        action=""create"",
        success_condition=""status.applicationState.state == COMPLETED""
    ).after(step2)
    pyviz = kfp.dsl.ContainerOp( 
        name=""visualize-slice-of-dicom"",
        image=""rawkintrevo/visualize-dicom-output:0.0.11"",
        command=[""python"", ""/program.py""],
        arguments=[
            '--bucket_name', ""covid-dicoms"",
        ],
    ).apply(kfp.gcp.use_gcp_secret(secret_name='user-gcp-sa')).after(rop)


kfp.compiler.Compiler().compile(covid_dicom_pipeline,""dicom-pipeline-2.zip"")
client = kfp.Client()

my_experiment = client.create_experiment(name='my-experiments')
my_run = client.run_pipeline(my_experiment.id, 'my-run1', 'dicom-pipeline-2.zip')


This container was not discussed, but it simply downloads images from a GCP bucket to our local PVC.","CT 스캔 노이즈 제거 파이프 라인
kfp.gcp에서 가져 오기 use_gcp_secret
@ kfp.dsl.pipeline (
    name = ""Covid DICOM 파이프 v2"",
    description = ""노이즈 제거 된 CT 스캔 시각화""
)
def covid_dicom_pipeline () :
    vop = kfp.dsl.VolumeOp (
        name = ""requisition-PVC"",
        resource_name = ""datapvc"",
        size = ""20Gi"", # 10 Gi 폭발 ...
        modes = kfp.dsl.VOLUME_MODE_RWO
    )
    1 단계 = kfp.dsl.ContainerOp (
        name = ""download-dicom"",
        image = ""rawkintrevo / download-dicom : 0.0.0.4"",
        명령 = [ ""/ run.sh""],
        pvolumes = { ""/ data"": vop.volume}
    )
    2 단계 = kfp.dsl.ContainerOp (
        name = ""convert-dicoms-to-vectors"",
        image = ""rawkintrevo / covid-prep-dicom : 0.9.5"",
        인수 = [
            '--bucket_name', ""covid-dicoms"",
        ],
        command = [ ""python"", ""/program.py""],
        pvolumes = { ""/ mnt / data"": step1.pvolume}
    ) .apply (kfp.gcp.use_gcp_secret (secret_name = 'user-gcp-sa'))
    rop = kfp.dsl.ResourceOp (
        name = ""calculate-basis-vectors"",
        k8s_resource = container_manifest,
        action = ""create"",
        success_condition = ""status.applicationState.state == COMPLETED""
    ) .after (2 단계)
    pyviz = kfp.dsl.ContainerOp (
        name = ""visualize-slice-of-dicom"",
        image = ""rawkintrevo / visualize-dicom-output : 0.0.11"",
        command = [ ""python"", ""/program.py""],
        인수 = [
            '--bucket_name', ""covid-dicoms"",
        ],
    ) .apply (kfp.gcp.use_gcp_secret (secret_name = 'user-gcp-sa')). after (rop)


kfp.compiler.Compiler (). compile (covid_dicom_pipeline, ""dicom-pipeline-2.zip"")
클라이언트 = kfp.Client ()

my_experiment = client.create_experiment (name = 'my-experiments')
my_run = client.run_pipeline (my_experiment.id, 'my-run1', 'dicom-pipeline-2.zip')


이 컨테이너는 논의되지 않았지만 단순히 GCP 버킷에서 로컬 PVC로 이미지를 다운로드합니다.",,
2682,Here we convert our DICOM into a matrix and upload it to a specified GCP bucket.,여기에서 DICOM을 매트릭스로 변환하고 지정된 GCP 버킷에 업로드합니다.,,
2683,This is the Spark job that calculates the singular value decomposition.,특이 값 분해를 계산하는 Spark 작업입니다.,,
2684,This is where DICOM images are reconstructed.,DICOM 이미지가 재구성되는 곳입니다.,,
2685,"For GCP we use_gcp_secret, but similar functions exist for Azure and AWS.",GCP의 경우 _gcp_secret을 사용하지만 Azure 및 AWS에도 유사한 기능이 있습니다.,,
2686,"For illustration, Figures FIGURE 9-1 through FIGURE 9-3 are slices of the DICOM image at various levels of denoising.",설명을 위해 그림 9-1에서 그림 9-3은 다양한 수준의 노이즈 제거에서 DICOM 이미지의 조각입니다.,,
2687,"As we are not radiology experts, we won’t try to make any points about changes in quality or what is optimal, other than to point out that at 10% denoising we’ve probably gone too far, and at 30% we unquestionably have.",우리는 방사선과 전문가가 아니기 때문에 품질이나 최적의 변화에 대해 어떠한 지적도하지 않을 것입니다. 10 % 노이즈 제거에서는 아마 너무 멀리 갔을 것이고 30 %에서는 의심 할 여지없이.,,
2688,Figure 9-1.,그림 9-1.,,
2689,"Original slice of DICOM



Figure 9-2.","DICOM의 원래 조각



그림 9-2.",,
2690,"1% denoised DICOM slice (left); 5% denoised DICOM slice (right)



Figure 9-3.","1 % denoised DICOM 슬라이스 (왼쪽);5 % 노이즈 제거 DICOM 슬라이스 (오른쪽)



그림 9-3.",,
2691,"10% denoised DICOM slice (left); .5% denoised DICOM slice (right)

Again we see that while this pipeline is now hardcoded for GCP, it can with only a few lines of updates be changed to work with AWS or Azure; specifically, how we mount secrets to the container.","10 % denoised DICOM 슬라이스 (왼쪽);.5 % 노이즈 제거 DICOM 슬라이스 (오른쪽)

이 파이프 라인은 이제 GCP 용으로 하드 코딩되었지만 몇 줄의 업데이트만으로 AWS 또는 Azure에서 작동하도록 변경할 수 있습니다.특히 컨테이너에 비밀을 마운트하는 방법입니다.",,
2692,A significant advantage of this is that we are able to safely decouple passcodes from code.,이것의 중요한 장점은 코드에서 암호를 안전하게 분리 할 수 있다는 것입니다.,,
2693,"Using RStats
Our examples have all been Python- or Scala-based, but remember—a container is just an OS that is going to run a program.","RStats 사용
우리의 예제는 모두 Python 또는 Scala 기반이지만, 컨테이너는 프로그램을 실행하는 OS 일뿐입니다.",,
2694,"As such, you can use any language that can exist in a container.",따라서 컨테이너에 존재할 수있는 모든 언어를 사용할 수 있습니다.,,
2695,"To use an RStats script as a pipeline step:


Create a Docker container (probably from a preexisting images such as r-base:latest).","RStats 스크립트를 파이프 라인 단계로 사용하려면 :


Docker 컨테이너를 만듭니다 (아마도 r-base : latest와 같은 기존 이미지에서).",,
2696,Create a program that takes command-line arguments.,명령 줄 인수를 사용하는 프로그램을 만듭니다.,,
2697,Output the results to a mounted PVC or save to a cloud storage provider.,결과를 마운트 된 PVC로 출력하거나 클라우드 스토리지 제공자에 저장하십시오.,,
2698,9.2.,9.2.,,
2699,"Sharing the Pipeline
A final important benefit of Kubeflow is the reproducibility of experiments.","파이프 라인 공유
Kubeflow의 마지막 중요한 이점은 실험의 재현성입니다.",,
2700,"While often underscored in academia, reproducibiltiy
is an important concept in business settings as well.","학계에서 종종 강조되지만, 재현성
비즈니스 환경에서도 중요한 개념입니다.",,
2701,"By containerizing pipeline steps, we can remove hidden dependencies
that allow a program to only run on one device—or, to put it another way, reproducibility prevents you from developing an algorithm that only runs
on one person’s machine.","파이프 라인 단계를 컨테이너화하여 숨겨진 종속성을 제거 할 수 있습니다.
프로그램이 하나의 장치에서만 실행될 수 있도록합니다. 즉, 다시 말해서 재현성은 실행되는 알고리즘 만 개발하지 못하게합니다.
한 사람의 컴퓨터에서.",,
2702,The pipeline we present here should run on any Kubeflow deployment.,여기에 제시된 파이프 라인은 모든 Kubeflow 배포에서 실행되어야합니다.,,
2703,"[3]
This also allows for rapid iteration.","[삼]
이것은 또한 빠른 반복을 허용합니다.",,
2704,"Any reader can use this pipeline as a basis and, for instance, could create a final step where some deep learning is performed on the denoised images and the original images to compare the effects of denoising.","모든 독자는이 파이프 라인을 기초로 사용할 수 있으며, 예를 들어 노이즈 제거 효과를 비교하기 위해 노이즈 제거 이미지와 원본 이미지에 대해 딥 러닝을 수행하는 최종 단계를 만들 수 있습니다.",,
2705,9.3.,9.3.,,
2706,"Conclusion
We have now seen how to create very maintainable pipelines by leveraging containers that have most, if not all, of the required dependencies to make our program run.","결론
이제 프로그램을 실행하는 데 필요한 종속성 중 전부는 아니더라도 대부분이있는 컨테이너를 활용하여 유지 관리가 매우 쉬운 파이프 라인을 만드는 방법을 살펴 보았습니다.",,
2707,"This not only removes the technical debt of having to maintain a system with all of
these dependencies, but makes the program much more transferable, and our research much more easily transferable and reproducible.","이는 시스템을 유지해야하는 기술적 부채를 제거 할뿐만 아니라
이러한 종속성은 프로그램을 훨씬 더 이전 가능하게 만들고 우리의 연구는 훨씬 더 쉽게 이전하고 재현 할 수 있습니다.",,
2708,"There exists a large and exciting galaxy of Docker containers, and odds are you already have some steps Dockerized in preexisting
containers.","크고 흥미로운 Docker 컨테이너 은하계가 존재하며 이미 기존에 Dockerized 단계가있을 가능성이 높습니다.
용기.",,
2709,"Being able to leverage these containers for Kubeflow Pipeline steps is certainly one of Kubeflow’s biggest
strengths.","이러한 컨테이너를 Kubeflow 파이프 라인 단계에 활용할 수 있다는 것은 확실히 Kubeflow의 가장 큰
강점.",,
2710,[1] The full paper can be found  here.,[1] 전체 논문은 여기에서 찾을 수 있습니다.,,
2711,[2] The Radiological Society of North America hopes to publish a repository of COVID-19 CT scans soon.,[2] 북미 방사선 학회는 곧 COVID-19 CT 스캔 저장소를 게시하기를 희망합니다.,,
2712,[3] With minor tuning for no GCE deployments.,[3] GCE 배포를위한 사소한 조정 포함.,,
2713,Chapter 10.,10 장.,,
2714,"Hyperparameter Tuning and Automated 
Machine Learning
In the previous chapters, we have seen how Kubeflow helps with the various phases of machine learning.","하이퍼 파라미터 튜닝 및 자동화
기계 학습
이전 장에서 Kubeflow가 다양한 기계 학습 단계에서 어떻게 도움이되는지 살펴 보았습니다.",,
2715,But knowing what to do in each phase—whether it’s feature preparation or training or deploying models—requires some amount of expert knowledge and experimentation.,"그러나 기능 준비, 모델 교육 또는 배포 등 각 단계에서 수행 할 작업을 파악하려면 어느 정도의 전문 지식과 실험이 필요합니다.",,
2716,"According to the “no free lunch” theorem, no single model works best for every machine learning problem, therefore each model must be constructed carefully.","""공짜 점심 없음""정리에 따르면 모든 기계 학습 문제에 가장 적합한 단일 모델은 없으므로 각 모델을 신중하게 구성해야합니다.",,
2717,It can be very time-consuming and expensive to fully build a highly performing model if each phase requires significant human input.,각 단계에 상당한 인적 입력이 필요한 경우 고성능 모델을 완전히 구축하는 데 시간과 비용이 많이 소요될 수 있습니다.,,
2718,"Naturally, one might wonder: is it possible to automate parts—or even the entirety—of the machine learning process?",당연히 궁금 할 것입니다. 기계 학습 프로세스의 일부 또는 전체를 자동화 할 수 있습니까?,,
2719,Can we reduce the amount of overhead for data scientists while still sustaining high model quality?,높은 모델 품질을 유지하면서 데이터 과학자의 오버 헤드를 줄일 수 있습니까?,,
2720,"In machine learning, the umbrella term for solving these type of problems is automated machine learning (AutoML).",기계 학습에서 이러한 유형의 문제를 해결하는 포괄적 인 용어는 자동화 된 기계 학습 (AutoML)입니다.,,
2721,"It is a constantly evolving field of research, and has found its way to the industry with practical applications.",지속적으로 진화하는 연구 분야이며 실용적인 응용 분야로 업계에 진출했습니다.,,
2722,"AutoML seeks to simplify machine learning for experts and nonexperts alike by reducing the need for manual interaction in the more time-consuming and iterative phases of machine learning: feature engineering, model construction, and hyperparameter configuration.","AutoML은 기능 엔지니어링, 모델 구성, 초 매개 변수 구성과 같이 시간이 많이 걸리고 반복적 인 머신 러닝 단계에서 수동 상호 작용의 필요성을 줄여 전문가와 비전문가 모두를위한 머신 러닝을 단순화하고자합니다.",,
2723,"In this chapter we will see how Kubeflow can be used to automate hyperparameter search and neural architecture search, two important subfields of AutoML.",이 장에서는 Kubeflow를 사용하여 AutoML의 두 가지 중요한 하위 필드 인 하이퍼 파라미터 검색 및 신경 아키텍처 검색을 자동화하는 방법을 살펴 봅니다.,,
2724,10.1.,10.1.,,
2725,"AutoML: An Overview
AutoML refers to the various processes and tools that automate parts of the machine learning process.","AutoML : 개요
AutoML은 머신 러닝 프로세스의 일부를 자동화하는 다양한 프로세스와 도구를 나타냅니다.",,
2726,"At a high level, AutoML refers to any algorithms and methodologies that seek to solve one or more of the following problems:

Data preprocessing

Machine learning requires data, and raw data can come from various sources and in different formats.","높은 수준에서 AutoML은 다음 문제 중 하나 이상을 해결하려는 모든 알고리즘 및 방법론을 나타냅니다.

데이터 전처리

기계 학습에는 데이터가 필요하며 원시 데이터는 다양한 소스와 다양한 형식에서 가져올 수 있습니다.",,
2727,"To make raw data useful, human experts typically have to comb over the data, normalize values, remove erroneous or corrupted data, and ensure data consistency.",원시 데이터를 유용하게 만들기 위해 인간 전문가는 일반적으로 데이터를 살펴보고 값을 정규화하고 오류가 있거나 손상된 데이터를 제거하고 데이터 일관성을 보장해야합니다.,,
2728,"Feature engineering

Training models with too few input variables (or “features”) can lead to inaccurate models.","기능 엔지니어링

입력 변수 (또는 ""특성"")가 너무 적은 훈련 모델은 부정확 한 모델로 이어질 수 있습니다.",,
2729,"However, having too many features can also be problematic; the learning process would be slower and more resource-consuming, and overfitting problems can occur.",그러나 너무 많은 기능을 갖는 것도 문제가 될 수 있습니다.학습 과정은 더 느리고 더 많은 자원을 소비하며 과적 합 문제가 발생할 수 있습니다.,,
2730,Coming up with the right set of features can be the most time-consuming part of building a machine learning model.,올바른 기능 집합을 찾는 것은 기계 학습 모델을 구축하는 데 가장 시간이 많이 걸리는 부분 일 수 있습니다.,,
2731,"Automated feature engineering can speed up the process of feature extraction, selection, and 
transformation.","자동화 된 기능 엔지니어링은 기능 추출, 선택 및
변환.",,
2732,"Model selection

Once you have all the training data, you need to pick the right training model for your dataset.","모델 선택

훈련 데이터를 모두 확보했으면 데이터 세트에 적합한 훈련 모델을 선택해야합니다.",,
2733,The ideal model should be as simple as possible while still providing a good measure of prediction accuracy.,이상적인 모델은 예측 정확도에 대한 좋은 척도를 제공하면서 가능한 한 간단해야합니다.,,
2734,"Hyperparameter tuning

Most learning models have a number of parameters that are external to the model, such as the learning rate, the batch size, and the number of layers in the neural network.","초 매개 변수 조정

대부분의 학습 모델에는 학습률, 배치 크기 및 신경망의 계층 수와 같이 모델 외부에있는 여러 매개 변수가 있습니다.",,
2735,We call these hyperparameters to distinguish them from model parameters that are adjusted by the learning process.,학습 프로세스에 의해 조정되는 모델 매개 변수와 구별하기 위해 이러한 하이퍼 파라미터를 호출합니다.,,
2736,Hyperparameter tuning is the process of automating the search process for these parameters in order to improve the accuracy of the model.,하이퍼 파라미터 튜닝은 모델의 정확성을 향상시키기 위해 이러한 파라미터에 대한 검색 프로세스를 자동화하는 프로세스입니다.,,
2737,"Neural architecture search

A related field to hyperparameter tuning is neural architecture search (NAS).","신경 아키텍처 검색

하이퍼 파라미터 튜닝과 관련된 분야는 신경 아키텍처 검색 (NAS)입니다.",,
2738,"Instead of choosing between a fixed range of values for each hyperparameter value, NAS seeks to take automation one step further and generates an entire neural network that outperforms handcrafted architectures.",각 하이퍼 파라미터 값에 대해 고정 된 값 범위를 선택하는 대신 NAS는 자동화를 한 단계 더 발전시키고 수작업 아키텍처를 능가하는 전체 신경망을 생성합니다.,,
2739,Common methodologies for NAS include reinforcement learning and evolutionary algorithms.,NAS의 일반적인 방법론에는 강화 학습 및 진화 알고리즘이 포함됩니다.,,
2740,The focus of this chapter will be on the latter two problems—hyperparameter tuning and neural architecture search.,이 장에서는 초 매개 변수 조정과 신경 아키텍처 검색이라는 두 가지 문제에 초점을 맞출 것입니다.,,
2741,"As they are related, they can be solved using similar methodologies.",관련되어 있기 때문에 유사한 방법론을 사용하여 해결할 수 있습니다.,,
2742,10.2.,10.2.,,
2743,"Hyperparameter Tuning with Kubeflow Katib
In CHAPTER 7, it was mentioned that we needed to set a few hyperparameters.","Kubeflow Katib를 사용한 초 매개 변수 조정
7 장에서는 몇 가지 하이퍼 파라미터를 설정해야한다고 언급했습니다.",,
2744,"In machine learning, hyperparameters refer to parameters that are set before the training process begins (as opposed to model parameters which are learned from the training process).",기계 학습에서 초 매개 변수는 학습 프로세스가 시작되기 전에 설정된 매개 변수를 나타냅니다 (학습 프로세스에서 학습 된 모델 매개 변수와 반대).,,
2745,"Examples of hyperparameters include the learning rate, number of decision trees, number of layers in a neural network, etc.","하이퍼 파라미터의 예로는 학습률, 의사 결정 트리 수, 신경망의 계층 수 등이 있습니다.",,
2746,The concept of hyperparameter optimization is very simple: select the set of hyperparameter values that lead to optimal model performance.,초 매개 변수 최적화의 개념은 매우 간단합니다. 최적의 모델 성능으로 이어지는 초 매개 변수 값 세트를 선택하는 것입니다.,,
2747,A hyperparameter tuning framework is a tool that does exactly that.,초 매개 변수 조정 프레임 워크는이를 정확히 수행하는 도구입니다.,,
2748,"Typically, the user of such a tool would define a few things:


The list of hyperparameters and their valid range of values (called the search space)


The metrics used to measure model performance


The methodology to use for the searching process


Kubeflow comes packaged with Katib, a general framework for hyperparameter tuning.","일반적으로 이러한 도구의 사용자는 몇 가지를 정의합니다.


하이퍼 파라미터 목록 및 유효한 값 범위 (검색 공간이라고 함)


모델 성능을 측정하는 데 사용되는 메트릭


검색 프로세스에 사용할 방법론


Kubeflow는 초 매개 변수 조정을위한 일반 프레임 워크 인 Katib와 함께 제공됩니다.",,
2749,"Among similar open source tools, Katib has a few distinguishing features:

It is Kubernetes native

This means that Katib experiments can be ported wherever Kubernetes runs.","유사한 오픈 소스 도구 중에서 Katib에는 몇 가지 특징이 있습니다.

Kubernetes 네이티브입니다.

즉, Kubernetes가 실행되는 모든 곳에서 Katib 실험을 포팅 할 수 있습니다.",,
2750,"It has multiframework support

Katib supports many popular learning frameworks, with first-class support for TensorFlow and PyTorch distributed training.","다중 프레임 워크 지원

Katib는 TensorFlow 및 PyTorch 분산 학습에 대한 최고 수준의 지원을 통해 많은 인기 학습 프레임 워크를 지원합니다.",,
2751,"It is language-agnostic

Training code can be written in any language, as long as it is built as a Docker image.","언어에 구애받지 않습니다.

교육 코드는 Docker 이미지로 빌드되는 한 모든 언어로 작성할 수 있습니다.",,
2752,"Note
The name katib means “secretary” or “scribe” in Arabic, and is an homage to the Vizier framework that inspired its initial version (“vizier” being Arabic for a minister or high official).","노트
katib이라는 이름은 아랍어로 ""비서""또는 ""서기관""을 의미하며 초기 버전에 영감을 준 Vizier 프레임 워크에 대한 오마주입니다 ( ""vizier""는 장관 또는 고위 관리를위한 아랍어 임).",,
2753,"In this chapter, we’ll take a look at how Katib simplifies hyperparameter optimization.",이 장에서는 Katib가 어떻게 하이퍼 파라미터 최적화를 단순화하는지 살펴 보겠습니다.,,
2754,10.3.,10.3.,,
2755,"Katib Concepts
Let’s begin by defining a few terms that are central to the workflow of Katib (as illustrated in FIGURE 10-1):

Experiment

An experiment is an end-to-end process that takes a problem (e.g., tuning a training model for handwriting recognition), an objective metric (maximize the prediction accuracy), and a search space (range for hyperparameters), and produces a final set of optimal hyperparameter values.","Katib 개념
Katib 워크 플로의 중심이되는 몇 가지 용어를 정의하여 시작하겠습니다 (그림 10-1 참조).

실험

실험은 문제 (예 : 필기 인식을위한 학습 모델 조정), 객관적 측정 항목 (예측 정확도 극대화) 및 검색 공간 (초 매개 변수 범위)을 가져와 최종 결과를 생성하는 종단 간 프로세스입니다.최적의 하이퍼 파라미터 값 세트.",,
2756,"Suggestion

A suggestion is one possible solution to the problem we are trying to solve.","암시

제안은 해결하려는 문제에 대한 가능한 해결책 중 하나입니다.",,
2757,"Since we are trying to find the combination of hyperparameter values that lead to optimal model performance, a suggestion would be one set of hyperparameter values from the specified search space.",최적의 모델 성능으로 이어지는 하이퍼 파라미터 값의 조합을 찾으려고하므로 지정된 검색 공간에서 한 세트의 하이퍼 파라미터 값을 제안합니다.,,
2758,"Trial

A trial is one iteration of the experiment.","시도

시행은 실험을 한 번 반복하는 것입니다.",,
2759,Each trial takes a suggestion and executes a worker process (packaged through Docker) that produces evaluation metrics.,각 시도는 제안을 받고 평가 지표를 생성하는 작업자 프로세스 (Docker를 통해 패키징 됨)를 실행합니다.,,
2760,Katib’s controller then computes the next suggestion based on previous metrics and spawns new trials.,그런 다음 Katib의 컨트롤러는 이전 측정 항목을 기반으로 다음 제안을 계산하고 새로운 시도를 생성합니다.,,
2761,Figure 10-1.,그림 10-1.,,
2762,"Katib system workflow

Note
In Katib, experiments, suggestions, and trials are all custom resources.","Katib 시스템 워크 플로우

노트
Katib에서 실험, 제안 및 시도는 모두 사용자 지정 리소스입니다.",,
2763,This means they are stored in Kubernetes and can be manipulated using standard Kubernetes APIs.,"즉, Kubernetes에 저장되고 표준 Kubernetes API를 사용하여 조작 할 수 있습니다.",,
2764,Another important aspect of hyperparameter tuning is how to find the next set of parameters.,초 매개 변수 조정의 또 다른 중요한 측면은 다음 매개 변수 집합을 찾는 방법입니다.,,
2765,"As of the time of this writing, Katib supports the following search 
algorithms:

Grid search

Also known as a parameter sweep, grid search is the simplest approach—exhaustively search through possible parameter values in the specified search space.","이 글을 쓰는 시점에서 Katib은 다음 검색을 지원합니다.
알고리즘 :

그리드 검색

매개 변수 스윕이라고도하는 그리드 검색은 지정된 검색 공간에서 가능한 매개 변수 값을 철저히 검색하는 가장 간단한 방법입니다.",,
2766,"Although resource-intensive, grid search has the advantage of having high parallelism since the tasks are completely independent.",리소스 집약적이지만 그리드 검색은 작업이 완전히 독립적이기 때문에 병렬 처리가 높다는 장점이 있습니다.,,
2767,"Random search

Similar to grid search, the tasks in random search are completely independent.","무작위 검색

그리드 검색과 유사하게 임의 검색의 작업은 완전히 독립적입니다.",,
2768,"Instead of enumerating every possible value, random search attempts to generate parameter values through random selection.",가능한 모든 값을 열거하는 대신 임의 검색은 임의 선택을 통해 매개 변수 값을 생성하려고합니다.,,
2769,"When there are many hyperparameters to tune (but only a few have significant impact on model performance), random search can vastly outperform grid search.",튜닝 할 하이퍼 파라미터가 많지만 모델 성능에 상당한 영향을 미치는 하이퍼 파라미터가 많으면 임의 검색이 그리드 검색보다 훨씬 뛰어난 성능을 발휘할 수 있습니다.,,
2770,"Random search can also be useful when the number of discrete parameters is high, which makes grid search 
infeasible.","임의 검색은 불연속 매개 변수 수가 많을 때도 유용 할 수 있으므로 그리드 검색이 가능합니다.
불가능합니다.",,
2771,"Bayesian optimization

This is a powerful approach that uses probability and statistics to seek better parameters.","베이지안 최적화

이것은 더 나은 매개 변수를 찾기 위해 확률과 통계를 사용하는 강력한 접근 방식입니다.",,
2772,"Bayesian optimization builds a probabilistic model for the objective function, finds parameter values that perform well on the model, and then iteratively updates the model based on metrics collected during trial runs.",베이지안 최적화는 목적 함수에 대한 확률 모델을 구축하고 모델에서 잘 수행되는 매개 변수 값을 찾은 다음 시험 실행 중에 수집 된 메트릭을 기반으로 모델을 반복적으로 업데이트합니다.,,
2773,"Intuitively speaking, Bayesian optimization seeks to improve upon a model by making informed guesses.",직관적으로 말하면 베이지안 최적화는 정보에 입각 한 추측을 통해 모델을 개선하려고합니다.,,
2774,"This optimization method relies on previous iterations to find new parameters, and can be parallelized.",이 최적화 방법은 이전 반복에 의존하여 새 매개 변수를 찾고 병렬화 할 수 있습니다.,,
2775,"While trials are not as independent as grid or random search, Bayesian optimization can find results with fewer trials overall.",시행은 그리드 또는 무작위 검색만큼 독립적이지 않지만 베이지안 최적화는 전체 시행 횟수가 더 적은 결과를 찾을 수 있습니다.,,
2776,"Hyperband

This is a relatively new approach that selects configuration values randomly.","하이퍼 밴드

이것은 구성 값을 무작위로 선택하는 비교적 새로운 접근 방식입니다.",,
2777,"But unlike traditional random search, hyperband only evaluates each trial for a small number of iterations.",그러나 기존의 임의 검색과 달리 하이퍼 밴드는 적은 수의 반복에 대해서만 각 시행을 평가합니다.,,
2778,"Then it takes the best-performing configurations and runs them longer, repeating this process until a desired result is reached.",그런 다음 가장 성능이 좋은 구성을 가져와 더 오래 실행하여 원하는 결과에 도달 할 때까지이 프로세스를 반복합니다.,,
2779,"Due to its similarity to random search, tasks can be highly parallelized.",임의 검색과 유사하기 때문에 작업을 고도로 병렬화 할 수 있습니다.,,
2780,"Other experimental algorithms

These include the tree of Parzen estimators (TPE) and covariance matrix adaptation evolution strategy (CMA-ES), both implemented by using the Goptuna optimization framework.","기타 실험 알고리즘

여기에는 Goptuna 최적화 프레임 워크를 사용하여 구현 된 Parzen 추정량 트리 (TPE) 및 공분산 행렬 적응 진화 전략 (CMA-ES)이 포함됩니다.",,
2781,One final piece of the puzzle in Katib is the metrics collector.,Katib의 마지막 퍼즐 조각은 메트릭 수집기입니다.,,
2782,"This is the process that collects and parses evaluation metrics after each trial and pushes them into the 
persistent database.","이것은 각 시행 후 평가 메트릭을 수집하고 구문 분석하여
영구 데이터베이스.",,
2783,"Katib implements metrics collection through a sidecar container, which runs alongside the main container in a pod.",Katib은 포드의 기본 컨테이너와 함께 실행되는 사이드카 컨테이너를 통해 메트릭 수집을 구현합니다.,,
2784,"Overall, Katib’s design makes it highly scalable, portable, and extensible.","전반적으로 Katib의 디자인은 확장 성, 휴대 성 및 확장 성이 뛰어납니다.",,
2785,"Since it is part of the Kubeflow platform, Katib natively supports integration with many of Kubeflow’s other training components, like the TFJob and PyTorch operators.",Kubeflow 플랫폼의 일부이기 때문에 Katib은 기본적으로 TFJob 및 PyTorch 연산자와 같은 Kubeflow의 다른 교육 구성 요소와의 통합을 지원합니다.,,
2786,"Katib is also the first hyperparameter tuning framework that supports multitenancy, making it ideal for a cloud hosted environment.",Katib은 멀티 테넌시를 지원하는 최초의 하이퍼 파라미터 튜닝 프레임 워크이기도하므로 클라우드 호스팅 환경에 이상적입니다.,,
2787,10.4.,10.4.,,
2788,"Installing Katib
Katib is installed by default.","Katib 설치
Katib는 기본적으로 설치됩니다.",,
2789,"To install Katib as a standalone service, you can use the following script in the Kubeflow GitHub repo:
git clone https://github.com/kubeflow/katib
bash ./katib/scripts/v1beta1/deploy.sh
If your Kubernetes cluster doesn’t support dynamic volume provisioning, you would also create a persistent volume:
pv_path=https://raw.githubusercontent.com/kubeflow/katib/master/manifests\
/v1beta1/pv/pv.yaml
kubectl apply -f pv_path
After installing Katib components, you can navigate to the Katib dashboard to verify that it is running.","Katib를 독립형 서비스로 설치하려면 Kubeflow GitHub 리포지토리에서 다음 스크립트를 사용할 수 있습니다.
git clone https://github.com/kubeflow/katib
bash ./katib/scripts/v1beta1/deploy.sh
Kubernetes 클러스터가 동적 볼륨 프로비저닝을 지원하지 않는 경우 영구 볼륨도 생성합니다.
pv_path = https : //raw.githubusercontent.com/kubeflow/katib/master/manifests \
/v1beta1/pv/pv.yaml
kubectl apply -f pv_path
Katib 구성 요소를 설치 한 후 Katib 대시 보드로 이동하여 실행 중인지 확인할 수 있습니다.",,
2790,"If you installed Katib through Kubeflow and have an endpoint, simply navigate to the Kubeflow dashboard and select “Katib” in the menu.","Kubeflow를 통해 Katib을 설치하고 엔드 포인트가있는 경우 Kubeflow 대시 보드로 이동하여 메뉴에서 ""Katib""을 선택하면됩니다.",,
2791,"Otherwise, you can set up port forwarding to test your deployment:
kubectl port-forward svc/katib-ui -n kubeflow 8080:80
Then navigate to:
http://localhost:8080/katib/


10.5.","그렇지 않으면 포트 전달을 설정하여 배포를 테스트 할 수 있습니다.
kubectl 포트 포워드 svc / katib-ui -n kubeflow 8080 : 80
그런 다음 다음으로 이동하십시오.
http : // localhost : 8080 / katib /


10.5.",,
2792,"Running Your First Katib Experiment
Now that Katib is up and running in your cluster, let’s take a look at how to run an actual experiment.","첫 번째 Katib 실험 실행
이제 Katib이 클러스터에서 실행되고 있으므로 실제 실험을 실행하는 방법을 살펴 보겠습니다.",,
2793,In this section we will use Katib to tune a simple MNist model.,이 섹션에서는 Katib을 사용하여 간단한 MNist 모델을 조정합니다.,,
2794,You can find the source code and all configuration files on Katib’s GitHub page.,Katib의 GitHub 페이지에서 소스 코드와 모든 구성 파일을 찾을 수 있습니다.,,
2795,10.5.1.,10.5.1.,,
2796,"Prepping Your Training Code
The first step is to prepare your training code.","교육 코드 준비
첫 번째 단계는 교육 코드를 준비하는 것입니다.",,
2797,"Since Katib runs training jobs for trial evaluation, each training job needs to be packaged as a Docker container.",Katib는 시험 평가를 위해 훈련 작업을 실행하므로 각 훈련 작업은 Docker 컨테이너로 패키징되어야합니다.,,
2798,"Katib is language-agnostic, so it does not matter how you write the training code.",Katib은 언어에 구애받지 않으므로 교육 코드를 작성하는 방법은 중요하지 않습니다.,,
2799,"However, to be compatible with Katib, the training code must satisfy a couple of requirements:


Hyperparameters must be exposed as command-line arguments.","그러나 Katib과 호환 되려면 교육 코드가 다음 두 가지 요구 사항을 충족해야합니다.


하이퍼 파라미터는 명령 줄 인수로 노출되어야합니다.",,
2800,"For example:


python mnist.py --batch_size=100 --learning_rate=0.1


Metrics must be exposed in a format consistent with the metrics collector.","예를 들면 :


python mnist.py --batch_size = 100 --learning_rate = 0.1


메트릭은 메트릭 수집기와 일치하는 형식으로 노출되어야합니다.",,
2801,"Katib currently supports metrics collection through standard output, file, TensorFlow events, or custom.","Katib는 현재 표준 출력, 파일, TensorFlow 이벤트 또는 사용자 지정을 통해 메트릭 수집을 지원합니다.",,
2802,"The simplest option is to use the standard metrics collector, which means the evaluation metrics must be written to stdout, in the following format:


metrics_name=metrics_value
The example training model code that we will use can be found on this GitHub site.","가장 간단한 옵션은 표준 메트릭 수집기를 사용하는 것입니다. 즉, 평가 메트릭을 다음 형식으로 stdout에 작성해야합니다.


metrics_name = metrics_value
우리가 사용할 예제 훈련 모델 코드는이 GitHub 사이트에서 찾을 수 있습니다.",,
2803,"After preparing the training code, simply package it as a Docker image and it is ready to go.",훈련 코드를 준비한 후 Docker 이미지로 패키징하기 만하면 바로 사용할 수 있습니다.,,
2804,10.5.2.,10.5.2.,,
2805,"Configuring an Experiment
Once you have the training container, the next step is to write a spec for your experiment.","실험 구성
학습 컨테이너가 있으면 다음 단계는 실험에 대한 사양을 작성하는 것입니다.",,
2806,Katib uses Kubernetes custom resources to represent experiments.,Katib은 Kubernetes 사용자 지정 리소스를 사용하여 실험을 나타냅니다.,,
2807,EXAMPLE 10-1 can be downloaded from this GitHub page.,예제 10-1은이 GitHub 페이지에서 다운로드 할 수 있습니다.,,
2808,Example 10-1.,예 10-1.,,
2809,"Example experiment spec
apiVersion: ""kubeflow.org/v1beta1""
kind: Experiment
metadata:
  namespace: kubeflow
  labels:
    controller-tools.k8s.io: ""1.0""
  name: random-example
spec:
  objective:               
    type: maximize
    goal: 0.99
    objectiveMetricName: Validation-accuracy
    additionalMetricNames:
      - Train-accuracy
  algorithm:               
    algorithmName: random
  parallelTrialCount: 3    
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:              
    - name: --lr
      parameterType: double
      feasibleSpace:
        min: ""0.01""
        max: ""0.03""
    - name: --num-layers
      parameterType: int
      feasibleSpace:
        min: ""2""
        max: ""5""
    - name: --optimizer
      parameterType: categorical
      feasibleSpace:
        list:
        - sgd
        - adam
        - ftrl
  trialTemplate:           
    goTemplate:
        rawTemplate: |-
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: {{.Trial}}
            namespace: {{.NameSpace}}
          spec:
            template:
              spec:
                containers:
                - name: {{.Trial}}
                  image: docker.io/kubeflowkatib/mxnet-mnist
                  command:
                  - ""python3""
                  - ""/opt/mxnet-mnist/mnist.py""
                  - ""--batch-size=64""
                  {{- with .HyperParameters}}
                  {{- range .}}","실험 사양 예
apiVersion : ""kubeflow.org/v1beta1""
종류 : 실험
메타 데이터 :
  네임 스페이스 : kubeflow
  라벨 :
    controller-tools.k8s.io : ""1.0""
  이름 : 임의의 예
투기:
  객관적인:
    유형 : 최대화
    목표 : 0.99
    objectiveMetricName : 유효성 검사 정확도
    additionalMetricNames :
      -열차 정확도
  연산:
    algorithmName : 임의
  parallelTrialCount : 3
  maxTrialCount : 12
  maxFailedTrialCount : 3
  매개 변수 :
    -이름 : --lr
      parameterType : 더블
      feasibleSpace :
        최소 : ""0.01""
        최대 : ""0.03""
    -이름 : --num-layers
      parameterType : 정수
      feasibleSpace :
        최소 : ""2""
        최대 : ""5""
    -이름 : --optimizer
      parameterType : 범주 형
      feasibleSpace :
        명부:
        -sgd
        -아담
        -ftrl
  trialTemplate :
    goTemplate :
        rawTemplate : |-
          apiVersion : batch / v1
          종류 : 직업
          메타 데이터 :
            이름 : {{.Trial}}
            네임 스페이스 : {{.NameSpace}}
          투기:
            주형:
              투기:
                용기 :
                -이름 : {{.Trial}}
                  이미지 : docker.io/kubeflowkatib/mxnet-mnist
                  명령:
                  - ""python3""
                  - ""/opt/mxnet-mnist/mnist.py""
                  - ""-배치 크기 = 64""
                  {{-.HyperParameters 사용}}
                  {{-범위.}}",,
2810,"- ""{{.Name}}={{.Value}}""
                  {{- end}}
                  {{- end}}
                restartPolicy: Never
That’s quite a lot to follow.","- ""{{.Name}} = {{. Value}}""
                  {{-끝}}
                  {{-끝}}
                restartPolicy : 없음
따라야 할 일이 꽤 많습니다.",,
2811,"Let’s take a closer look at each part of the spec section:


Objective.","사양 섹션의 각 부분을 자세히 살펴 보겠습니다.


객관적인.",,
2812,"This is where you configure how to measure the performance of your training model, and the goal of the experiment.",여기에서 학습 모델의 성능을 측정하는 방법과 실험의 목표를 구성합니다.,,
2813,"In this experiment, we are trying to maximize the validation-accuracy metric.",이 실험에서 우리는 검증-정확도 메트릭을 최대화하려고 노력하고 있습니다.,,
2814,We are stopping our experiment if we reach the objective goal of 0.99 (99% accuracy).,목표 목표 인 0.99 (99 % 정확도)에 도달하면 실험을 중단합니다.,,
2815,"The additionalMetricsNames represents metrics that are collected from each trial, but aren’t used to evaluate the trial.",additionalMetricsNames는 각 시행에서 수집되지만 시행 평가에 사용되지 않는 측정 항목을 나타냅니다.,,
2816,Algorithm.,연산.,,
2817,In this experiment we are using random search, some algorithms may require additional configurations.,이 실험에서는 무작위 검색을 사용합니다.일부 알고리즘에는 추가 구성이 필요할 수 있습니다.,
2818,Budget configurations.,예산 구성.,,
2819,This is where we configure our experiment budget.,여기에서 실험 예산을 구성합니다.,,
2820,"In this experiment, we would run 3 trials in parallel, with a total of 12 trials.",이 실험에서 우리는 총 12 개의 시행과 함께 3 개의 시행을 병렬로 실행합니다.,,
2821,We would also stop our experiment if we have three failed trials.,세 번의 시도가 실패하면 실험을 중단 할 것입니다.,,
2822,This last part is also called an error budget—an important concept in maintaining production-grade system uptime.,이 마지막 부분을 오류 예산이라고도합니다. 이는 프로덕션 등급 시스템 가동 시간을 유지하는 데 중요한 개념입니다.,,
2823,Parameters.,매개 변수.,,
2824,Here we define which parameters we want to tune and the search space for each.,여기에서 조정하려는 매개 변수와 각각에 대한 검색 공간을 정의합니다.,,
2825,"For example, the learning rate parameter is exposed in the training code as --lr.",예를 들어 학습률 매개 변수는 학습 코드에서 --lr로 노출됩니다.,,
2826,"It is a double, with a contiguous search space between 0.01 and 0.03.",0.01에서 0.03 사이의 연속적인 검색 공간이있는 double입니다.,,
2827,Trial template.,평가판 템플릿.,,
2828,The last part of the experiment spec is the template from which each trial is configured.,실험 사양의 마지막 부분은 각 시도가 구성되는 템플릿입니다.,,
2829,"For the purpose of this example, the only important parts are:

    image: docker.io/kubeflowkatib/mxnet-mnist
    command:
      - ""python3""
      - ""/opt/mxnet-mnist/mnist.py""
      - ""--batch-size=64""
This should point to the Docker image that you built in the previous step, with the command-line entry point to run the code.","이 예에서 중요한 부분은 다음과 같습니다.

    이미지 : docker.io/kubeflowkatib/mxnet-mnist
    명령:
      - ""python3""
      - ""/opt/mxnet-mnist/mnist.py""
      - ""-배치 크기 = 64""
이는 코드를 실행하기위한 명령 줄 진입 점과 함께 이전 단계에서 빌드 한 Docker 이미지를 가리켜 야합니다.",,
2830,10.5.3.,10.5.3.,,
2831,"Running the Experiment
After everything is configured, apply the resource to start the experiment:
kubectl apply -f random-example.yaml
You can check the status of the experiment by running the following:
kubectl -n kubeflow describe experiment random-example
In the output, you should see something like EXAMPLE 10-2.","실험 실행
모든 구성이 완료되면 리소스를 적용하여 실험을 시작합니다.
kubectl apply -f random-example.yaml
다음을 실행하여 실험 상태를 확인할 수 있습니다.
kubectl -n kubeflow 설명 실험 임의의 예
출력에서 EXAMPLE 10-2와 같은 것을 볼 수 있습니다.",,
2832,Example 10-2.,예 10-2.,,
2833,"Example experiment output
Name:         random-example
Namespace:    kubeflow
Labels:       controller-tools.k8s.io=1.0
Annotations:  <none>
API Version:  kubeflow.org/v1beta1
Kind:         Experiment
Metadata:
  Creation Timestamp:  2019-12-22T22:53:25Z
  Finalizers:
    update-prometheus-metrics
  Generation:        2
  Resource Version:  720692
  Self Link:         /apis/kubeflow.org/v1beta1/namespaces/kubeflow/experiments/random-example
  UID:               dc6bc15a-250d-11ea-8cae-42010a80010f
Spec:
  Algorithm:
    Algorithm Name:        random
    Algorithm Settings:    <nil>
  Max Failed Trial Count:  3
  Max Trial Count:         12
  Metrics Collector Spec:
    Collector:
      Kind:  StdOut
  Objective:
    Additional Metric Names:
      accuracy
    Goal:                   0.99
    Objective Metric Name:  Validation-accuracy
    Type:                   maximize
  Parallel Trial Count:     3
  Parameters:
    Feasible Space:
      Max:           0.03
      Min:           0.01
    Name:            --lr
    Parameter Type:  double
    Feasible Space:
      Max:           5
      Min:           2
    Name:            --num-layers
    Parameter Type:  int
    Feasible Space:
      List:
        sgd
        adam
        ftrl
    Name:            --optimizer
    Parameter Type:  categorical
  Trial Template:
    Go Template:
      Raw Template:  apiVersion: batch/v1
kind: Job
metadata:
  name: {{.Trial}}
  namespace: {{.NameSpace}}
spec:
  template:
    spec:
      containers:
      - name: {{.Trial}}
        image: docker.io/kubeflowkatib/mxnet-mnist-example
        command:
        - ""python""
        - ""/mxnet/example/image-classification/train_mnist.py""
        - ""--batch-size=64""
        {{- with .HyperParameters}}
        {{- range .}}","실험 결과 예시
이름 : 임의의 예
네임 스페이스 : kubeflow
레이블 : controller-tools.k8s.io = 1.0
주석 : <없음>
API 버전 : kubeflow.org/v1beta1
종류 : 실험
메타 데이터 :
  생성 타임 스탬프 : 2019-12-22T22 : 53 : 25Z
  종료 자 :
    update-prometheus-metrics
  세대 : 2
  리소스 버전 : 720692
  셀프 링크 : /apis/kubeflow.org/v1beta1/namespaces/kubeflow/experiments/random-example
  UID : dc6bc15a-250d-11ea-8cae-42010a80010f
투기:
  연산:
    알고리즘 이름 : 임의
    알고리즘 설정 : <nil>
  최대 실패 시도 횟수 : 3
  최대 시도 횟수 : 12
  메트릭 수집기 사양 :
    수집기:
      종류 : StdOut
  객관적인:
    추가 측정 항목 이름 :
      정확성
    목표 : 0.99
    목표 메트릭 이름 : 유효성 검사 정확도
    유형 : 최대화
  병렬 시도 횟수 : 3
  매개 변수 :
    가능한 공간 :
      최대 : 0.03
      최소 : 0.01
    이름 : --lr
    매개 변수 유형 : double
    가능한 공간 :
      최대 : 5
      최소 : 2
    이름 : --num-layers
    매개 변수 유형 : int
    가능한 공간 :
      명부:
        sgd
        아담
        ftrl
    이름 : --optimizer
    매개 변수 유형 : 범주 형
  평가판 템플릿 :
    Go 템플릿 :
      원시 템플릿 : apiVersion : batch / v1
종류 : 직업
메타 데이터 :
  이름 : {{.Trial}}
  네임 스페이스 : {{.NameSpace}}
투기:
  주형:
    투기:
      용기 :
      -이름 : {{.Trial}}
        이미지 : docker.io/kubeflowkatib/mxnet-mnist-example
        명령:
        - ""파이썬""
        - ""/mxnet/example/image-classification/train_mnist.py""
        - ""-배치 크기 = 64""
        {{-.HyperParameters 사용}}
        {{-범위.}}",,
2834,"- ""{{.Name}}={{.Value}}""
        {{- end}}
        {{- end}}
      restartPolicy: Never
Status:                                       
  Conditions:
    Last Transition Time:  2019-12-22T22:53:25Z
    Last Update Time:      2019-12-22T22:53:25Z
    Message:               Experiment is created
    Reason:                ExperimentCreated
    Status:                True
    Type:                  Created
    Last Transition Time:  2019-12-22T22:55:10Z
    Last Update Time:      2019-12-22T22:55:10Z
    Message:               Experiment is running
    Reason:                ExperimentRunning
    Status:                True
    Type:                  Running
  Current Optimal Trial:                      
    Observation:
      Metrics:
        Name:   Validation-accuracy
        Value:  0.981091
    Parameter Assignments:
      Name:          --lr
      Value:         0.025139701133432946
      Name:          --num-layers
      Value:         4
      Name:          --optimizer
      Value:         sgd
  Start Time:        2019-12-22T22:53:25Z
  Trials:            12                       
  Trials Running:    2
  Trials Succeeded:  10
Events:              <none>
Some of the interesting parts of the output are:


Status.","- ""{{.Name}} = {{. Value}}""
        {{-끝}}
        {{-끝}}
      restartPolicy : 없음
상태:
  정황:
    마지막 전환 시간 : 2019-12-22T22 : 53 : 25Z
    마지막 업데이트 시간 : 2019-12-22T22 : 53 : 25Z
    메시지 : 실험이 생성되었습니다.
    이유 : ExperimentCreated
    상태 : 참
    유형 : 생성됨
    마지막 전환 시간 : 2019-12-22T22 : 55 : 10Z
    마지막 업데이트 시간 : 2019-12-22T22 : 55 : 10Z
    메시지 : 실험이 실행 중입니다.
    이유 : ExperimentRunning
    상태 : 참
    유형 : 달리기
  현재 최적의 시도 :
    관측:
      측정 항목 :
        이름 : 검증 정확도
        값 : 0.981091
    매개 변수 지정 :
      이름 : --lr
      값 : 0.025139701133432946
      이름 : --num-layers
      값 : 4
      이름 : --optimizer
      값 : sgd
  시작 시간 : 2019-12-22T22 : 53 : 25Z
  시험 : 12
  시험 진행 중 : 2
  성공한 시험 : 10
이벤트 : <없음>
출력의 흥미로운 부분은 다음과 같습니다.


상태.",,
2835,"Here you can see the current state of the experiment, as well as its previous states.",여기에서 실험의 현재 상태와 이전 상태를 볼 수 있습니다.,,
2836,Current Optimal Trial.,현재 최적의 시도.,,
2837,"This is the “best” trial so far, i.e., the trial that produced the best outcome as determined by our predefined metrics.","이것은 지금까지 ""최고의""시험입니다. 즉, 사전 정의 된 측정 항목에 의해 결정된 최상의 결과를 도출 한 시험입니다.",,
2838,You can also see this trial’s parameters and metrics.,이 시도의 매개 변수와 측정 항목도 볼 수 있습니다.,,
2839,Trials Succeeded/Running/Failed.,시도 성공 / 실행 / 실패.,,
2840,"In this section, you can see how your experiment is progressing.",이 섹션에서는 실험이 어떻게 진행되고 있는지 확인할 수 있습니다.,,
2841,10.5.4.,10.5.4.,,
2842,"Katib User Interface
Alternatively, you can use Katib’s user interface (UI) to submit and monitor your experiments.","Katib 사용자 인터페이스
또는 Katib의 사용자 인터페이스 (UI)를 사용하여 실험을 제출하고 모니터링 할 수 있습니다.",,
2843,"If you have a Kubeflow deployment, you can navigate to the Katib UI by clicking “Katib” in the navigation panel and then “Hyperparameter Tuning” on the main page, shown in FIGURE 10-2.","Kubeflow 배포가있는 경우 탐색 패널에서 ""Katib""을 클릭 한 다음 그림 10-2에 표시된 기본 페이지에서 ""초 매개 변수 조정""을 클릭하여 Katib UI로 이동할 수 있습니다.",,
2844,Figure 10-2.,그림 10-2.,,
2845,"Katib UI main page

Let’s submit our random search experiment (see FIGURE 10-3).","Katib UI 메인 페이지

무작위 검색 실험을 제출하겠습니다 (그림 10-3 참조).",,
2846,"You can simply paste a YAML in the textbox here, or have one generated for you by following the UI.",여기의 텍스트 상자에 YAML을 간단히 붙여 넣거나 UI를 따라 생성되도록 할 수 있습니다.,,
2847,"To do this, click the Parameters tab.",이렇게하려면 매개 변수 탭을 클릭합니다.,,
2848,Figure 10-3.,그림 10-3.,,
2849,"Configuring a new experiment, part 1

You should see a panel like FIGURE 10-4.","새 실험 구성, 1 부

그림 10-4와 같은 패널이 표시되어야합니다.",,
2850,Enter the necessary configuration parameters on this page, define a run budget and the validation metrics.,이 페이지에서 필요한 구성 매개 변수를 입력하십시오.실행 예산 및 검증 메트릭을 정의합니다.,
2851,Figure 10-4.,그림 10-4.,,
2852,"Configuring a new experiment, part 2

Then scroll down the page and finish up the rest of the experiment by configuring the search space and the trial template.","새 실험 구성, 2 부

그런 다음 페이지를 아래로 스크롤하고 검색 공간과 평가판 템플릿을 구성하여 나머지 실험을 완료합니다.",,
2853,"For the latter, you can just leave it on the default template.",후자의 경우 기본 템플릿에 그대로 둘 수 있습니다.,,
2854,"When you are done, click “Deploy.”
Now that the experiment is running, you can monitor its status and see a visual graph of the progress (see FIGURE 10-5).","완료되면 ""배포""를 클릭합니다.
이제 실험이 실행 중이므로 상태를 모니터링하고 진행 상황에 대한 시각적 그래프를 볼 수 있습니다 (그림 10-5 참조).",,
2855,"You can see your running and completed experiments by navigating to the drop-down menu in the Katib dashboard, and then selecting “UI” and then “Monitor.”


Figure 10-5.","Katib 대시 보드의 드롭 다운 메뉴로 이동 한 다음 'UI'를 선택한 다음 '모니터'를 선택하면 실행중인 실험과 완료된 실험을 볼 수 있습니다.


그림 10-5.",,
2856,"Katib UI for an experiment

Below this graph, you will see a detailed breakdown of each trial (shown in FIGURE 10-6), the values of the hyperparameters for each of the trials, and the final metric values.","실험을위한 Katib UI

이 그래프 아래에는 각 시행 (그림 10-6 참조), 각 시행에 대한 하이퍼 파라미터 값 및 최종 메트릭 값에 대한 자세한 분석이 표시됩니다.",,
2857,This is very useful for comparing the effects of certain hyperparameters on the model’s performance.,이는 특정 하이퍼 파라미터가 모델 성능에 미치는 영향을 비교하는 데 매우 유용합니다.,,
2858,Figure 10-6.,그림 10-6.,,
2859,"Katib metrics for an experiment

Since we are also collecting validation metrics along the way, we can actually plot the graph for each trial.","실험을위한 Katib 측정 항목

도중에 검증 메트릭도 수집하고 있으므로 실제로 각 시행에 대한 그래프를 그릴 수 있습니다.",,
2860,Click a row to see how the model performs with the given hyperparameter values across time (as in FIGURE 10-7).,행을 클릭하면 시간에 따라 주어진 하이퍼 파라미터 값으로 모델이 어떻게 작동하는지 볼 수 있습니다 (그림 10-7 참조).,,
2861,Figure 10-7.,그림 10-7.,,
2862,"Metrics for each trial




10.6.","각 시행에 대한 메트릭




10.6.",,
2863,"Tuning Distributed Training Jobs
In CHAPTER 7 we saw an example of using Kubeflow to orchestrate distributed training.","분산 훈련 작업 조정
7 장에서 Kubeflow를 사용하여 분산 교육을 조정하는 예를 보았습니다.",,
2864,What if we want to use Katib to tune parameters for a distributed training job?,Katib를 사용하여 분산 훈련 작업의 매개 변수를 조정하려면 어떻게해야합니까?,,
2865,The good news is that Katib natively supports integration with TensorFlow and PyTorch distributed training.,좋은 소식은 Katib이 기본적으로 TensorFlow 및 PyTorch 분산 교육과의 통합을 지원한다는 것입니다.,,
2866,An MNIST example with TensorFlow can be found at this Katib GitHub page.,TensorFlow를 사용한 MNIST 예제는이 Katib GitHub 페이지에서 찾을 수 있습니다.,,
2867,"This example uses the same MNIST distributed training example we saw in CHAPTER 7, and directly integrates it into the Katib framework.",이 예제는 7 장에서 본 것과 동일한 MNIST 분산 교육 예제를 사용하고이를 Katib 프레임 워크에 직접 통합합니다.,,
2868,"In EXAMPLE 10-3, we will launch an experiment to tune hyperparameters (learning rate and batch size) for a distributed TensorFlow job.",예제 10-3에서는 분산 된 TensorFlow 작업에 대한 하이퍼 파라미터 (학습률 및 배치 크기)를 조정하는 실험을 시작합니다.,,
2869,Example 10-3.,예 10-3.,,
2870,"Distributed training example
apiVersion: ""kubeflow.org/v1beta1""
kind: Experiment
metadata:
  namespace: kubeflow
  name: tfjob-example
spec:
  parallelTrialCount: 3             
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:                        
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy_1
  algorithm:
    algorithmName: random
  metricsCollectorSpec:             
    source:
      fileSystemPath:
        path: /train
        kind: Directory
    collector:
      kind: TensorFlowEvent
  parameters:                       
    - name: learning_rate
      parameterType: double
      feasibleSpace:
        min: ""0.01""
        max: ""0.05""
    - name: batch_size
      parameterType: int
      feasibleSpace:
        min: ""100""
        max: ""200""
  trialTemplate:
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: learning_rate
      - name: batchSize
        description: Batch Size
        reference: batch_size
    trialSpec:
      apiVersion: ""kubeflow.org/v1""
      kind: TFJob
      spec:
        tfReplicaSpecs:             
          Worker:
            replicas: 2
            restartPolicy: OnFailure
            template:
              spec:
                containers:
                  - name: tensorflow
                    image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
                    imagePullPolicy: Always
                    command:
                      - ""python""
                      - ""/var/tf_mnist/mnist_with_summaries.py""
                      - ""--log_dir=/train/metrics""
                      - ""--learning_rate=${trialParameters.learningRate}""
                      - ""--batch_size=${trialParameters.batchSize}""


The total and parallel trial counts are similar to the previous experiment.","분산 교육 예제
apiVersion : ""kubeflow.org/v1beta1""
종류 : 실험
메타 데이터 :
  네임 스페이스 : kubeflow
  이름 : tfjob-example
투기:
  parallelTrialCount : 3
  maxTrialCount : 12
  maxFailedTrialCount : 3
  객관적인:
    유형 : 최대화
    목표 : 0.99
    objectiveMetricName : 정확도 _1
  연산:
    algorithmName : 임의
  metricsCollectorSpec :
    출처:
      fileSystemPath :
        경로 : / train
        종류 : 디렉토리
    수집기:
      종류 : TensorFlowEvent
  매개 변수 :
    -이름 : learning_rate
      parameterType : 더블
      feasibleSpace :
        최소 : ""0.01""
        최대 : ""0.05""
    -이름 : batch_size
      parameterType : 정수
      feasibleSpace :
        최소 : ""100""
        최대 : ""200""
  trialTemplate :
    trialParameters :
      -이름 : learningRate
        설명 : 학습 모델의 학습률
        참조 : learning_rate
      -이름 : batchSize
        설명 : 배치 크기
        참조 : batch_size
    trialSpec :
      apiVersion : ""kubeflow.org/v1""
      종류 : TFJob
      투기:
        tfReplicaSpecs :
          노동자:
            복제본 : 2
            restartPolicy : OnFailure
            주형:
              투기:
                용기 :
                  -이름 : tensorflow
                    이미지 : gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
                    imagePullPolicy : 항상
                    명령:
                      - ""파이썬""
                      - ""/var/tf_mnist/mnist_with_summaries.py""
                      - ""--log_dir = / train / metrics""
                      - ""--learning_rate = $ {trialParameters.learningRate}""
                      - ""--batch_size = $ {trialParameters.batchSize}""


총 및 병렬 시행 횟수는 이전 실험과 유사합니다.",,
2871,In this case they refer to the total and parallel number of distributed training jobs to run.,이 경우 실행할 분산 학습 작업의 총 및 병렬 수를 나타냅니다.,,
2872,The objective specification is also similar—in this case we want to maximize the accuracy measurement.,객관적인 사양도 비슷합니다.이 경우 정확도 측정을 최대화하려고합니다.,,
2873,The metrics collector specification looks slightly different.,메트릭 수집기 사양은 약간 다르게 보입니다.,,
2874,"This is because this is a TensorFlow job, and we can use TFEvents outputted by TensorFlow directly.",이는 TensorFlow 작업이기 때문이며 TensorFlow에서 출력 한 TFEvents를 직접 사용할 수 있습니다.,,
2875,"Using the built-in TensorFlowEvent collector type, Katib can automatically parse TensorFlow events and populate the metrics database.",내장 된 TensorFlowEvent 수집기 유형을 사용하여 Katib는 자동으로 TensorFlow 이벤트를 구문 분석하고 메트릭 데이터베이스를 채울 수 있습니다.,,
2876,The parameter configurations are exactly the same—in this case we are tuning the learning rate and batch size of the model.,매개 변수 구성은 정확히 동일합니다.이 경우 모델의 학습률과 배치 크기를 조정합니다.,,
2877,The trial template should look familiar to you if you read CHAPTER 7—it’s the same distributed training example spec that we ran before.,7 장을 읽으면 평가판 템플릿이 익숙해 보일 것입니다. 이전에 실행 한 것과 동일한 분산 교육 예제 사양입니다.,,
2878,The imporant difference here is that we’ve parameterized the input to learning_rate and batch_size.,여기서 중요한 차이점은 learning_rate 및 batch_size에 대한 입력을 매개 변수화했다는 것입니다.,,
2879,So now you have learned how to use Katib to tune hyperparameters.,이제 Katib를 사용하여 하이퍼 파라미터를 조정하는 방법을 배웠습니다.,,
2880,But notice that you still have to select the model yourself.,그러나 여전히 모델을 직접 선택해야합니다.,,
2881,Can we reduce the amount of human work even further?,인간의 노동량을 더 줄일 수 있습니까?,,
2882,What about other subfields in AutoML?,AutoML의 다른 하위 필드는 어떻습니까?,,
2883,In the next section we will look at how Katib supports the generation of entire artificial neural networks.,다음 섹션에서는 Katib이 전체 인공 신경망 생성을 지원하는 방법을 살펴볼 것입니다.,,
2884,10.7.,10.7.,,
2885,"Neural Architecture Search
Neural architecture search (NAS) is a growing subfield in automated machine learning.","신경 아키텍처 검색
신경 아키텍처 검색 (NAS)은 자동화 된 기계 학습에서 성장하는 하위 분야입니다.",,
2886,"Unlike hyperparameter tuning, where the model is already chosen and our goal is to optimize its performance by turning a few knobs, in NAS we are trying to generate the network architecture itself.",모델이 이미 선택되어 있고 우리의 목표는 몇 개의 노브를 돌려 성능을 최적화하는 하이퍼 파라미터 튜닝과 달리 NAS에서는 네트워크 아키텍처 자체를 생성하려고합니다.,,
2887,"Recent research has shown that NAS can outperform handcrafted neural networks on tasks like image classification, object detection, and semantic segmentation.","최근 연구에 따르면 NAS는 이미지 분류, 객체 감지 및 의미 론적 세분화와 같은 작업에서 수제 신경망을 능가 할 수 있습니다.",,
2888,"[1]
Most the methodologies for NAS can be categorized as either generation methods or mutation methods.","[1]
NAS에 대한 대부분의 방법론은 생성 방법 또는 돌연변이 방법으로 분류 할 수 있습니다.",,
2889,"In generation methods, the algorithm will propose one or more candidate architectures in each iteration.",생성 방법에서 알고리즘은 각 반복에서 하나 이상의 후보 아키텍처를 제안합니다.,,
2890,These proposed architectures are then evaluated and then refined in the next iteration.,이러한 제안 된 아키텍처는 평가되고 다음 반복에서 개선됩니다.,,
2891,"In mutation methods, an overly complex architecture is proposed first, and subsequent iterations will attempt to prune the model.",변이 방법에서는 지나치게 복잡한 아키텍처가 먼저 제안되고 후속 반복은 모델을 정리하려고 시도합니다.,,
2892,"Katib currently supports two implementations of NAS: Differentiable Architecture Search (DARTS),[2] and Efficient Neural Architecture Search (ENAS).","Katib는 현재 DARTS (Differentiable Architecture Search), [2] 및 ENAS (Efficient Neural Architecture Search)의 두 가지 NAS 구현을 지원합니다.",,
2893,[3] DARTS achieves scalability of NAS by relaxing the search space to be continuous instead of discrete and utilizes gradient descent to optimize the architecture.,[3] DARTS는 검색 공간을 이산 대신 연속적으로 완화하여 NAS의 확장 성을 달성하고 경사 하강 법을 활용하여 아키텍처를 최적화합니다.,,
2894,"ENAS takes a different approach, by observing that in most NAS algorithms the bottleneck occurs during the training of each child model.",ENAS는 대부분의 NAS 알고리즘에서 각 하위 모델의 훈련 중에 병목 현상이 발생한다는 것을 관찰함으로써 다른 접근 방식을 취합니다.,,
2895,"ENAS forces each child model to share parameters, thus improving the overall efficiency.",ENAS는 각 하위 모델이 매개 변수를 공유하도록하여 전반적인 효율성을 향상시킵니다.,,
2896,"The general workflow of NAS in Katib is similar to hyperparameter search, with an additional step for constructing the model architecture.",Katib에서 NAS의 일반적인 워크 플로우는 하이퍼 파라미터 검색과 유사하며 모델 아키텍처를 구성하기위한 추가 단계가 있습니다.,,
2897,"An internal module of Katib, called the model manager, is responsible for taking topological configurations and mutation parameters, and constructing new models.",모델 관리자라고하는 Katib의 내부 모듈은 토폴로지 구성 및 변이 매개 변수를 취하고 새 모델을 구성합니다.,,
2898,Katib then uses the same concepts of trials and metrics to evaluate the model’s performance.,그런 다음 Katib은 동일한 개념의 시행 및 측정 항목을 사용하여 모델의 성능을 평가합니다.,,
2899,"As an example, see the spec of a NAS experiment using DARTS in EXAMPLE 10-4.","예를 들어, 예 10-4의 DARTS를 사용한 NAS 실험 사양을 참조하십시오.",,
2900,Example 10-4.,예 10-4.,,
2901,"Example NAS experiment spec
apiVersion: ""kubeflow.org/v1beta1""
kind: Experiment
metadata:
  namespace: kubeflow
  name: darts-example-gpu
spec:
  parallelTrialCount: 1
  maxTrialCount: 1
  maxFailedTrialCount: 1
  objective:
    type: maximize
    objectiveMetricName: Best-Genotype
  metricsCollectorSpec:
    collector:
      kind: StdOut
    source:
      filter:
        metricsFormat:
          - ""([\\w-]+)=(Genotype.","NAS 실험 사양의 예
apiVersion : ""kubeflow.org/v1beta1""
종류 : 실험
메타 데이터 :
  네임 스페이스 : kubeflow
  이름 : darts-example-gpu
투기:
  parallelTrialCount : 1
  maxTrialCount : 1
  maxFailedTrialCount : 1
  객관적인:
    유형 : 최대화
    objectiveMetricName : Best-Genotype
  metricsCollectorSpec :
    수집기:
      종류 : StdOut
    출처:
      필터:
        metricsFormat :
          - ""([\\ w-] +) = (유전자형.",,
2902,"*)""
  algorithm:
    algorithmName: darts
    algorithmSettings:
      - name: num_epochs
        value: ""3""
  nasConfig:                     
    graphConfig:
      numLayers: 3
    operations:
      - operationType: separable_convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - ""3""
      - operationType: dilated_convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - ""3""
                - ""5""
      - operationType: avg_pooling
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - ""3""
      - operationType: max_pooling
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - ""3""
      - operationType: skip_connection
  trialTemplate:
    trialParameters:
      - name: algorithmSettings
        description: Algorithm settings of DARTS Experiment
        reference: algorithm-settings
      - name: searchSpace
        description: Search Space of DARTS Experiment
        reference: search-space
      - name: numberLayers
        description: Number of Neural Network layers
        reference: num-layers
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: docker.io/kubeflowkatib/darts-cnn-cifar10
                imagePullPolicy: Always
                command:
                  - python3
                  - run_trial.py
                  - --algorithm-settings=""${trialParameters.algorithmSettings}""
                  - --search-space=""${trialParameters.searchSpace}""
                  - --num-layers=""${trialParameters.numberLayers}""
                resources:
                  limits:
                    nvidia.com/gpu: 1
            restartPolicy: Never


The general structure of a NAS experiment is similar to that of a hyperparameter search experiment.","*) ""
  연산:
    algorithmName : 다트
    algorithmSettings :
      -이름 : num_epochs
        값 : ""3""
  nasConfig :
    graphConfig :
      numLayers : 3
    작업 :
      -operationType : separable_convolution
        매개 변수 :
          -이름 : filter_size
            parameterType : 범주 형
            feasibleSpace :
              명부:
                - ""삼""
      -operationType : dilated_convolution
        매개 변수 :
          -이름 : filter_size
            parameterType : 범주 형
            feasibleSpace :
              명부:
                - ""삼""
                - ""5""
      -operationType : avg_pooling
        매개 변수 :
          -이름 : filter_size
            parameterType : 범주 형
            feasibleSpace :
              명부:
                - ""삼""
      -operationType : max_pooling
        매개 변수 :
          -이름 : filter_size
            parameterType : 범주 형
            feasibleSpace :
              명부:
                - ""삼""
      -operationType : skip_connection
  trialTemplate :
    trialParameters :
      -이름 : algorithmSettings
        설명 : DARTS 실험의 알고리즘 설정
        참조 : 알고리즘 설정
      -이름 : searchSpace
        설명 : DARTS 실험의 검색 공간
        참조 : 검색 공간
      -이름 : numberLayers
        설명 : 신경망 계층의 수
        참조 : num-layers
    trialSpec :
      apiVersion : batch / v1
      종류 : 직업
      투기:
        주형:
          투기:
            용기 :
              -이름 : 교육 컨테이너
                이미지 : docker.io/kubeflowkatib/darts-cnn-cifar10
                imagePullPolicy : 항상
                명령:
                  -python3
                  -run_trial.py
                  ---algorithm-settings = ""$ {trialParameters.algorithmSettings}""
                  ---search-space = ""$ {trialParameters.searchSpace}""
                  ---num-layers = ""$ {trialParameters.numberLayers}""
                자원:
                  제한:
                    nvidia.com/gpu : 1
            restartPolicy : 없음


NAS 실험의 일반적인 구조는 초 매개 변수 검색 실험의 구조와 유사합니다.",,
2903,The majority of the specification should look very familiar, the most important difference is the addition of the nasConfig.,대부분의 사양은 매우 친숙하게 보입니다.가장 중요한 차이점은 nasConfig의 추가입니다.,
2904,"This is where you can configure the specifications of the neural network that you want to create, such as the number of layers, the inputs and outputs at each layer, and the types of operations.","여기에서 레이어 수, 각 레이어의 입력 및 출력, 작업 유형과 같이 만들려는 신경망의 사양을 구성 할 수 있습니다.",,
2905,10.8.,10.8.,,
2906,"Advantages of Katib over Other Frameworks
There are many similar open source systems for hyperparameter search, among them NNI, Optuna, Ray Tune, and Hyperopt.","다른 프레임 워크에 비해 Katib의 장점
NNI, Optuna, Ray Tune 및 Hyperopt 중에서 하이퍼 파라미터 검색을위한 유사한 오픈 소스 시스템이 많이 있습니다.",,
2907,"In addition, the original design of Katib was inspired by Google Vizier.",또한 Katib의 원래 디자인은 Google Vizier에서 영감을 받았습니다.,,
2908,"While these frameworks offer many capabilities similar to Katib’s, namely the ability to configure parallel hyperparameter sweeps using a variety of algorithms, there are a few features of Katib that make it unique:

Design catering to both user and admin

Most tuning frameworks are designed to cater to the user—the data scientist performing the tuning experiment.","이러한 프레임 워크는 Katib와 유사한 많은 기능, 즉 다양한 알고리즘을 사용하여 병렬 하이퍼 파라미터 스윕을 구성하는 기능을 제공하지만이를 고유하게 만드는 Katib의 몇 가지 기능이 있습니다.

사용자와 관리자 모두에게 적합한 디자인

대부분의 튜닝 프레임 워크는 튜닝 실험을 수행하는 데이터 과학자 인 사용자를 위해 설계되었습니다.",,
2909,"Katib is also designed to make life easier for the system admin, who is responsible for maintaining the infrastructure, allocating compute resources, and monitoring system health.","Katib은 또한 인프라 유지 관리, 컴퓨팅 리소스 할당 및 시스템 상태 모니터링을 담당하는 시스템 관리자의 삶을 편하게하도록 설계되었습니다.",,
2910,"Cloud native design

Other frameworks (such as Ray Tune) may support integration with Kubernetes, but often require additional effort to set up a cluster.","클라우드 네이티브 디자인

다른 프레임 워크 (예 : Ray Tune)는 Kubernetes와의 통합을 지원할 수 있지만 종종 클러스터를 설정하기 위해 추가 노력이 필요합니다.",,
2911,"By contrast, Katib is the first hyperparameter search framework to base its design entirely on Kubernetes; every one of its resources can be accessed and manipulated by Kubernetes APIs.",대조적으로 Katib은 설계를 전적으로 Kubernetes에 기반한 최초의 초 매개 변수 검색 프레임 워크입니다.모든 리소스는 Kubernetes API로 액세스하고 조작 할 수 있습니다.,,
2912,"Scalable and portable

Because Katib uses Kubernetes as its orchestration engine, it is very easy to scale up an experiment.","확장 가능하고 휴대 가능

Katib은 Kubernetes를 오케스트레이션 엔진으로 사용하기 때문에 실험을 확장하기가 매우 쉽습니다.",,
2913,You can run the same experiments on a laptop for prototyping and deploy the job to a production cluster with minimal changes to the spec.,프로토 타이핑을 위해 랩톱에서 동일한 실험을 실행하고 사양을 최소한으로 변경하여 작업을 프로덕션 클러스터에 배포 할 수 있습니다.,,
2914,"By contrast, other frameworks require additional effort to install and configure depending on the hardware availability.",반대로 다른 프레임 워크는 하드웨어 가용성에 따라 설치 및 구성에 추가적인 노력이 필요합니다.,,
2915,"Extensible

Katib offers flexible and pluggable interfaces for its search algorithms and storage systems.","확장 가능

Katib은 검색 알고리즘 및 스토리지 시스템을위한 유연하고 플러그 가능한 인터페이스를 제공합니다.",,
2916,Most other frameworks come with a preset list of algorithms and have hardcoded mechanisms for metrics collection.,대부분의 다른 프레임 워크는 사전 설정된 알고리즘 목록과 함께 제공되며 메트릭 수집을위한 하드 코딩 된 메커니즘이 있습니다.,,
2917,"In Katib, the user can easily implement a custom search algorithm and integrate it with the framework.",Katib에서 사용자는 사용자 지정 검색 알고리즘을 쉽게 구현하고이를 프레임 워크와 통합 할 수 있습니다.,,
2918,"Native support

Katib natively supports advanced features like distributed training and neural architecture search.","기본 지원

Katib은 기본적으로 분산 교육 및 신경 아키텍처 검색과 같은 고급 기능을 지원합니다.",,
2919,10.9.,10.9.,,
2920,"Conclusion
In this chapter we’ve taken a quick overview of AutoML and learned how it can accelerate the development of machine learning models by automating time-consuming tasks like hyperparameter search.","결론
이 장에서는 AutoML에 대한 간략한 개요를 살펴보고 초 매개 변수 검색과 같이 시간이 많이 걸리는 작업을 자동화하여 머신 러닝 모델 개발을 가속화하는 방법을 배웠습니다.",,
2921,"With techniques like automated hyperparameter tuning, you can scale up the development of your models while sustaining high model quality.",자동화 된 하이퍼 파라미터 튜닝과 같은 기술을 사용하면 높은 모델 품질을 유지하면서 모델 개발을 확장 할 수 있습니다.,,
2922,We have then used Katib—a Kubernetes-native tuning service from the Kubeflow platform—to configure and execute a hyperparameter search experiment.,그런 다음 Kubeflow 플랫폼의 Kubernetes 네이티브 튜닝 서비스 인 Katib를 사용하여 하이퍼 파라미터 검색 실험을 구성하고 실행했습니다.,,
2923,"We have also shown how you can use Katib’s dashboard to submit, track, and visualize your 
experiments.","또한 Katib의 대시 보드를 사용하여 제출, 추적 및 시각화 할 수있는 방법도 보여주었습니다.
실험.",,
2924,We’ve also explored how Katib handles neural architecture search (NAS).,또한 Katib이 신경 아키텍처 검색 (NAS)을 처리하는 방법을 살펴 보았습니다.,,
2925,"Katib currently supports two methods of NAS—DARTS and ENAS, with more development to follow.",Katib은 현재 DARTS와 ENAS의 두 가지 NAS 방법을 지원하며 더 많은 개발이 진행될 예정입니다.,,
2926,"Hopefully, this has given you some insights into how Katib can be leveraged to reduce the amount of work in your machine learning workflows.",이를 통해 Katib을 활용하여 기계 학습 워크 플로의 작업량을 줄이는 방법에 대한 통찰력을 얻을 수 있기를 바랍니다.,,
2927,"Katib is still an evolving project, and you can follow the latest developments on this Katib GitHub page.",Katib은 여전히 진화하는 프로젝트이며이 Katib GitHub 페이지에서 최신 개발을 따를 수 있습니다.,,
2928,Thank you for joining us on your adventures in learning Kubeflow.,Kubeflow를 배우는 데 참여 해주셔서 감사합니다.,,
2929,We hope that Kubeflow meets your needs and helps you deliver on machine learning’s ability to bring value to your organization.,Kubeflow가 귀하의 요구 사항을 충족하고 귀하의 조직에 가치를 제공하는 기계 학습의 능력을 제공하는 데 도움이되기를 바랍니다.,,
2930,"To keep up to date on the latest changes with Kubeflow, we encourage you to join the Kubeflow Slack workspace and mailing lists.",Kubeflow의 최신 변경 사항을 확인하려면 Kubeflow Slack 작업 영역 및 메일 링리스트에 가입하는 것이 좋습니다.,,
2931,"[1] T. Elsken, J. H. Metzen, F. Hutter, “Neural Architecture Search: A Survey,” Journal of Machine Learning Research 20 (2019), https://oreil.ly/eO-CV, pp.","[1] T. Elsken, J. H. Metzen, F. Hutter, ""신경 아키텍처 검색 : 설문 조사"", Journal of Machine Learning Research 20 (2019), https://oreil.ly/eO-CV, pp.",,
2932,1-21.,1-21.,,
2933,"[2] H. Liu, K. Simonyan, and Y. Tang, “Differentiable Architecture Search (DARTS),” https://oreil.ly/JSAIX.","[2] H. Liu, K. Simonyan 및 Y. Tang, ""DARTS (Differentiable Architecture Search)"", https://oreil.ly/JSAIX.",,
2934,"[3] H. Pham et al., “Efficient Neural Architecture Search via Parameter Sharing,” https://oreil.ly/SQPxn.","[3] H. Pham 등,“매개 변수 공유를 통한 효율적인 신경 아키텍처 검색”, https://oreil.ly/SQPxn.",,
2935,"Appendix A. Argo Executor Configurations and Trade-Offs
Until recently, all Kubernetes implementations supported Docker APIs.","부록 A. Argo Executor 구성 및 트레이드 오프
최근까지 모든 Kubernetes 구현은 Docker API를 지원했습니다.",,
2936,The initial Argo implementation depended on them.,초기 Argo 구현은 이들에 의존했습니다.,,
2937,"With the introduction of OpenShift 4, which doesn’t support the Docker APIs, the situation changed.",Docker API를 지원하지 않는 OpenShift 4의 도입으로 상황이 바뀌 었습니다.,,
2938,"To support the absence of Docker APIs, Argo introduced several new executors: Docker, Kubelet, and Kubernetes APIs.","Docker API의 부재를 지원하기 위해 Argo는 Docker, Kubelet 및 Kubernetes API와 같은 몇 가지 새로운 실행기를 도입했습니다.",,
2939,The containerRuntimeExecutor config value in the Argo parameters file controls which executor is used.,Argo 매개 변수 파일의 containerRuntimeExecutor 구성 값은 사용되는 실행기를 제어합니다.,,
2940,The pros and cons of each executor (based on the information here) are summarized in TABLE A-1.,여기에있는 정보를 기반으로 한 각 실행기의 장단점은 표 A-1에 요약되어 있습니다.,,
2941,This table should help you pick the correct value of the Argo executor.,이 표는 Argo 실행기의 올바른 값을 선택하는 데 도움이됩니다.,,
2942,Table A-1.,표 A-1.,,
2943,"Argo and Kubernetes APIs


Executor
Docker
Kubelet
Kubernetes API
PNC




Pros
Supports all workflow examples.","Argo 및 Kubernetes API


집행자
Docker
Kubelet
Kubernetes API
PNC




장점
모든 워크 플로우 예제를 지원합니다.",,
2944,"Most reliable, well tested, very scalable.",가장 신뢰할 수 있고 잘 테스트되었으며 확장 성이 뛰어납니다.,,
2945,Communicates with Docker daemon for heavy lifting.,무거운 작업을 위해 Docker 데몬과 통신합니다.,,
2946,Secure.,안전한.,,
2947,Can’t escape pod’s service account privileges.,포드의 서비스 계정 권한을 벗어날 수 없습니다.,,
2948,Medium scalability.,중간 규모의 확장 성.,,
2949,Log retrieval and container polling are done against Kubelet.,로그 검색 및 컨테이너 폴링은 Kubelet에 대해 수행됩니다.,,
2950,Secure.,안전한.,,
2951,Can’t escape privileges of pod’s service account.,포드의 서비스 계정 권한을 벗어날 수 없습니다.,,
2952,No extra configuration.,추가 구성이 없습니다.,,
2953,Secure.,안전한.,,
2954,Can’t escape service account privileges.,서비스 계정 권한을 벗어날 수 없습니다.,,
2955,Artifact collection can be done from base image layer.,아티팩트 수집은 기본 이미지 레이어에서 수행 할 수 있습니다.,,
2956,"Scalable: process polling is done over procfs, not kubelet/k8s API.",확장 가능 : 프로세스 폴링은 kubelet / k8s API가 아닌 procfs를 통해 수행됩니다.,,
2957,"Cons
Least secure.","단점
가장 안전하지 않습니다.",,
2958,Requires docker.sock of host to be mounted (often rejected by OPA).,호스트의 docker.sock을 마운트해야합니다 (종종 OPA에서 거부 됨).,,
2959,Additional kubelet configuration may be required.,추가 kubelet 구성이 필요할 수 있습니다.,,
2960,"Can only save params/artifacts in volumes (e.g., emptyDir), and not the base image layer (e.g., /tmp).",기본 이미지 레이어 (예 : / tmp)가 아닌 볼륨 (예 : emptyDir)에만 매개 변수 / 아티팩트를 저장할 수 있습니다.,,
2961,Least scalable.,확장 성이 가장 낮습니다.,,
2962,Log retrieval and container polling are done against k8s API server.,k8s API 서버에 대해 로그 검색 및 컨테이너 폴링이 수행됩니다.,,
2963,"Can only save params/artifacts in volumes (e.g., emptyDir), and not the base image layer (e.g., /tmp).",기본 이미지 레이어 (예 : / tmp)가 아닌 볼륨 (예 : emptyDir)에만 매개 변수 / 아티팩트를 저장할 수 있습니다.,,
2964,Processes no longer run with pid 1.,프로세스는 더 이상 pid 1로 실행되지 않습니다.,,
2965,Artifact collection may fail for containers completing too fast.,컨테이너가 너무 빨리 완료되면 아티팩트 수집이 실패 할 수 있습니다.,,
2966,Can’t capture artifact directories from base image layer with volume mounted under it.,볼륨이 마운트 된 기본 이미지 레이어에서 아티팩트 디렉토리를 캡처 할 수 없습니다.,,
2967,Immature.,미성숙.,,
2968,"Argo Config
docker
kubelet
k8sapi
pns





Appendix B. Cloud-Specific Tools and Configuration
Cloud-specific tools can accelerate your development, but they can also cause vendor lock-in.","Argo 구성
도커
Kubelet
k8sapi
pns





부록 B. 클라우드 관련 도구 및 구성
클라우드 전용 도구는 개발을 가속화 할 수 있지만 공급 업체에 종속 될 수도 있습니다.",,
2969,B.1.,B.1.,,
2970,"Google Cloud
Since Kubeflow originates from Google, it is no surprise that there are some extra features available when running on Google Cloud.","구글 클라우드
Kubeflow는 Google에서 시작되었으므로 Google Cloud에서 실행할 때 사용할 수있는 추가 기능이 있다는 것은 놀라운 일이 아닙니다.",,
2971,"We’ll quickly point out how to use TPUs and Dataflow to accelerate your machine learning pipelines, and more Google-specific components are available in the Kubeflow GitHub repo.",TPU 및 Dataflow를 사용하여 머신 러닝 파이프 라인을 가속화하는 방법을 빠르게 설명하고 Kubeflow GitHub 저장소에서 더 많은 Google 관련 구성 요소를 사용할 수 있습니다.,,
2972,B.1.1.,B.1.1.,,
2973,"TPU-Accelerated Instances
Different parts of the machine learning process can benefit from not only different numbers of machines, but also different types of machines.","TPU 가속 인스턴스
머신 러닝 프로세스의 여러 부분은 다양한 머신 수뿐만 아니라 다양한 유형의 머신에서 이점을 얻을 수 있습니다.",,
2974,"The most common example is with model serving: often lots of low-memory machines can perform reasonably well, but for model training, high-memory or TPU accelerated machines can offer greater benefits.",가장 일반적인 예는 모델 제공입니다. 많은 저 메모리 머신이 합리적으로 잘 수행 될 수 있지만 모델 학습의 경우 높은 메모리 또는 TPU 가속 머신이 더 큰 이점을 제공 할 수 있습니다.,,
2975,"While there is a handy built-in shorthand for using GPUs, with TPUs you need to explicitly import kfp.gcp as gcp.",GPU 사용에 대한 편리한 기본 제공 약어가 있지만 TPU를 사용하면 kfp.gcp를 gcp로 명시 적으로 가져와야합니다.,,
2976,"Once you’ve imported kfp’s gcp you can add TPU resources to any container operation in a similar way to GPUs by adding .apply(gcp.use_tpu(tpu_cores=cores, tpu_resource=version, tf_version=tf_version)) to your container operation.","kfp의 gcp를 가져온 후에는 컨테이너 작업에 .apply (gcp.use_tpu (tpu_cores = cores, tpu_resource = version, tf_version = tf_version))을 추가하여 GPU와 유사한 방식으로 모든 컨테이너 작업에 TPU 리소스를 추가 할 수 있습니다.",,
2977,"Warning
TPU nodes are only available in certain regions.","경고
TPU 노드는 특정 지역에서만 사용할 수 있습니다.",,
2978,Check this Google Cloud page for a list of supported regions.,지원되는 지역 목록은이 GCP 페이지를 확인하세요.,,
2979,B.1.2.,B.1.2.,,
2980,"Dataflow for TFX
On Google Cloud you can configure Kubeflow’s TFX components to use Google’s Dataflow for distributed processing.","TFX 용 데이터 흐름
Google Cloud에서는 분산 처리를 위해 Google의 Dataflow를 사용하도록 Kubeflow의 TFX 구성 요소를 구성 할 수 있습니다.",,
2981,"To do this, you will need to specify a distributed output location (since there is not a shared persistent volume between the workers), and configure TFX to use the Dataflow runner.",이렇게하려면 분산 출력 위치를 지정하고 (작업자간에 공유 된 영구 볼륨이 없기 때문에) Dataflow 실행기를 사용하도록 TFX를 구성해야합니다.,,
2982,The simplest way to show this is by revisiting EXAMPLE 5-8, to use Dataflow we would change it to EXAMPLE B-1.,이를 보여주는 가장 간단한 방법은 예 5-8을 다시 방문하는 것입니다.Dataflow를 사용하려면 예 B-1로 변경합니다.,
2983,Example B-1.,예 B-1.,,
2984,"Changing the pipeline to use Dataflow
generated_output_uri = root_output_uri + kfp.dsl.EXECUTION_ID_PLACEHOLDER
beam_pipeline_args = [
    '--runner=DataflowRunner',
    '--project=' + project_id,
    '--temp_location=' + root_output_uri + '/tmp'),
    '--region=' + gcp_region,
    '--disk_size_gb=50', # Adjust as needed
]

records_example = tfx_csv_gen(
    input_uri=fetch.output, # Must be on distributed storage
    beam_pipeline_args=beam_pipeline_args,
    output_examples_uri=generated_output_uri)
As you can see, changing the pipeline to use Dataflow is relatively simple and opens up a larger scale of data for processing.","Dataflow를 사용하도록 파이프 라인 변경
generated_output_uri = root_output_uri + kfp.dsl.EXECUTION_ID_PLACEHOLDER
beam_pipeline_args = [
    '--runner = DataflowRunner',
    '--project ='+ project_id,
    '--temp_location ='+ root_output_uri + '/ tmp'),
    '--region ='+ gcp_region,
    '--disk_size_gb = 50', # 필요에 따라 조정
]

records_example = tfx_csv_gen (
    input_uri = fetch.output, # 분산 스토리지에 있어야합니다.
    beam_pipeline_args = beam_pipeline_args,
    output_examples_uri = generated_output_uri)
보시다시피 Dataflow를 사용하도록 파이프 라인을 변경하는 것은 비교적 간단하며 처리 할 데이터의 규모가 더 커집니다.",,
2985,"While cloud-specific accelerations can be beneficial, be careful that the trade-off is worth the additional future headache if you ever need to change providers.","클라우드 별 가속화가 도움이 될 수 있지만, 공급자를 변경해야하는 경우 향후 추가 골칫거리가 될 가치가 있다는 점에주의하십시오.",,
2986,"Appendix C. Using Model Serving in Applications
In CHAPTER 8 you learned different approaches for exposing model servers provided by Kubeflow.","부록 C. 애플리케이션에서 모델 제공 사용
8 장에서는 Kubeflow에서 제공하는 모델 서버를 노출하는 다양한 접근 방식을 배웠습니다.",,
2987,"As described there, Kubeflow provides several ways of deploying trained models and providing both REST and gRPC interfaces for running model inference.",여기에 설명 된대로 Kubeflow는 학습 된 모델을 배포하고 모델 추론을 실행하기위한 REST 및 gRPC 인터페이스를 모두 제공하는 여러 방법을 제공합니다.,,
2988,"However, it falls short in providing support for using these models in custom applications.",그러나 사용자 지정 응용 프로그램에서 이러한 모델을 사용하기위한 지원을 제공하는 데는 부족합니다.,,
2989,Here we will present some of the approaches to building applications by leveraging model servers exposed by Kubeflow.,여기에서는 Kubeflow에서 제공하는 모델 서버를 활용하여 애플리케이션을 구축하는 몇 가지 접근 방식을 소개합니다.,,
2990,"When it comes to applications leveraging model inference, they can be broadly classified into two categories: real time and batch applications.",모델 추론을 활용하는 애플리케이션의 경우 실시간 및 배치 애플리케이션의 두 가지 범주로 크게 분류 할 수 있습니다.,,
2991,"In the real time/stream applications model, inference is done on data directly as it is produced or received.",실시간 / 스트림 애플리케이션 모델에서는 데이터가 생성되거나 수신 될 때 직접 추론이 수행됩니다.,,
2992,"In this case, typically only one request is available at a time and it can be used for inferencing as it arrives.",이 경우 일반적으로 한 번에 하나의 요청 만 사용할 수 있으며 도착시 추론에 사용할 수 있습니다.,,
2993,In the batch scenarios all of the data is available up front and can be used for inference either sequentially or in parallel.,배치 시나리오에서는 모든 데이터를 미리 사용할 수 있으며 순차적으로 또는 병렬로 추론에 사용할 수 있습니다.,,
2994,We will start from the streaming use case and then take a look at possible batch implementations.,스트리밍 사용 사례부터 시작한 다음 가능한 배치 구현을 살펴 보겠습니다.,,
2995,C.1.,C.1.,,
2996,"Building Streaming Applications Leveraging Model Serving
The majority of today’s streaming applications leverage Apache Kafka as the data backbone of a system.","모델 서빙을 활용 한 스트리밍 애플리케이션 구축
오늘날 스트리밍 애플리케이션의 대부분은 Apache Kafka를 시스템의 데이터 백본으로 활용합니다.",,
2997,The two possible options for implementing streaming applications themselves are: usage of stream processing engines and usage of stream processing libraries.,스트리밍 애플리케이션 자체를 구현할 수있는 두 가지 옵션은 스트림 처리 엔진 사용과 스트림 처리 라이브러리 사용입니다.,,
2998,C.1.1.,C.1.1.,,
2999,"Stream Processing Engines and Libraries
As defined in the article “Defining the Execution Semantics of Stream Processing Engines,”[1] modern stream processing engines are based on organizing computations into blocks and leveraging cluster architectures.","스트림 처리 엔진 및 라이브러리
""스트림 처리 엔진의 실행 의미 정의""기사에 정의 된대로 최신 스트림 처리 엔진은 계산을 블록으로 구성하고 클러스터 아키텍처를 활용하는 것을 기반으로합니다.",,
3000,"[2]
Splitting computations in blocks enables execution parallelism, where different blocks run on different threads on the same machine, or on different machines.","[2]
블록으로 계산을 분할하면 다른 블록이 동일한 시스템 또는 다른 시스템의 다른 스레드에서 실행되는 병렬 실행이 가능합니다.",,
3001,It also enables failover by moving execution blocks from failed machines to healthy ones.,또한 실패한 컴퓨터에서 정상 컴퓨터로 실행 블록을 이동하여 장애 조치를 활성화합니다.,,
3002,"Additionally, checkpointing supported by modern engines further improves the reliability of cluster-based execution.",또한 최신 엔진이 지원하는 체크 포인트는 클러스터 기반 실행의 안정성을 더욱 향상시킵니다.,,
3003,"Stream processing libraries, on the other hand, are libraries with a domain-specific language providing a set of constructs that simplify building streaming applications.",반면 스트림 처리 라이브러리는 스트리밍 애플리케이션 구축을 단순화하는 일련의 구성을 제공하는 도메인 별 언어를 사용하는 라이브러리입니다.,,
3004,Such libraries typically do not support distribution and/or clustering—this is typically left as an exercise for developers.,이러한 라이브러리는 일반적으로 배포 및 / 또는 클러스터링을 지원하지 않습니다. 이는 일반적으로 개발자를위한 연습으로 남겨집니다.,,
3005,"Because these options sound similar, they are often used interchangeably.",이러한 옵션은 비슷하게 들리기 때문에 종종 같은 의미로 사용됩니다.,,
3006,"In reality, as Jay Kreps has outlined in his blog, stream processing engines and stream processing libraries are two very different approaches to building streaming applications and choosing one of them is a trade-off between power and simplicity.",실제로 Jay Kreps가 그의 블로그에서 설명했듯이 스트림 처리 엔진과 스트림 처리 라이브러리는 스트리밍 애플리케이션을 구축하는 매우 다른 두 가지 접근 방식이며 그중 하나를 선택하는 것은 성능과 단순성 사이의 균형입니다.,,
3007,"As described previously, stream processing engines provide more functionality, but require a developer to  adhere to their programming model and deployment.",앞서 설명한 것처럼 스트림 처리 엔진은 더 많은 기능을 제공하지만 개발자는 프로그래밍 모델 및 배포를 준수해야합니다.,,
3008,They also often require a steeper learning curve for mastering their functionality.,또한 기능을 마스터하기 위해 더 가파른 학습 곡선이 필요한 경우가 많습니다.,,
3009,"Stream processing libraries, on another hand, are typically easier to use, providing more flexibility, but require specific implementation of deployment, scalability, and load 
balancing.","반면에 스트림 처리 라이브러리는 일반적으로 사용하기 쉽고 더 많은 유연성을 제공하지만 배포, 확장 성 및로드의 특정 구현이 필요합니다.
균형.",,
3010,"Today’s most popular stream processing engines include the following:


Apache Spark


Apache Flink


Apache Beam


The most popular stream libraries are:


Apache Kafka streams


Akka streams


All of these can be used as a platform for building streaming applications including model
serving.","오늘날 가장 널리 사용되는 스트림 처리 엔진은 다음과 같습니다.


Apache Spark


Apache Flink


Apache Beam


가장 인기있는 스트림 라이브러리는 다음과 같습니다.


Apache Kafka 스트림


Akka 스트림


이들 모두는 모델을 포함한 스트리밍 애플리케이션 구축을위한 플랫폼으로 사용할 수 있습니다.
피복재.",,
3011,"[3]
A side-by-side comparison of stream processing engines (Flink) and stream processing libraries (Kafka streams), done jointly by data Artisans (currently Vervetica) and Confluent teams, also emphasizes yet another difference between stream processing engines and libraries: enterprise ownership.","[삼]
데이터 장인 (현재 Vervetica)과 Confluent 팀이 공동으로 수행 한 스트림 처리 엔진 (Flink)과 스트림 처리 라이브러리 (Kafka 스트림)를 나란히 비교 한 결과 스트림 처리 엔진과 라이브러리 간의 또 다른 차이점 인 엔터프라이즈 소유권도 강조합니다..",,
3012,"Stream processing engines are typically owned and managed centrally by enterprise-wide units, while stream processing libraries are typically under the purview of individual development teams, which often makes their adoption much simpler.","스트림 처리 엔진은 일반적으로 전사적 단위가 중앙에서 소유하고 관리하는 반면, 스트림 처리 라이브러리는 일반적으로 개별 개발 팀의 권한하에 있으므로 채택이 훨씬 더 간단 해집니다.",,
3013,"A stream processing engine is a good fit for applications that require features provided out of the box by such engines, including cluster scalability and high throughput through parallelism across a cluster, event-time semantics, checkpointing, built-in support for monitoring and management, and mixing of stream and batch processing.","스트림 처리 엔진은 클러스터, 이벤트 시간 의미 체계, 검사 점, 모니터링 및 관리를위한 내장 지원을 통한 클러스터 확장 성 및 높은 처리량을 포함하여 이러한 엔진에서 즉시 제공되는 기능을 필요로하는 애플리케이션에 적합합니다.및 스트림 및 배치 처리의 혼합.",,
3014,The drawback of using engines is that you are constrained by the programming and deployment models they provide.,엔진 사용의 단점은 엔진이 제공하는 프로그래밍 및 배포 모델의 제약을 받는다는 것입니다.,,
3015,"In contrast, the stream processing libraries provide a programming model that allows developers to build the applications or microservices the way that fits their precise needs and deploy them as simple standalone Java applications.",반대로 스트림 처리 라이브러리는 개발자가 정확한 요구 사항에 맞는 방식으로 애플리케이션 또는 마이크로 서비스를 빌드하고 간단한 독립형 Java 애플리케이션으로 배포 할 수있는 프로그래밍 모델을 제공합니다.,,
3016,"But in this case they need to roll out their own scalability, high availability, and monitoring solutions (Kafka-based implementations support some of them by leveraging Kafka).","그러나이 경우에는 자체 확장 성, 고 가용성 및 모니터링 솔루션을 출시해야합니다 (Kafka 기반 구현은 Kafka를 활용하여 일부를 지원합니다).",,
3017,C.1.2.,,,
3018,"Introducing Cloudflow
In reality, most of the streaming application implementations require usage of multiple engines and libraries for building individual applications, which creates additional integration and maintenance complexities.",,,
3019,"Many of these can be alleviated by using an open source project, like Cloudflow, which allows you to quickly develop, orchestrate, and operate distributed streaming applications on Kubernetes.",,,
3020,"Cloudflow supports building streaming applications as a set of small, composable components communicating over Kafka and wired together with schema-based contracts.",,,
3021,This approach can significantly improve reuse and allows you to dramatically accelerate streaming application development.,,,
3022,"At the time of this writing, such components can be implemented using Akka Streams; Flink and Spark streaming with Kafka Streams support is coming soon.",,,
3023,The overall architecture of Cloudflow is presented in FIGURE C-1.,,,
3024,Figure C-1.,,,
3025,"Cloudflow architecture

In the heart of Cloudflow is a Cloudflow operator, which is responsible for deploying/undeploying, management, and scaling of pipelines and individual streamlets.",,,
3026,The operator also leverages existing Flink and Spark operators to manage Flink and Spark streamlets.,,,
3027,A set of provided Helm charts allows for simple installation of the operator and supporting components.,,,
3028,A common challenge when building streaming applications is wiring all of the components together and testing them end-to-end before going into production.,,,
3029,Cloudflow addresses this by allowing you to validate the connections between components and to run your application locally during development to avoid surprises during deployment.,,,
3030,"Everything in Cloudflow is done in the context of an application, which represents a self-contained distributed system (graph) of data processing services connected together by data streams over Kafka.",,,
3031,"Cloudflow supports:

Development

By generating a lot of boilerplate code, it allows developers to focus on business logic.",,,
3032,"Build

It provides all the tooling for going from business logic to a deployable Docker image.",,,
3033,"Deploy

It provides Kubernetes tooling to deploy your distributed application with a single command.",,,
3034,"Operate

It provides all the tools you need to get insights, observability, and life cycle management for your distributed streaming application.",,,
3035,Another important operational concern directly supported by Cloudflow is an ability to scale individual components of the stream.,,,
3036,"When using Cloudflow for implementing streaming applications, model server invocation is typically implemented by a separate streamlet[4] based on a dynamically controlled stream pattern.",,,
3037,"In FIGURE C-2 an implementation contains a state, where a state is a URL to the model serving server, in the case when a model server is used for inference.",,,
3038,[5] The actual data processing in this case is done by invoking a model server to get an inference result.,,,
3039,This call can be done using either REST or gRPC (or any other interface supported by the model server).,,,
3040,Figure C-2.,,,
3041,"Dynamically controlled stream pattern

This state can be updated through an additional Kafka topic, which allows for switching the URL (in the case when model server deployment is moved) without redeployment of the applications.",,,
3042,The state is used by a data processor for processing incoming data.,,,
3043,"Additional streamlets (with the same architecture) can be introduced into the application to get model serving insights, such as explanation and drift detection (see SECTION 8.2 for more details).",,,
3044,C.2.,,,
3045,"Building Batch Applications Leveraging Model Serving
A typical batch application is implemented by reading a dataset containing all the samples and then processing them, invoking the model server for every one of them.",,,
3046,"The simplest batch application implementation is doing this sequentially, one data element at a time.",,,
3047,"Although such implementation will work, it is not very performant, due to the network overhead for processing every element.",,,
3048,One popular way to speed up processing is to use batching.,,,
3049,"TFServing, for example, supports two batching approaches: server-side batching and client-side batching.",,,
3050,Server-side batching is supported out of the box by TFServing.,,,
3051,"[6] To enable batching, set --enable_batching and --batching_parameters_file flags.",,,
3052,"To achieve the best trade-offs between latency and throughput, pick appropriate batching parameters.",,,
3053,[7] Some of the recommendations for the parameters values for both CPU and GPU usage can be found in this TFServing GitHub repo.,,,
3054,"Upon reaching full batch on the server side, inference requests are merged internally into a single large request (tensor) and a Tensorflow Session is run on the merged request.",,,
3055,You need to use asynchronous client requests to populate server-side batches.,,,
3056,Running a batch of requests on a single session is where CPU/GPU parallelism can really be leveraged.,,,
3057,Client-side batching is just grouping multiple inputs together on the client to make a single request.,,,
3058,"Although batching can significantly improve performance of the batch inference, it’s often not sufficient for reaching performance goals.",,,
3059,Another popular approach for performance improvement is multithreading.,,,
3060,"[8]
The idea behind this approach is to deploy multiple instances of a model server, split data processing into multiple threads, and allow each thread to do inference for part of the data it is responsible for.",,,
3061,One of the ways to implement multithreading is through a batch implementation via streaming.,,,
3062,This can be done by implementing software component[9] reading source data and writing each record to Kafka for processing.,,,
3063,This approach effectively turns batch processing into a streaming one to allow for better scalability through an architecture as shown in FIGURE C-3.,,,
3064,Figure C-3.,,,
3065,"Using stream processing for batch serving implementation

This deployment includes three layers:


Cloudflow-based stream processing that invokes model serving for every element of the stream.",,,
3066,Every streamlet of this solution can be scaled appropriately to provide required throughput.,,,
3067,A model server that does the actual model inference.,,,
3068,This layer can be independently scaled by changing the amount of model servers.,,,
3069,"Load balancers, for example Istio or Ambassador, that provide load balancing for inference REST/gRPC requests.",,,
3070,"Because every layer in this architecture can scale independently, such an architecture can provide a model serving solution that is quite scalable for both streaming and batch use cases.",,,
3071,"[1] L. Affetti et al., “Defining the Execution Semantics of Stream Processing Engines,” Journal of Big Data 4 (2017), https://oreil.ly/TcI39.",,,
3072,[2] Compare to MapReduce architecture.,,,
3073,"[3] For implementation details, see the report, Serving Machine Learning Models, and Kai Waehner’s project on GitHub.",,,
3074,"[4] Some of the examples of such implementations for TFServing integration can be found in this GitHub repo, and for Seldon integration, in this GitHub repo.",,,
3075,"[5] In the case of embedded model usage, the state is a model itself.",,,
3076,[6] See this TFServing document for more details.,,,
3077,"[7] For the complete definitions of available parameters, see this TFServing GitHub repo.",,,
3078,[8] Compare to the MapReduce programming model.,,,
3079,"[9] Streamlet, in the case of Cloudflow-based implementation.",,,
3080,"IndexAA/B testing, Model Updatingadministrator of Kubeflow cluster, Kubeflow Multiuser IsolationAmazon EMR, Spark operators in KubeflowAmbassador, Serving Requestsannotations on pipelines, Building a Simple Pipeline in PythonApache Beamabout, Distributed ToolingPython support, TensorFlow ExtendedTensorFlow Extended on top of, TensorFlow ExtendedApache Flink, Stream Processing Engines and LibrariesApache Mahout, The Denoising CT Scans Example, DS-SVD with Apache SparkApache Software Foundation (see mailing list data preparation)Apache SpamAssassin, Data Cleaning: Filtering Out the Junk, Putting It Together in a PipelineApache Sparkabout, Apache Spark, Distributed Tooling, Distributed Data Using Apache Sparkbasics, Spark operators in Kubeflowcloud-specific options for running, Spark operators in Kubeflowconfiguring, Spark operators in Kubeflowdata denoising example id=ch09-dd5, The Denoising CT Scans Exampledata denoising pipeline, The CT Scan Denoising Pipeline-The pipelinefeature preparation example, Distributed Feature Preparation Using Apache SparkJupyter notebooks, Distributed Data Using Apache SparkKubeflow native operator, Spark operators in Kubeflow-Spark operators in Kubeflowmailing list example, Distributed Feature Preparation Using Apache SparkMinIO configuration, Spark operators in KubeflowResourceOp request validation, Spark operators in Kubeflowresources on, Distributed Data Using Apache Sparkschema validation, Validating the schemaSQL, Filtering out bad datausing with Kubeflow, Data/Feature Preparation, Distributed Data Using Apache SparkApache Spark in Kubeflowcomponents, Apache SparkarchitectureDifferentiable Architecture Search (DARTS), Neural Architecture SearchEfficient Neural Architecture Search (ENAS), Neural Architecture Searchneural architecture search support and Katb, Neural Architecture SearchArgo executors APIs, Argo Executor Configurations and Trade-OffsArgo Workflowsdeleting a workflow, Argo: the Foundation of PipelinesDocker as executor, Argo: the Foundation of Pipelines, Argo Executor Configurations and Trade-Offsexecuting pipeline YAML files, Building a Simple Pipeline in Pythonexecution information, Argo: the Foundation of Pipelinesexecution logs, Argo: the Foundation of Pipelinesexecutors, Argo: the Foundation of Pipelines, Argo Executor Configurations and Trade-Offsflow execution graph details, Argo: the Foundation of Pipelinesinstalling, Argo: the Foundation of PipelinesKubeflow Pipelines built on, Kubeflow Pipelines, Introduction to Kubeflow Pipelines Components-Argo: the Foundation of PipelinesKubeflow Pipelines enhancing, What Kubeflow Pipelines Adds to Argo Workfloworchestration controller, Kubeflow Pipelinesparameter passing, Building a Pipeline Using Existing Imagespipelines visible, Argo: the Foundation of Pipelines, Argo: the Foundation of PipelinesUI for pipeline execution, Argo: the Foundation of Pipelines, Argo: the Foundation of PipelinesUI installation, Argo: the Foundation of PipelinesYAML files for pipelines, Exploring the Prepackaged Sample Pipelinesartifact store, for logged metadata events, Kubeflow Metadata UIattribution for code examples, Using Code Examplesauthor contact information, How to Contact the AuthorsAutoML (automated machine learning)about, Hyperparameter Tuning and Automated 
Machine Learningcontinuous learning as, Summary of Inference RequirementsKubeflow Katib, Hyperparameter Tuning, Hyperparameter Tuning with Kubeflow KatibBbatch applications via model serving, Building Batch Applications Leveraging Model Serving-Building Batch Applications Leveraging Model ServingBayesian optimizationin Katib, Hyperparameter Tuning, Katib Conceptsbeginners’ resources for ML, Our Assumption About You-Our Assumption About You(see also getting started)biases of machine learning, Your Responsibility as a Practitionerblue-green deployment, Model UpdatingKFServing endpoints, Data Plane, Model updatingCCaffe2 for distributed training, Using Other Frameworks for Distributed Trainingcanary deployment, Model Updatingcanary deploymentsKFServing endpoints, Data Plane, Model updatingCanonical resources, Code Examplescentral dashboard, Getting Around the Central Dashboardcentral storage distributed training, Distributed TrainingClipper, Clipper (RiseLabs)cloud native microservices, Deploying a TensorFlow Training JobCloudflow, Introducing Cloudflow-Introducing Cloudflowcode examples in bookdownload link, Code Examplespermission for use, Using Code Examplescollaborative filtering, Building a Recommender with TensorFlowcompeting models, Model Updatingcomponentsabout, Kubeflow’s Design and Core Components-Component Overview, Kubeflow Pipeline Componentscentral dashboard, Getting Around the Central Dashboardfile-fetching component, Kubeflow Pipeline ComponentsGoogle-specific, Google Cloudhyperparameter tuning, Hyperparameter Tuning-Hyperparameter Tuningload_component function warning, Kubeflow Pipeline Components, Keeping your data quality: TensorFlow data validationload_component_from_file function, Keeping your data quality: TensorFlow data validationmetadata management, Metadata(see also Kubeflow ML Metadata)model inference, Model Inferencemultiuser isolation, Kubeflow Multiuser Isolationpipelines, Kubeflow Pipelines, Kubeflow Pipelines(see also Kubeflow Pipelines)repositories, Kubeflow Multiuser Isolation, Kubeflow Pipeline Componentstraining operators, Training Operatorscomposability of Kubeflow, Kubeflow’s Design and Core Componentsconcept drift, Model Accuracy, Drift, and Explainabilityconditional execution of pipelines, Conditional Execution of Pipeline Stages-Conditional Execution of Pipeline Stagescontainer registry, Setting up Dockercontainersabout, Why Containerize?beginners’ resources, Our Assumption About Youbuilding example pipeline, Building a Simple Pipeline in Pythoncontainer registry, Setting up Dockercustom containers, Custom Containersoverhead, Why Containerize?pipeline custom code and tools, Building a Pipeline Using Existing Images, Custom Containersresource about, Why Containerize?serverless, Model InferenceSpamAssassin package, Data Cleaning: Filtering Out the Junk, Putting It Together in a Pipelinetag for pushing, Setting up Dockerwhy containerize, Why Containerize?continuous learning (CL), Summary of Inference Requirementscontrol plane, Serverless and the Service PlaneCOVID-19 pandemic, CT Scans, The Denoising CT Scans ExampleCRDs (see custom resource definitions)credentials for MinIO, MinIOCSV component in recommender system, Keeping your data quality: TensorFlow data validationCT scan data denoisedabout data, CT Scans, Case Study Using Multiple Tools, The Denoising CT Scans ExampleApache Spark, Filtering out bad data, The CT Scan Denoising Pipeline-The pipelinedata preparation, Data Prep with Pythondecomposing CT scan, DS-SVD with Apache Sparkdenoising pipeline, The CT Scan Denoising Pipeline-The pipelineopen source method, Case Study Using Multiple Tools, The Denoising CT Scans Exampleresource on math, The Denoising CT Scans Examplesharing the pipeline, Sharing the Pipelinesingular value decomposition, Case Study Using Multiple Tools, DS-SVD with Apache Sparkvisualizing denoised DICOMs, Visualization-Recomposing the matrix into denoised imagescustom containers, Custom Containerscustom resource definitions (CRDs)Knative Serving, KnativePipeline Service, Kubeflow Pipelinescustom resources on Kubernetes, Deploying a TensorFlow Training JobKubeflow Katib, Katib Concepts, Configuring an ExperimentDdatadata lineage, Artifact and Metadata StoreDICOM file format, Data Prep with Pythondistributed object storage server, MinIO, Storing Data Between Stepsenvironment variables for pipelines, Building a Pipeline Using Existing Imagesexploring new, Putting It Together in a Pipelinefile-fetching component, Kubeflow Pipeline ComponentsKubernetes Pods storing, Kubeflow Pipelinesmetadata definition, Artifact and Metadata Store(see also metadata)persistent volumes, Storing Data Between Steps-Storing Data Between StepsApache Spark output, Saving the outputfilesystem/get_file component, Keeping your data quality: TensorFlow data validationlocal data preparation, Fetching the Datapreparation of, Data/Feature Preparation, Data and Feature Preparation(see also data preparation)sources for datasets, Data Prep with Pythontracked by Kubeflow, Kubeflow Pipelinesvalidation via TensorFlow Extended, Keeping your data quality: TensorFlow data validation-Keeping your data quality: TensorFlow data validationdata cleaningabout CT scan data, CT Scans, The Denoising CT Scans ExampleApache Spark, The CT Scan Denoising Pipeline-The pipelinedenoising pipeline, The CT Scan Denoising Pipeline-The pipelineopen source method, Case Study Using Multiple Tools, The Denoising CT Scans Exampledata parallelism distributed training, Distributed Trainingdata plane of KFServing, Data Plane-Data Plane, Model servingdata preparationabout, Data and Feature PreparationAutoML for, AutoML: An OverviewCT scan data denoised, Data Prep with Pythondistributedabout, Distributed ToolingApache Spark feature preparation, Distributed Feature Preparation Using Apache SparkApache Spark for, Spark operators in Kubeflow-Distributed Feature Preparation Using Apache SparkApache Spark setup, Distributed Data Using Apache Spark-Spark operators in Kubeflowdata validation, Keeping your data quality: TensorFlow data validation-Keeping your data quality: TensorFlow data validation, Spark operators in Kubeflow-Distributed Feature Preparation Using Apache Sparkmissing data, Handling missing fieldsrejected records check, Keeping your data quality: TensorFlow data validationfeature preparationabout, Data and Feature Preparation, Feature PreparationApache Spark, Distributed Feature Preparation Using Apache SparkAutoML for, AutoML: An Overviewdata formatting and, Formatting the Datarecommendation system, Starting a New Notebook SessionTensorFlow Transform, TensorFlow Transform, with TensorFlow Extended on Beam-TensorFlow Transform, with TensorFlow Extended on Beamlocalabout, Local Data and Feature Preparationcustom containers, Custom Containersfetching the data, Fetching the Datafiltering out junk, Data Cleaning: Filtering Out the Junkformatting the data, Formatting the Datamissing data, Data Cleaning: Filtering Out the JunkSpamAssassin package, Data Cleaning: Filtering Out the Junkmissing datadistributed platform, Handling missing fieldslocal, Data Cleaning: Filtering Out the JunkScikit-learn and, Data Preparationputting together into a pipeline, Putting It Together in a Pipeline-Using an Entire Notebook as a Data Preparation 
Pipeline Stageentire notebook as pipeline stage, Using an Entire Notebook as a Data Preparation 
Pipeline StageRandom Forest algorithm, Data Preparation-Data PreparationScikit-learn and missing data, Data Preparationtools online resource, Deciding on the Correct Toolingtools, local versus distributed, Deciding on the Correct ToolingUS Census dataset, Data Preparation-Data PreparationDatabricks MLflowabout, MLflow (Databricks), Artifact and Metadata Storemetadata toolsabout, Using MLflow’s Metadata Tools with Kubeflowlogging data on runs, Logging Data on RunsMLflow Tracking, Using MLflow’s Metadata Tools with KubeflowMLflow Tracking Server, Using MLflow’s Metadata Tools with Kubeflow-Creating and Deploying an MLflow Tracking ServerUI, Using the MLflow UIdatasets (see data)debuggingKFServingInferenceService, Debugging an InferenceServiceperformance, Debugging performanceTFJob deployment, Deploying a TensorFlow Training Jobdeep learning, Building a Recommender with TensorFlowsharing a pipeline, Sharing the Pipelinedenoising dataabout CT scan data, CT Scans, Case Study Using Multiple Tools, The Denoising CT Scans ExampleApache Spark, Filtering out bad data, The CT Scan Denoising Pipeline-The pipelineCT scan case study, Case Study Using Multiple Tools-Sharing the Pipelinedata preparation, Data Prep with Pythondecomposing CT scan, DS-SVD with Apache Sparkdenoising pipeline, The CT Scan Denoising Pipeline-The pipelineopen source method, Case Study Using Multiple Tools, The Denoising CT Scans Exampleresource on math, The Denoising CT Scans Examplesharing the pipeline, Sharing the Pipelinesingular value decomposition, Case Study Using Multiple Tools, DS-SVD with Apache Sparkvisualizing denoised DICOMs, Visualization-Recomposing the matrix into denoised imagesdeployment of Kubeflowclick-to-deploy on Google Cloud, Getting Set Up with Kubeflowmodel serving options, Model Inferencenamespace, Creating Our First Kubeflow ProjectDICOM file format, Data Prep with Pythonsources for datasets, Data Prep with PythonDifferentiable Architecture Search (DARTS), Neural Architecture Searchdisk space for Minikube, Minikubedisplay_schema, Keeping your data quality: TensorFlow data validationdistributed stochastic singular value decomposition (DS-SVD), Case Study Using Multiple Tools, DS-SVD with Apache Sparkdistributed trainingabout, Distributed TrainingDockerApache Spark on Jupyter notebooks, Distributed Data Using Apache SparkArgo Workflows executor, Argo: the Foundation of Pipelines, Argo Executor Configurations and Trade-Offscontainer registry, Setting up Dockerdeploying recommender training code, Deploying a TensorFlow Training Jobentire notebook as pipeline stage, Using an Entire Notebook as a Data Preparation 
Pipeline Stageinstalling, Setting up Dockerinstalling Minikube, Minikubeparameters passed by value, Building a Pipeline Using Existing Imagesprebuilt Docker images, Building a Pipeline Using Existing Images-Building a Pipeline Using Existing ImagesSeldon Core local testing, Local testing with DockerEEfficient Neural Architecture Search (ENAS), Neural Architecture SearchEMR native Spark operator, Spark operators in Kubeflow-Spark operators in Kubeflowenvironment variables for pipelines, Building a Pipeline Using Existing Imagesevents via Knative EventingKafkaSource to send events, Knative EventingKFServing, Model Inference, Knative Eventingonline documentation, Knative EventingSeldon Core, Outlier and drift detectionexample generators in TensorFlow Extended, Keeping your data quality: TensorFlow data validationexecutors for Argo Workflows, Argo: the Foundation of Pipelines, Argo Executor Configurations and Trade-Offsexperiments, Exploring the Prepackaged Sample Pipelines, Building a Simple Pipeline in Python, Building a Pipeline Using Existing ImagesKubeflow Katib, Hyperparameter Tuning, Katib Conceptsconfiguring, Configuring an Experimentreproducibility by sharing pipeline, Sharing the Pipelineexplaining the modelScikit-learn, Scikit-Learn Training-Explaining the Modelexplaining the model, importance of, Scikit-Learn Training, Model Accuracy, Drift, and ExplainabilityFfailover, Training Operatorsfeature preparationabout, Data and Feature Preparation, Feature PreparationApache Spark, Distributed Feature Preparation Using Apache SparkAutoML for, AutoML: An Overviewdata formatting and, Formatting the Datarecommendation system, Starting a New Notebook SessionTensorFlow Transform, TensorFlow Transform, with TensorFlow Extended on Beam-TensorFlow Transform, with TensorFlow Extended on Beamfile-fetching component, Kubeflow Pipeline Componentsfilesystem/get_file component, Keeping your data quality: TensorFlow data validationfile_output mechanism, Storing Data Between Steps, Keeping your data quality: TensorFlow data validationGgetting startedgetting started guide, Going Beyond a Local Deploymentinstalling Kubeflow, Getting Set Up with Kubeflow-Installing Kubeflow and Its Dependencies, Creating Our First Kubeflow Project, Going Beyond a Local Deploymentfirst project, Creating Our First Kubeflow Project-Test Queryinstalling Kubeflow Katib, Installing Katibfirst experiment, Running Your First Katib Experiment-Running the Experimentmachine learning, Our Assumption About You-Our Assumption About YouGoogle BigQuery example generators, Keeping your data quality: TensorFlow data validationGoogle Cloud Platform (GCP)click-to-deploy Kubeflow app, Getting Set Up with KubeflowGoogle-specific components, Google CloudTPU-accelerated instances, TPU-Accelerated InstancesGoogle codelabs, ConclusionGoogle DataflowApache Beam for, Distributed ToolingTensorFlow Extended configured for, Dataflow for TFXGoogle Dataproc for Apache Spark, Spark operators in Kubeflow-Spark operators in KubeflowGoogle Kubernetes Engine (GKE), Exploring the Prepackaged Sample PipelinesGoogle Vizier, Hyperparameter Tuning, Hyperparameter Tuning with Kubeflow KatibGPUsautoscaling in KFServing, KFServing, Going layer by layer, Model servingautoscaling lacking in Seldon Core, Model servingresource marking in code, Building a Simple Pipeline in Python, Using an Entire Notebook as a Data Preparation 
Pipeline Stagetraining using, Using GPUsgrid search in Katib, Katib ConceptsHhandwriting recognition via RandomForestClassifier, Creating Our First Kubeflow Project-Test Queryhello world project, Creating Our First Kubeflow Project-Test QueryhyperparametersAutoML for tuning, AutoML: An Overviewdefinition, Hyperparameter Tuning, Hyperparameter Tuning with Kubeflow KatibKubeflow Katib for tuning, Hyperparameter Tuning-Hyperparameter Tuning, Hyperparameter Tuning with Kubeflow Katib, Advantages of Katib over Other Frameworks(see also Kubeflow Katib)neural architecture search, AutoML: An OverviewTensorFlow recommender, TensorFlow Trainingtuning supported by Kubeflow, Hyperparameter TuningIincome predictor model, US Census income predictor model example-US Census income predictor model exampleIstioabout, Istio, Going layer by layerKFServinginfrastructure, Going layer by layermodel inference, Model InferenceJJupyter notebooksadding system software, Data Cleaning: Filtering Out the JunkApache Spark via Dockerfile, Distributed Data Using Apache Sparkdata and feature preparationabout, Local Data and Feature Preparationadding system software, Data Cleaning: Filtering Out the Junkentire notebook as pipeline stage, Using an Entire Notebook as a Data Preparation 
Pipeline StageGPU resources, Building a Simple Pipeline in Python, Using an Entire Notebook as a Data Preparation 
Pipeline StageJupyterHub, Notebooks (JupyterHub), Training Operators, Using an Entire Notebook as a Data Preparation 
Pipeline Stagekubectl for Kubernetes management, Notebooks (JupyterHub)Kubeflow component support via, Notebooks (JupyterHub)Kubeflow support for, Data Exploration with Notebooks, Setting Up Your Kubeflow Development Environmentmultiuser isolation, Kubeflow Multiuser IsolationScikit-learn notebook setup, Training a Model Using Scikit-Learn-Training a Model Using Scikit-LearnTensorFlow recommender notebook setup, Building a Recommender with TensorFlow-Starting a New Notebook SessionKKafkaSource to send Knative events, Knative EventingKatib (Kubeflow)about, Hyperparameter Tuning, Hyperparameter Tuning with Kubeflow Katib, Katib Conceptsabout katib meaning, Hyperparameter Tuning with Kubeflow Katibadvantages of, Advantages of Katib over Other Frameworksdistributed training jobs, Tuning Distributed Training Jobsexperiments, Hyperparameter Tuning, Katib Conceptsconfiguring, Configuring an Experimentfirst experiment, Running Your First Katib Experiment-Running the Experimentfirst experimentabout, Running Your First Katib Experimentconfiguring experiment, Configuring an Experimentprepping training code, Prepping Your Training Coderunning, Running the Experiment-Running the Experimentinstalling, Installing Katibjobs, Hyperparameter Tuningmetrics collector, Katib Conceptsneural architecture search support, Neural Architecture Searchabout NAS, Neural Architecture Searchexample DARTS experiment, Neural Architecture Search-Neural Architecture Searchmodel manager, Neural Architecture Searchsearch algorithmsBayesian optimization, Katib Conceptsgrid search, Katib Conceptshyperbrand, Katib Conceptsrandom search, Katib Conceptssuggestions, Hyperparameter Tuning, Katib Conceptstrials, Hyperparameter Tuning, Katib ConceptsUI, Katib User InterfaceKeras API, Building a Recommender with TensorFlowkfctl repository, Kubeflow Multiuser IsolationKFServingabout, KFServing, ReviewAPI documentation, API documentation, API documentationcapabilities of, Additional featurescomparison chart, Model Inference in Kubeflowcurl 404 Not Found, Recommender exampledata plane, Data Plane-Data Planecomponent in, Data Planeendpoint in, Data Planeexplainer in, Data Planeprediction protocol in, Data Planepredictor in, Data Planetransformer in, Data Planedebugging InferenceService, Debugging an InferenceServicedebugging performance, Debugging performancedeployment strategies, Model updatingendpointsblue-green deployment, Data Planeinference, KFServing-SummaryInferenceServiceautoscaling via escape hatches, Escape hatches-Escape hatchesdebugging, Debugging an InferenceServiceescape hatches, Escape hatches-Escape hatchesexamples, Simplicity and extensibility-Simplicity and extensibility, Recommender exampleKafkaSource to send Knative events, Knative Eventingnamespace, Recommender examplerecommender, Recommender example-Recommender exampleinfrastructure stack, Peeling Back the Underlying Infrastructuredebugging InferenceService, Debugging an InferenceServicedebugging performance, Debugging performanceescape hatches, Escape hatches-Escape hatchesIstio, Going layer by layerKnative, Data Plane, Going layer by layer, Going layer by layer, Knative EventingKnative Eventing, Model Inference, Knative EventingKnative Serving, Going layer by layer, Knative Eventing, Model updatingKubernetes, Going layer by layermodel monitoring, Model monitoringmodel serving, Model servingmodel updating, Model updatingnetwork monitoring and telemetry, Model monitoringSDK documentation, Recommender exampleserverless inferencing, KFServing, Recommender example, Knative Eventingservice plane, Serverless and the Service Planesetting up, Setting up KFServing-Setting up KFServingnamespaces and, Setting up KFServingtroubleshooting guide online, Setting up KFServingKnativearchitecture, Knativecomponents in Kubeflow, KnativeEventingKafkaSource to send events, Knative EventingKFServing, Model Inference, Knative Eventingonline documentation, Knative EventingSeldon Core, Outlier and drift detectionKFServing infrastructure, Data Plane, Going layer by layer, Knative EventingServing, Knative, KFServingKFServing, Going layer by layer, Knative Eventing, Model updatingkubectldeployment of Kubeflow, Creating Our First Kubeflow Projectinstalling, Installing Kubeflow and Its DependenciesJupyter notebook incorporation, Notebooks (JupyterHub)Kubeflowabout, Kubeflow: What It Is and Who It Is For, Why Kubernetes?alternatives to, Alternatives to Kubeflow-Others, TensorFlow ExtendedApache 2 license, Code Examplescore components, Kubeflow’s Design and Core Components-Component Overview(see also components)dataset tools, Data/Feature Preparationfirst project, Creating Our First Kubeflow Project-Test Querygetting started guide, Going Beyond a Local Deploymenthyperparameter tuning, Hyperparameter Tuning(see also hyperparameters)installing, Getting Set Up with Kubeflow-Installing Kubeflow and Its Dependencies, Creating Our First Kubeflow Project, Training and Monitoring Progress, Going Beyond a Local Deploymentinstalling development environment, Setting Up Your Kubeflow Development Environmentlocal installation, Setting Up Local Kuberneteslocal to distributed with ease, Getting Set Up with Kubeflow, Going Beyond a Local Deploymentonline community, Conclusion, Conclusionoverhead, Why Containerize?training frameworks, Trainingweb UI installation, Training and Monitoring ProgressKubeflow Katibabout, Hyperparameter Tuning, Hyperparameter Tuning with Kubeflow Katib, Katib Conceptsabout katib meaning, Hyperparameter Tuning with Kubeflow Katibadvantages of, Advantages of Katib over Other Frameworksdistributed training jobs, Tuning Distributed Training Jobsexperiments, Hyperparameter Tuning, Katib Conceptsconfiguring, Configuring an Experimentfirst experiment, Running Your First Katib Experiment-Running the Experimentfirst experimentabout, Running Your First Katib Experimentconfiguring experiment, Configuring an Experimentprepping training code, Prepping Your Training Coderunning, Running the Experiment-Running the Experimentinstalling, Installing Katibjobs, Hyperparameter Tuningmetrics collector, Katib Conceptsneural architecture search support, Neural Architecture Searchabout NAS, Neural Architecture Searchexample DARTS experiment, Neural Architecture Search-Neural Architecture Searchmodel manager, Neural Architecture Searchsearch algorithmsBayesian optimization, Katib Conceptsgrid search, Katib Conceptshyperbrand, Katib Conceptsrandom search, Katib Conceptssuggestions, Hyperparameter Tuning, Katib Conceptstrials, Hyperparameter Tuning, Katib ConceptsUI, Katib User InterfaceKubeflow ML Metadataabout, Artifact and Metadata Store, Kubeflow ML Metadatadataset tracking, Kubeflow ML Metadatadefining a workspace, Kubeflow ML Metadatainformation about model and metrics, Kubeflow ML Metadatainformation organization, Kubeflow ML Metadatalimitations of, Kubeflow Metadata UIPython only APIs, Kubeflow ML Metadatarequired imports, Kubeflow ML MetadataKubeflow Pipelinesabout, Pipelines, Getting Set Up with Kubeflow, Kubeflow Pipelines, Kubeflow Pipelines, Kubeflow Pipelinesand TensorFlow Extended, TensorFlow Extendedannotations, Building a Simple Pipeline in PythonArgo alternative, Argo: the Foundation of PipelinesArgo Workflows enhanced by, What Kubeflow Pipelines Adds to Argo WorkflowArgo Workflows foundation, Kubeflow Pipelines, Introduction to Kubeflow Pipelines Components-Argo: the Foundation of Pipelinesbuilding examples in Python, Building a Simple Pipeline in Python-Building a Simple Pipeline in PythoncamelCase function name bug in DSL, Building a Simple Pipeline in Pythoncompiler, Kubeflow Pipelines, Building a Simple Pipeline in Pythoncomponents of, Kubeflow Pipelines, Kubeflow Pipeline Componentsconditional execution, Conditional Execution of Pipeline Stages-Conditional Execution of Pipeline Stagescustom code and tools inside, Building a Pipeline Using Existing Images, Custom Containersdata and feature preparation, Data and Feature Preparation, Putting It Together in a Pipeline-Using an Entire Notebook as a Data Preparation 
Pipeline Stageenvironment variables, Building a Pipeline Using Existing Imagesexperiments, Exploring the Prepackaged Sample Pipelines, Building a Simple Pipeline in Python, Building a Pipeline Using Existing Imagesreproducibility by sharing pipeline, Sharing the Pipelineexploring sample, Exploring the Prepackaged Sample Pipelinesgeneric versus Google Kubernetes Engine, Exploring the Prepackaged Sample PipelinesGPU resource marking, Using an Entire Notebook as a Data Preparation 
Pipeline StageGPU resource marking in DSL, Building a Simple Pipeline in Pythonlanguage capabilities, Custom Containers, Case Study Using Multiple Toolsdenoising CT scan case study, Case Study Using Multiple Tools-Sharing the Pipelineload_component function warning, Kubeflow Pipeline Components, Keeping your data quality: TensorFlow data validationload_component_from_file function, Keeping your data quality: TensorFlow data validationoperators chaining execution, Training Operatorsperiodic execution of, Running Pipelines on Scheduleprebuilt Docker images, Building a Pipeline Using Existing Images-Building a Pipeline Using Existing ImagesPython SDK, Kubeflow Pipelinesrunning, Exploring the Prepackaged Sample Pipelines, Building a Simple Pipeline in Pythonon a schedule, Running Pipelines on ScheduleSDK installation, Setting Up Your Kubeflow Development EnvironmentService, Kubeflow Pipelinesrepository, Kubeflow Multiuser Isolationshared storage, MinIOtraining first project, Training and Monitoring Progresstraining integrated into, Integration into Pipelinestransformation code, TensorFlow Transform, with TensorFlow Extended on BeamUI, Exploring the Prepackaged Sample PipelinesKubeflow Slack workspace, Conclusion, ConclusionKubernetesabout, Why Kubernetes?Argo Workflows, Kubeflow Pipelines, Introduction to Kubeflow Pipelines Componentsbeginners’ resources, Our Assumption About Youclient, Building a Pipeline Using Existing Imagescloud native microservices, Deploying a TensorFlow Training Jobcustom resourcesKubeflow Katib, Katib Concepts, Configuring an Experimentcustom resources APIs, Deploying a TensorFlow Training Job, Katib Conceptsinstalling Kubeflow, Installing Kubeflow and Its DependenciesKFServing infrastructure, Going layer by layerkubectldeployment of Kubeflow, Creating Our First Kubeflow Projectinstalling, Installing Kubeflow and Its DependenciesJupyter notebook incorporation, Notebooks (JupyterHub)local cluster via Minikube, Setting Up Local KubernetesPipeline Service custom resource definitions, Kubeflow PipelinesPodsdata stored by, Kubeflow Pipelinesdeployment of Kubeflow, Creating Our First Kubeflow Projectresource creation, Notebooks (JupyterHub)YAML configuration editing, Editing YAMLKubernetes custom resourcesLlanguage capabilities of pipelines, Custom Containers, Case Study Using Multiple Toolsdenoising CT scan case study, Case Study Using Multiple Tools-Sharing the Pipelinelibrariesdata validation via TensorFlow Extended, Keeping your data quality: TensorFlow data validation, Keeping your data quality: TensorFlow data validationimporting, Building a Simple Pipeline in PythonKubernetes Python library, Building a Pipeline Using Existing ImagesScikit-learn, Putting It Together in a Pipelinestream processing, Stream Processing Engines and Librarieslightweight Python functions, Building a Simple Pipeline in Python-Building a Simple Pipeline in Pythonload_component warning, Keeping your data quality: TensorFlow data validationload_component_from_file, Keeping your data quality: TensorFlow data validationMMaaS (model serving as a service), Model Serving-Model ServingAPIs, Model Servingmachine learning (ML)AutoMLabout, Hyperparameter Tuning and Automated 
Machine Learningcontinuous learning as, Summary of Inference RequirementsKubeflow Katib, Hyperparameter Tuning, Hyperparameter Tuning with Kubeflow Katibbeginners’ resources, Our Assumption About You-Our Assumption About Youbiases, Your Responsibility as a Practitionerexplainability importance, Scikit-Learn Training, Model Accuracy, Drift, and Explainabilityframework selection, Scikit-Learn Trainingno single model works best, Hyperparameter Tuning and Automated 
Machine Learningreproducibility importance, Artifact and Metadata Storemailing list data preparationabout mailing list data, Mailing List DataApache SpamAssassin package, Data Cleaning: Filtering Out the Junk, Putting It Together in a PipelineApache Sparkfiltering out bad data, Filtering out bad datahandling missing data, Handling missing fieldsreading input data, Reading the input datasaving the output, Saving the output, Putting It Together in a PipelineSQL, Filtering out bad datafetching the data, Fetching the Datafiltering out junk, Data Cleaning: Filtering Out the Junkparallelize for data fetching, Reading the input dataputting together into a pipeline, Putting It Together in a Pipeline-Using an Entire Notebook as a Data Preparation 
Pipeline Stagemanual profile creation, Getting Around the Central Dashboardmetadataabout storing model creation metadata, Kubeflow ML Metadataartifact store and, Kubeflow Metadata UIdefined, Artifact and Metadata StoreKubeflow Metadata (see Kubeflow ML Metadata)Kubernetes Pods, Kubeflow Pipelinesmanagement component, Metadatareproducibility importance, Artifact and Metadata Storeresource on, Artifact and Metadata Storetracked by Kubeflow, Kubeflow Pipelines, Metadatatracking tool in Kubeflow, Artifact and Metadata Store(see also Kubeflow ML Metadata)viewingMetadata UI, Kubeflow Metadata UIprogrammatic query, Programmatic Query-Programmatic QueryMinikubeabout, Setting Up Local Kuberneteslocal installation of Kubeflow, Setting Up Local Kubernetesmemory for, Minikuberesources online, MinikubeMinIO, MinIO-MinIOApache Spark configuration, Spark operators in KubeflowClient exporting a model, TensorFlow Trainingdata validation via TensorFlow Extended, Keeping your data quality: TensorFlow data validationdistributed object storage server, MinIO-MinIOfile_output, Storing Data Between Steps, Keeping your data quality: TensorFlow data validationHadoop version for, MinIOsecrets for credentials, MinIOmirrored distributed training strategy, Distributed TrainingML (see machine learning)ML Metadata TensorFlow Extended (TFX), Artifact and Metadata StoreMLflow (Databricks)about, MLflow (Databricks), Artifact and Metadata Storemetadata toolsabout, Using MLflow’s Metadata Tools with Kubeflowlogging data on runs, Logging Data on RunsMLflow Tracking, Artifact and Metadata Store, Using MLflow’s Metadata Tools with KubeflowMLflow Tracking Server, Using MLflow’s Metadata Tools with Kubeflow-Creating and Deploying an MLflow Tracking ServerUI, Using the MLflow UIMNIST (Modified National Institute of Standards and Technology)about, Modified National Institute of Standards and Technologydata registration example, Kubeflow ML Metadatadistributed training, Distributed Training-Distributed Traininghello world project, Creating Our First Kubeflow Project-Test QueryKubeflow Katib first experimentabout, Running Your First Katib Experimentconfiguring experiment, Configuring an Experimentprepping training code, Prepping Your Training Coderunning experiment, Running the Experiment-Running the ExperimentPython script for first project, Test Querymodel as data MaaS, Model Servingmodel development life cycle (MDLC), Model Development Life Cycle, Data Exploration with Notebooks-Inference/Prediction, Summary of Inference Requirementsmodel drift, Model Accuracy, Drift, and Explainability, Model Accuracy, Drift, and ExplainabilitySeldon Core, Outlier and drift detection, Outlier and drift detectionmodel explainabilityimportance of, Scikit-Learn Training, Model Accuracy, Drift, and ExplainabilityScikit-learn, Scikit-Learn Training-Explaining the Model, Model Accuracy, Drift, and ExplainabilitySeldon Core, Model explainabilitymodel inferenceabout, Model Inference, Summary of Inference Requirementsaccuracy, Model Accuracy, Drift, and Explainabilityas code Maas, Model Servingcomponents, Model Inferencecontinuous learning, Summary of Inference Requirementsdebugging TFJob deployment, Deploying a TensorFlow Training Jobdeployment of in distributed training MNIST example, Distributed Training-Distributed Trainingdeployment reproducibility importance, Artifact and Metadata Storedeployment strategies, Deploying a TensorFlow Training Jobfirst project test query, Test QueryIstio, Model InferenceKFServing, KFServing-Summaryabout, KFServing, Reviewautoscaling via escape hatches, Escape hatches-Escape hatchescapabilities of, Additional featurescomparison chart, Model Inference in Kubeflowdata plane, Data Plane-Data Planedebugging InferenceService, Debugging an InferenceServicedebugging performance, Debugging performancedeployment strategies, Model updatingInferenceService debugging, Debugging an InferenceServiceInferenceService escape hatches, Escape hatches-Escape hatchesInferenceService namespace, Recommender exampleInferenceService recommender, Recommender example-Recommender exampleinfrastructure stack, Peeling Back the Underlying Infrastructuremodel monitoring, Model monitoringmodel serving, Model servingmodel updating, Model updatingnetwork monitoring and telemetry, Model monitoringserverless inferencing, KFServing, Recommender exampleservice plane, Serverless and the Service Planesetting up, Setting up KFServing-Setting up KFServingsetting up and namespaces, Setting up KFServingKubeflow, Model InferenceKubeflow model inference, Inference/Prediction, Model Inference in Kubeflowmodel monitoring, Model Monitoringaccuracy, drift, explainability, Model Accuracy, Drift, and ExplainabilityKFServing, Model monitoringrequirements, Model Monitoring RequirementsSeldon Core, Monitoring Your Models, Outlier and drift detection, Model monitoringTensorFlow Serving, Model monitoringmodel serving, Model Servingembedded, Model ServingKFServing, Model servingmodel serving as a service, Model Serving-Model ServingSeldon Core, Model servingTensorFlow Serving, Model servingmodel serving requirements, Model Serving Requirements-Model Serving Requirementsmodel updating, Model UpdatingKFServing, Model updatingrequirements, Model Updating RequirementsSeldon Core, Model updatingTensorFlow Serving, Model updatingSeldon Core, Seldon Core-Summaryabout, Seldon Corecomparison chart, Model Inference in Kubeflowdeployment, Creating a SeldonDeploymentexample graphs, Creating a SeldonDeployment-Creating a SeldonDeploymentexplaining the model, Model explainabilityincome predictor model, US Census income predictor model example-US Census income predictor model exampleinference graph, Seldon Coremodel serving, Model servingmodel updating, Model updatingmonitoring models, Monitoring Your Models, Outlier and drift detection, Model monitoringpackaging the model, Packaging your modelSeldonMessage, Serving Requestssentiment prediction model, Sentiment prediction model-Sentiment prediction modelserverless primitives lacking, KFServingserving requests, Serving Requestssetting up, Setting up Seldon Coretesting the model, Testing Your Model, Local testing with DockerTensorFlow recommender deploymentwith TensorFlow Serving, TensorFlow Serving-ReviewTensorFlow Serving, TensorFlow Serving-Reviewabout, TensorFlow Servingcomparison chart, Model Inference in Kubeflowmodel monitoring, Model monitoringmodel serving, Model servingmodel updating, Model updatingrecommendation system, TensorFlow Serving-Reviewserverless primitives lacking, KFServingTensorFlow Extended and, Distributed Toolingupdating models, Model UpdatingTensorFlow Serving, Model updatingmodel servingabout, Model Servingcustom applicationsabout, Using Model Serving in Applicationsbatch applications, Building Batch Applications Leveraging Model Serving-Building Batch Applications Leveraging Model Servingstreaming applications, Building Streaming Applications Leveraging 
Model Serving-Introducing Cloudflowembedded, Model ServingKFServing, Model servingmodel serving as a service, Model Serving-Model Servingmodel updating, Model UpdatingKFServing, Model updatingrequirements, Model Updating RequirementsSeldon Core, Model updatingTensorFlow Serving, Model updatingmonitoring, Model MonitoringKFServing, Model monitoringKnative serving project, Model Inferencerequirements, Model Monitoring Requirementsresources on, Model Monitoring RequirementsSeldon Core, Monitoring Your Models, Outlier and drift detection, Model monitoringTensorFlow Serving, Model monitoringrequirements, Model Serving Requirements-Model Serving RequirementsSeldon Core, Model servingTensorFlow Serving, Model servingmodel serving as a service (MaaS), Model Serving-Model Servingmodel training (see training)modelsabout the impact of, Your Responsibility as a Practitionercontinuous learning, Summary of Inference Requirementsevaluating competing, Model Updatingexplainability importance, Scikit-Learn TrainingSeldon Core, Model explainabilityexportingScikit-learn, Exporting ModelTensorFlow, TensorFlow Trainingmonitoring, Model MonitoringKFServing, Model monitoringKnative serving project, Model Inferencerequirements, Model Monitoring Requirementsresources on, Model Monitoring RequirementsSeldon Core, Monitoring Your Models, Outlier and drift detection, Model monitoringTensorFlow Serving, Model monitoringserving options, Model Inferenceupdating, Model UpdatingKFServing, Model updatingrequirements, Model Updating RequirementsSeldon Core, Model updatingTensorFlow Serving, Model updatingvalidation, Model Validation, Test Query, Model Accuracy, Drift, and ExplainabilityModified National Institute of Standards and Technology (see MNIST)monitoringabout, Model MonitoringKFServing, Model monitoringKnative serving project, Model Inferencemodel serving, Model Accuracy, Drift, and Explainabilityrequirements, Model Monitoring Requirementsresources on, Model Monitoring RequirementsSeldon Core, Monitoring Your Models, Outlier and drift detection, Model monitoringTensorFlow Serving, Model monitoringmulti-armed bandits, Model updatingmultiuser isolation, Kubeflow Multiuser Isolationmultiworker mirrored distributed training strategy, Distributed TrainingNnamespacesdeployment of Kubeflow, Creating Our First Kubeflow ProjectKFServingInferenceService, Recommender examplesetup, Setting up KFServingmanual profile creation, Getting Around the Central Dashboardprofile definition, Kubeflow Multiuser IsolationSeldon Core installation, Setting up Seldon CoreNAS (see neural architecture search)natural language processing (NLP), Why Containerize?neural architecture search (NAS)about, AutoML: An Overview, Neural Architecture SearchAutoML, AutoML: An OverviewDifferentiable Architecture Search, Neural Architecture SearchEfficient Neural Architecture Search, Neural Architecture Searchgeneration versus mutation methods, Neural Architecture SearchKubeflow Katib supporting, Neural Architecture Searchexample DARTS experiment, Neural Architecture Search-Neural Architecture Searchmodel manager, Neural Architecture Searchnotebooks (see Jupyter notebooks)Oobject storesdistributed object storage server, MinIO, Storing Data Between Steps(see also MinIO)using with Apache Spark, Saving the outputobservability automated by operators, Training Operatorsone-hot encoding in Scikit-learn, Data Preparationonline community for Kubeflow, Conclusion, Conclusiononline resources (see resources)orchestration controllers, Kubeflow Pipelines, Model InferencePparallelize for data fetching, Reading the input dataparameter server distributed training, Distributed Trainingpersistent volume storageabout, Storing Data Between Steps-Storing Data Between StepsApache Spark output, Saving the outputfilesystem/get_file component, Keeping your data quality: TensorFlow data validationlocal data preparation, Fetching the Datapinned deployments, Model UpdatingKFServing endpoints, Data Plane, Model updatingPods (Kubernetes)data stored by, Kubeflow Pipelinesdeployment of Kubeflow, Creating Our First Kubeflow Projectportability of KubeflowKubernetes foundation, Kubeflow’s Design and Core Components, Deploying a TensorFlow Training Jobobject storage and, Storing Data Between Stepsprediction (see model inference)product recommender (see recommendation systems)profilesautomatic creation, Kubeflow Multiuser Isolationdefinition, Kubeflow Multiuser Isolationmanual creation, Getting Around the Central Dashboardmultiuser isolation, Kubeflow Multiuser IsolationPythonApache Beam support of, TensorFlow ExtendedApache Sparkbasics, Spark operators in Kubeflowreading input data, Reading the input databuilding example pipelines, Building a Simple Pipeline in Python-Building a Simple Pipeline in PythoncamelCase function name bug, Building a Simple Pipeline in Pythonclient for Python-wrapped models, Python client for Python language wrapped modelsDSL compiler, Kubeflow PipelinesGPU resource marking, Building a Simple Pipeline in Python, Using an Entire Notebook as a Data Preparation 
Pipeline Stageinstalling, Setting up the Pipeline SDKKFServing API documentation, API documentationKubeflow ML Metadata, Kubeflow ML MetadataKubeflow native Spark operator, Spark operators in KubeflowKubernetes client, Building a Pipeline Using Existing Imageslibrary imports, Building a Simple Pipeline in Pythonlightweight Python functions, Building a Simple Pipeline in Python-Building a Simple Pipeline in PythonMNIST image script, Test QueryPandas and, Keeping your data quality: TensorFlow data validationpipeline components, Kubeflow Pipelinespipeline custom code and tools, Building a Pipeline Using Existing Images, Custom ContainersScikit-learn, Training a Model Using Scikit-LearnTensorFlow Extended as Python tool, TensorFlow Extendedvirtual environments for projects, Setting up the Pipeline SDKPyTorch for distributed training, Using Other Frameworks for Distributed Trainingjob spec example, Using Other Frameworks for Distributed TrainingQquality of data maintained, Keeping your data quality: TensorFlow data validationRRandom Forest algorithmabout, Training a Model Using Scikit-Learndata preparation, Data Preparation-Data Preparationrunning, Scikit-Learn Trainingrandom search in Katib, Katib Conceptsrecommendation systemsabout, Product Recommender, Building a Recommender with TensorFlowcollaborative filtering, Building a Recommender with TensorFlowKFServing InferenceService, Recommender example-Recommender exampleTensorFlowdeployment with TFServing, TensorFlow Serving-Reviewrepositoriescomponents, Kubeflow Multiuser Isolation, Kubeflow Pipeline ComponentsCOVID-19 CT scans, Data Prep with Pythonkfctl, Kubeflow Multiuser IsolationPipelines Service, Kubeflow Multiuser Isolationreproducibility in machine learning, Artifact and Metadata StoreResourceOp request validation, Spark operators in Kubeflowresources for Kubeflowalternatives, Othersclick-to-deploy Kubeflow app, Getting Set Up with Kubeflowcode examples for download, Code Examplescomponent repositories, Kubeflow Multiuser Isolation, Kubeflow Pipeline Componentsgetting started guide, Going Beyond a Local Deploymentinstallation guide, Creating Our First Kubeflow Projectonline community, Conclusion, ConclusionSscalability of KubeflowApache Spark feature preparation, Distributed Feature Preparation Using Apache Sparkinference component, Model InferenceKFServing for inferencing, KFServingautoscaling via escape hatches, Escape hatches-Escape hatchesKubernetes foundation, Kubeflow’s Design and Core Components, Going Beyond a Local Deployment, Deploying a TensorFlow Training Joboperators automating, Training Operatorsschemadata validation via TensorFlow Extended, Keeping your data quality: TensorFlow data validation, Keeping your data quality: TensorFlow data validation-Keeping your data quality: TensorFlow data validationinferred by TensorFlow Data Validation, Keeping your data quality: TensorFlow data validationinspecting, Keeping your data quality: TensorFlow data validationrejected records check, Keeping your data quality: TensorFlow data validationsaved to catch changes, Keeping your data quality: TensorFlow data validationtool for modifying, Keeping your data quality: TensorFlow data validationvalidation by Apache Spark, Validating the schemaScikit-learnabout, Training a Model Using Scikit-Learnexplaining the model, Scikit-Learn Training-Explaining the Modelexporting the model, Exporting Modellibrary, Putting It Together in a Pipelinemissing data and, Data Preparationone-hot encoding, Data PreparationRandomForestClassifier, Training and Monitoring Progress-Test QueryScikit-learn Jupyter notebook setup, Training a Model Using Scikit-Learn-Training a Model Using Scikit-LearnSeldon Core, Serving Requestsabout, Seldon Corecomparison chart, Model Inference in Kubeflowdeployment, Creating a SeldonDeploymentexample graphs, Creating a SeldonDeployment-Creating a SeldonDeploymentexplaining the model, Model explainabilityincome predictor model, US Census income predictor model example-US Census income predictor model exampleinference, Seldon Core-Summaryinference graph, Seldon CoreIstio ingress gateway and, Serving Requestsmodel serving, Model servingmodel updating, Model updatingmonitoring models, Monitoring Your Models, Outlier and drift detection, Model monitoringoutlier and drift detection in, Outlier and drift detectionpackaging the model, Packaging your modelSeldonMessage, Serving Requestssentiment prediction model, Sentiment prediction model-Sentiment prediction modelserverless primitives lacking, KFServingserving requests, Serving Requestssetting up, Setting up Seldon Coretesting the model, Testing Your Modellocal testing with Docker, Local testing with Dockersentiment prediction model, Sentiment prediction model-Sentiment prediction modelserverlessabout, Serverless and the Service Planecontainers on Kubernetes, Model InferenceKFServing, KFServing, Recommender example, Knative EventingKnative Serving, KFServingKnative serving and, Model Inferenceserverless applicationsKnative Serving, Knativeservice meshabout, Going layer by layercomponents, with Istio, Istiowith Istio, Going layer by layerservice plane, Serverless and the Service Planeshadow models, Model Updatingsingle-worker TensorFlow jobs, Distributed Trainingsingular value decomposition (SVD), Case Study Using Multiple Tools, DS-SVD with Apache SparkSpamAssassin package, Data Cleaning: Filtering Out the Junk, Putting It Together in a PipelineSQL in Apache Spark, Filtering out bad datastoragedistributed object storage server, MinIO, Storing Data Between StepsMinikube requirements, Minikubepersistent volumes, Storing Data Between Steps-Storing Data Between StepsApache Spark output, Saving the outputfilesystem/get_file component, Keeping your data quality: TensorFlow data validationlocal data preparation, Fetching the Datastorage classes, Storing Data Between Stepsstoring data between steps, Storing Data Between Steps-Storing Data Between StepsUI to explore, MinIOstreaming applicationsabout, Building Streaming Applications Leveraging 
Model ServingCloudflow, Introducing Cloudflow-Introducing Cloudflowprocessing engines versus libraries, Stream Processing Engines and Librariessuggestions (Kubeflow Katib), Katib ConceptsTtag for pushing containers, Setting up DockerTekton for running pipelines, Argo: the Foundation of PipelinesTensorFlowabout, Building a Recommender with TensorFlowdistributed trainingabout, Distributed Trainingdistribution strategies, Distributed TrainingMNIST example, Distributed Training-Distributed Trainingjobs as Kubernetes custom resources, Deploying a TensorFlow Training Jobrecommenderabout, Product Recommender, Building a Recommender with TensorFlowcreating TensorFlow session, TensorFlow Trainingdeployment, Deploying a TensorFlow Training Job-Deploying a TensorFlow Training Jobdeployment with TFServing, TensorFlow Serving-Reviewexporting model, TensorFlow Traininghyperparameters, TensorFlow TrainingKeras API, Building a Recommender with TensorFlowmodel selection, Building a Recommender with TensorFlownotebook setup, Building a Recommender with TensorFlow-Starting a New Notebook Sessionrunning training code, TensorFlow Trainingsingle-worker jobs, Distributed TrainingTensorFlow Data Validation (TFDV), Keeping your data quality: TensorFlow data validation-Keeping your data quality: TensorFlow data validationinstalling, Keeping your data quality: TensorFlow data validationschema inferred by, Keeping your data quality: TensorFlow data validationschema inspection, Keeping your data quality: TensorFlow data validationTensorFlow Extended (TFX)about, Distributed Tooling, TensorFlow ExtendedApache Beam Python support and, TensorFlow Extendedexample generators, Keeping your data quality: TensorFlow data validationGoogle Dataflow, Dataflow for TFXinstalling, Keeping your data quality: TensorFlow data validationinstalling components, Keeping your data quality: TensorFlow data validation, Keeping your data quality: TensorFlow data validationKubeflow pipelines and TFX pipelines, TensorFlow ExtendedML Metadata, Artifact and Metadata StorePandas dataframes accepted by, Keeping your data quality: TensorFlow data validationschema inferred by TFDV, Keeping your data quality: TensorFlow data validationTensorFlow Data Validation, Keeping your data quality: TensorFlow data validation-Keeping your data quality: TensorFlow data validationTransform feature preparation, TensorFlow Transform, with TensorFlow Extended on Beam-TensorFlow Transform, with TensorFlow Extended on BeamTensorFlow Model Analysis, TensorFlow Transform, with TensorFlow Extended on BeamTensorFlow Serving (TFServing)about, TensorFlow Servingbatch applications, Building Batch Applications Leveraging Model Servingcomparison chart, Model Inference in Kubeflowinference, TensorFlow Serving-Reviewmodel monitoring, Model monitoringmodel serving, Model servingmodel updating, Model updatingrecommendation system, TensorFlow Serving-Reviewserverless primitives lacking, KFServingTensorFlow Extended integrating with, Distributed ToolingTensorFlow Transform (TFT)feature preparation, TensorFlow Transform, with TensorFlow Extended on Beam-TensorFlow Transform, with TensorFlow Extended on BeamKubeflow support for, Data/Feature PreparationModel Analysis integration, TensorFlow Transform, with TensorFlow Extended on BeamtestingArgo installation, Argo: the Foundation of PipelinesDocker installation, Setting up Dockerfirst project test query, Test QuerySeldon Core inference model, Testing Your Modellocal testing with Docker, Local testing with DockerPython-wrapped models, Python client for Python language wrapped modelsTFJob for deploymentmultiworker distributed training, Distributed Trainingspecifications, Deploying a TensorFlow Training JobTensorFlow recommender, Deploying a TensorFlow Training Job-Deploying a TensorFlow Training JobTFServing (see TensorFlow Serving)TFX (see TensorFlow Extended)tfx/Transform component, TensorFlow Transform, with TensorFlow Extended on BeamTPU distributed training strategy, Distributed TrainingTPU-accelerated instances, TPU-Accelerated Instancestracking data and metadata, Kubeflow Pipelinestrainingabout, Training a Machine Learning Modeldeep learning, Building a Recommender with TensorFlowsharing a pipeline, Sharing the Pipelinedistributed trainingabout, Distributed Trainingdata versus model parallelism, Distributed TrainingGPUs for, Using GPUsKubeflow Katib, Tuning Distributed Training JobsMNIST example, Distributed Training-Distributed Trainingother frameworks for, Using Other Frameworks for Distributed Trainingfirst Kubeflow project, Training and Monitoring Progressframeworks supported, Trainingimpact of using more data, Data and Feature PreparationKubeflow components, Training Operatorsmodel selection, Building a Recommender with TensorFlowAutoML for, AutoML: An Overviewoperators, Training Operators, Integration into Pipelinespipeline integration, Integration into PipelinesScikit-learnabout, Training a Model Using Scikit-Learnabout Random Forest, Training a Model Using Scikit-Learndata preparation, Data Preparation-Data Preparationexplaining the model, Scikit-Learn Training-Explaining the Modelexporting the model, Exporting Modelrunning Random Forest, Scikit-Learn Trainingtraining with and evaluation, Scikit-Learn TrainingTensorFlow recommenderabout TensorFlow, Building a Recommender with TensorFlowcreating TensorFlow session, TensorFlow Trainingdeployment, Deploying a TensorFlow Training Job-Deploying a TensorFlow Training Jobdeployment with TFServing, TensorFlow Serving-Reviewexporting model, TensorFlow Traininghyperparameters, TensorFlow TrainingKeras API, Building a Recommender with TensorFlowmodel selection, Building a Recommender with TensorFlownotebook setup, Building a Recommender with TensorFlow-Starting a New Notebook Sessionrunning training code, TensorFlow Trainingsingle-worker jobs, Distributed Trainingtrials (Kubeflow Katib), Katib ConceptsUUS Census datasetabout dataset, Training a Model Using Scikit-Learnabout Random Forest, Training a Model Using Scikit-Learndata preparation, Data Preparation-Data Preparationexplaining the model, Scikit-Learn Training-Explaining the Modelexporting the model, Exporting Modelincome predictor model, US Census income predictor model example-US Census income predictor model exampletraining, Scikit-Learn Trainingtraining with and evaluation, Scikit-Learn Traininguser interfaces (UI)Argo UI, Argo: the Foundation of Pipelinesinstallation, Argo: the Foundation of Pipelinescentral dashboard, Getting Around the Central Dashboarddisplay_schema, Keeping your data quality: TensorFlow data validationinstallation of Kubeflow web UI, Training and Monitoring ProgressKatib, Katib User InterfaceKubeflow Pipelines UI, Exploring the Prepackaged Sample Pipelines, Building a Simple Pipeline in PythonMetadata UI, Kubeflow Metadata UIMinIO to explore storage, MinIOMLflow (Databricks), Using the MLflow UIuser of Kubeflow cluster, Kubeflow Multiuser IsolationVvalidation of dataApache Spark, Spark operators in Kubeflow-Distributed Feature Preparation Using Apache SparkTensorFlow Extended, Keeping your data quality: TensorFlow data validation-Keeping your data quality: TensorFlow data validationschema inferred, Keeping your data quality: TensorFlow data validationvalidation of modelsimportance of, Test QueryKubeflow support for, Model Validationmodel accuracy, Model Accuracy, Drift, and Explainabilityvirtual environments in Python, Setting up the Pipeline SDKWweb UI for Pipeline, Exploring the Prepackaged Sample Pipelines, Building a Simple Pipeline in PythonYYAMLcomponent options, Kubeflow Pipeline ComponentsDSL compiler producing, Kubeflow Pipelines, Exploring the Prepackaged Sample Pipelines, Building a Simple Pipeline in Pythonediting, Editing YAMLKafkaSource to send Knative events, Knative EventingKFServing InferenceService, Recommender exampleresource creation, Notebooks (JupyterHub)secrets for MinIO credentials, MinIOTensorFlow distributed training job, Distributed Training
hideTOCEQUATIONinline_EQEXAMPLEFIGURETABLEForewordPreface_Our Assumption About You_Your Responsibility as a Practitioner_Conventions Used in This Book_Code Examples__Using Code Examples_O’Reilly Online Learning_How to Contact the Authors_How to Contact Us_Acknowledgments_Grievances1.",,,
3081,Kubeflow: What It Is and Who It Is For_1.1.,,,
3082,Model Development Life Cycle_1.2.,,,
3083,Where Does Kubeflow Fit In?_1.3.,,,
3084,Why Containerize?_1.4.,,,
3085,Why Kubernetes?_1.5.,,,
3086,Kubeflow’s Design and Core Components__1.5.1.,,,
3087,Data Exploration with Notebooks__1.5.2.,,,
3088,Data/Feature Preparation__1.5.3.,,,
3089,Training__1.5.4.,,,
3090,Hyperparameter Tuning__1.5.5.,,,
3091,Model Validation__1.5.6.,,,
3092,Inference/Prediction__1.5.7.,,,
3093,Pipelines__1.5.8.,,,
3094,Component Overview_1.6.,,,
3095,Alternatives to Kubeflow__1.6.1.,,,
3096,Clipper (RiseLabs)__1.6.2.,,,
3097,MLflow (Databricks)__1.6.3.,,,
3098,Others_1.7.,,,
3099,Introducing Our Case Studies__1.7.1.,,,
3100,Modified National Institute of Standards and Technology__1.7.2.,,,
3101,Mailing List Data__1.7.3.,,,
3102,Product Recommender__1.7.4.,,,
3103,CT Scans_1.8.,,,
3104,Conclusion2.,,,
3105,Hello Kubeflow_2.1.,,,
3106,Getting Set Up with Kubeflow__2.1.1.,,,
3107,Installing Kubeflow and Its Dependencies__2.1.2.,,,
3108,Setting Up Local Kubernetes___2.1.2.1.,,,
3109,Minikube__2.1.3.,,,
3110,Setting Up Your Kubeflow Development Environment___2.1.3.1.,,,
3111,Setting up the Pipeline SDK___2.1.3.2.,,,
3112,Setting up Docker___2.1.3.3.,,,
3113,Editing YAML__2.1.4.,,,
3114,Creating Our First Kubeflow Project_2.2.,,,
3115,Training and Deploying a Model__2.2.1.,,,
3116,Training and Monitoring Progress__2.2.2.,,,
3117,Test Query_2.3.,,,
3118,Going Beyond a Local Deployment_2.4.,,,
3119,Conclusion3.,,,
3120,Kubeflow Design: Beyond the Basics_3.1.,,,
3121,Getting Around the Central Dashboard__3.1.1.,,,
3122,Notebooks (JupyterHub)__3.1.2.,,,
3123,Training Operators__3.1.3.,,,
3124,Kubeflow Pipelines__3.1.4.,,,
3125,Hyperparameter Tuning__3.1.5.,,,
3126,Model Inference__3.1.6.,,,
3127,Metadata__3.1.7.,,,
3128,Component Summary_3.2.,,,
3129,Support Components__3.2.1.,,,
3130,MinIO__3.2.2.,,,
3131,Istio__3.2.3.,,,
3132,Knative__3.2.4.,,,
3133,Apache Spark__3.2.5.,,,
3134,Kubeflow Multiuser Isolation_3.3.,,,
3135,Conclusion4.,,,
3136,Kubeflow Pipelines_4.1.,,,
3137,Getting Started with Pipelines__4.1.1.,,,
3138,Exploring the Prepackaged Sample Pipelines__4.1.2.,,,
3139,Building a Simple Pipeline in Python__4.1.3.,,,
3140,Storing Data Between Steps_4.2.,,,
3141,Introduction to Kubeflow Pipelines Components__4.2.1.,,,
3142,Argo: the Foundation of Pipelines__4.2.2.,,,
3143,What Kubeflow Pipelines Adds to Argo Workflow__4.2.3.,,,
3144,Building a Pipeline Using Existing Images__4.2.4.,,,
3145,Kubeflow Pipeline Components_4.3.,,,
3146,Advanced Topics in Pipelines__4.3.1.,,,
3147,Conditional Execution of Pipeline Stages__4.3.2.,,,
3148,Running Pipelines on Schedule_4.4.,,,
3149,Conclusion5.,,,
3150,Data and Feature Preparation_5.1.,,,
3151,Deciding on the Correct Tooling_5.2.,,,
3152,Local Data and Feature Preparation__5.2.1.,,,
3153,Fetching the Data__5.2.2.,,,
3154,Data Cleaning: Filtering Out the Junk__5.2.3.,,,
3155,Formatting the Data__5.2.4.,,,
3156,Feature Preparation__5.2.5.,,,
3157,Custom Containers_5.3.,,,
3158,Distributed Tooling__5.3.1.,,,
3159,TensorFlow Extended___5.3.1.1.,,,
3160,Keeping your data quality: TensorFlow data validation___5.3.1.2.,,,
3161,"TensorFlow Transform, with TensorFlow Extended on Beam__5.3.2.",,,
3162,Distributed Data Using Apache Spark___5.3.2.1.,,,
3163,Spark operators in Kubeflow___5.3.2.2.,,,
3164,Reading the input data___5.3.2.3.,,,
3165,Validating the schema___5.3.2.4.,,,
3166,Handling missing fields___5.3.2.5.,,,
3167,Filtering out bad data___5.3.2.6.,,,
3168,Saving the output__5.3.3.,,,
3169,Distributed Feature Preparation Using Apache Spark_5.4.,,,
3170,Putting It Together in a Pipeline_5.5.,,,
3171,"Using an Entire Notebook as a Data Preparation 
Pipeline Stage_5.6.",,,
3172,Conclusion6.,,,
3173,Artifact and Metadata Store_6.1.,,,
3174,Kubeflow ML Metadata__6.1.1.,,,
3175,Programmatic Query__6.1.2.,,,
3176,Kubeflow Metadata UI_6.2.,,,
3177,Using MLflow’s Metadata Tools with Kubeflow__6.2.1.,,,
3178,Creating and Deploying an MLflow Tracking Server__6.2.2.,,,
3179,Logging Data on Runs__6.2.3.,,,
3180,Using the MLflow UI_6.3.,,,
3181,Conclusion7.,,,
3182,Training a Machine Learning Model_7.1.,,,
3183,Building a Recommender with TensorFlow__7.1.1.,,,
3184,Getting Started__7.1.2.,,,
3185,Starting a New Notebook Session__7.1.3.,,,
3186,TensorFlow Training_7.2.,,,
3187,Deploying a TensorFlow Training Job_7.3.,,,
3188,Distributed Training__7.3.1.,,,
3189,Using GPUs__7.3.2.,,,
3190,Using Other Frameworks for Distributed Training_7.4.,,,
3191,Training a Model Using Scikit-Learn__7.4.1.,,,
3192,Starting a New Notebook Session__7.4.2.,,,
3193,Data Preparation__7.4.3.,,,
3194,Scikit-Learn Training__7.4.4.,,,
3195,Explaining the Model__7.4.5.,,,
3196,Exporting Model__7.4.6.,,,
3197,Integration into Pipelines_7.5.,,,
3198,Conclusion8.,,,
3199,Model Inference_8.1.,,,
3200,Model Serving__8.1.1.,,,
3201,Model Serving Requirements_8.2.,,,
3202,Model Monitoring__8.2.1.,,,
3203,"Model Accuracy, Drift, and Explainability__8.2.2.",,,
3204,Model Monitoring Requirements_8.3.,,,
3205,Model Updating__8.3.1.,,,
3206,Model Updating Requirements_8.4.,,,
3207,Summary of Inference Requirements_8.5.,,,
3208,Model Inference in Kubeflow_8.6.,,,
3209,TensorFlow Serving__8.6.1.,,,
3210,Review___8.6.1.1.,,,
3211,Model serving___8.6.1.2.,,,
3212,Model monitoring___8.6.1.3.,,,
3213,Model updating___8.6.1.4.,,,
3214,Summary_8.7.,,,
3215,Seldon Core__8.7.1.,,,
3216,Designing a Seldon Inference Graph___8.7.1.1.,,,
3217,Setting up Seldon Core___8.7.1.2.,,,
3218,Packaging your model___8.7.1.3.,,,
3219,Creating a SeldonDeployment__8.7.2.,,,
3220,Testing Your Model___8.7.2.1.,,,
3221,Python client for Python language wrapped models___8.7.2.2.,,,
3222,Local testing with Docker__8.7.3.,,,
3223,Serving Requests__8.7.4.,,,
3224,Monitoring Your Models___8.7.4.1.,,,
3225,Model explainability___8.7.4.2.,,,
3226,Sentiment prediction model___8.7.4.3.,,,
3227,US Census income predictor model example___8.7.4.4.,,,
3228,Outlier and drift detection__8.7.5.,,,
3229,Review___8.7.5.1.,,,
3230,Model serving___8.7.5.2.,,,
3231,Model monitoring___8.7.5.3.,,,
3232,Model updating___8.7.5.4.,,,
3233,Summary_8.8.,,,
3234,KFServing__8.8.1.,,,
3235,Serverless and the Service Plane__8.8.2.,,,
3236,Data Plane__8.8.3.,,,
3237,Example Walkthrough___8.8.3.1.,,,
3238,Setting up KFServing___8.8.3.2.,,,
3239,Simplicity and extensibility___8.8.3.3.,,,
3240,Recommender example__8.8.4.,,,
3241,Peeling Back the Underlying Infrastructure___8.8.4.1.,,,
3242,Going layer by layer___8.8.4.2.,,,
3243,Escape hatches___8.8.4.3.,,,
3244,Debugging an InferenceService___8.8.4.4.,,,
3245,Debugging performance___8.8.4.5.,,,
3246,Knative Eventing___8.8.4.6.,,,
3247,Additional features___8.8.4.7.,,,
3248,API documentation__8.8.5.,,,
3249,Review___8.8.5.1.,,,
3250,Model serving___8.8.5.2.,,,
3251,Model monitoring___8.8.5.3.,,,
3252,Model updating___8.8.5.4.,,,
3253,Summary_8.9.,,,
3254,Conclusion9.,,,
3255,Case Study Using Multiple Tools_9.1.,,,
3256,The Denoising CT Scans Example__9.1.1.,,,
3257,Data Prep with Python__9.1.2.,,,
3258,DS-SVD with Apache Spark__9.1.3.,,,
3259,Visualization___9.1.3.1.,,,
3260,Downloading DRMs___9.1.3.2.,,,
3261,Recomposing the matrix into denoised images__9.1.4.,,,
3262,The CT Scan Denoising Pipeline___9.1.4.1.,,,
3263,Spark operation manifest___9.1.4.2.,,,
3264,The pipeline_9.2.,,,
3265,Sharing the Pipeline_9.3.,,,
3266,Conclusion10.,,,
3267,"Hyperparameter Tuning and Automated 
Machine Learning_10.1.",,,
3268,AutoML: An Overview_10.2.,,,
3269,Hyperparameter Tuning with Kubeflow Katib_10.3.,,,
3270,Katib Concepts_10.4.,,,
3271,Installing Katib_10.5.,,,
3272,Running Your First Katib Experiment__10.5.1.,,,
3273,Prepping Your Training Code__10.5.2.,,,
3274,Configuring an Experiment__10.5.3.,,,
3275,Running the Experiment__10.5.4.,,,
3276,Katib User Interface_10.6.,,,
3277,Tuning Distributed Training Jobs_10.7.,,,
3278,Neural Architecture Search_10.8.,,,
3279,Advantages of Katib over Other Frameworks_10.9.,,,
3280,ConclusionA.,,,
3281,Argo Executor Configurations and Trade-OffsB.,,,
3282,Cloud-Specific Tools and Configuration_B.1.,,,
3283,Google Cloud__B.1.1.,,,
3284,TPU-Accelerated Instances__B.1.2.,,,
3285,Dataflow for TFXC.,,,
3286,Using Model Serving in Applications_C.1.,,,
3287,"Building Streaming Applications Leveraging 
Model Serving__C.1.1.",,,
3288,Stream Processing Engines and Libraries__C.1.2.,,,
3289,Introducing Cloudflow_C.2.,,,
3290,Building Batch Applications Leveraging Model ServingIndexExample 2-1.,,,
3291,Install kubectl with snapExample 2-2.,,,
3292,Install kubectl with HomebrewExample 2-3.,,,
3293,Install KubeflowExample 2-4.,,,
3294,Create a virtual environmentExample 2-5.,,,
3295,Install Kubeflow Pipeline SDKExample 2-6.,,,
3296,Clone the Kubeflow Pipelines repoExample 2-7.,,,
3297,Specify the new container is built on top of Kubeflow’s containerExample 2-8.,,,
3298,Build the new container and push to a registry for useExample 2-9.,,,
3299,Create first example projectExample 2-10.,,,
3300,Create training workflow exampleExample 2-11.,,,
3301,Model query exampleuntitled_programlisting_1untitled_programlisting_2Example 3-1.,,,
3302,Setting up port-forwardingExample 3-2.,,,
3303,Install MinIO on MacExample 3-3.,,,
3304,Install MinIO on LinuxExample 3-4.,,,
3305,Configure MinIO client to talk to Kubeflow’s MinIOExample 3-5.,,,
3306,Create a bucket with MinIOExample 3-6.,,,
3307,Sample MinIO secretuntitled_programlisting_3untitled_programlisting_4untitled_programlisting_5untitled_programlisting_6Example 4-1.,,,
3308,A simple Python functionExample 4-2.,,,
3309,A less-simple Python functionExample 4-3.,,,
3310,A simple pipelineuntitled_programlisting_7untitled_programlisting_8untitled_programlisting_9Example 4-4.,,,
3311,Mailing list data prepExample 4-5.,,,
3312,File output exampleExample 4-6.,,,
3313,Argo installationExample 4-7.,,,
3314,Listing Argo executionsExample 4-8.,,,
3315,Getting Argo execution detailsExample 4-9.,,,
3316,Getting the log of Argo executionExample 4-10.,,,
3317,Argo execution logExample 4-11.,,,
3318,Deleting Argo executionuntitled_programlisting_10Example 4-12.,,,
3319,Exporting Kubernetes clientExample 4-13.,,,
3320,Obtaining pipeline experimentExample 4-14.,,,
3321,Example recommender pipelineExample 4-15.,,,
3322,Pipeline releaseExample 4-16.,,,
3323,Load GCS download componentExample 4-17.,,,
3324,Loading pipeline storage component from relative path and web linkExample 4-18.,,,
3325,Importing required componentsExample 4-19.,,,
3326,Functions implementationExample 4-20.,,,
3327,Pipeline implementationExample 5-1.,,,
3328,Downloading the mailing list dataExample 5-2.,,,
3329,Data cleaningExample 5-3.,,,
3330,Installing SpamAssassinExample 5-4.,,,
3331,Writing and combining text-processing functions into featuresExample 5-5.,,,
3332,Installing TFX and TFDVExample 5-6.,,,
3333,Loading the componentsExample 5-7.,,,
3334,Download recommender dataExample 5-8.,,,
3335,Using CSV componentExample 5-9.,,,
3336,Creating the schemaExample 5-10.,,,
3337,Download the schema locallyExample 5-11.,,,
3338,Display the schemaExample 5-12.,,,
3339,Validating the dataExample 5-13.,,,
3340,TFT importsExample 5-14.,,,
3341,Creating the entry pointExample 5-15.,,,
3342,Compute the vocabularyExample 5-16.,,,
3343,Using the TFT componentExample 5-17.,,,
3344,Adding SparkExample 5-18.,,,
3345,Sample service definitionExample 5-19.,,,
3346,Installing requirements and copying the applicationExample 5-20.,,,
3347,Using the ResourceOp to launch a Spark jobExample 5-21.,,,
3348,Launching your Spark sessionExample 5-22.,,,
3349,Configuring your Spark sessionExample 5-23.,,,
3350,Installing Python 3.6 in Spark’s worker containerExample 5-24.,,,
3351,Configuring Spark to use MinIOExample 5-25.,,,
3352,Reading our data’s Parquet-formatted outputExample 5-26.,,,
3353,Specifying the schemaExample 5-27.,,,
3354,Dropping recordsExample 5-28.,,,
3355,Filtering out bad dataExample 5-29.,,,
3356,Using Spark SQLExample 5-30.,,,
3357,Saving to a persistent volumeExample 5-31.,,,
3358,Writing to ParquetExample 5-32.,,,
3359,Preparing features for the mailing listExample 5-33.,,,
3360,Putting the functions togetherExample 5-34.,,,
3361,Installing Scikit-learnExample 5-35.,,,
3362,Specifying a containerExample 5-36.,,,
3363,Using an entire notebook as data preparationExample 5-37.,,,
3364,Using RUN to add Python dependencies to the containerExample 6-1.,,,
3365,Required importsExample 6-2.,,,
3366,Define a workspaceExample 6-3.,,,
3367,Metadata exampleExample 6-4.,,,
3368,Another metadata exampleExample 6-5.,,,
3369,List all modelsExample 6-6.,,,
3370,Basic lineageExample 6-7.,,,
3371,Find the executionExample 6-8.,,,
3372,Getting all related eventsExample 6-9.,,,
3373,MLflow Tracking ServerExample 6-10.,,,
3374,MLflow startup scriptExample 6-11.,,,
3375,Installing MLflow server with HelmExample 6-12.,,,
3376,Install requiredExample 6-13.,,,
3377,Import required librariesExample 6-14.,,,
3378,Set environment variablesExample 6-15.,,,
3379,Create experimentExample 6-16.,,,
3380,Sample KNN modelExample 6-17.,,,
3381,Getting the runs for a given experimentExample 7-1.,,,
3382,Setting up prerequisitesExample 7-2.,,,
3383,Creating a TensorFlow sessionExample 7-3.,,,
3384,DeepCollaborativeFiltering learningExample 7-4.,,,
3385,Model creationExample 7-5.,,,
3386,Setting Training configurationExample 7-6.,,,
3387,Fitting modelExample 7-7.,,,
3388,Model training resultsExample 7-8.,,,
3389,Setting export destinationExample 7-9.,,,
3390,Exporting the modelExample 7-10.,,,
3391,TFJob Dockerfileuntitled_programlisting_11Example 7-11.,,,
3392,Single-container TFJob exampleExample 7-12.,,,
3393,Deploying TFJobExample 7-13.,,,
3394,Viewing the state of TFJobExample 7-14.,,,
3395,TF Recommender job descriptionExample 7-15.,,,
3396,Distributed TFJob exampleuntitled_programlisting_12untitled_programlisting_13Example 7-16.,,,
3397,TFJob execution resultExample 7-17.,,,
3398,TFJob with GPU exampleExample 7-18.,,,
3399,Pytorch Distributed Training ExampleExample 7-19.,,,
3400,Feature preparationExample 7-20.,,,
3401,Combining columns using column transformerExample 7-21.,,,
3402,Data transformerExample 7-22.,,,
3403,Using RandomForestClassifierExample 7-23.,,,
3404,Evaluating training resultsExample 7-24.,,,
3405,Training resultsExample 7-25.,,,
3406,Defining the tabular anchorExample 7-26.,,,
3407,Tabular anchorExample 7-27.,,,
3408,Prediction calculationExample 7-28.,,,
3409,Prediction calculation resultExample 7-29.,,,
3410,Model explanationExample 7-30.,,,
3411,Model explanation resultExample 7-31.,,,
3412,Model explanationExample 7-32.,,,
3413,Model explanation resultExample 7-33.,,,
3414,Exporting modeluntitled_programlisting_14Example 8-1.,,,
3415,Port-forwarding TFServing servicesuntitled_programlisting_15Example 8-2.,,,
3416,TFServing Recommender model version statusuntitled_programlisting_16Example 8-3.,,,
3417,Sending a request to your TFServing Recommender serviceExample 8-4.,,,
3418,Output from your TFServing Recommender serviceExample 8-5.,,,
3419,Helm install for a custom Seldon Core versionuntitled_programlisting_17Example 8-6.,,,
3420,Seldon Core Istio GatewayExample 8-7.,,,
3421,Simple Seldon Core prepackaged model serverExample 8-8.,,,
3422,Simple Seldon Core custom language wrapperExample 8-9.,,,
3423,Seldon Core Python model classuntitled_programlisting_18Example 8-10.,,,
3424,Sending a request to your Seldon Core custom microserviceExample 8-11.,,,
3425,Exposing Seldon Core microservice in a local Docker clientExample 8-12.,,,
3426,Sending a request to your local Seldon Core microserviceuntitled_programlisting_19Example 8-13.,,,
3427,SeldonMessage containing an ndarrayExample 8-14.,,,
3428,SeldonMessage containing JSON dataExample 8-15.,,,
3429,SeldonDeployment with Anchor ExplainersExample 8-16.,,,
3430,Sending a prediction request to your Seldon Core movie sentiment modelExample 8-17.,,,
3431,Prediction response from your Seldon Core movie sentiment modelExample 8-18.,,,
3432,Sending an explanation request to your Seldon Core movie sentiment modelExample 8-19.,,,
3433,Explanation response from your Seldon Core movie sentiment modelExample 8-20.,,,
3434,SeldonDeployment for income predictorExample 8-21.,,,
3435,Sending a prediction request to your Seldon Core income predictor modelExample 8-22.,,,
3436,Prediction response from your Seldon Core income predictor modelExample 8-23.,,,
3437,Sending a explanation request to your Seldon Core income predictor modelExample 8-24.,,,
3438,Explanation response from your Seldon Core income predictor modeluntitled_programlisting_20untitled_programlisting_21untitled_programlisting_22untitled_programlisting_23untitled_programlisting_24Example 8-25.,,,
3439,Simple sklearn KFServing InferenceServiceExample 8-26.,,,
3440,Simple TensorFlow KFServing InferenceServiceExample 8-27.,,,
3441,Simple PyTorch KFServing InferenceServiceExample 8-28.,,,
3442,Sophisticated Canary KFServing InferenceServiceExample 8-29.,,,
3443,KFServing-annotated MinIO secretExample 8-30.,,,
3444,Service Account with attached MinIO secretExample 8-31.,,,
3445,KFServing Recommender InferenceServiceuntitled_programlisting_25Example 8-32.,,,
3446,Sending a prediction request to your KFServing Recommender InferenceServiceuntitled_programlisting_26Example 8-33.,,,
3447,Custom target concurrency via annotations in KFServing InferenceServiceuntitled_programlisting_27Example 8-34.,,,
3448,KafkaSource that sends events to a KFServing Recommender InferenceServiceExample 9-1.,,,
3449,Lightweight Python function converts DICOMs to tensorsExample 9-2.,,,
3450,Decomposing a CT scan with Spark and MahoutExample 9-3.,,,
3451,Helper function to download a directory from GCSExample 9-4.,,,
3452,Helper function to read Mahout DRMs into NumPy matricesExample 9-5.,,,
3453,A loop to write several imagesExample 9-6.,,,
3454,Spark operation manifestExample 9-7.,,,
3455,CT scan denoising pipelineuntitled_programlisting_28untitled_programlisting_29untitled_programlisting_30untitled_programlisting_31untitled_programlisting_32untitled_programlisting_33Example 10-1.,,,
3456,Example experiment specuntitled_programlisting_34untitled_programlisting_35Example 10-2.,,,
3457,Example experiment outputExample 10-3.,,,
3458,Distributed training exampleExample 10-4.,,,
3459,Example NAS experiment specExample B-1.,,,
3460,Changing the pipeline to use DataflowFigure P-1.,,,
3461,Timbit the dogFigure P-2.,,,
3462,Tina the catFigure P-3.,,,
3463,Apache and MeowskaFigure 1-1.,,,
3464,Model development life cycleFigure 1-2.,,,
3465,Jupyter notebook running in KubeflowFigure 1-3.,,,
3466,A Kubeflow pipelineFigure 2-1.,,,
3467,Kubeflow web UIFigure 2-2.,,,
3468,Pipelines web UIFigure 2-3.,,,
3469,Pipeline detail pageFigure 2-4.,,,
3470,Handwritten 3Figure 3-1.,,,
3471,Kubeflow architectureFigure 3-2.,,,
3472,The central dashboardFigure 3-3.,,,
3473,Metadata diagramFigure 3-4.,,,
3474,MinIO dashboardFigure 3-5.,,,
3475,Istio architectureFigure 3-6.,,,
3476,Knative architectureFigure 4-1.,,,
3477,Kubeflow pipelines UI: prepackaged pipelinesFigure 4-2.,,,
3478,Kubeflow pipelines UI: pipeline graph viewFigure 4-3.,,,
3479,Kubeflow pipelines UI: pipeline viewFigure 4-4.,,,
3480,Pipeline executionFigure 4-5.,,,
3481,Argo UI for pipeline executionFigure 4-6.,,,
3482,Argo UI execution graphFigure 4-7.,,,
3483,Viewing Kubeflow pipelines in Argo UIFigure 4-8.,,,
3484,Execution of recommender pipelines exampleFigure 4-9.,,,
3485,Execution of conditional pipelines exampleFigure 4-10.,,,
3486,Viewing conditional pipeline logFigure 4-11.,,,
3487,Setting up periodic execution of a pipelineFigure 6-1.,,,
3488,Accessing Metadata UIFigure 6-2.,,,
3489,List of artifacts in the Artifact Store UIFigure 6-3.,,,
3490,Artifact viewFigure 6-4.,,,
3491,Overall architecture of MLflow components deploymentFigure 6-5.,,,
3492,MLflow main pageFigure 6-6.,,,
3493,View of the individual runFigure 6-7.,,,
3494,Run comparison viewFigure 6-8.,,,
3495,Run metrics comparison viewFigure 8-1.,,,
3496,TFServing architectureFigure 8-2.,,,
3497,Seldon inference graph exampleFigure 8-3.,,,
3498,Seldon graph examplesFigure 8-4.,,,
3499,Seldon explainer componentFigure 8-5.,,,
3500,Data science monitoring of models with Seldon Core and KnativeFigure 8-6.,,,
3501,KFServing data planeFigure 8-7.,,,
3502,KFServing infrastructure stackFigure 8-8.,,,
3503,KFServing request flowFigure 9-1.,,,
3504,Original slice of DICOMFigure 9-2.,,,
3505,1% denoised DICOM slice (left), 5% denoised DICOM slice (right)Figure 9-3.,,
3506,10% denoised DICOM slice (left), .5% denoised DICOM slice (right)Figure 10-1.,,
3507,Katib system workflowFigure 10-2.,,,
3508,Katib UI main pageFigure 10-3.,,,
3509,"Configuring a new experiment, part 1Figure 10-4.",,,
3510,"Configuring a new experiment, part 2Figure 10-5.",,,
3511,Katib UI for an experimentFigure 10-6.,,,
3512,Katib metrics for an experimentFigure 10-7.,,,
3513,Metrics for each trialFigure C-1.,,,
3514,Cloudflow architectureFigure C-2.,,,
3515,Dynamically controlled stream patternFigure C-3.,,,
3516,Using stream processing for batch serving implementationTable 3-1.,,,
3517,Examples of ML Metadata operationsTable 6-1.,,,
3518,List of modelsuntitled_table_1Table 6-2.,,,
3519,Query result as a tableTable 8-1.,,,
3520,Comparing embedded with MaaSTable 8-2.,,,
3521,Comparing different model inference approachesTable 8-3.,,,
3522,KFServing V1 data planeTable A-1.,,,
3523,Argo and Kubernetes APIs,,,
